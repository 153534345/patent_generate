标题title
一种基于深度学习的大视角喉镜
摘要abst
本发明公开了一种基于深度学习的大视角喉镜，包括微镜头成像组件用于获取图像数据；所述微镜头成像组件包括视场不重叠至少两组小口径微镜头；柔性传像组件与微镜头成像组件连接，用于传输图像数据；图像处理模块，连接于柔性传像组件另一端，所述图像处理模块根据微镜头成像组件获得的图像数据，通过使用生成对抗神经网络训练以获得图像融合模型，所述图像融合模型将训练输出的结果重新拼接为消除了不重叠视场图像之间缝隙的完整图像；显示组件用于显示完整图像。本发明的技术方案基于柔性传像和人工智能图像融合技术，在单次拍摄中对超大视角的场景进行高分辨率成像的能力，通过显示屏观测经由智能图像融合算法重建的超大视场图像。
权利要求书clms
1.一种基于深度学习的大视角喉镜，其特征在于，包括：微镜头成像组件，用于获取图像数据；所述微镜头成像组件包括视场不重叠至少两组小口径微镜头；柔性传像组件，与微镜头成像组件连接，用于传输图像数据；为末端外圈直径小于1.6mm、数量为1-6条的柔性传像束；图像处理模块，连接于柔性传像组件另一端，所述图像处理模块根据微镜头成像组件获得的图像数据，通过使用生成对抗神经网络训练以获得图像融合模型，所述图像融合模型将训练输出的结果重新拼接为消除了不重叠视场图像之间缝隙的完整图像；以及显示组件，与图像处理模块连接，用于显示所述图像处理模块重新拼接的完整图像；所述生成对抗神经网络包含生成器G和判别器D两部分，其训练过程为：S1、获取训练数据；S2、搭建生成器神经网络和判别器神经网络；S3、生成器和判别器对抗训练，获得图像融合模型。2.根据权利要求1所述的基于深度学习的大视角喉镜，其特征在于，步骤S1中，所述训练数据的获取步骤为：S11、针对相同条件下的喉部静态样本，微镜头成像组件沿镜头分布平面移动，连续采集至少10张包含缝隙的系列图像，相邻图像重叠区域不小于单张图像面积的50%；S12、以其中一张包含缝隙的图像为基准，将该图像不重叠地切分成256×256像素的图像小块，对每个图像小块采用尺度不变特征变换，并与系列图像中的其他图像分别进行特征匹配，在每张图像中获取与之匹配的图像小块区域；S13、将该图像小块和与之匹配的图像小块区域进行分析：如果都含有缝隙则舍弃；如果均不含缝隙则将其中任意一个作为生成对抗神经网络的条件x输入，另一个作为真值y；否则将含有缝隙的图像小块作为条件x输入，不含缝隙的图像小块作为真值y；从而获得成对的图像块输入作为训练数据。3.根据权利要求2所述的基于深度学习的大视角喉镜，其特征在于，图像小块是否含有缝隙的判别标准为：具有超过50个亮度值为0的点的图像小块为含缝隙的图像；否则判别为不含缝隙的图像。4.根据权利要求1所述的基于深度学习的大视角喉镜，其特征在于，步骤S2中，生成器G采用具有编码器/解码器结构的U型对称网络结构，编码器部分的每一层特征图的尺寸减半，解码器的每一层尺寸翻倍；每一层的滤波器数量在编码器部分逐层变为原来的两倍，而在解码器部分减半。5.根据权利要求4所述的基于深度学习的大视角喉镜，其特征在于，生成器G的第一层滤波器数量为64，编码器和解码器各有7层。6.根据权利要求1所述的基于深度学习的大视角喉镜，其特征在于，步骤S2中，判别器D采用全卷积形式，共有4层，每一层特征图的尺寸减半，数量加倍，最终对矩阵求平均值，得到的数值代表对图像结果是否是真值的概率判断。7.根据权利要求1所述的基于深度学习的大视角喉镜，其特征在于，步骤S3的训练过程中，对于生成器G和与之对应的判别器D，对抗神经网络的损失函数表达为：其中和/＞表示在全体数据下的均值，z为生成器G的噪声输入，x为该对抗网络的条件输入，y为该对抗网络训练的真值输入；预测值与真实值之间的L1范数误差的损失函数表达式为：该对抗网络训练的目标函数公式为：式中，λ为两种损失的权重，λ设置为100。
说明书desc
技术领域本发明涉及喉镜技术领域，具体涉及一种基于深度学习的大视角喉镜。背景技术对喉部的检查是医学诊断领域的重点问题。由于喉部位置较深且结构复杂，一般情况下难以直接目视探测，因此一般需要借助视频探测设备进行高动态、高空间分辨率的成像及观察。视频喉镜是喉部检查设备中一类应用广泛的代表。对于困难的气管插管过程，视频喉镜通过图像传感器采集喉部影像，通过视频传输线在显示屏进行实时显示。它一方面超越了普通喉镜中人眼的视野范围，另一方面视频喉镜的镜片无需将喉部结构进行移动，因而对病人的痛苦较轻，同时由于其符合人体喉部的解剖结构，因而降低了气管插管的难度，具有上手快、采集方便、成功率高、声门显露情况改善等优点。常用的视频喉镜结构中的成像模块一般以摄像手柄和主机的协同方式进行，即摄像手柄中包含一套镜头和图像传感器单元以用于对镜头对应的视场进行高速成像，此外还包含光源用于在喉部内较暗环境下的照明。这类方法中，视频喉镜的观测效果主要取决于采用的镜头和传感器的视场大小、空间分辨率以及成像信噪比等因素，同时，具有一定的操作局限性。一方面，由于摄像系统的视场角大小固定，在需要改变或移动视野时，需要对摄像系统进行机械移动，以寻找所需的结构。这既提高了操作难度，又提高了成像的时间成本。另一方面，由于喉部结构较细，所采用的镜头和图像传感器一般体积较小，空间分辨率较低，无法提供更高的成像精度以进行更细尺度的喉部观测。为此，已经有采用多个镜头实现内窥观测的方法被提出，但是传统的图像融合方法需要在相邻视场之间保留一部分重叠区域，无法最大化提升成像视场角度。因此，目前通用的视频喉镜技术仅采用了传统的成像技术，结合多个镜头实现的内窥方法也没有利用深度学习等人工智能方法在学习和生成新特征方面的优势，因此很难在保持目前体积小、高实时性、操作方便等优点的同时，在单次拍摄中无需机械移动，最大限度采集超大视角、高空间分辨率的大规模喉部图像。发明内容本发明的目的是提供一种基于深度学习的大视角喉镜，将利用微镜头序列拍摄的局部图像自动导入计算机并进行融合显示，无需任何昂贵的附加设备，同时保持了通用的视频喉镜固有的全部优势。本发明为达到上述目的，具体通过以下技术方案得以实现的：一种基于深度学习的大视角喉镜，包括：微镜头成像组件，用于获取图像数据；所述微镜头成像组件包括视场不重叠至少两组小口径微镜头；柔性传像组件，与微镜头成像组件连接，用于传输图像数据；为末端外圈直径小于1.6mm、数量为1-6条的柔性传像束；图像处理模块，连接于柔性传像组件另一端，所述图像处理模块根据微镜头成像组件获得的图像数据，通过使用生成对抗神经网络训练以获得图像融合模型，所述图像融合模型将训练输出的结果重新拼接为消除了不重叠视场图像之间缝隙的完整图像；以及显示组件，与图像处理模块连接，用于显示所述图像处理模块重新拼接的完整图像；所述生成对抗神经网络包含生成器G和鉴别器D两部分，其训练过程为：S1、获取训练数据；S2、搭建生成器神经网络和判别器神经网络；S3、生成器和判别器对抗训练，获得图像融合模型。进一步地，步骤S1中，所述训练数据的获取步骤为：S11、针对相同条件下的喉部静态样本，微镜头成像组件沿镜头分布平面移动，连续采集至少10张包含缝隙的系列图像，相邻图像重叠区域不小于单张图像面积的50%；S12、以其中一张包含缝隙的图像为基准，将该图像不重叠地切分成256×256像素的图像小块，对每个图像小块采用尺度不变特征变换，并与系列图像中的其他图像分别进行特征匹配，在每张图像中获取与之匹配的图像小块区域；S13、将该图像小块和与之匹配的图像小块区域进行分析：如果都含有缝隙则舍弃；如果均不含缝隙则将其中任意一个作为生成对抗神经网络的条件x输入，另一个作为真值y；否则将含有缝隙的图像小块作为条件x输入，不含缝隙的图像小块作为真值y；从而获得成对的图像块输入作为训练数据。进一步地，图像小块是否含有缝隙的判别标准为：具有超过50个亮度值为0的点的图像小块为含缝隙的图像；否则判别为不含缝隙的图像。进一步地，步骤S2中，生成器G采用具有编码器/解码器结构的U型对称网络结构，编码器部分的每一层特征图的尺寸减半，解码器的每一层尺寸翻倍；每一层的滤波器数量在编码器部分逐层变为原来的两倍，而在解码器部分减半。进一步地，生成器G的第一层滤波器数量为64，编码器和解码器各有7层。进一步地，步骤S2中，判别器D采用全卷积形式，共有4层，每一层特征图的尺寸减半，数量加倍，最终对矩阵求平均值，得到的数值代表对图像结果是否是真值的概率判断。进一步地，步骤S3的训练过程中，对于生成器G和与之对应的判别器D，对抗神经网络的损失函数表达为：其中和/＞表示在全体数据下的均值，z为生成器G的噪声输入，x为该对抗网络的条件输入，y为该对抗网络训练的真值输入；预测值与真实值之间的L1范数误差的损失函数表达式为：该对抗网络训练的目标函数公式为：式中，λ为两种损失的权重，λ设置为100。本发明的技术方案基于柔性传像和人工智能图像融合技术，将外置的图像传感器连接至柔性导像装置的末尾以中继微镜头序列采集的局部图像，并进行常规的喉镜检查，在单次拍摄中对超大视角的场景进行高分辨率成像的能力，通过显示屏观测经由智能图像融合算法重建的超大视场图像，从而提高视频喉镜的探测范围和成像精度，从而在视频喉镜诊断领域具有重要的意义。本技术的优势还包括：本技术仅需对传统视频喉镜进行低成本的改装，保持了其操作方便、轻量级等优点；通过本技术获得的喉部图像具有显著提高的视野范围和空间分辨率，一方面，由于采用了高空间分辨率和像素数的体外图像传感器，因而可以在不同的区域同步记录多个视角的喉部图像，因此适用于实时视频成像；另一方面，区别于传统图像融合需要保留相邻视野之间的重叠区域，本方法通过快速的深度学习算法处理，无需保留重叠区域，从而进一步有效提高了系统的成像通量，有效避免了对时间或空间分辨率的牺牲；本发明可应用在除喉镜体外的其它体内探测领域，仅需根据实际情况对所采取的微镜头序列、图像传感器和人工智能算法参数进行调整，即可在广泛的临床场景中进行应用。附图说明图1为本发明的整体结构示意图；图2为本发明中的图像融合模型的生成流程图；图3为本发明中生成对抗神经网络的架构图。图中，1-微镜头成像组件；2-柔性传像组件；3-图像处理模块；4-显示组件。具体实施方式以下结合附图及实施例对本发明作进一步详细说明。如图1所示，本发明的一种基于深度学习的大视角喉镜，包括微镜头成像组件1，用于获取图像数据；所述微镜头成像组件包括视场不重叠至少两组小口径微镜头；柔性传像组件2，与微镜头成像组件1连接，用于传输图像数据；为末端外圈直径小于1.6mm、数量为1-6条的柔性传像束；图像处理模块3，连接于柔性传像组件2另一端，所述图像处理模块3根据微镜头成像组件1获得的图像数据，通过使用生成对抗神经网络训练以获得图像融合模型，所述图像融合模型将训练输出的结果重新拼接为消除了不重叠视场图像之间缝隙的完整图像；以及显示组件4，与图像处理模块3连接，用于显示所述图像处理模块3重新拼接的完整图像。本发明通过将传统视频喉镜中镜片内部的单个镜头替换为具有不同朝向的微镜头组以扩大成像视场角。在保留与原有的镜头朝向相同的方向外，增设以原有方向为对称轴前后对称的若干个镜头，并与原有镜头的方向的夹角呈等差数列分布，同时确保相邻镜头的视场范围不重叠，以尽量扩大视场范围，将镜头相对位置进行固定。如图1所示，在一个优选实施例中，微镜头成像组件1采用三组小口径微镜头，小口径镜头采用日本住田光学玻璃公司生产的适合应用于医疗内窥镜的小口径镜头模组1/18 SEL120-015，其水平视场角约为62.8°。在相邻镜头的视场不重叠时，3个相邻的镜头产生的成像等效视场角至少为188.4°。将喉镜片前端进行相应的透明镜片覆盖后。该步骤中镜头的数量和位置关系亦可根据实际需求进行增减，但镜头尺寸的选型应主要考虑喉镜前端的尺寸不宜过大。一个可能的实施例为，对于张口度10mm以上的病人，不宜选择长度超过3mm的微镜头。微镜头组的排布可根据实际情况进行调整，包括对于是否重叠、对称性等要求亦可调整。采用微镜头组的目的是产生更大的视场角，基于该目的，所采用的微镜头组型号亦可根据需求进行调整。例如，采用性能更好的图像融合算法，可以降低对镜头质量的要求；如果采用较大规模的镜头，可能会产生较大的边缘畸变，此时可适当使相邻区域成像具有一定的重叠，以获得更优的图像融合性能。对于柔性传像组件2，本发明通过采用可弯曲、轻便、使用寿命长的玻璃光纤束将微镜头组的成像结果导出至体外，避免将大规模传感器集成至喉镜前端的困难。与上述实施例对应的一个具体的实施例是，采用3个德国肖特公司生产的外径为1.2mm的柔性传像束，分别与微镜头成像组件1的3个微镜头连接。其中，3个微镜头的对称性确保了传像束传像距离在理论上一致。将3条柔性传像束紧密加固并集成至喉镜内部以导出至体外，将传像束的另一侧分别固定在高分辨率传感器的不同区域，而传感器的图像经过后续处理通过配套软件实时显示在屏幕上。镜头数量与采用的柔性传像束的数量保持一致，其上限应主要考虑喉镜前端的尺寸不宜过大。一个可能的实例为，对于张口度10mm以上的病人，由于采用的外径为1.2mm的柔性传像束的近端套圈直径约为1.6mm，因此至多采用5-6条传像束与对应数量的微镜头搭配使用。柔性传像组件2所采用的传像设备理论上也可以替代为光纤面板等其他任何传像装置，只要具备尺寸类似、可弯曲、易于与镜头连接、成像损失低等必需性质即可。在基于深度学习的大视角图像融合部分，由于本发明的图像处理方法首先将采集到的各张无重叠区域的子图像按照微镜头组的空间位置关系放置到一张空白图像的不同位置，因此该图像理论上包含若干条由于图像不重叠而产生的缝隙。缝隙区域不属于任意子图像，且亮度值为0。在这种情况下，完成对缝隙的消除，即实现了图像的融合。具体而言，本发明参考采用生成对抗网络本身对目标信号的学习和高鲁棒性的特质，因而提出了一种基于条件GAN的深度神经网络。该算法采用监督学习的思路，在执行前首先应进行深度神经网络模型的训练。大视角图像融合部分，所采用的人工智能算法在理论上可能替代为其他的神经网络结构，参数亦可根据实际情况进行调整。如图2和图3所示，本发明中所述生成对抗神经网络包含生成器G和鉴别器D两部分，其训练过程为：S1、获取训练数据；S2、搭建生成器神经网络和判别器神经网络；S3、生成器和判别器对抗训练，获得图像融合模型。具体实施例中，生成对抗神经网络的训练过程的步骤S1中，训练数据的获取步骤为：S11、针对相同条件下的喉部静态样本，微镜头成像组件沿镜头分布平面移动，连续采集至少10张包含缝隙的系列图像，相邻图像重叠区域不小于单张图像面积的50%；柔性传像组件1的3个微镜头一次拍摄的图像为一张，由于相邻镜头市场不重叠，则一张图像中必然包含缝隙；相邻图像重叠区域不小于单张图像面积的50%才能保证图像处理中在匹配图像小块时，能够匹配充分获得足够的成对的训练数据；为保证足够的训练数据，包含缝隙的系列图像更优选为至少20张；S12、以其中一张包含缝隙的图像为基准，将该图像不重叠地切分成256×256像素的图像小块，对每个图像小块采用尺度不变特征变换，并与系列图像中的其他图像分别进行特征匹配，在每张图像中获取与之匹配的图像小块区域；S13、将该图像小块和与之匹配的图像小块区域进行分析：如果都含有缝隙则舍弃；如果均不含缝隙则将其中任意一个作为生成对抗神经网络的条件x输入，另一个作为真值y；否则将含有缝隙的图像小块作为条件x输入，不含缝隙的图像小块作为真值y；从而获得成对的图像块输入作为训练数据。优选的，图像小块是否含有缝隙的判别标准为：具有超过50个亮度值为0的点的图像小块为含缝隙的图像；否则判别为不含缝隙的图像。优选的，步骤S2中，生成器G采用具有编码器/解码器结构的U型对称网络结构，编码器部分的每一层特征图的尺寸减半，解码器的每一层尺寸翻倍；每一层的滤波器数量在编码器部分逐层变为原来的两倍，而在解码器部分减半。优选的，生成器G的第一层滤波器数量为64，编码器和解码器各有7层。优选的，步骤S2中，判别器D采用全卷积形式，共有4层，每一层特征图的尺寸减半，数量加倍，最终对矩阵求平均值，得到的数值代表对图像结果是否是真值的概率判断。优选的，步骤S3的训练过程中，对于生成器G和与之对应的判别器D，对抗神经网络的损失函数表达为：其中和/＞表示在全体数据下的均值，z为生成器G的噪声输入，x为该对抗网络的条件输入，y为该对抗网络训练的真值输入；预测值与真实值之间的L1范数误差的损失函数表达式为：该对抗网络训练的目标函数公式为：式中，λ为两种损失的权重，λ设置为100。λ参数起到调节两种损失大小的作用，本发明中设置为100。本发明的深度学习程序由Tensorflow来实现，采用Adam 优化器，初始学习率设定为0.0002。对于每个样本，训练集的大小为10000。在单个NVIDIA GeForce RTX 2080 Ti GPU上训练400次后获得了训练模型。在实施例中，对微镜头成像组件1的微镜头组采集到的实时图像不重叠地切分成256×256像素的图像小块，分别输入至本方法提出的经过训练后的深度神经网络模型中，将生成器输出的结果G重新拼接为完整的图像，显示到屏幕上。该融合算法执行时间小于1秒，满足实时性要求。本发明中的具体实施例仅仅是对本发明的解释，其并不是对本发明的限制，本领域技术人员在阅读完本说明书后可以根据需要对本实施例做出没有创造性贡献的修改，但只要在本发明的权利要求范围内都受到专利法的保护。
