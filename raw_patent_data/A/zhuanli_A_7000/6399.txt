标题title
智能假肢系统及控制方法
摘要abst
本发明涉及一种智能假肢系统及其控制方法，包括假肢手、RGB和Depth数据采集装置、物体和假肢手感知模块、假肢手动作预测模块和控制器，物体和假肢手感知模块获取物体的点云信息和假肢手腕部的6D姿态；所述假肢手动作预测模块根据物体的点云信息、假肢手腕部的6D姿态和假肢手关节状态J，预测假肢手动作梯度αp，根据假肢手动作梯度、物体的点云信息、假肢手关节状态J、假肢手腕部最近n步的6D姿态轨迹，预测假肢手动作梯度的幅度αs和残差αr；所述控制器根据假肢手动作预测模块的预测结果，控制假肢手对物体进行抓取。本发明可使假肢手对物体抓取控制更加灵巧、可靠。
权利要求书clms
1.一种智能假肢系统，其特征在于，包括：假肢手，所述假肢手用于执行对物体抓取；RGB和Depth数据采集装置，所述RGB和Depth数据采集装置用于获取环境和假肢手的视觉信息；物体感知模块和假肢手感知模块，所述物体感知模块用于根据环境视觉信息感知物体的点云信息，所述假肢手感知模块用于根据假肢手视觉信息估计假肢手腕部的6D姿态；假肢手动作预测模块，所述假肢手动作预测模块包括动作梯度预测模块和动作幅度与残差预测模块，所述动作梯度预测模块用于根据物体的点云信息、假肢手腕部的6D姿态和假肢手关节状态J，预测假肢手动作梯度αp，所述动作幅度与残差预测模块用于根据假肢手动作梯度、物体的点云信息、假肢手关节状态J、假肢手腕部最近n 步的6D姿态轨迹，预测假肢手动作梯度的幅度αs和残差αr；控制器，所述控制器根据假肢手动作预测模块的预测结果，控制假肢手对物体进行抓取。2.根据权利要求1所述的智能假肢系统，其特征在于：假肢手动作预测模块中，将假肢手关节动作梯度αp与幅度αs和残差αr相结合得到当前假肢手各关节的相对运动角度αt ,式中，⊙为哈达玛积。3.根据权利要求2所述的智能假肢系统，其特征在于：包括假肢手动作执行模块，假肢手执行模块将当前各关节的相对运动角度αt和当前假肢手关节状态Jt结合得到当前目标关节状态Jtargett，Jtargett=Jt+αt ，将当前目标关节状态Jtargett 输入至控制器。4.根据权利要求1所述的智能假肢系统，其特征在于：动作梯度预测模块通过扩散模型预测假肢手动作梯度αp ；动作幅度与残差预测模块通过强化学习模型预测假肢手动作梯度的幅度αs和残差αr。5.根据权利要求1所述的智能假肢系统，其特征在于：RGB和Depth数据采集装置采用RGB-D相机；物体感知模块基于RGB-D相机采集抓取初始化时的场景点云信息，通过点云分割模型分割场景点云，得到物体的部分点云数据。6.根据权利要求1所述的智能假肢系统，其特征在于：假肢手感知模块通过姿态预测网络实时估计假肢手腕部的6D姿态b= 其中bp为假肢手腕部的三维坐标， bq为假肢手腕部的四元数。7.根据权利要求3所述的智能假肢系统，其特征在于：假肢手动作预测模块的学习在仿真环境中进行，基于假肢手模型和多样的物体模型使用抓取位姿生成算法生成不同物体不同区域的抓取姿态数据集，用于学习动作梯度预测模块；基于真实人类抓取时腕部的轨迹数据生成轨迹模式数据集，基于抓取姿态数据集和轨迹模式数据集，用于学习假肢手动作幅度与残差模块。8.根据权利要求7所述的智能假肢系统，其特征在于：训练假肢手动作幅度与残差模块过程中的奖励函数设置如下，其中I为指示函数，即抓取成功，值为1，抓取失败时，值为0；△h为物体抓取后的高度与抓取前高度的差值。9.根据权利要求2所述的智能假肢系统，其特征在于：当检测到假肢手关节扭矩大于设定阈值时，则将对应关节的相对运动角度αt设为0。10.一种利用权利要求1至9任何一项所述智能假肢系统的控制方法，其特征在于，包括如下步骤：步骤1：RGB和Depth数据采集装置获取环境和假肢手的视觉信息；步骤2：物体感知模块根据环境视觉信息感知物体的点云信息，假肢手感知模块用于根据假肢手视觉信息估计假肢手腕部的6D姿态；步骤3：动作梯度预测模块根据物体的点云信息、假肢手腕部的6D姿态和当前假肢手关节状态J，预测假肢手动作梯度αp，假肢手关节状态J实时通过控制器从假肢手获得；动作幅度与残差预测模块根据假肢手动作梯度、物体的点云信息、当前假肢手关节状态J、假肢手腕部最近n 步的6D姿态轨迹，预测假肢手动作梯度的幅度αs和残差αr；步骤4：控制器根据假肢手动作预测模块的预测结果，控制假肢手对物体进行抓取。
说明书desc
技术领域本发明涉及假肢手，尤其是一种智能假肢系统及其控制方法。背景技术人类与各种物体的交互依赖于人手独特的形态结构，然而上肢残障人士由于手部的缺失，对工作、社交尤其是日常生活造成了较大的影响。假肢手常用于辅助上肢残障人士更好的进行生活。传统假肢手控制方式通过检测人体的肌肉电信号 或脑电信号 ,直接映射到预定义的假肢自由度，但该类方法实际效果受到电极移动、肌肉疲劳等多方面因素的影响，控制鲁棒性往往不高，适应性差。除此之外，该方法需要用户显示的去控制实现各种功能，对人类的认知负担较大。为了解决上述问题，研究者开始结合其他模态的输入，如RGB，Depth 等信息来使得假肢手更智能化。该类方法通常首先采集物体的 RGB，Depth 等数据，标注预定义的抓取位姿，再基于深度学习的方法训练神经网络来预测物体的抓取位姿，并通过人体电信号来判断抓取位姿是否满足人类要求，是否执行抓取等。现有抓取位姿通常只考虑抓取位姿与物体是一一映射的，无法实现多样化的抓取，即对于相同的物体，抓取位姿需要随着假肢手移动的轨迹进行调整，进而抓取物体的特定区域，方便人类后续执行其他操作。发明内容本发明的发明目的在于提供一种智能假肢系统及控制方法，假肢手对物体抓取控制更加灵巧、可靠。基于同一发明构思，本发明具有两个独立的技术方案：1、一种智能假肢系统，其包括：假肢手，所述假肢手用于执行对物体抓取；RGB和Depth数据采集装置，所述RGB和Depth数据采集装置用于获取环境和假肢手的视觉信息；物体和假肢手感知模块，所述物体感知模块用于根据环境视觉信息感知物体的点云信息，所述假肢手感知模块用于根据假肢手视觉信息估计假肢手腕部的6D姿态；假肢手动作预测模块，所述假肢手动作预测模块包括动作梯度预测模块和动作幅度与残差预测模块，所述动作梯度预测模块用于根据物体的点云信息、假肢手腕部的6D姿态和假肢手关节状态J，预测假肢手动作梯度αp，所述动作幅度与残差预测模块用于根据假肢手动作梯度、物体的点云信息、假肢手关节状态J、假肢手腕部最近n步的6D姿态轨迹，预测假肢手动作梯度的幅度αs和残差αr；控制器，所述控制器根据假肢手动作预测模块的预测结果，控制假肢手对物体进行抓取。进一步地，假肢手动作预测模块中，将假肢手关节动作梯度αp与幅度αs和残差αr相结合得到当前假肢手各关节的相对运动角度αt，式中，⊙为哈达玛积。进一步地，包括假肢手动作执行模块，假肢手执行模块将当前各关节的相对运动角度αt和当前假肢手关节状态Jt结合得到当前目标关节状态Jtargett，Jtargett=Jt+αt，将当前目标关节状态Jtargett输入至控制器。进一步地，动作梯度预测模块通过扩散模型预测假肢手动作梯度αp；动作幅度与残差预测模块通过强化学习模型预测假肢手动作梯度的幅度αs和残差αr。进一步地，RGB和Depth数据采集装置采用RGB-D相机；物体感知模块基于RGB-D相机采集抓取初始化时的场景点云信息，通过点云分割模型分割场景点云，得到物体的部分点云数据。进一步地，假肢手感知模块通过姿态预测网络实时估计假肢手腕部的6D姿态b= 其中bp为假肢手腕部的三维坐标，bq为假肢手腕部的四元数。进一步地，假肢手动作预测模块的学习在仿真环境中进行，基于假肢手模型和多样的物体模型使用抓取位姿生成算法生成不同物体不同区域的抓取姿态数据集，用于学习动作梯度预测模块；基于真实人类抓取时腕部的轨迹数据生成轨迹模式数据集，基于抓取姿态数据集和轨迹模式数据集，用于学习假肢手动作幅度与残差模块。进一步地，训练假肢手动作幅度与残差模块过程中的奖励函数设置如下，其中I为指示函数，即抓取成功，值为1，抓取失败时，值为0；△h为物体抓取后的高度与抓取前高度的差值。进一步地，当检测到假肢手关节扭矩大于设定阈值时，则将对应关节的相对运动角度αt设为0。2、一种利用上述智能假肢系统的控制方法，包括如下步骤：步骤1：RGB和Depth数据采集装置获取环境和假肢手的视觉信息；步骤2：物体感知模块根据环境视觉信息感知物体的点云信息，假肢手感知模块用于根据假肢手视觉信息估计假肢手腕部的6D姿态；步骤3：动作梯度预测模块根据物体的点云信息、假肢手腕部的6D姿态和假肢手关节状态J，预测假肢手动作梯度αp，假肢手关节状态J实时通过控制器从假肢手获得；动作幅度与残差预测模块根据假肢手动作梯度、物体的点云信息、假肢手关节状态J、假肢手腕部最近n步的6D姿态轨迹，预测假肢手动作梯度的幅度αs和残差αr；步骤4：控制器根据假肢手动作预测模块的预测结果，控制假肢手对物体进行抓取。本发明具有的有益效果：本发明包括RGB和Depth数据采集装置，所述RGB和Depth数据采集装置用于获取环境和假肢手的视觉信息；物体和假肢手感知模块，所述物体感知模块用于根据环境视觉信息感知物体的点云信息，所述假肢手感知模块用于根据假肢手视觉信息估计假肢手腕部的6D姿态；假肢手动作预测模块，所述假肢手动作预测模块包括动作梯度预测模块和动作幅度与残差预测模块，所述动作梯度预测模块用于根据物体的点云信息、假肢手腕部的6D姿态和假肢手关节状态J，预测假肢手动作梯度αp，所述动作幅度与残差预测模块用于根据假肢手动作梯度、物体的点云信息、假肢手关节状态J、假肢手腕部最近n步的6D姿态轨迹，预测假肢手动作梯度的幅度αs和残差αr；控制器，所述控制器根据假肢手动作预测模块的预测结果，控制假肢手对物体进行抓取。本发明可根据假肢手腕部移动的轨迹，预测假肢手动作梯度αp和假肢手动作梯度的幅度αs和残差αr，进而对假肢手实现控制，本发明不需检测人体的肌肉电信号 或脑电信号，假肢手对物体抓取控制更加灵巧、可靠，实现对不同物体与不同物体区域的自适应抓取，满足多样化的抓取需求。本发明动作梯度预测模块通过扩散模型学习人类的抓取姿态意图，用于预测假肢手动作梯度αp；动作幅度与残差预测模块通过强化学习模型学习人类的抓取时机意图，用于预测假肢手动作梯度的幅度αs和残差αr。假肢手动作预测模块的学习在仿真环境中进行，基于假肢手模型和多样的物体模型使用抓取位姿生成算法生成不同物体不同区域的抓取姿态数据集，用于学习动作梯度预测模块；基于真实人类抓取时腕部的轨迹数据生成轨迹模式数据集，基于抓取姿态数据集和轨迹模式数据集，用于学习假肢手动作幅度与残差模块。本发明通过扩散模型和强化学习模型相结合，实现了对大量物体的泛化性抓取，以及实时的、平滑的动作调整，进一步保证假肢手对物体抓取控制的灵巧性和可靠性。本发明通过上述方法对假肢手动作预测模块进行学习，进一步保证了假肢手动作预测模块预测的可靠性。附图说明图1是本发明智能假肢系统的结构框图；图2是假肢手多样化抓取姿态示意图；图3是假肢手抓取时机示意图。具体实施方式下面结合附图所示的各实施方式对本发明进行详细说明，但应当说明的是，这些实施方式并非对本发明的限制，本领域普通技术人员根据这些实施方式所作的功能、方法、或者结构上的等效变换或替代，均属于本发明的保护范围之内。实施例一：智能假肢系统如图1所示，本发明智能假肢系统包括：假肢手。所述假肢手采用五指灵巧手，用于执行对物体抓取。五指灵巧手与人手大小接近，采用绳驱动控制，有22个自由度，食指、中指、无名指各有4个自由度，小拇指有5个自由度，其中食指、中指、无名指和小拇指各有一个欠驱动的关节，大拇指有5个自由度，接近人手的自由度，固定在上肢残障人士的肢体上。RGB和Depth数据采集装置。所述RGB和Depth数据采集装置用于获取环境和假肢手的视觉信息。实施时，RGB和Depth数据采集装置采用RGB-D相机，佩戴于头部。物体和假肢手感知模块。所述物体和假肢手感知模块为假肢手动作预测模块提供输入。所述物体感知模块用于根据环境视觉信息感知物体的点云信息，所述假肢手感知模块用于根据假肢手视觉信息估计假肢手腕部的6D姿态。物体感知模块基于RGB-D相机采集抓取初始化时的场景点云信息，通过contrastive boundary learning分割场景点云，得到物体的部分点云数据。假肢手感知模块通过姿态预测网络实时估计假肢手腕部的6D姿态b= 其中bp为假肢手腕部的三维坐标，bq为假肢手腕部的四元数。假肢手动作预测模块。所述假肢手动作预测模块包括动作梯度预测模块和动作幅度与残差预测模块，所述动作梯度预测模块用于根据物体的点云信息、假肢手腕部的6D姿态和假肢手关节状态J，通过扩散模型Denoising Score-Matching 预测假肢手动作梯度αp，所述动作幅度与残差预测模块用于根据假肢手动作梯度、物体的点云信息、假肢手关节状态J、假肢手腕部最近5步的6D姿态轨迹，通过基于PointNet的强化学习模型预测假肢手动作梯度的幅度αs和残差αr。假肢手关节状态J通过控制器获取。假肢手动作预测模块中，将假肢手关节动作梯度αp与幅度αs和残差αr相结合得到当前假肢手各关节的相对运动角度αt，式中，⊙为哈达玛积。在物体与假肢手较远时，假肢手动作预测模块输出的动作倾向于张开假肢手，随着假肢手逐渐靠近物体，假肢手动作预测模块输出的动作会倾向于逐渐闭合假肢手，实现对物体进行抓取。假肢手动作预测模块的学习在仿真环境中进行，基于假肢手模型和多样的物体模型使用抓取位姿生成算法DexGraspNet生成不同物体不同区域的抓取姿态数据集，用于学习动作梯度预测模块；基于真实人类抓取时腕部的轨迹数据DexYCB生成轨迹模式数据集，基于抓取姿态数据集和轨迹模式数据集，在IsaacGym构建仿真环境，用于学习假肢手动作幅度与残差模块。训练假肢手动作幅度与残差模块过程中的奖励函数设置如下，其中I为指示函数，即抓取成功，值为1，抓取失败时，值为0；△h为物体抓取后的高度与抓取前高度的差值。当检测到假肢手关节扭矩大于设定阈值时，则将对应关节的相对运动角度αt设为0。假肢手动作执行模块。假肢手行模块将当前各关节的相对运动角度αt和当前假肢手关节状态Jt结合得到当前目标关节状态Jtargett，Jtargett=Jt+αt，将当前目标关节状态Jtargett输入至控制器。控制器，所述控制器根据假肢手动作预测模块的预测结果，即目标关节状态Jtargett，控制假肢手对物体进行抓取。实施例二：一种利用实施例一所述智能假肢系统的控制方法包括如下步骤：步骤1：RGB和Depth数据采集装置获取环境和假肢手的视觉信息；步骤2：物体感知模块根据环境视觉信息感知物体的点云信息，假肢手感知模块用于根据假肢手视觉信息估计假肢手腕部的6D姿态；步骤3：动作梯度预测模块根据物体的点云信息、假肢手腕部的6D姿态和假肢手关节状态J，预测假肢手动作梯度αp，假肢手关节状态J实时通过控制器从假肢手获得；动作幅度与残差预测模块根据假肢手动作梯度、物体的点云信息、假肢手关节状态J、假肢手腕部最近n步的6D姿态轨迹，预测假肢手动作梯度的幅度αs和残差αr；步骤4：控制器根据假肢手动作预测模块的预测结果，控制假肢手对物体进行抓取。上文所列出的一系列的详细说明仅仅是针对本发明的可行性实施方式的具体说明，它们并非用以限制本发明的保护范围，凡未脱离本发明技艺精神所作的等效实施方式或变更均应包含在本发明的保护范围之内。对于本领域技术人员而言，显然本发明不限于上述示范性实施例的细节，而且在不背离本发明的精神或基本特征的情况下，能够以其他的具体形式实现本发明。因此，无论从哪一点来看，均应将实施例看作是示范性的，而且是非限制性的，本发明的范围由所附权利要求而不是上述说明限定，因此旨在将落在权利要求的等同要件的含义和范围内的所有变化囊括在本发明内。
