标题title
一种聚合通信的方法、系统和计算机设备
摘要abst
本申请公开了一种聚合通信的方法、系统以及计算机设备，该方法应用于聚合通信系统，该系统至少包括第一计算芯片和第二计算芯片，其中，第一计算芯片通过至少一个通信通道与第二计算芯片通信，方法包括：第一计算芯片压缩第一数据，并通过通信通道将压缩后的第一数据发送给第二计算芯片；第二计算芯片根据压缩后的第一数据进行运算。依次提高聚合通信的效率。
权利要求书clms
1.一种聚合通信的方法，其特征在于，所述方法应用于聚合通信系统，所述系统包括多个计算芯片，所述多个计算芯片中每两个计算芯片建立有通信通道，所述多个计算芯片之间通过所述通信通道传输数据以执行集合通信操作，所述方法包括：所述多个计算芯片中的第一计算芯片压缩待通信的数据得到压缩后数据；所述第一计算芯片根据所述压缩后的数据确定传输至第二计算芯片的传输数据，所述传输数据包括压缩数据及压缩信息，所述第二计算芯片为所述多个计算芯片中与所述第一计算芯片通信的任意一个计算芯片；所述第一计算芯片通过第一通信通道将所述传输数据发送至所述第二计算芯片；所述第二计算芯片接收到所述传输数据后，根据所述压缩信息对所述压缩数据执行与所述集合通信操作对应的计算操作。2.根据权利要求1所述的聚合通信的方法，其特征在于，所述第一计算芯片通过一个通信通道与所述第二计算芯片通信，所述第二计算芯片为所述通信通道的根节点，则所述第二计算芯片根据所述压缩信息对所述压缩数据执行与所述集合通信操作对应的计算操作，具体包括：所述第二计算芯片根据所述压缩信息将所述压缩数据与压缩后的第二数据聚合，所述第二数据为所述第二计算芯片上待通信的数据；所述第二计算芯片将所述聚合结果发送至所述第一计算芯片。3.根据权利要求1所述的聚合通信的方法，其特征在于，所述第一计算芯片通过一个通信通道与所述第二计算芯片通信，所述第二计算芯片为所述通信通道的根节点，则所述第二计算芯片根据所述压缩信息对所述压缩数据执行与所述集合通信操作对应的计算操作，具体包括：所述第二计算芯片根据所述压缩信息将所述压缩数据与压缩后的第二数据合并，所述第二数据为所述第二计算芯片上待通信的数据；所述第二计算芯片将所述合并结果发送至所述第一计算芯片。4.根据权利要求1所述的聚合通信的方法，其特征在于，所述第一计算芯片通过多个通信通道与所述第二计算芯片通信，所述多个通信通道包括第一通信通道，所述压缩数据为所述压缩后数据的部分数据则所述第二计算芯片根据所述压缩信息对所述压缩数据执行与所述集合通信操作对应的计算操作，具体包括：所述第二计算芯片根据所述压缩信息将所述压缩数据与第二数据的部分数据聚合，所述第二数据为所述第二计算芯片上待通信的数据。5.根据权利要求1、2或4所述的聚合通信方法，其特征在于，所述聚合通信系统用于使用推荐模型结合用户的特征和商品的特征为用户推荐商品，在所述第一计算芯片压缩所述待通信的数据之前，所述方法包括：所述第一处理芯片根据嵌入表将所述用户的特征和所述商品的特征转化为所述待通信的数据；则所述方法还包括：所述第二计算芯片将所述第二计算芯片执行计算操作得到的运算结果输入所述推荐模型得到所述嵌入表的更新值和所述推荐模型的更新值；所述第二计算芯片根据所述推荐模型的更新值更新所述推荐模型；所述第二计算芯片根据所述嵌入表的更新值更新所述嵌入表。6.根据权利要求1至5任一所述的聚合通信方法，其特征在于，所述待通信的数据中数值为0的数据的个数大于数值非0的数据的个数。7.根据权利要求1至6任一所述的聚合通信的方法，其特征在于，所述计算芯片包括：图形处理器、张量处理器、神经网络处理器、深度学习处理器中的其中一个或多个。8.一种聚合通信的系统，其特征在于，所述系统包括多个计算芯片，所述多个计算芯片中每两个计算芯片建立有通信通道，所述多个计算芯片之间通过所述通信通道传输数据以执行集合通信操作：所述多个计算芯片中的第一计算芯片用于压缩待通信的数据得到压缩后数据；所述第一计算芯片还用于根据所述压缩后的数据确定传输至第二计算芯片的传输数据，所述传输数据包括压缩数据及压缩信息，所述第二计算芯片为所述多个计算芯片中与所述第一计算芯片通信的任意一个计算芯片；所述第一计算芯片还用于通过第一通信通道将所述传输数据发送至所述第二计算芯片；所述第二计算芯片用于接收到所述传输数据后，根据所述压缩信息对所述压缩数据执行与所述集合通信操作对应的计算操作。9.根据权利要求8所述的聚合通信的系统，其特征在于，所述第一计算芯片通过一个通信通道与所述第二计算芯片通信，所述第二计算芯片为所述通信通道的根节点，则所述第二计算芯片还用于：根据所述压缩信息将所述压缩数据与第二数据聚合，所述第二数据为所述第二计算芯片上待通信的数据；将所述聚合结果发送至所述第一计算芯片。10.根据权利要求8所述的聚合通信的系统，其特征在于，所述第一计算芯片通过一个通信通道与所述第二计算芯片通信，所述第二计算芯片为所述通信通道的根节点，则所述第二计算芯片还用于：根据所述压缩信息将所述压缩数据与第二数据合并，所述第二数据为所述第二计算芯片上待通信的数据；将所述合并结果发送至所述第一计算芯片。11.根据权利要求8所述的聚合通信的系统，其特征在于，所述第一计算芯片通过多个通信通道与所述第二计算芯片通信，所述多个通信通道包括第一通信通道，所述压缩数据为所述压缩后数据的部分数据，所述第二计算芯片还用于根据所述压缩信息将所述压缩数据与第二数据的部分数据聚合，所述第二数据为所述第二计算芯片上待通信的数据。12.根据权利要求8、9或11所述的聚合通信系统，其特征在于，所述聚合通信系统用于使用推荐模型结合用户的特征和商品的特征为用户推荐商品，所述第一计算芯片还用于：在所述第一计算芯片压缩第一数据之前，根据嵌入表将所述用户的特征和所述商品的特征转化为所述待通信数据；则所述第二计算芯片还用于，将所述第二计算芯片执行计算操作得到的运算结果输入所述推荐模型得到所述嵌入表的更新值和所述推荐模型的更新值；根据所述推荐模型的更新值更新所述推荐模型；根据所述嵌入表的更新值更新所述嵌入表。13.根据权利要求8至12任一所述的聚合通信的系统，其特征在于，所述待通信的数据中数值为0的数据的个数大于数值非0的数据的个数。14.根据权利要求8至13任一所述的聚合通信的系统，其特征在于，所述计算芯片包括：图形处理器、张量处理器、神经网络处理器、深度学习处理器中的其中一个或多个。
说明书desc
技术领域本申请涉及计算机领域，尤其涉及一种聚合通信的方法、系统和计算机设备。背景技术随着互联网个性化时代的到来，推荐算法可以在用户购买意图不明确的情况下，利用深度学习算法结合用户特征和商品特征，从海量的商品中找到用户感兴趣的商品，提升用户购买效率和产品体验，从而成为了目前众多互联网头部企业的盈利核心。推荐算法通常使用多张GPU并行完成计算任务，并结合聚合通信技术在多个处理器之间完成数据的迁移。目前，推出了两套硬件系统/＞和/＞以及与硬件系统相匹配的GPU聚合通信库/＞用于支持GPU之间的聚合通信。然而在实际应用中，由于用户特征和商品特征的数据中包含着大量数值为0的数据，稀疏度极高，现有的聚合通信技术对于稀疏数据存在大量无效的0的传输，降低了通信效率。因此如何提供一种提高稀疏数据的聚合通信效率的方法成为亟待解决的技术问题。发明内容本申请提供了一种聚合通信的方法、系统和计算机设备，以此提供一种高效的稀疏数据的聚合通信的方法，提高聚合通信系统处理需要在多个计算芯片之间完成数据传输的算法的能力。第一方面，提供一种聚合通信的方法，可以应用于聚合通信系统，该系统至少包括第一计算芯片和第二计算芯片，其中，第一计算芯片通过至少一个通信通道与第二计算芯片通信，所述方法包括：第一计算芯片压缩第一数据并且通过通信通道将压缩后的第一数据发送给第二计算芯片，然后由所述第二计算芯片根据所述压缩后的第一数据进行运算。通过上述方法，第一计算芯片可以将原始数据压缩后发送给第二芯片，减少第一芯片与第二芯片之间的数据的传输量。在一种可能的实现方式中，第一计算芯片通过一个通信通道与第二计算芯片通信，其中，第二计算芯片为通信通道的根节点，则第二计算芯片根据压缩后的第一数据进行运算的方法可以包括：第二计算芯片将压缩后的第一数据与第二数据聚合，其中，第二数据为所述第二计算芯片上待通信的数据；第二计算芯片将聚合结果发送至第一计算芯片。通过上述方法，第一芯片可以通过一个通道将压缩后的数据发送给第二计算芯片，由第二芯片聚合数据后发送回给第一芯片，得到聚合通信中的allreduce操作的结果，并且提高了allreduce操作的执行时间。在另一种可能的实现方式中，聚合通信系统还包括处理器，第一计算芯片通过一个通信通道与第二计算芯片通信，其中，第二计算芯片为通信通道的根节点，则该方法包括：第一计算芯片压缩第一数据；第二计算芯片压缩第二数据。处理器获取所述压缩的第一数据和压缩的第二数据的大小，并且调用通信库中的allgather接口将压缩后的第一数据发送给第二计算芯片，压缩后的第二数据发送给第一计算芯片。最后，第一计算芯片将压缩后的第二数据与第一数据聚合；第二计算芯片将压缩后的第一数据与第二数据聚合。通过上述方法，处理器可以调用已有的通信库中的接口完成allreduce操作，提高了allreduce操作的效率而无需更改大量的代码。在另一种可能的实现方式中，第一计算芯片也通过一个通信通道与第二计算芯片通信，其中，第二计算芯片为通信通道的根节点，则第二计算芯片根据压缩后的第一数据进行运算的方法可以包括：第二计算芯片将压缩后的第一数据与第二数据合并，其中，第二数据为所述第二计算芯片上待通信的数据；第二计算芯片将聚合结果发送至第一计算芯片。通过上述方法，第一芯片可以通过一个通道将压缩后的数据发送给第二计算芯片，由第二芯片合并数据后发送回给第一芯片，得到聚合通信中的allgather操作的结果，并且提高了allgather操作的执行时间。在另一种可能的实现方式中，第一计算芯片通过多个通信通道与第二计算芯片通信，其中，多个通信通道包括第一通信通道，则第一计算芯片通过通信通道将压缩后的第一数据发送给第二计算芯片的方法可以包括：第一计算芯片通过第一通信通道将第一数据的第一部分数据发送给第二计算芯片，其中，第二计算芯片为第一通信通道的根节点。则第二计算芯片根据压缩后的第一数据进行运算的方法可以包括：第二计算芯片将压缩后的第一数据的部分数据与第二数据的部分数据聚合，其中，第二数据为第二计算芯片上待通信的数据。通过上述方法，第一计算芯片可以通过多个通道中的每一个通道将压缩后的数据发送给每个通道的根节点，当一个通道的根节点为第二计算芯片时，第一计算芯片通过这个通道将压缩后的数据发送给第二计算芯片，由第二计算芯片聚合数据，得到聚合通信中的reduce-scatter操作的结果，并且提高了reduce-scatter操作的执行时间。在另一种可能的实现方式中，聚合通信系统可以用于使用推荐模型结合用户的特征和商品的特征为用户推荐商品，在第一计算芯片压缩第一数据之前，该方法包括第一处理芯片根据嵌入表将用户的特征和所述商品的特征转化为第一数据；则该方法还包括：第二计算芯片将第二计算芯片根据压缩后的第一数据进行运算得到的运算结果输入推荐模型得到嵌入表的更新值和推荐模型的更新值；然后第二计算芯片根据推荐模型的更新值更新推荐模型，并且根据所述嵌入表的更新值更新所述嵌入表。通过上述方法，本申请提出的聚合通信的方法可以结合推荐模型用于为用户推荐商品，在根据嵌入表得到推荐模型的输入值之间，提高了第一计算芯片和第二计算芯片之间的数据传输的效率，减少了为用户推荐商品的时间。在另一种可能的实现方式中，聚合通信系统可以用于使用推荐模型结合用户的特征和商品的特征为用户推荐商品，在第一计算芯片压缩第一数据之前，该方法包括第一处理芯片根据嵌入表将用户的特征和所述商品的特征转化为第四数据；然后，第二计算芯片将第四数据输入推荐模型得到第一数据和推荐模型的更新值；则该方法还包括：第二计算芯片根据推荐模型的更新值更新所述推荐模型，并且根据第二计算芯片根据压缩后的第一数据进行运算得到的运算结果更新嵌入表。通过上述方法，本申请提出的聚合通信的方法可以结合推荐模型用于为用户推荐商品，在根据更新嵌入表的操作中，提高了第一计算芯片和第二计算芯片之间的数据传输的效率，减少了为用户推荐商品的时间。在另一种可能的实现方式中，聚合通信系统可以用于使用推荐模型结合用户的特征和商品的特征为用户推荐商品，在第一计算芯片压缩第一数据之前，该方法包括第一处理芯片根据嵌入表将用户的特征和所述商品的特征转化为查询向量，并压缩查询向量，然后根据压缩后的查询向量得到所述第一数据；则该方法还包括：第二计算芯片第二计算芯片根据压缩后的第一数据进行运算得到的运算结果得到嵌入向量，并将嵌入向量输入推荐模型得到嵌入表的更新值和推荐模型的更新值；然后第二计算芯片根据推荐模型的更新值更新推荐模型，并且根据所述嵌入表的更新值和压缩后的查询向量更新所述嵌入表。通过上述方法，可以进一步减少第一数据的传输时间，提高聚合通信效率。在另一种可能的实现方式中，第一数据中数值为0的数据的个数大于数值非0的数据的个数。可以通过上述方法，有效减少数据中无效的0的传输，提高通信效率。在另一种可能的实现方式中，计算芯片包括：图形处理器、张量处理器、神经网络处理器、深度学习处理器中的其中一个或多个。第二方面，本申请提供一种聚合通信的系统，至少包括第一计算芯片和第二计算芯片，其中，第一计算芯片通过至少一个通信通道与第二计算芯片通信，聚合通信的系统用于实现如上述第一方面及第一方面任意一种可能实现方式中相应主体所执行的方法的操作步骤。第三方面，本申请提供一种计算机设备，所述计算机设备包括处理器、存储器、第一计算芯片和第二计算芯片，所述存储器中用于存储计算机执行指令，所述计算机设备运行时，所述处理器执行所述存储器中的计算机执行指令以利用所述第一计算芯片和第二计算芯片执行第一方面或第一方面任一种可能实现方式中所述方法的操作步骤。第四方面，本申请提供一种计算机可读存储介质，所述计算机可读存储介质中存储有指令，当其在计算机上运行时，使得计算机执行上述第一方面或第一方面任一种可能实现方式中所述方法的操作步骤。第五方面，本申请提供了一种包含指令的计算机程序产品，当其在计算机上运行时，使得计算机执行第一方面或第一方面任一种可能实现方式中所述方法的操作步骤。本申请在上述各方面提供的实现方式的基础上，还可以进行进一步组合以提供更多实现方式。附图说明图1为本申请实施例提供的一种聚合通信的系统100的结构示意图；图2为本申请提供的一种数据迁移操作的数据流示意图；图3为本申请提供的一种聚合运算操作的数据流示意图；图4为本申请提供的一种聚合通信的方法的流程示意图；图5为本申请提供的另一种聚合通信的方法的流程示意图；图6为本申请提供的另一种聚合通信的方法的流程示意图；图7为本申请提供的另一种聚合通信的方法的流程示意图；图8是本申请提供的另一种聚合通信的方法的流程示意图；图9是本申请提供的另一种聚合通信的方法的流程示意图。具体实施方式下面结合附图对本申请实施例中的技术方案进行描述。图1为本申请实施例提供的一种聚合通信的系统100的结构示意图，如图所示，系统100包括设备110。设备110可以是具有计算功能的设备，用于单独完成深度学习中涉及的计算任务。设备110包括处理器111、内存112、通信接口114以及至少两个计算芯片，例如计算芯片1131和计算芯片1132。在设备110中，处理器111、内存112、通信接口114和所有的GPU通过总线连接，例如，快捷外围部件互连标准。该总线也可以为其他类型实现设备内器件间连接的总线。此外，总线除了包括数据总线之外，还可以包括电源总线、控制总线和状态信号总线等。计算芯片之间还可以通过提出的/＞总线互相连接。处理器111用于执行内存112存储的计算机执行指令以实现设备110的功能。示例性地，处理器111可以是CPU，还可以是其他通用处理器、数字信号处理器、专用集成电路、现场可编程门阵列或者其他可编程逻辑器件、分立门或者晶体管逻辑器件、分立硬件组件等。通用处理器可以是微处理器或者是任何常规的处理器等。内存112可以包括只读存储器和随机存取存储器，并向处理器111提供指令和数据。内存112还可以包括非易失性随机存取存储器。内存112还可以是易失性存储器或非易失性存储器，或可包括易失性和非易失性存储器两者。其中，非易失性存储器可以是只读存储器、可编程只读存储器、可擦除可编程只读存储器、电可擦除可编程只读存储器或闪存。易失性存储器可以是随机存取存储器，其用作外部高速缓存。通过示例性但不是限制性说明，许多形式的RAM可用，例如静态随机存取存储器、动态随机存取存储器、同步动态随机存取存储器、双倍数据速率同步动态随机存取存储器、增强型同步动态随机存取存储器、同步连接动态随机存取存储器和直接内存总线随机存取存储器。计算芯片是适用于执行深度学习算法的处理器，例如图像处理器，张量处理器、神经网络处理器、深度学习处理器。需要说明的是，设备110可以包括至少两个相同或者不同类型的计算芯片，例如，设备110可以如图1所示包括两个GPU，也可以包括两个NPU，还可以包括一个GPU和一个NPU。多个计算芯片可以并行执行深度学习相关算法，例如，神经网络的训练和推理，计算芯片之间可以使用聚合通信技术通过总线完成数据的传输。可选地，系统100还可以包括多台设备，例如设备110和设备120，其中，其他设备的结构与设备110类似。系统100的不同设备之间通过网络进行通信。网络包括有线或无线的传输方式，其中，有线的传输方式包括利用以太、光纤等形式进行数据传输，无线传输方式包括移动热点、蓝牙、红外等传输方式。具体实施过程中，可以利用一个或多个交换机和/或路由器实现多个节点之间的通信处理。当系统100包括多台设备时，设备110可以与其他设备协同完成深度学习中涉及的计算任务。此时，设备110可以包括处理器111、内存112、通信接口114以及至少一个计算芯片。不同设备的计算芯片可以并行执行深度学习相关算法，相同设备内的计算芯片之间使用聚合通信技术通过总线完成数据的传输，不同设备之间的计算芯片之间使用聚合通信技术通过网络完成数据的传输。值得说明的是，图1所示的计算资源的管理系统架构仅仅是为了更好的说明本申请所提供的计算资源的管理方法所提供的系统架构的示例，并不构成对本申请实施例的限定。接下来，基于图1所示系统，进一步结合图2至图9图详细介绍本申请提供的聚合通信的方法。聚合通信的操作有以下三种类型：同步、数据迁移和聚合运算。同步操作用于同步通信域内的所有进程，执行同步操作的进程必须等待所有的进程执行完同步操作之后该进程在继续执行。数据迁移操作用于将进程中的数据发送到通信域中的其他进程上，又包括广播、收集、全收集和分散。图2为本申请提供的一种数据迁移操作的数据流示意图，如图所示：左一为broadcast，可以将节点1的数据1分别发送给节点1和节点2；左二为gather，可以将节点1的数据1、节点2的数据2以及结点3的数据3全部发送给节点1；左三为allgather，可以将节点1的数据1分别发送给节点2和节点3，节点2的数据2分别发送给节点1和节点3，节点3的数据3分别发送给节点1和节点2，最终节点1至节点3中的每一个节点都拥有数据1至数据3；左四为scatter，可以将节点1的数据2发送给节点2，数据3发送给节点3。聚合运算操作用于实现数据算术运算，例如求解最小值和最大值、求和、逻辑与运算以及其他用户自定义的计算算法。聚合运算操作包括规约、全规约和规约分散。图3为本申请提供的一种聚合运算操作的数据流示意图，以算术运算为求和为例，如图所示：左一为reduce，将节点1、节点2和节点3的数据分别相加并存储在节点1中；左二为allreduce，可以看做是reduce加上broadcast，将节点1的reduce的结果发送至其余所有节点；左三为reduce-scatter，可以看做是reduce加上scatter，最终节点1的数据为节点1至节点3第一个数据的和，节点2的数据为节点1至节点3第二个数据的和，节点3的数据为节点1至节点3第三个数据的和。在推荐算法中，使用较多的聚合通信方法为reduce-scatter、allreduce以及allgather，因此本申请将分别提供适用于稀疏矩阵的聚合通信方法中的reduce-scatter的方法、allreduce的方法以及allgather的方法，并将这些方法与推荐算法结合中。需要说明的是，本申请提供的聚合通信的方法也适用于其他算法中具有稀疏数据聚合通信的场景。图4为本申请提供的一种聚合通信的方法的流程示意图，具体地，可以完成reduce-scatter操作，可由如图1所示的设备110执行，也可以由如图1所示的设备110和其他设备共同执行。下面以设备110单独执行为例阐述方法的流程，如图4所示，具体方法包括：S401、待通信的计算芯片压缩待通信矩阵。设备110上的处理器111下发指令，指示待通信的计算芯片对自身芯片上的待通信的矩阵进行压缩，压缩方式可以采用本领域技术人员掌握的矩阵压缩方式，例如可以采用以下压缩方式的任意一种：方式一：行压缩。行压缩将原始矩阵压缩后得到一个压缩矩阵和一个压缩向量。其中压缩向量记录了非0行的行号，和矩阵的总行号，而压缩矩阵记录了与行号对应的非0行的数据。例如对于矩阵行压缩后压缩矩阵为/＞压缩向量为。其中，0表示向量矩阵中第一行数据对应的行号，类似的，3和5分别表示向量矩阵中第二行和第三行数据对应的行号，7表示原始矩阵的总行号为7。行压缩方式为无损压缩，压缩后的数据可以连续存储或者分开存储。方式二：坐标格式压缩。COO压缩方法将每一个原始矩阵中的非0元素，用一个三元组来表示，三元组中包含三个向量，分别为行号向量，列号向量和数值向量。其中，行号向量中存放非0元素的行号，列号向量存放非0元素的列号，数值向量存放非0元素的数值，三个向量中的数据位置一一对应。例如对于矩阵共有四个非0元素，则行号向量为，列号向量为，数值向量为。方式三：压缩稀疏行格式压缩。CSR压缩方法将每一个原始矩阵中的非0元素，用三类数据来表示，分别为数值向量、列号向量以及行偏移向量。其中数值向量和列号向量与COO压缩方法一致，行偏移向量中第一个数据表示第一行的第一个元素在所有非0元素中的位置，例如对于矩阵C，第一行的非0数据为1，它是非0元素中的第一个数据，位置为0，则行偏移向量中的第一个数据为0；行偏移向量中第二个数据表示第二行的第一个元素在所有非0元素中的位置，例如对于矩阵C，第二行的非0数据为2，它是非0元素中的第二个数据，位置为1，则行偏移向量中的第二个数据为1；以此类推，行偏移向量中的最后一个数据为所有非0元素的总数。则对于矩阵C，行偏移向量为。示例性地，在示例1中，假设设备110包括4个待通信GPU，分别为GPU1、GPU2、GPU3和GPU4，每个GPU上待通信的矩阵为：采用行压缩后GPU1至GPU4上的待通信矩阵分别为：每个GPU的通信向量分别为：S402、待通信计算芯片之间建立通信通道。根据待通信计算芯片的数量，建立通信通道，使通信通道的数量与待通信计算芯片的相等，每一个通信通道传输待通信矩阵的部分数据。可以将压缩前的待通信矩阵的数据按照行数平均分配给每一个通信通道。可选地，还可以根据通信通道的实际的数据传输量，动态的规划每一个通信通道传输的待通信矩阵的行数数量。对于示例1，可以按照平均分配的方式建立4个通信通道，第1个通信通道传输压缩前的待通信矩阵的第0行至第3行数据，第2个通信通道传输压缩前的待通信矩阵的第4行至第7行数据，以此类推。S403、处理器110从待通信计算芯片中确定根节点。对于reduce-scatter操作，每一个通信通道具有一个根节点，用于接收和发送通信通道内其他计算芯片的数据并完成算术运算。根节点可以由用户指定，也可以由处理器111根据每个计算芯片的性能选择，例如，核心数量、核心频率、存储速度、显存位宽、容量。本申请对选择的方法不做限定。对于示例1，可以选择GPU1作为通信通道1的根节点，GPU2作为通信通道2的根节点，以此类推。S404、根节点接收其他待通信计算芯片的数据并得到聚合运算结果。对于每一个通信通道，非根节点的待通信计算芯片扫描压缩后的矩阵，将矩阵中属于这个通信通道的数据以及行号发送给这个通信通道的根节点。例如，对于示例1，在通信通道1中，通信通道1传输压缩前的待通信矩阵的第0行至第3行数据，并且GPU1是通信通道1的根节点，则GPU2扫描压缩向量后可知在原始矩阵的前四行数据中，第1,2,3行有待通信的数据。GPU2将压缩矩阵中，第1,2,3行对应的数据{3,3,3,3},{4,4,4,4},{3,3,3,3}和行号1,2,3发送至GPU1。而GPU3和GPU4扫描压缩向量后可知在原始矩阵的前四行数据中，并没有待通信的数据，因此无需发送。其余通信通道的发送方法可以以此类推。根节点可以在存储空间中创建新的矩阵区域接收非根节点的计算芯片发送的数据，新的矩阵的行数等于通信通道传输的行数。然后根节点将数据根据行号与压缩前的原始矩阵相应的行的数据进行聚合，得到最终的聚合通信reduce-scatter结果。对于示例1，GPU1接收到数据{3,3,3,3},{4,4,4,4},{3,3,3,3}和行号1,2,3后，分别将{3,3,3,3},{4,4,4,4},{3,3,3,3}与原始矩阵第0,1,2,3行的数据相加。GPU2接收到数据{3,3,3,3},{6,6,6,6},{7,7,7,7}和行号5,4,7后，分别与原始矩阵第4,5,6,7行的数据相加。其余的GPU的操作也可以以此类推，最终得到聚合通信reduce-scatter的结果为：可选地，根节点可以将接收到的数据根据行号直接与压缩前的原始矩阵相应的行的数据进行计算，无需创建新的存储区域。由于根节点可以同时接收并计算多个计算芯片发送的数据，因此需要对数据进行加锁，避免同时对一个数据进行多次计算。根节点可以每次接受一个数据，每个数据计算完毕后才可以接收新的数据。可选地，根节点还可以同时接收一行数据，每一行数据计算完毕后才接收新的数据。通过上述方法，本申请中的聚合通信的方法可以在发送数据之前对待通信矩阵进行压缩，减少reduce-scatter操作中每一个通道的无效的0的传输，提高reduce-scatter操作的效率。下面介绍本申请实施例提供的一种聚合通信的allreduce操作的方法，图5为本申请提供的另一种聚合通信方法的流程示意图，可由如图1所示的设备110执行，也可以由如图1所示的设备110和其他设备共同执行。下面以设备110单独执行为例阐述方法的流程，如图5所示，具体方法包括：S501、待通信的计算芯片压缩待通信矩阵，与S401类似。S502、待通信计算芯片之间建立通信通道，与S402类似。S503、处理器110从待通信计算芯片中确定根节点。对于allreduce操作，所有的通信通道可以指定同一个根节点，用于接收和发送其他计算芯片的数据并完成算术运算。根节点的确定方式与S403的确定方式类似。对于示例1，可以选择GPU1作为根节点。S504、根节点接收其他待通信计算芯片的数据并得到聚合运算结果。与S404类似，根节点接收其他待通信计算芯片的数据并完成计算。不同的是，在allreduce操作中，所有通信通道的根节点是同一个计算芯片，因此最后由一个计算芯片接收并聚合了所有的待通信计算芯片的数据。对于示例1，根节点GPU1的计算结果如下：GPU1:{1,1,1,1},{3,3,3,3},{4,4,4,4},{3,3,3,3},{6,6,6,6},{1,1,1,1},{4,4,4,4},{7,7,7,7},{5,5,5,5},{8,8,8,8},{1,1,1,1},{6,6,6,6},{1,1,1,1},{3,3,3,3},{9,9,9,9},{8,8,8,8}S505、根节点将数据发送给其他待通信计算芯片。根节点以broadcast的形式将S504得到的矩阵发送给其他的待通信计算芯片，完成allreduce操作。对于示例1，最终allreduce的结果为：通过上述方法，本申请中的聚合通信的方法可以在发送数据之前对待通信矩阵进行压缩，减少allreduce操作中每一个通道的无效的0的传输，提高allreduce操作的效率。下面介绍本申请实施例提供的一种allgather操作的方法，图6为本申请提供的另一种聚合通信的方法的流程示意图，可由如图1所示的设备110执行，也可以由如图1所示的设备110和其他设备共同执行。下面以设备110单独执行为例阐述方法的流程，如图6所示，具体方法包括：S601、待通信的计算芯片压缩待通信矩阵，与S401类似。S602、待通信计算芯片之间建立通信通道，与S402类似。S603、处理器110从待通信计算芯片中确定根节点。对于allgather操作，所有的通信通道可以指定同一个根节点，用于接收和发送其他计算芯片的数据。根节点的确定方式与S403的确定方式类似。对于示例1，可以选择GPU1作为根节点。S604、根节点接收其他待通信计算芯片的数据并得到合并结果。其他待通信计算芯片可以将压缩矩阵和压缩向量发送给根节点，对于示例1，可以得到：GPU1:{1,1,1,1},{1,1,1,1},{1,1,1,1},{1,1,1,1},{3,3,3,3},{4,4,4,4},{3,3,3,3},{4,4,4,4},{5,5,5,5},{3,3,3,3},{6,6,6,6},{7,7,7,7},{8,8,8,8},{6,6,6,6},{8,8,8,8},{9,9,9,9},对应也可以得到所有的压缩向量：GPU1:{0,5,10,11,16}{1,2,3,6,8,12,16}{4,7,9,11,15,16}{14,16}根节点得到压缩矩阵和压缩向量之后，在芯片的存储空间中创建一个新的矩阵用于存放最终的聚合通信结果，新的矩阵的行数等于压缩向量的总行数与通信通道的数量的乘积。然后根节点依次将压缩矩阵的每一个非0行，按照压缩向量的行号，填入新的矩阵中。最后没有填充数据的行用0填充。以示例1中的GPU1为例，GPU1首先在芯片的存储空间中创建一个64行4列的新矩阵，再根据压缩向量依次将S603中的非0行填入新的矩阵中。例如，第一行{1,1,1,1}在压缩向量中行号为0，则将{1,1,1,1}填入新的矩阵的第0行，第二行{1,1,1,1}在压缩向量中行号为5，则将{1,1,1,1}填入新的矩阵的第5行，以此类推，最终没有填充数据的行用0填充，可以得到GPU1的结果为：GPU1:{1,1,1,1},{0,0,0,0},{0,0,0,0},{0,0,0,0},{0,0,0,0},{1,1,1,1},{0,0,0,0},{0,0,0,0},{0,0,0,0},{0,0,0,0},{1,1,1,1},{0,0,0,0},{1,1,1,1},{0,0,0,0},{0,0,0,0},{0,0,0,0}{0,0,0,0},{3,3,3,3},{4,4,4,4},{3,3,3,3},{0,0,0,0},{0,0,0,0},{4,4,4,4},{0,0,0,0},{5,5,5,5},{0,0,0,0},{0,0,0,0},{0,0,0,0},{0,0,0,0},{3,3,3,3},{0,0,0,0},{0,0,0,0}{0,0,0,0},{0,0,0,0},{0,0,0,0},{0,0,0,0},{6,6,6,6},{0,0,0,0},{0,0,0,0},{7,7,7,7},{0,0,0,0},{8,8,8,8},{0,0,0,0},{6,6,6,6},{0,0,0,0},{0,0,0,0},{0,0,0,0},{8,8,8,8}{0,0,0,0},{0,0,0,0},{0,0,0,0},{0,0,0,0},{0,0,0,0},{0,0,0,0},{0,0,0,0},{0,0,0,0},{0,0,0,0},{0,0,0,0},{0,0,0,0},{0,0,0,0},{0,0,0,0},{0,0,0,0},{9,9,9,9},{0,0,0,0}S605、根节点将数据发送给其他待通信计算芯片。类似S505，根节点以broadcast的形式将S604得到的矩阵发送给其他的待通信计算芯片，完成allgather操作。通过上述方法，本申请中的聚合通信的方法可以在发送数据之前对待通信矩阵进行压缩，减少allgather操作中的无效的0的传输，提高allgather操作的效率。对于已经安装了的GPU聚合通信库/＞设备，可以在调用/＞通信库中提供的聚合操作上，进一步。图7为本申请提供的另一种聚合通信的方法的流程示意图，具体地，可以执行allreduce操作，可由如图1所示的设备110执行，也可以由如图1所示的设备110和其他设备共同执行。下面以设备110单独执行为例阐述方法的流程，如图7所示，具体方法包括：S701、待通信的计算芯片压缩待通信矩阵，与S401类似。S702、处理器111获取压缩矩阵的最大大小。处理器111可以直接调用通信库中allreduce函数的接口，获取每个待通信计算芯片上的压缩矩阵的行数。可选地，每个待通信的计算芯片还可以遍历压缩矩阵，并将行数发送给处理器111。可选地，每个待通信的计算芯片还可以直接从压缩向量中读取行数，并发送给处理器111。处理器111根据行数的最大值，将计算芯片上行数未达到最大值的压缩矩阵用0填充，使行数达到最大值。以示例1中压缩后的矩阵为例，GPU1至GPU4的行数分别为4,6,5,1，其中GPU2的行数最大，则其余的GPU使用数据0将行数填充至6行，结果如下：S703、处理器111调用allgather接口。处理器111可以调用通信库中的allgather接口，将每个待通信GPU上的压缩矩阵和压缩向量互相发送给其余的计算芯片，则每个计算芯片都可以得到所有的压缩矩阵。对于示例1，可以得到：对应每个GPU也都可以得到所有的压缩向量：S704、待通信计算芯片根据压缩向量进行运算。计算芯片得到压缩矩阵和压缩向量之后，在芯片的存储空间中创建一个新的矩阵用于存放最终的聚合通信结果，新的矩阵的行数等于压缩向量的总行数。然后计算芯片依次将压缩矩阵的每一个非0行，按照压缩向量的行号，填入新的矩阵中。如果压缩矩阵中的两行数据对应的行号相同，那么计算芯片按照运算方式将两行数据计算的结果填入新的矩阵中。以示例1中的GPU1为例，GPU1首先在芯片的存储空间中创建一个16行4列的新矩阵，再根据压缩向量依次将S703中的非0行填入新的矩阵中。例如，第一行{1,1,1,1}在压缩向量中行号为0，则将{1,1,1,1}填入新的矩阵的第0行，第二行{1,1,1,1}在压缩向量中行号为5，则将{1,1,1,1}填入新的矩阵的第5行，以此类推，最终可以得到所有GPU的allreduce结果：通过上述方法，本申请中的聚合通信的方法可以在直接调用现有的通信库，操作简单，并且可以通过压缩矩阵，减少allreduce操作中每一个通道的无效的0的传输，提高allreduce操作的效率。在推荐系统中，由于用户特征和商品特征的数据中包含着大量数值为0的数据，稀疏度极高，因此嵌入是推荐系统的核心操作。嵌入操作主要用于使用一个矩阵将稀疏向量转换成稠密向量。转换后的向量称为嵌入向量，用于转换的矩阵称为嵌入表。例如，公式1中将两个5维特性向量转换成了2个3维向量：在推荐系统中，推荐模型的训练的每一次迭代可以由正向传播和反向传播两个过程组成，其中，正向传播用于得到输入数据经过嵌入表的转换和推荐模型计算后的结果，反向传播用于根据计算后的结果与实际值的差值得到推荐模型以及嵌入表的更新。随着模型的复杂度和数据量的不断增加，目前嵌入表的大小已经达到百GB到TB的级别，10TB级别也即将到来。由于完整的嵌入表的数据量过大，一般由多个计算芯片共同存储，每个计算芯片存放嵌入表的一部分数据。因此在正向传播过程中，使用到的嵌入向量需要根据查询向量从多个计算芯片存储的嵌入表中查询并取出对应行的数据，可以通过聚合通信中的reduce-scatter或者allreduce操作组合成本次迭代过程中的嵌入向量。最后将该嵌入向量输入推荐模型进行训练。不仅如此，由于计算量过大，推荐模型也会分别存储在不同的计算芯片中，每一次迭代的计算后，每一个计算芯片只能得到一部分的嵌入向量的更新值。因此在反向传播过程中，可以通过聚合通信中的allgather操作，将嵌入向量的更新值汇总并发送给所有的计算芯片，得到最终的嵌入表的更新值。图8是本申请提供的另一种聚合通信的方法的流程示意图，可由如图1所示的设备110执行，也可以由如图1所示的设备110和其他设备共同执行。下面以设备110单独执行为例阐述方法的流程，如图8所示，具体方法如下：S801、计算芯片根据用户特征和商品特征得到查询向量。查询向量中存储着嵌入表的行与嵌入向量的行的对应关系。查询向量中的数据的数量是嵌入向量的行数，每一个数据的位置是嵌入向量的行，每一个数据的大小是嵌入表的行，例如查询向量为{1,2,3,4}时，嵌入向量为一个4行矩阵，第1个数据为1，表示嵌入向量第1行是嵌入表第1行的数据；第2个数据为2，表示嵌入向量第2行是嵌入表第2行的数据。S802、计算芯片根据查询向量从嵌入表中得到嵌入向量。具体地，这一步可以分为两步，包括：S8021、计算芯片通过查询向量得到每个计算芯片的待通信矩阵。每个计算芯片可以首先创建一个所有数据为0的待通信矩阵，待通信矩阵的行数等于查询向量的数据的总数。则每个计算芯片分别根据查询向量中的数据从本地存储的嵌入表中取出对应行的数据，组成待通信矩阵。示例性地，在示例2中，假设设备110包括4个待通信GPU，分别为GPU1、GPU2、GPU3和GPU4，每个GPU存储的嵌入表分别为：每个GPU矩阵前的数字表示嵌入表的行号，对于GPU1，存储了完整嵌入表的第1、2、3行，每一行的数据分别是{0,0,0,0}、{1,1,1,1}和{2,2,2,2}。假设查询向量为：{2,4,5,4,7,2,5,8,6,9,2,7,2,4,10,9}，共16行，GPU1至GPU4首先分别创建一个所有数据为0的16行4列的矩阵。根据查询向量，嵌入表的第2行对应嵌入向量的第1、6、11、13行，则GPU1从本地存储的嵌入表中取出第2行数据，分别填入矩阵的第1、6、11、13行；嵌入表的第4行对应嵌入向量的第2、4、14行，嵌入表的第5行对应嵌入向量的第3、7行，嵌入表的第6行对应嵌入向量的第6行，则GPU2从本地存储的嵌入表中取出第4行数据，填入矩阵的第2、4、14行，取出第5行数据，填入矩阵的第3、7行，取出第6行数据，填入矩阵的第6行，以此类推。最终得到每个GPU的待通信矩阵为：S8022、计算芯片使用本申请提供的reduce-scatter或者allreduce操作得到嵌入向量。当推荐模型分成多个部分，分别由多个计算芯片执行训练时，可以使用本申请图4提供的reduce-scatter操作，每个通信的计算芯片可以得到嵌入向量的一部分值，分别输入该计算芯片上的推荐模型进行下一步的计算。当推荐模型完整的由一个计算芯片或者同时由多个计算芯片执行训练是，可以使用本申请图5或者图7提供的allreduce操作，得到完整的嵌入向量，输入推荐模型进行下一步的计算。S803、计算芯片将嵌入向量输入推荐模型进行计算，得到计算结果。S804、计算计算结果与真实值的之间的损失函数。S805、通过损失函数计算得到嵌入向量的更新值。S806、计算芯片根据嵌入向量的更新值得到嵌入表的更新值。具体地，这一步可以分为两步，包括：S8061、计算芯片使用本申请提供的allgather操作得到完整的嵌入向量的更新值。当推荐模型分成多个部分，分别由多个计算芯片执行训练时，每一个计算芯片只能得到一部分的嵌入向量的更新值，可以采用本申请图6提供的allgather操作，是每一个计算芯片都得到完整的嵌入向量的更新值。以示例2为例，假设4个GPU上得到的嵌入向量的更新值分别为：经过本申请图6提供的allgather操作后，可以得到：S8062、计算芯片根据查询向量得到嵌入表的更新值。根据每个计算芯片存储的嵌入表的行在查询向量中对应的嵌入向量的行，从嵌入向量的更新值得到嵌入表中的每一行的更新值。当嵌入表的行在查询向量中对应多个嵌入向量的行时，将所有的嵌入向量的行的数据相加后作为嵌入表的行。对于示例2，查询向量为：{2,4,5,4,7,2,5,8,6,9,2,7,2,4,10,9}，嵌入表第2行对应嵌入向量的第1、6、11、13行，则GPU1从获得的嵌入表的更新值中取出第1、6、11、13行的数据，{0.1,0.1,0.1,0.1}，{0.3,0.3,0.3,0.3}，{0.8,0.8,0.8,0.8}，{0.1,0.1,0.1,0.1}，相加后，作为嵌入表第2行的更新，{1.3,1.3,1.3,1.3}。以此类推，最终得到嵌入表的更新值为：S807、计算芯片根据嵌入表的更新值更新计算芯片存储的嵌入表。通过上述方法，本申请中的聚合通信的方法可以在嵌入向量组合和嵌入表更新过程中通过压缩矩阵，提高聚合通信的效率，减少推荐模型的训练过程中使用的时间。图9是本申请提供的另一种聚合通信的方法的流程示意图，可由如图1所示的设备110执行，也可以由如图1所示的设备110和其他设备共同执行。下面以设备110单独执行为例阐述方法的流程，与图8的方法相比，图9的方法只有S902和S906步骤与图8所示的方法不同，其与步骤均与图8类似，具体方法如下：S901、计算芯片根据用户特征和商品特征得到查询向量。S902、计算芯片根据查询向量从嵌入表中得到嵌入向量。具体地，这一步可以分为三个步骤，包括：S9021、计算芯片压缩查询向量，得到查询向量的压缩向量和查询向量的恢复向量。将查询向量中重复的元素去除，并使用查询向量的恢复向量记录压缩后的查询向量中每一个数据在压缩前的查询向量中出现的位置。如示例2所示，查询向量为：{2,4,5,4,7,2,5,8,6,9,2,7,2,4,10,9}，压缩后的查询向量为{2,4,5,7,8,6,9,10},查询向量的恢复向量为{{1,6,11},{2,3,14},{3,7},{5,12},{8},{9},{10,16},{15}}，表示，1出现在压缩前的查询向量的1,6,11的位置上，3出现在压缩前的查询向量的2,4,14的位置上，以此类推。S9022、计算芯片根据压缩后的查询向量得到每个计算芯片的待通信矩阵，与S8021类似。对于示例2，可以得到每个GPU的待通信矩阵为：S9023、计算芯片使用本申请提供的allreduce操作得到压缩的嵌入向量。可以使用本申请图5或者图7提供的allreduce操作，得到压缩的嵌入向量。对于示例2，得到的压缩的嵌入向量为：S9024、计算芯片根据查询向量的恢复向量恢复压缩的嵌入向量。计算芯片可以首先创建一个新的矩阵用于存放最终的嵌入向量，新的矩阵的行数等于压缩前的查询向量的数据的总数。然后计算芯片依次将压缩后的嵌入向量的每一行数据根据行号，确定其在查询向量的恢复向量中的位置，并进一步确定这一行的数据在原始的查询向量中的位置。最后，计算芯片将这一行数据根据原始的查询向量中的位置填入到最终的嵌入向量的矩阵中。以示例2中的GPU1为例，GPU1首先在芯片的存储空间中创建一个16行4列的新嵌入向量的矩阵，再根据压缩向量依次确定S9023中的每一行数据对应在原始的查询向量中的位置。例如，第一行{1,1,1,1}在压缩后的嵌入向量中行号为1，则其是查询向量的恢复向量中的第一个数据，对应的数据内容为{1,6,11}，表示这一行数据在原始的查询向量中的第1,6,11行。则计算矩阵将{1,1,1,1}填入新的矩阵的第1,6,11行,以此类推，最终可以得到所有GPU的allreduce结果：S903、计算芯片将嵌入向量输入推荐模型进行计算，得到计算结果。S904、计算计算结果与真实值的之间的损失函数。S905、通过损失函数计算得到嵌入向量的更新值。S906、计算芯片根据嵌入向量的更新值得到嵌入表的更新值。具体地，这一步可以分为两步，包括：S9061、计算芯片根据查询向量去除嵌入向量更新值中的重复数据。与S8061类似，当推荐模型分成多个部分，分别由多个计算芯片执行训练时，每一个计算芯片只能得到一部分的嵌入向量的更新值。正如前面所述，查询向量中每一个数据的位置是嵌入向量的行，每一个数据的大小是嵌入表的行，计算芯片可以遍历查询向量中部分嵌入向量的行的位置对应的数据后，将查询向量上数据的值相同的位置对应的嵌入向量的行的更新值相加，写入嵌入向量对应行的任意一行中，并将其他行赋值为0。以示例2的GPU1为例，嵌入向量的更新值为：查询向量为{2,4,5,4,7,2,5,8,6,9,2,7,2,4,10,9}，GPU1得到的部分嵌入向量为完整嵌入向量的第1-4行，GPU1遍历查询向量的第1-4个数据{2,4,5,4}，其中第2个数据和第4个数据的值都为4，因此可以将GPU1中嵌入向量的第2行和第4行的数据相加，写入第2行，并将第4行的数据赋值为0。以此类推，得到嵌入向量的更新值为：由于查询向量中相同数值的数据对应的嵌入表中的相同行，因此可以提前将其对应的嵌入向量的多行数据转变为一行，增加下一步中待通信的矩阵的稀疏性，提高聚合通信效率。当查询向量中重复的数据越多时，越能提高通信效率。S9062、计算芯片使用本申请提供的allgather操作得到完整的嵌入向量的更新值，与S8062类似。S9063、计算芯片根据查询向量得到嵌入表的更新值，与S8062类似。S907、计算芯片根据嵌入表的更新值更新计算芯片存储的嵌入表。通过上述方法，本申请中的聚合通信的方法可以最大程度的需要通信的嵌入向量进行压缩，进一步减少了通信中传输的数据量，提高聚合通信的效率，减少推荐模型的训练过程中使用的时间。值得说明的是，对于上述方法实施例，为了简单描述，故将其都表述为一系列的动作组合，但是本领域技术人员应该知悉，本申请并不受所描述的动作顺序的限制。本领域的技术人员根据以上描述的内容，能够想到的其他合理的步骤组合，也属于本申请的保护范围内。其次，本领域技术人员也应该熟悉，说明书中所描述的实施例均属于优选实施例，所涉及的动作并不一定是本申请所必须的。本申请还提供一种聚合通信的系统，可以为图1所示的系统100。该聚合通信的系统至少包括第一计算芯片和第二计算芯片，其中，第一计算芯片通过至少一个通信通道与第二计算芯片通信。示例性地，第一计算芯片和第二计算芯片可以分别为图1所示的计算芯片1131和计算芯片1132，也可以分别为图1所示的计算芯片1131和计算芯片1231。聚合通信的系统用于实现如上述聚合通信方法中相应主体所执行的方法的操作步骤。通过上述聚合通信的系统，可以减少计算芯片之间的数据的数量，提高聚合通信效率。所述系统还可以使用在为用户推荐商品的场景下，减少计算速度，提高用户的使用体验。上述实施例，可以全部或部分地通过软件、硬件、固件或其他任意组合来实现。当使用软件实现时，上述实施例可以全部或部分地以计算机程序产品的形式实现。所述计算机程序产品包括一个或多个计算机指令。在计算机上加载或执行所述计算机程序指令时，全部或部分地产生按照本申请实施例所述的流程或功能。所述计算机可以为通用计算机、专用计算机、计算机网络、或者其他可编程装置。所述计算机指令可以存储在计算机可读存储介质中，或者从一个计算机可读存储介质向另一个计算机可读存储介质传输，例如，所述计算机指令可以从一个网站站点、计算机、服务器或数据中心通过有线)或无线方式向另一个网站站点、计算机、服务器或数据中心进行传输。所述计算机可读存储介质可以是计算机能够存取的任何可用介质或者是包含一个或多个可用介质集合的服务器、数据中心等数据存储设备。所述可用介质可以是磁性介质、光介质、或者半导体介质。半导体介质可以是固态硬盘。以上所述，仅为本申请的具体实施方式。熟悉本技术领域的技术人员根据本申请提供的具体实施方式，可想到变化或替换，都应涵盖在本申请的保护范围之内。
