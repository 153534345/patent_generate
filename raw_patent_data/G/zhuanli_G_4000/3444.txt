标题title
一种模型并行训练中的自适应模型划分方法、系统及设备
摘要abst
本发明公开了一种模型并行训练中的自适应模型划分方法、系统及设备，包括如下步骤：S1：将神经网络模型的原始层划分为块，将所述块作为神经网络模型新的层结构；S2：以划分后各阶段的计算和通信时间最大值最小为目标，计算得到神经网络模型所有阶段的分割层；S3：基于所有阶段的分割层并结合动态层迁移技术对神经网络模型进行划分，并对划分后的神经网络模型进行模型训练；S4：实时检测GPUm‑1与GPUm之间的带宽和GPUm的计算能力，设定周期固定的批处理，循环步骤S2至S3，以周期性更新神经网络模型划分；该模型划分方法能够实现针对不同GPU时神经网络模型实时最优划分。
权利要求书clms
1.一种模型并行训练中的自适应模型划分方法，其特征在于，包括如下步骤：S1：将神经网络模型的原始层划分为块，将所述块作为神经网络模型新的层结构，所述块由连续一至多个所述原始层构成；S2：以划分后各阶段的计算和通信时间最大值最小为目标，计算得到所述神经网络模型所有阶段的分割层；S3：基于所有阶段的分割层并结合动态层迁移技术对神经网络模型进行划分，并对划分后的神经网络模型进行模型训练；S4：实时检测GPUm-1与GPUm之间的带宽和GPUm的计算能力/＞，设定周期固定的批处理，循环步骤S2至S3，以周期性更新神经网络模型划分；所述所有阶段的分割层的计算过程如下：其中，表示使用m台机器在第1层和第/＞层之间的最优分配的情况下，最慢阶段所用的时间，/＞是第1层和第/＞层之间最优子阶段中最慢阶段所用的时间；/＞表示层/＞与层/＞之间传递激活和梯度所用的时间，/＞表示GPUm对层/＞到层/＞所需的计算时间，/＞表示GPUm对层/＞的计算时间，/＞表示网络层/＞的计算量，/＞表示层/＞的输出激活值，/＞表示GPUm的计算能力，/＞表示GPUm-1与GPUm间的带宽，GPUm表示第m个GPU编号，GPUm-1表示第m-1个GPU编号。2.根据权利要求1所述的模型并行训练中的自适应模型划分方法，其特征在于，在所述步骤S1：将神经网络模型的原始层划分为块之前，对神经网络模型所需参数进行定义，GPU顺序按实际拓扑顺序固定，所述参数包括；GPUm、、/＞、/＞、/＞、/＞、/＞、/＞。3.根据权利要求2所述的模型并行训练中的自适应模型划分方法，其特征在于，在步骤S1：将神经网络模型的原始层划分为块中，具体包括：将神经网络模型的几个连续的层视为一个整体进行分配得到块，以更新神经网络模型；对更新后的神经网络模型进行切分合并得到更新后的和/＞；将更新后的和/＞带入分割层计算过程。4.根据权利要求1所述的模型并行训练中的自适应模型划分方法，其特征在于，在步骤S2：以划分后各阶段的计算和通信时间最大值最小为目标，计算得到所述神经网络模型所有阶段的分割层，具体包括：当最优分配包含多个阶段时，将所述最优分配分解为最优子阶段和最后单个阶段，所述最优子阶段由个GPU计算层1到层/＞，所述最后单个阶段由第m个GPU单独计算层到层/＞；以所述最后单个阶段的计算和通信时间最大值最小为目标，计算得到所述最后单个阶段的；使用二维数组来存储/＞的相应值与最后单个阶段的/＞；基于最后单个阶段的向前追溯递推得到所述最优子阶段中所有阶段的分割层。5.根据权利要求4所述的模型并行训练中的自适应模型划分方法，其特征在于，在所述基于最后单个阶段的向前追溯递推得到所述最优子阶段中所有阶段的分割层中，具体为：由二维数组得到分割层/＞，由二维数组/＞得到/＞，以此类推得到/＞、···/＞；m台GPU的模型划分结果为第一台GPU分得层，第二台GPU分得层/＞，第三台GPU分得层/＞，···第m台GPU分得/＞。6.根据权利要求3所述的模型并行训练中的自适应模型划分方法，其特征在于，网络层的计算量/＞是通过对神经网络模型进行预训练得到，并实时检测GPUm的计算能力/＞和GPUm-1与GPUm间的带宽/＞。7.一种模型并行训练中的自适应模型划分系统，其特征在于，包括块构建模块、分割层计算模块、模型划分模块和循环划分模块；块构建模块用于将神经网络模型的原始层划分为块，将所述块作为神经网络模型新的层结构，所述块由连续一至多个所述层构成；分割层计算模块用于以划分后各阶段的计算和通信时间最大值最小为目标，计算得到所述神经网络模型所有阶段的分割层；模型划分模块用于基于所有阶段的分割层并结合动态层迁移技术对神经网络模型进行划分，并对划分后的神经网络模型进行模型训练；循环划分模块用于实时检测GPUm-1与GPUm之间的带宽和GPUm的计算能力/＞，设定周期固定的批处理，循环分割层计算模块和模型划分模块，以周期性更新神经网络模型划分；所述的计算过程如下：/＞其中，表示使用m台机器在第1层和第/＞层之间的最优分配的情况下，最慢阶段所用的时间，/＞是第1层和第/＞层之间最优子阶段中最慢阶段所用的时间；/＞表示层/＞与层/＞之间传递激活和梯度所用的时间，/＞表示GPUm对层/＞到层/＞所需的计算时间，/＞表示GPUm对层/＞的计算时间，/＞表示网络层/＞的计算量，/＞表示层i的输出激活值，/＞表示GPUm的计算能力，/＞表示GPUm-1与GPUm间的带宽，GPUm表示第m个GPU编号，GPUm-1表示第m-1个GPU编号。8.一种模型并行训练中的自适应模型划分设备，其特征在于，所述模型划分设备包括存储器、处理器、以及存储在所述存储器上并可在所述处理器上运行的模型划分程序，所述模型划分程序配置用于实现如权利要求1至6任一所述的模型划分方法。
说明书desc
技术领域本发明涉及网络信息技术领域，尤其涉及一种模型并行训练中的自适应模型划分方法、系统及设备。背景技术随着深度学习的发展，神经网络的规模日趋庞大，而在面对越来越多的超大规模神经网络的训练时，往往需要多台机器以进行分布式训练。目前常见的分布式训练方式包括数据并行与模型并行。模型并行就是将模型拆分为若干个串行的阶段，每个分布式机器分别训练所分配的阶段，通过流水线方式将这些阶段进行串行并通过协调达到能够训练完整模型的目的。模型并行包括异步模型并行与同步模型并行。Pipedream是微软研究院开发的一种异步模型并行的框架，可以支持任意台机器进行异步模型并行。而想让模型并行训练时训练总时间最短的第一步就是通过合理划分模型使各机器分配模型中不同的层。如果模型的划分不合理会致使某个节点的训练时间远远长于其他节点，导致其他节点存在等待时间，使总训练时间变长。目前Pipedream给定的动态规划法的模型划分方法是把节点GPU看作性能相同的GPU带入进行模型划分，且是在训练之前就已经完成了的，训练开始后不再进行进一步相关模型划分。缺点一是没有考虑到训练时不同环境时GPU存在性能差异，此外本身GPU的自身性能就存在差异，在计算能力，带宽等方面可能存在显著差异，不同GPU的在训练相同的模型时的训练时间也会出现较大区别。二是认定GPU的性能是静态的，一成不变的。没有考虑到GPU的计算能力、网络带宽等性能会因资源异质性、网络波动、多任务抢占等因素而实时变化。即使是同一个GPU在这些因素的变化下也存在计算能力的变化。三是不能在训练中根据得到的模型划分算法实时进行模型划分的调整。发明内容基于背景技术存在的技术问题，本发明提出了一种模型并行训练中的自适应模型划分方法、系统及设备，实现针对不同GPU时神经网络模型实时最优划分。本发明提出的自适应模型划分方法，包括如下步骤：S1：将神经网络模型的原始层划分为块，将所述块作为神经网络模型新的层结构，所述块由连续一至多个所述层构成；S2：以划分后各阶段的计算和通信时间最大值最小为目标，计算得到神经网络模型所有阶段的分割层；S3：基于所有阶段的分割层并结合动态层迁移技术对神经网络模型进行划分，并对划分后的神经网络模型进行模型训练；S4：实时检测GPUm-1与GPUm之间的带宽和GPUm的计算能力/＞，设定周期固定的批处理，循环步骤S2至S3，以周期性更新神经网络模型划分；所述所有阶段的分割层的计算过程如下：其中，表示使用m台机器在第1层和第/＞层之间的最优分配的情况下，最慢阶段所用的时间，/＞是第1层和第/＞层之间最优子阶段中最慢阶段所用的时间；表示层/＞与层/＞之间传递激活和梯度所用的时间，/＞表示GPUm对层/＞到层所需的计算时间，/＞表示GPUm对层/＞的计算时间，/＞表示网络层/＞的计算量，/＞表示层/＞的输出激活值，/＞表示GPUm的计算能力，/＞表示GPUm-1与GPUm间的带宽，GPUm表示第m个GPU编号，GPUm-1表示第m-1个GPU编号。进一步地，在所述步骤S1：将神经网络模型的原始层划分为块之前，对神经网络模型所需参数进行定义，GPU顺序按实际拓扑顺序固定，所述参数包括；GPUm、、/＞、、/＞、/＞、/＞、/＞。进一步地，在步骤S1：将神经网络模型的原始层划分为块中，具体包括：将神经网络模型的几个连续的层视为一个整体进行分配得到块，以更新神经网络模型；对更新后的神经网络模型进行切分合并得到更新后的和/＞；将更新后的和/＞带入分割层计算过程。进一步地，在步骤S2：以划分后各阶段的计算和通信时间最大值最小为目标，计算得到神经网络模型所有阶段的分割层，具体包括：当最优分配包含多个阶段时，将所述最优分配分解为最优子阶段和最后单个阶段，所述最优子阶段由个GPU计算层1到层/＞，所述最后单个阶段由第m个GPU单独计算层/＞到层/＞；以所述最后单个阶段的计算和通信时间最大值最小为目标，计算得到所述最后单个阶段的；使用二维数组来存储/＞的相应值与最后单个阶段的/＞；基于最后单个阶段的向前追溯递推得到所述最优子阶段中所有阶段的分割层；进一步地，在所述基于最后单个阶段的向前追溯递推得到所述最优子阶段中所有阶段的分割层中，具体为：/＞由二维数组得到分割层/＞，由二维数组/＞得到，以此类推得到/＞、···/＞；m台GPU的模型划分结果为第一台GPU分得层，第二台GPU分得层，第三台GPU分得层/＞，···第m台GPU分得/＞。进一步地，网络层的计算量/＞是通过对神经网络模型进行预训练得到，并实时检测GPUm的计算能力/＞和GPUm-1与GPUm间的带宽/＞。一种模型并行训练中的自适应模型划分系统，包括块构建模块、分割层计算模块、模型划分模块和循环划分模块；块构建模块用于将神经网络模型的原始层划分为块，将所述块作为神经网络模型新的层结构，所述块由连续一至多个所述层构成；分割层计算模块用于以划分后各阶段的计算和通信时间最大值最小为目标，计算得到神经网络模型所有阶段的分割层；模型划分模块用于基于所有阶段的分割层并结合动态层迁移技术对神经网络模型进行划分，并对划分后的神经网络模型进行模型训练；循环划分模块用于实时检测GPUm-1与GPUm之间的带宽和GPUm的计算能力，设定周期固定的批处理，循环分割层计算模块和模型划分模块，以周期性更新神经网络模型划分；所述的计算过程如下：其中，表示使用m台机器在第1层和第/＞层之间的最优分配的情况下，最慢阶段所用的时间，/＞是第1层和第/＞层之间最优子阶段中最慢阶段所用的时间；表示层/＞与层/＞之间传递激活和梯度所用的时间，/＞表示GPUm对层/＞到层所需的计算时间，/＞表示GPUm对层/＞的计算时间，/＞表示网络层/＞的计算量，/＞表示层i的输出激活值，/＞表示GPUm的计算能力，/＞表示GPUm-1与GPUm间的带宽，GPUm表示第m个GPU编号，GPUm-1表示第m-1个GPU编号。一种模型并行训练中的自适应模型划分设备，所述模型划分设备包括存储器、处理器、以及存储在所述存储器上并可在所述处理器上运行的模型划分程序，所述模型划分程序配置用于实现如上所述的模型划分方法。本领域普通技术人员可以理解：实现上述方法实施例的全部或部分步骤可以通过程序指令相关的硬件来完成，前述的程序可以存储于一计算机可读取存储介质中，该程序在执行时，执行包括上述方法实施例的步骤；而前述的存储介质包括：ROM、RAM、磁碟或者光盘等各种可以存储程序代码的介质。本发明提供的一种模型并行训练中的自适应模型划分方法、系统及设备的优点在于：本发明结构中提供的一种模型并行训练中的自适应模型划分方法、系统及设备，能够根据不同GPU实时的计算能力及带宽进行模型划分的变化的目的，并且根据得到的模型划分可以结合提出的动态层迁移技术进行实时的模型划分调整而做到不中断当前训练过程，实现针对不同GPU时神经网络模型实时最优划分，使各节点间负载均衡，每个节点的模型训练时间相近，总时间更低。附图说明图1为本发明的流程图；图2为整体流程图；图3为设定新的网络层的示意图；图4为层到块的划分结果示意图。具体实施方式下面，通过具体实施例对本发明的技术方案进行详细说明，在下面的描述中阐述了很多具体细节以便于充分理解本发明。但是本发明能够以很多不同于在此描述的其他方式来实施，本领域技术人员可以在不违背本发明内涵的情况下做类似改进，因此本发明不受下面公开的具体实施的限制。对于神经网络模型划分问题，本质上是集合划分问题，集合划分问题是把m个正整数组成的集合A划分为n个互不相交的子集合A1、A2、…、An，以使子集各元素的和的最大值最小。集合划分问题是一个典型的NP完全问题，可以使用动态规划算法进行解决。动态规划方法常用于解决多阶段决策过程的最优化问题，将求解分成多阶段进行，求出的解既是全过程的解，又包括后面子过程的解。动态规划的中心思想是对每阶段都进行最优规划和资源分配，使得每一阶段任务的目标函数最小，从而使总体目标函数最小，即总体模型训练时间最短。动态规划方法解题的基本思路是将一个多阶段决策问题转化为依次求解多个单阶段的决策问题，从而简化计算过程。如图1至4所示，本发明提出的自适应模型划分方法，包括如下步骤：S1：将神经网络模型的原始层划分为块，将所述块作为神经网络模型新的层结构，所述块由连续一至多个所述层构成；该步骤中，首先对神经网络模型的所有需要的参数进行定义，GPU顺序按实际拓扑顺序固定，所述参数如下：其中是对神经网络模型进行预处理后得到的，/＞、/＞可以通过现有的检测工具实时检测得到，上表其余参数可以在如下实施例中计算得到。由于一个深度神经网络可能存在上千层，如果深度网络模型划分的颗粒度为单个层的话可能会使模型划分算法的花费时间太长，且由于神经网络的复杂性，某些神经网络层需要由同一个机器进行训练；由此我们考虑通过预训练得到神经网络结构，同时兼顾模型划分算法的花费时间与模型划分的准确性，将精细度由层变为块；将神经网络切分为若干个块，块代替层的结构进行模型划分；具体切分方法为将几个连续的层视为一个整体的块，在进行模型划分时将几个连续的层视为一个整体进行分配。需要说明的是，步骤S2至S4中所涉及到的层概念均对应为神经网络模型划分成块后所形成新的层，只是本实施例为方便描述在以下简称为层。S2：以划分后各阶段的计算和通信时间最大值最小为目标，计算得到神经网络模型所有阶段的分割层。该步骤中，在获取到神经网络模型划分方法所需参数后执行模型划分方法。模型划分的总目标是合理利用每个GPU，确定每个GPU训练的网络层使训练的总时间最短；神经网络训练需要多次迭代，为了使训练总时间最小，只需要考虑一次迭代的训练总时间最小；在多机器训练的模型并行下，训练总时间即为划分后各阶段的计算和通信时间的最大值，即划分目标为使划分后各阶段的计算和通信时间的最大值最小。假设表示使用m台机器在第1层和第/＞层之间的最优分配的情况下，最慢阶段所用的时间；/＞表示计算层/＞到层/＞的单个阶段l所用的时间；当最优分配包含多个阶段时，它可以被分解成一个最优的子问题和后续的最后单个阶段；因为传输和计算是可以重叠的，所以不需要相加，直接取最大数值；因此，利用动态规划的基本方程及最优子问题的性质，可以得到：其中，表示使用m台机器在第1层和第/＞层之间的最优分配的情况下，最慢阶段所用的时间，/＞是第1层和第/＞层之间最优子阶段中最慢阶段所用的时间，/＞是小于/＞的，1至/＞层分成了1至/＞层以及/＞至/＞层；/＞表示层/＞与层/＞之间传递激活和梯度所用的时间，与层/＞的输出激活及GPU带宽有关，/＞表示GPUm对层/＞到层/＞所需的计算时间，即对各层的计算时间累加/＞，与GPU的算力及网络层的计算量有关，/＞表示GPUm对层/＞的计算时间，即GPUm在计算层l的计算时间为层l的计算量/＞与GPUm的计算能力/＞的比，/＞表示网络层/＞的计算量，/＞表示层i的输出激活值，/＞表示GPUm的计算能力，表示GPUm-1与GPUm间的带宽，GPUm表示第m个GPU编号，GPUm-1表示第m-1个GPU编号。为了避免重复计算，将通信时间改为该阶段与上下两阶段的通信时间的最大值；最后用二维数组来存储/＞相应的值及最优子阶段与最后单个阶段的切割点/＞，从而可设计解决此问题的动态规划算法，得出相应的最优解。S3：基于所述最后单个阶段的向前回溯递推得到所述最优子阶段中所有阶段的分割层。在已知的基础上运用回溯法进行递推即可得到所有的切割点；即由二维数组得到分割层/＞，由二维数组/＞得到，以此类推得到/＞、/＞、···/＞；m台GPU的模型划分结果为第一台GPU分得层，第二台GPU分得层，第三台GPU分得层/＞，···第m台GPU分得/＞。S4：基于所有分割层并结合动态层迁移技术对神经网络模型进行划分，并对划分后的神经网络模型进行模型训练。对划分后的神经网络模型进行模型的训练过程可以采用样本集进行训练，具体训练过程可以使用现有的训练方案进行训练。S5：实时检测GPUm-1与GPUm之间的带宽和GPUm的计算能力/＞，设定周期固定的批处理，循环步骤S2至S4，以周期性更新神经网络模型划分。在运用动态层迁移技术进行模型划分后立即执行神经网络模型训练；同时实时监测GPU的性能、/＞并周期进行模型划分，设定周期固定的batch进行一次新的模型划分，在每训练周期固定的batch后根据得到新的模型划分方式结合动态层迁移技术进行实时更新模型划分。将动态规划方法代入模型划分中，可以实现针对不同GPU时神经网络模型实时最优划分。例如本实施例中，参与神经网络模型并行训练的GPU数为4个，按顺序型号分别为A100、T40、P4、P4，训练的神经网络模型为Bert，将Bert模型进行切分合并得到新的和/＞，将/＞，/＞以及更新后的/＞和/＞带入分割层的计算过程，可得/＞、/＞、/＞分别为2、5、7；即第一台GPU分得1、2层；第二台GPU分得3、4、5层；第三台GPU分得6、7层；第四台GPU分得8,9,10层，然后对划分后的神经网络模型进行模型训练，设定周期为每训练100个batch进行一次新的模型划分，在每训练100个batch后根据得到新的模型划分方式结合动态层迁移技术进行实时更新模型划分。因而本实施例考虑到GPU间计算能力差异与训练环境的变化性，模型训练时将各GPU算力与GPU间带宽进行实时监测，使得到的划分结果更结合实时环境。结合提出的动态层迁移技术，实现边训练边根据环境进行训练网络层迁移。以上所述，仅为本发明较佳的具体实施方式，但本发明的保护范围并不局限于此，任何熟悉本技术领域的技术人员在本发明揭露的技术范围内，根据本发明的技术方案及其发明构思加以等同替换或改变，都应涵盖在本发明的保护范围之内。
