标题title
识别跳舞教学视频片段的方法、装置及终端设备
摘要abst
本申请涉及互联网技术领域，公开了一种识别跳舞教学视频片段的方法、装置、终端设备、服务端及存储介质。该方法包括：在跳舞教学视频中提取音乐片段；将音乐片段的音频特征与其完整音乐音频的音频特征进行匹配处理，得到第一结果；将音乐片段的歌词与其完整音乐音频的歌词进行匹配处理，得到第二结果；基于第一结果和第二结果，确定音乐片段所属的演示子视频在跳舞教学视频中的起、止位置；将演示子视频识别为正面或背面演示；在跳舞教学视频中提取纯人声片段；确定纯人声片段所属的教学子视频在跳舞教学视频中的起、止位置；将教学子视频识别为正面或背面教学。利用本申请能够高效准确地确定跳舞教学视频中的各个分段教学视频。
权利要求书clms
1.一种识别跳舞教学视频片段的方法，其特征在于，所述跳舞教学视频中包括用于跳舞演示的演示子视频和用于跳舞教学的教学子视频，所述演示子视频仅包括音乐片段，所述教学子视频仅包括纯人声片段；所述识别跳舞教学视频片段的方法包括：在跳舞教学视频中提取第一音乐片段；将所述第一音乐片段的音频特征与其完整音乐音频的音频特征进行匹配处理，得到第一匹配结果，所述第一匹配结果包括所述第一音乐片段在其完整音乐音频中可能的位置信息；将所述第一音乐片段的歌词与其完整音乐音频的歌词进行匹配处理，得到第二匹配结果，所述第二匹配结果包括所述第一音乐片段在其完整音乐音频中可能的位置信息；基于第一匹配结果和第二匹配结果，确定所述第一音乐片段所属的演示子视频在所述跳舞教学视频中的起始位置和终止位置；基于所述演示子视频中跳舞演示者的特征将所述演示子视频识别为正面演示或背面演示；在所述跳舞教学视频中提取第一纯人声片段；通过扩大所述第一纯人声片段的时长并判断扩大后是否仍为纯人声片段的方式，确定所述第一纯人声片段所属的教学子视频在所述跳舞教学视频中的起始位置和终止位置；以及基于所述教学子视频中跳舞教学者的特征将所述教学子视频识别为正面教学或背面教学。2.根据权利要求1所述的方法，其特征在于，其中，在教学视频中提取第一音乐片段或第一纯人声片段时，进一步包括：在所述跳舞教学视频中随机提取目标音频片段，判断目标音频片段是否仅包括一种声音；当目标音频片段包括多种声音时，将目标音频片段时长折半处理，直至目标音频片段仅包括一种声音；以及确定仅包括一种声音的目标音频片段为第一音乐片段或第一纯人声片段。3.根据权利要求1所述的方法，其特征在于，其中，基于所述第一匹配结果和所述第二匹配结果无法确定第一音乐片段所属的演示子视频在所述跳舞教学视频中的起始位置和终止位置时，扩大所述第一音乐片段的时长后重新匹配直至能够确定第一音乐片段所属的演示子视频在跳舞教学视频中的起始位置和终止位置。4.根据权利要求1所述的方法，其特征在于，其中，将所述第一音乐片段的歌词与其完整音乐音频的歌词进行匹配处理，得到第二匹配结果，包括：在第一音乐片段对应的关键帧图像中提取文本信息；在文本信息中获得第一音乐片段的歌词并与其完整音乐音频的歌词匹配得到第二匹配结果。5.根据权利要求4所述的方法，其特征在于， 其中，当所述文本信息中包括报幕文本时，在跳舞教学视频中重新提取第一音乐片段。6.根据权利要求1所述的方法，其特征在于， 其中，当所述演示子视频中包括跳舞演示者的正脸时，确定所述演示子视频为正面演示，否则为背面演示和/或当所述教学子视频包括跳舞教学者的正脸时，确定所述教学子视频为正面教学，否则为背面教学。7.根据权利要求1所述的方法，其特征在于，其中， 当所述演示子视频包括多个不同的跳舞演示者时，确定所述演示子视频为多人跳舞视频。8.一种识别跳舞教学视频片段的装置，其特征在于，包括：第一提取模块，用于在跳舞教学视频中提取第一音乐片段；匹配模块，用于将所述第一音乐片段的音频特征与其完整音乐音频的音频特征进行匹配处理，得到第一匹配结果，所述第一匹配结果包括所述第一音乐片段在其完整音乐音频中可能的位置信息；将所述第一音乐片段的歌词与其完整音乐音频的歌词进行匹配处理，得到第二匹配结果，所述第二匹配结果包括所述第一音乐片段在其完整音乐音频中可能的位置信息；第一确定模块，用于基于第一匹配结果和第二匹配结果，确定所述第一音乐片段所属的演示子视频在所述跳舞教学视频中的起始位置和终止位置；第一识别模块，用于基于所述演示子视频中跳舞演示者的特征将所述演示子视频识别为正面演示或背面演示；第二提取模块，用于在所述跳舞教学视频中提取第一纯人声片段；第二确定模块，用于通过扩大所述第一纯人声片段的时长并判断扩大后是否仍为纯人声片段的方式，确定所述第一纯人声片段所属的教学子视频在所述跳舞教学视频中的起始位置和终止位置；以及第二识别模块，用于基于所述教学子视频中跳舞教学者的特征将所述教学子视频识别为正面教学或背面教学。9.一种终端设备，其特征在于，包括：处理器以及存储有计算机程序指令的存储器；所述处理器执行所述计算机程序指令时实现如权利要求1-7中任一项所述的方法。10.一种计算机可读存储介质，其特征在于，所述计算机可读存储介质上存储有计算机程序指令，所述计算机程序指令被处理器执行时实现如权利要求1-7中任一项所述的方法。11.一种计算机程序产品，其特征在于，其包括计算机程序指令，所述计算机程序指令被处理器执行时实现如权利要求1-7中任一项所述的方法。
说明书desc
技术领域本申请涉及互联网技术领域，具体涉及视频处理技术，尤其涉及一种识别跳舞教学视频片段的方法、装置、终端设备、计算机可读存储介质及计算机程序产品。背景技术用户通过终端设备观看视频，可以学习各种知识，增加自己的见识和知识面。对于教学类视频，通常是指围绕特定主题进行教学或授课为主的视频，通常这类教学视频可视为包含多个部分，例如，对于阅读类的教学视频，整个视频可视为包含多个章节，对于舞蹈类的教学视频，整个视频可视为包含多组舞蹈动作。通过对教学视频进行打点分段，对完整视频中的多个教学部分进行标识，用户可以快速定位至想要观看的位置，学习感兴趣的教学内容。但是，现有的视频打点分段，通常采用人工打点的方式，针对每一个视频需要工作人员从头到尾观看播放，对视频中不同部分进行打点和分段，对每一部分输入对应的标签。这种人工打点的方式消耗大量时间和人力，并且容易出现打点错误、标签与视频分段内容不一致等问题。发明内容有鉴于此，本申请实施例提供一种识别跳舞教学视频片段的方法、装置、服务端设备、计算机可存储介质及计算机程序产品，用于解决至少一种技术问题。第一方面，本申请实施例提供一种识别跳舞教学视频片段的方法，所述跳舞教学视频中包括用于跳舞演示的演示子视频和用于跳舞教学的教学子视频，所述演示子视频仅包括音乐片段，所述教学子视频仅包括纯人声片段；所述识别跳舞教学视频片段的方法包括：在跳舞教学视频中提取第一音乐片段；将所述第一音乐片段的音频特征与其完整音乐音频的音频特征进行匹配处理，得到第一匹配结果，所述第一匹配结果包括所述第一音乐片段在其完整音乐音频中可能的位置信息；将所述第一音乐片段的歌词与其完整音乐音频的歌词进行匹配处理，得到第二匹配结果，所述第二匹配结果包括所述第一音乐片段在其完整音乐音频中可能的位置信息；基于第一匹配结果和第二匹配结果，确定所述第一音乐片段所属的演示子视频在所述跳舞教学视频中的起始位置和终止位置；基于所述演示子视频中跳舞演示者的特征将所述演示子视频识别为正面演示或背面演示；在所述跳舞教学视频中提取第一纯人声片段；通过扩大所述第一纯人声片段的时长并判断扩大后是否仍为纯人声片段的方式，确定所述第一纯人声片段所属的教学子视频在所述跳舞教学视频中的起始位置和终止位置；基于所述教学子视频中跳舞教学者的特征将所述教学子视频识别为正面教学或背面教学。根据本申请实施例的方法，在教学视频中提取第一音乐片段或第一纯人声片段时，进一步包括： 在所述跳舞教学视频中随机提取目标音频片段，判断目标音频片段是否仅包括一种声音；当目标音频片段包括多种声音时，将目标音频片段时长折半处理，直至目标音频片段仅包括一种声音；确定仅包括一种声音的目标音频片段为第一音乐片段或第一纯人声片段。根据本申请实施例的方法，基于所述第一匹配结果和所述第二匹配结果无法确定第一音乐片段所属的演示子视频在所述跳舞教学视频中的起始位置和终止位置时，扩大所述第一音乐片段的时长后重新匹配直至能够确定第一音乐片段所属的演示子视频在跳舞教学视频中的起始位置和终止位置。根据本申请实施例的方法，将所述第一音乐片段的歌词与其完整音乐音频的歌词进行匹配处理，得到第二匹配结果，包括：在第一音乐片段对应的关键帧图像中提取文本信息；在文本信息中获得第一音乐片段的歌词并与其完整音乐音频的歌词匹配得到第二匹配结果。根据本申请实施例的方法，当所述文本信息中包括报幕文本时，在跳舞教学视频中重新提取第一音乐片段。根据本申请实施例的方法，当所述演示子视频中包括跳舞演示者的正脸时，确定所述演示子视频为正面演示，否则为背面演示和/或当所述教学子视频包括跳舞教学者的正脸时，确定所述教学子视频为正面教学，否则为背面教学。根据本申请实施例的方法， 当所述演示子视频包括多个不同的跳舞演示者时，确定所述演示子视频为多人跳舞视频。第二方面，本申请实施例提供一种识别跳舞教学视频片段的装置，包括：第一提取模块，用于在跳舞教学视频中提取第一音乐片段；匹配模块，用于将所述第一音乐片段的音频特征与其完整音乐音频的音频特征进行匹配处理，得到第一匹配结果，所述第一匹配结果包括所述第一音乐片段在其完整音乐音频中可能的位置信息；将所述第一音乐片段的歌词与其完整音乐音频的歌词进行匹配处理，得到第二匹配结果，所述第二匹配结果包括所述第一音乐片段在其完整音乐音频中可能的位置信息；第一确定模块，用于基于第一匹配结果和第二匹配结果，确定所述第一音乐片段所属的演示子视频在所述跳舞教学视频中的起始位置和终止位置；第一识别模块，用于基于所述演示子视频中跳舞演示者的特征将所述演示子视频识别为正面演示或背面演示；第二提取模块，用于在所述跳舞教学视频中提取第一纯人声片段；第二确定模块，用于通过扩大所述第一纯人声片段的时长并判断扩大后是否仍为纯人声片段的方式，确定所述第一纯人声片段所属的教学子视频在所述跳舞教学视频中的起始位置和终止位置；第二识别模块，用于基于所述教学子视频中跳舞教学者的特征将所述教学子视频识别为正面教学或背面教学。第三方面，本申请的实施例提供一种终端设备，其特征在于，包括：处理器以及存储有计算机程序指令的存储器；所述处理器执行所述计算机程序指令时实现如上所述的方法。第四方面，本申请的实施例提供一种计算机可读存储介质，其特征在于，所述计算机存储介质上存储有计算机程序指令，所述计算机程序指令被处理器执行时实现如上所述的方法。第五方面，本申请的实施例提供一种计算机程序产品，其特征在于，其包括计算机程序指令，所述计算机程序指令被处理器执行时实现如上所述的方法。本申请的实施例针对跳舞教学视频进行打点分段，通过对跳舞教学视频文件中包含的音频和文本进行识别，确定跳舞教学视频中的舞蹈动作演示片段的起止位置，并通过对跳舞演示者的特征识别判断是正面演示还是背面演示；并且，本申请的实施例还通过对跳舞教学视频文件中的纯人声片段的识别，确定教学视频中的讲解片段的起止位置，并可判断是正面教学还是背面教学。照此打点分段之后，能够方便用户快速定位到舞蹈动作演示片段以及带人声讲解的片段，方便用户集中学习舞蹈的正面动作以及背面动作，操作十分便捷。利用本申请实施例提供的方法对跳舞教学视频进行自动打点分段，能够大幅减少视频处理过程中由人为因素引入的错误操作，不仅能够高效、准确地确定跳舞教学视频中的每个分段视频，还节省人工成本。附图说明为了更清楚地说明本申请实施例的技术方案，以下对本申请实施例中的附图作简单介绍。图1是根据本申请实施例的识别跳舞教学视频片段方法的流程框图。图2是根据本申请实施例的提取第一音乐片段或第一纯人声片段方法的流程框图。图3是根据本申请实施例的歌词匹配方法的流程框图。图4是根据本申请实施例的跳舞教学视频时间轴的结构示意图。图5是根据本申请实施例的确定音频片段为单一声音的结构示意图。图6是根据本申请实施例的确定音乐片段在完整音乐音频中可能的位置结构示意图。图7是根据本申请实施例的在视频关键帧中提取歌词界面示意图。图8是根据本申请实施例的识别跳舞教学者的界面示意图。图9是根据本申请实施例的识别跳舞教学者特征的界面示意图。图10是根据本申请实施例的识别跳舞教学视频片段的装置的结构示意图。图11是根据本申请实施例的终端设备的结构示意图。图12是根据本申请实施例的终端设备的软件结构示意图。具体实施方式以下将参考若干示例性实施方式来描述本申请的原理和精神。应当理解，提供这些实施方式的目的是为了使本申请的原理和精神更加清楚和透彻，使本领域技术人员能够更好地理解进而实现本申请的原理和精神。本文中提供的示例性实施方式仅是本申请的一部分实施方式，而不是全部的实施方式。基于本文中的实施方式，本领域普通技术人员在不付出创造性劳动前提下所获得的所有其他实施方式，都属于本申请保护的范围。本领域技术人员知晓，本申请的实施方式可以实现为一种系统、装置、设备、方法、计算机可读存储介质或计算机程序产品。因此，本申请可以具体实现为以下至少一种形式：完全的硬件、完全的软件，或者硬件与软件结合的形式。根据本申请的实施方式，本申请请求保护一种识别跳舞教学视频片段的方法、装置、终端设备、服务端及计算机可读存储介质。在本文中，诸如第一、第二、第三之类的用语，仅用来将一个实体与另一个实体区分开来，而不在于要求或暗示这些实体之间存在任何顺序或关联。本申请中的跳舞教学视频包括：用于跳舞演示的演示子视频和用于跳舞教学的教学子视频，其中演示子视频仅包括音乐片段，音乐片段即与跳舞动作相匹配的配乐；教学子视频中仅包括纯人声片段，纯人声片段即跳舞教学者在演示跳舞动作时讲解的声音。本方法针对跳舞教学视频的特点，采用音频识别、文本识别、图像识别等手段，快速对跳舞教学视频进行打点分段，并对每个分段标注相应的标签。基于本发明构思，本申请提出一种识别跳舞教学视频片段的方法。图1是根据本申请实施例的识别跳舞教学视频片段方法的流程框图，包括以下步骤：S101，在跳舞教学视频中提取第一音乐片段；S102，将该第一音乐片段的音频特征与其完整音乐音频的音频特征进行匹配处理，得到第一匹配结果，该第一匹配结果包括该第一音乐片段在其完整音乐音频中可能的位置信息；S103，将该第一音乐片段的歌词与其完整音乐音频的歌词进行匹配处理，得到第二匹配结果，该第二匹配结果包括该第一音乐片段在其完整音乐音频中可能的位置信息；S104，基于第一匹配结果和第二匹配结果，确定该第一音乐片段所属的演示子视频在该跳舞教学视频中的起始位置和终止位置；S105，基于该演示子视频中跳舞演示者的特征将该演示子视频识别为正面演示或背面演示；S106，在该跳舞教学视频中提取第一纯人声片段；S107，通过扩大该第一纯人声片段的时长并判断扩大后是否仍为纯人声片段的方式，确定该第一纯人声片段所属的教学子视频在该跳舞教学视频中的起始位置和终止位置；S108，基于该教学子视频中跳舞教学者的特征将该教学子视频识别为正面教学或背面教学。在跳舞教学视频中随机提取一段音乐片段，音乐片段中仅包括音乐而不包括人声。若该音乐片段包括人声，则需要重选提取。利用音频特征识别法确定第一匹配结果即音乐片段在其完整音乐音频中可能的位置信息；利用文本识别法确定第二匹配结果即音乐片段在其完整音乐音频中可能的位置信息。通过第二匹配结果对第一匹配结果进行校对，共同确定该音乐片段所属的演示子视频在跳舞教学视频中的起始位置和终止位置。通过第二匹配结果对第一匹配结果进行校验，能够提高匹配准确度。采用图像识别法确定演示子视频为正面演示或背面演示，并将正面演示或背面演示标签与该演示子视频关联。本申请采用音频特征识别法、文本识别法和图像识别法在跳舞教学视频中快速确定演示子视频的起、止位置，具有识别效率高、人工成本低等优点。在跳舞教学视频中随机提取一段纯人声片段，利用扩大音频时长法确定该纯人声片段所属的教学子视频在跳舞教学视频中的起始位置和终止位置，采用图像识别法确定教学子视频为正面教学或背面教学，并将正面教学或背面教学标签与该教学子视频关联。本申请采用扩大音频时长法和图像识别法在跳舞教学视频中快速确定教学子视频的起、止位置，能够提高识别效率，并且准确率高。图2是根据本申请实施例的提取第一音乐片段或第一纯人声片段方法的流程框图，包括以下步骤：S201，在该跳舞教学视频中随机提取目标音频片段，判断目标音频片段是否仅包括一种声音；S202，当目标音频片段包括多种声音时，将目标音频片段时长折半处理，直至目标音频片段仅包括一种声音；S203，确定仅包括一种声音的目标音频片段为第一音乐片段或第一纯人声片段。在跳舞教学视频中可以随机提取一段目标音频片段，通过折半处理的方式，找到仅包括单一声音的音频片段，然后利用传统方法或者深度学习方法判断此音乐片段是第一音乐片段或第一人声片段。利用上述方法，能够快速提取一段仅包括单一声音的音频片段，准确确认该音频片段的类型。在本申请的实施例中，基于该第一匹配结果和该第二匹配结果无法确定第一音乐片段所属的演示子视频在该跳舞教学视频中的起始位置和终止位置时，扩大该第一音乐片段的时长后重新匹配直至能够确定第一音乐片段所属的演示子视频在跳舞教学视频中的起始位置和终止位置。一般通过第一匹配结果和第二匹配结果，能够大概率确定第一音乐片段所属的演示子视频在该跳舞教学视频中的起始位置和终止位置。但是在特殊情况下，无法确定时，通过扩大时长的方式重新匹配，保证任何一段音乐片段均能够确定其所属的演示子视频在跳舞教学视频中的起始位置和终止位置，上述方法具有通用性，解决了特殊情况下无法识别的问题。图3是根据本申请实施例的歌词匹配方法的流程框图，包括以下步骤包括：S301，在第一音乐片段对应的关键帧图像中提取文本信息；S302，在文本信息中获得第一音乐片段的歌词并与其完整音乐音频的歌词匹配得到第二匹配结果。关键帧图像中包括报幕文本、歌词和logo中的一者或多者。可以利用OCR文字识别技术将关键帧图像中的文本信息提取出来，并识别出歌词，利用识别出的歌词与其完整音频的歌词匹配得到第二匹配结果。其中，可以通过在关键帧图像特定位置提取文本确定为歌词。在本申请的实施例中，当该文本信息中包括报幕文本时，在跳舞教学视频中重新提取第一音乐片段。报幕文本即跳舞教学者在教学时，讲解的字幕。当第一音乐片段对应的图像中包括报幕文本时，则说明第一音乐片段包括人声，此时需要重新提取第一音乐片段。通过上述方法，能够校验第一音乐片段是否仅包括一种声音，进而提高分段准确性。在本申请的实施例中，当该演示子视频中包括跳舞演示者的正脸时，确定该演示子视频为正面演示，否则为背面演示和/或当该教学子视频包括跳舞教学者的正脸时，确定该教学子视频为正面教学，否则为背面教学。根据跳舞表演者正脸的特征，能够快速确定是否为视频为正面视频或背面视频。在本申请的实施例中，当该演示子视频包括多个不同的跳舞演示者时，确定该演示子视频为多人跳舞视频。在演示视频中，可以是多个跳舞演示者组成舞队跳舞的情况。因此，将识别出有多个不同的跳舞演示者视为多人跳舞视频并将该标签与该视频片段关联，使得视频分类更加科学和准确。为了更清楚地说明本申请实施例可取得的优势，以下基于具体的例子，对本申请实施例的处理过程进行详细描述。图4是根据本申请实施例的跳舞教学视频时间轴的结构示意图。如图4所示，跳舞教学视频分解为视频帧和音频数据，视频帧与音频数据在时间轴上一一对应。其中，跳舞教学视频包括片头、正面演示视频、背面演示视频、正面教学视频、背面教学视频和片尾。片头和片尾的时长均为已知的固定时长，在识别视频片段时，可以在视频的头部和尾部根据固定时长，确定其与其他视频段的分界点。演示子视频包括正面演示视频和背面演示视频；教学子视频包括正面教学视频和背面教学视频。利用音频特征识别法和文本识别法，能够识别出演示子视频在跳舞教学视频中的起始位置和终止位置，然后利用图像识别法确定演示子视频具体为正面演示视频或背面演示视频。利用扩大音频时长法能够确定教学子视频在跳舞教学视频中的起始位置和终止位置，然后利用图像识别法能够确定教学子视频具体为正面教学视频或背面教学视频。因此，利用本申请的识别视频分段的方法，能够确定跳舞教学视频中任一种子视频的时长、在完整视频的具体位置以及该视频中的内容类型，实现完全的自动化识别，节省大量的人工成本，提高识别分段的效率。本领域的技术人员应当理解，跳舞教学视频包括片头、正面演示视频、背面演示视频、正面教学视频、背面教学视频和片尾视频中的一者或多者，并且正面演示视频、背面演示视频、正面教学视频、背面教学视频的播放顺序不固定，可以根据实际需求而调整。图5是根据本申请实施例的确定音频片段为单一声音的结构示意图。如图5所示，在跳舞教学视频的音频数据中随机提取一段音频片段。一般而言，音频片段包括音乐、人声和无声三种声音。在演示子视频中仅包括音乐；在教学子视频中仅包括人声和无声。 根据本申请的一个实施例，可以采用频谱分析法、深度学习法、基于统计学的方法和机器学习的方法中的一种或多种识别音频的类型。因为演示视频中，全程均有音乐，而教学视频中，跳舞教学者在讲解时，可能存在间歇、停顿的情况，因此将无声音频视为纯人声音频。参考图5，提取的音频片段判断包括歌声、人声和无声多种声音，利用折半查找法将该音频片段折半处理继续判断，经过判断，1/2处左半部分音频依然包括歌声和人声，而1/2处右半部分音频依然包括人声和无声。则对1/2处左半部分音频继续折半处理，对1/4处左半部分音频片段继续识别，结果仅包括歌声，则将单一声音片段501判断为音乐片段。其中，折半处理法即二分查找法，其基本思想为：将数组从中间分开，如果在数组的左半部分查找，判断是否仅包括一种声音，若是，则停止查找，否则在数组的右半部分继续执行查找。不断重复这个过程，直到找到一个仅包括单一声音的音频片段。图6是根据本申请实施例的确定音乐片段在完整音乐音频中可能的位置结构示意图。当单一声音片段501为音乐片段时，获得其完整音乐音频并分别获得单一声音片段501和完整音乐音频的音频特征。其中，完整音乐音频包括歌词文本。将单一声音片段501的音频特征和完整音乐音频的音频特征进行匹配，比较相似度，超过预设阈值则认为相同。通过匹配，在完整音乐音频上找到音乐片段502和音乐片段503与单一声音片段501相似度较高。图7是根据本申请实施例的在视频关键帧中提取歌词界面示意图。如图7所示，视频关键帧中包括多种文本信息，比如logo，歌曲字幕和其他文本。根据本申请的一个实施例，利用OCR文本识别技术提取关键帧中的文本信息。因为提取的文本信息包括多种类型，比如logo、报幕文本和其他文本均不是本次提取的有用信息，需要在多种文本信息中筛选出歌词本文。在本申请的跳舞教学视频中，歌词文本一般设置在视频的底部位置，因此可以通过提取特定区域的文本作为目标文本即只提取视频底部区域的文本作为歌词，从而缩短提取文本信息的时间，提高工作效率。例如，图7为单一声音片段501对应的一张关键帧图像。在图7中提取歌词，将提取的歌词与完整音乐音频中的歌词进行匹配，获取校验音乐片段，将校验音乐片段分别与音乐片段502和音乐片段503匹配，假设校验音乐片段与音乐片段503匹配，小于设定阈值范围，则确定音乐片段503与单一声音片段501相同。通过音乐片段503在完整音乐音频上的时间线、完整音乐音频的总时长和单一声音片段501在完整跳舞教学视频中的时间线共同确定单一声音片段501对应演示子视频在完整跳舞教学视频中的起始位置和终止位置。其中，时间线即音乐片段和/或视频片段在对应完整文件中的具体时间位置。例如，音乐片段502的时间线为在完整音乐音频上00:42-01:27的时间段。当单一声音片段501为纯人声片段时，向前和/或向后查找，扩大单一声音片段501的时长，并判断是否是纯人声片段，重新确定纯人声片段的边界，直到纯人声片段的边界是不同的音频段，确定该时间线边界为某一个视频分段片段的切分点。利用扩大时长法，能够确定教学子视频在完整跳舞教学视频中的起、止位置。虽然，通过上述方法能够确定演示子视频和教学子视频在完整跳舞教学视频中的起、止位置，但是，无法确定演示子视频为正面演示视频，还是背面演示视频。另外，上述方法识别出的教学子视频中可能包括正面教学视频和背面教学视频，还需要继续识别正面教学视频和背面教学视频之间的分界位置。本申请通过图像识别法以确认为正面视频或背面视频，具体参考以下内容：图8是根据本申请实施例的识别跳舞教学者的界面示意图。图9是根据本申请实施例的识别跳舞教学者特征的界面示意图。识别演示子视频在演示子视频中随机提取一关键帧图像，根据传统学习方法或者深度学习方法识别该图像是否存在完整跳舞人员。如图8所示，若存在，利用方框对完整跳舞人员进行标定。然后继续标定跳舞人员的人脸位置，如图9所示，利用方框对跳舞人员的脸部进行标定。当识别出人脸时，则将该子视频识别为正面演示视频，当识别结果为无脸或侧脸时，则将该子视频识别为背面演示视频。如果识别出多个不同的人脸时，将该子视频识别为多人正面演示视频，如果识别出多个不同的完整跳舞人员，且识别结果为无脸或侧脸，将该子视频识别为多人背面演示视频。识别教学子视频对教学子视频中提取全部或部分关键帧图像，根据传统学习方法或者深度学习方法识别该图像是否存在完整跳舞人员，若存在，则继续标定跳舞人员的人脸位置，通过检测多张关键帧图像中是否有人脸，确定教学子视频中正面教学视频与背面教学视频之间的分界点。并将识别结果有人脸的部分确定为正面教学视频，将识别结果为无脸或侧脸的部分确定为背面教学识别。利用图像识别法，能够快速、准确识别出目标视频为正面视频或背面视频，提高分段打点的工作效率。图10是根据本申请实施例的识别跳舞教学视频片段的装置的结构示意图。如图10所示，识别跳舞教学视频片段的装置100包括：第一提取模块110，用于在跳舞教学视频中提取第一音乐片段；匹配模块120，用于将所述第一音乐片段的音频特征与其完整音乐音频的音频特征进行匹配处理，得到第一匹配结果，所述第一匹配结果包括所述第一音乐片段在其完整音乐音频中可能的位置信息；将所述第一音乐片段的歌词与其完整音乐音频的歌词进行匹配处理，得到第二匹配结果，所述第二匹配结果包括所述第一音乐片段在其完整音乐音频中可能的位置信息；第一确定模块130，用于基于第一匹配结果和第二匹配结果，确定所述第一音乐片段所属的演示子视频在所述跳舞教学视频中的起始位置和终止位置；第一识别模块140，用于基于所述演示子视频中跳舞演示者的特征将所述演示子视频识别为正面演示或背面演示；第二提取模块150，用于在所述跳舞教学视频中提取第一纯人声片段；第二确定模块160，用于通过扩大所述第一纯人声片段的时长并判断扩大后是否仍为纯人声片段的方式，确定所述第一纯人声片段所属的教学子视频在所述跳舞教学视频中的起始位置和终止位置；第二识别模块170，用于基于所述教学子视频中跳舞教学者的特征将所述教学子视频识别为正面教学或背面教学。需要注意，所属领域的技术人员可以清楚地了解到，为了描述的方便和简洁，上述描述的系统、模块和单元的具体工作过程，可以参考前述方法实施例中的对应过程，在此不再赘述。本领域技术人员应理解，本文中所描述的实施例属于优选实施例，所涉及的动作、步骤、模块或单元等并不一定是本申请实施例所必须的。在上述实施例中，本申请实施例对各个实施例的描述都各有侧重，某个实施例中没有详述的部分，可以参见其他实施例的相关描述。图11是根据本申请实施例的终端设备的结构示意图。终端设备10包括处理器11、存储器12以及用于连接处理器11和存储器12的通信总线，其中在存储器12中存储有可以在处理器11上运行的计算机程序，处理器11运行该计算机程序时可执行或称实现本申请中各个实施例的方法中的步骤。终端设备10可以是本申请实施例中的服务器，终端设备10也可以是云端服务器。终端设备10也可以是本申请实施例中的AR设备。在合适的情况下终端设备也可称为计算设备。终端设备10还包括通信接口，用于接收和发送数据。在一些实施例中，处理器11可以是中央处理器、图形处理器、应用处理器、调制解调处理器、图像信号处理器、控制器、视频编解码器、数字信号处理器、基带处理器、神经网络处理器等；处理器11还可以是其他通用处理器、专用集成电路、现成可编程门阵列或其他可编程逻辑器件、分立门或晶体管逻辑器件、分立硬件组件等。通用处理器可以是微处理器，也可以是任何常规的处理器等。其中，神经网络处理器NPU通过借鉴生物神经网络结构，可对输入信息快速处理，还可以不断进行自我学习。通过NPU终端设备10可以实现智能认知等应用，例如图像识别、人脸识别、语义识别、语音识别、文本理解等。在一些实施例中，存储器12可以是终端设备10的内部存储单元，例如终端设备10的硬盘或内存；存储器12也可以是终端设备10的外部存储设备，例如终端设备10上配备的插接式硬盘、智能存储卡、安全数字卡、闪存卡等。存储器12还可以既包括终端设备10的内部存储单元也包括外部存储设备。存储器12可用于存储操作系统、应用程序、引导装载程序、数据以及其他程序等，例如计算机程序的程序代码等。存储器12包括但不限于是随机存储记忆体、只读存储器、可擦除可编程只读存储器或便携式只读存储器。存储器12用于存储终端设备10所执行的程序代码和所传输的数据。存储器12还可以用于暂时地存储已经输出或者将要输出的数据。本领域技术人员可以理解，图11仅是终端设备10的举例，并不构成对终端设备10的限定，终端设备10可以包括比图示更多或更少的部件，或者组合某些部件，或者包括不同的部件，例如还可以包括输入输出设备、网络接入设备等。图12是根据本申请实施例的终端设备的软件结构示意图。以手机操作系统为Android系统为例，在一些实施例中，将Android系统分为四层，分别为：应用程序层、应用程序框架层、系统层以及硬件抽象层，层与层之间通过软件接口通信。首先，应用程序层可以包括多个应用程序包，应用程序包可以是例如通话、相机、视频、导航、天气、即时通讯、教育等各种应用程序app，也可以是基于AR技术的应用程序app。第二，应用程序框架层FWK为应用程序层的应用程序提供应用编程接口和编程框架。应用程序框架层可以包括一些预先定义的函数，例如用于接收应用程序框架层所发送的事件的函数。应用程序框架层可以包括窗口管理器、资源管理器以及通知管理器等。其中，窗口管理器用于管理窗口程序。窗口管理器可以获取显示屏大小，判断是否有状态栏，锁定屏幕，截取屏幕等。内容提供器用来存放和获取数据，并使这些数据可以被应用程序访问。所述数据可以包括视频，图像，音频，拨打和接听的电话，浏览历史和书签，电话簿等。其中，资源管理器为应用程序提供各种资源，比如本地化字符串，图标，图片，布局文件，视频文件等等。其中，通知管理器使应用程序可以在状态栏中显示通知信息，可以用于传达告知类型的消息，可以短暂停留后自动消失，无需用户交互。比如通知管理器被用于告知下载完成，消息提醒等。通知管理器还可以是以图表或者滚动条文本形式出现在系统顶部状态栏的通知，例如后台运行的应用程序的通知，还可以是以对话窗口形式出现在屏幕上的通知。例如在状态栏提示文本信息，发出提示音，电子设备振动，指示灯闪烁等。此外，应用程序框架层还可以包括视图系统，视图系统包括可视控件，例如显示文字的控件、显示图片的控件等。视图系统可用于构建应用程序。显示界面可以由一个或多个视图组成的，例如短信通知图标的显示界面上可以包括显示文字的视图以及显示图片的视图。第三，系统层可以包括多个功能模块，例如传感器服务模块、物理状态识别模块、三维图形处理库，等等。其中，传感器服务模块用于对硬件层各类传感器上传的传感器数据进行监测，确定手机的物理状态；物理状态识别模块用于对用户手势、人脸等进行分析和识别；三维图形处理库用于实现三维图形绘图，图像渲染，合成，和图层处理等。此外，系统层还可以包括表面管理器和媒体库。表面管理器用于对显示子系统进行管理，并且为多个应用程序提供了2D和3D图层的融合。媒体库支持多种常用的音频，视频格式回放和录制，以及静态图像文件等。最后，硬件抽象层是硬件和软件之间的层。硬件抽象层可以包括显示驱动、摄像头驱动、传感器驱动等，用于驱动硬件层的相关硬件，如显示屏、摄像头、传感器等。本申请实施例还提供一种计算机可读存储介质，其存储有计算机程序或指令，该计算机程序或指令被执行时以实现上述实施例中所设计的方法中的步骤。本申请实施例还提供一种计算机程序产品，包括计算机程序或指令，该计算机程序或指令被执行时以实现上述实施例中所设计的方法中的步骤。示例性的，该计算机程序产品可以为一个软件安装包。关于上述实施例中描述的各个装置/产品，其中包含的模块/单元可以是软件模块/单元，也可以是硬件模块/单元，还可以部分是软件模块/单元，部分是硬件模块/单元。例如，对于应用或集成于芯片的装置/产品，其包含的各个模块/单元可以都用电路等硬件的方式实现，或者，至少部分模块/单元采用软件程序的方式实现，运行于芯片内部集成的处理器，剩余的部分模块/单元采用电路等硬件方式实现。又如，对于应用或集成于终端的装置/产品，其包含的各个模块/单元可以都采用电路等硬件的方式实现，或者，至少部分模块/单元采用软件程序的方式实现，运行于终端内部集成的处理器，剩余部分模块/单元可以采用电路等硬件方式实现。以上所述，仅为本申请的具体实施方式，所属领域的技术人员可以清楚地了解到，为了描述的方便和简洁，上述描述的系统、模块和单元的具体工作过程，可以参考前述方法实施例中的对应过程，在此不再赘述。应理解，本申请的保护范围并不局限于此，任何熟悉本技术领域的技术人员在本申请揭露的技术范围内，可轻易想到各种等效的修改或替换，这些修改或替换都应涵盖在本申请的保护范围之内。
