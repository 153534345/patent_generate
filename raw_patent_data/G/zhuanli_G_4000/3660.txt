标题title
一种基于几何约束下区域搜索的图像配准方法
摘要abst
本发明针对相对位置固定的红外可见光双目成像应用场景，提出了一种几何约束下基于区域搜索图像配准方法。首先利用相机标定信息进行立体校正，使红外可见光二者处于同一高度之上，接着利用相位一致性计算鲁棒的边缘图，在边缘图的基础上，提出两阶段同名特征点搜索方法完成精确高效红外可见光图像配准。通过与其他算法在不同场景上的数据进行实验，结果表明相较于其他异源图像配准算法，本发明方法能够适用于红外可见光双目成像的配准，在不同场景的图像都保证了特征点匹配数量和配准效果，并且能很好适应弱光环境下的图像配准工作，相对于其他算法取得了明显的优势。
权利要求书clms
1.一种基于几何约束下区域搜索的图像配准方法，其特征在于，包括如下步骤：步骤1，红外和可见光图像立体校正：利用相机标定得到的红外和可见光相机的内参和外参，通过立体校正可将红外和可见光图像约束到同一高度之上；步骤2，基于相位一致性获取图像的边缘特征图：在步骤1校正后图像的基础上，计算红外和可见光图像的相位一致性相应图，并计算最大矩获得鲁棒的边缘特征图像，得到红外边缘图像Iiredge和可见光边缘图像Ivisedge；步骤3，红外边缘图像特征点提取：在红外边缘图像进行FAST特征点的提取，并剔除掉原红外图像中背景中的无用特征点，同时在设定的邻域范围内使用非极大值抑制策略，得到特征点分布更加均匀的特征点集Vir；步骤4，两阶段特征点搜索匹配：先以NCC为衡量相似性指标计算两边缘图整体水平偏移参数，进一步减少后续同名特征点的搜索范围，降低时间复杂度；接着以步骤3得到的红外特征点集Vir为基准，在可见光边缘图像的搜索区域内，提出多尺度加权NCC作为相似性衡量指标，搜索最佳匹配点得到匹配的可见光图像特征点集Vvis；步骤5，误匹配的剔除：首先通过最小二乘法建立所有匹配特征点的变换模型，然后计算所有匹配点的误差和均方根误差，剔除不在设定邻域范围内的匹配点，直到均方根误差小于设定的阈值。2.如权利要求1所述的一种基于几何约束下区域搜索的图像配准方法，其特征在于：步骤1的具体实现方式如下；借助不同角度的多张黑白棋盘格图片，利用最小二乘法计算红外和可见光相机的内参和外参，然后通过Fusiello提出的方法对图像进行立体校正，将红外和可见光的图像校正到同一高度，红外和可见光图像的立体校正的计算公式如下：I'ir＝rectifyI'vis＝rectify其中，Iir和Ivis表示未进行立体矫正的红外和可见光图像，I′ir和I′vis分别表示立体矫正后的红外和可见光图像，rectify表示校正函数，Kir和Kvis分别表示红外相机和可见光相机的内参，表示外参，R表示两个相机的相对旋转参数，T表示相对平移参数。3.如权利要求1所述的一种基于几何约束下区域搜索的图像配准方法，其特征在于：步骤2的具体实现方式如下；步骤2.1，采用Kevesi提出的基于相位一致性边缘检测算法分别提取和红外和可见光的边缘图，选取若干个方向和尺度的Log-Gabor小波变换，计算每个方向上的相位一致性图，其计算公式如下：PCir＝calPCPCvis＝calPC其中，calPC表示边缘提取函数；θi表示选取的Log-Gabor滤波器方向，θ1～θ6分别为，s1～s4表示四个频率尺度；步骤2.2，利用六个方向的相位一致性信息，通过矩分析方法得到PC图的最大矩M，计算公式如下：其中，PC图的最大矩M代表了图像的边缘特征，具有亮度和对比度不变性，若像素点处的最大矩M＞T，则该位置为边缘点，T表示边缘点检测阈值；对于红外和可见光异源图像，采用相同的阈值T得到细节程度相当的红外边缘图像Iiredge和可见光边缘图像Ivisedge。4.如权利要求1所述的一种基于几何约束下区域搜索的图像配准方法，其特征在于：步骤3的具体实现方式如下；步骤3.1，在红外边缘图Iiredge的基础上，进行基于FAST的特征点检测，基于此得到的候选特征点集VirCandidate；步骤3.2，保留候选特征点集VirCandidate中目标主体上的特征点，舍弃背景中无用的特征点，得到保留后的候选特征点集V′irCandidate，候选特征点集V′irCandidate上的任一特征点在立体矫正后的红外图像I′ir中的灰度大于I′ir的灰度均值；步骤3.3，以候选特征点集V′irCandidate中的任意一个特征点为中心，在5ⅹ5的邻域内采用非极大值抑制策略，只保留邻域范围内FAST特征响应最大的特征点，基于此得到分布较为均匀的特征点集Vir。5.如权利要求1所述的一种基于几何约束下区域搜索的图像配准方法，其特征在于：步骤4的具体实现方式如下；步骤4.1，以NCC作为相似度的度量方式，粗略估计红外图像边缘图像Iiredge和可见光图像边缘图像Ivisedge的水平偏移量dx，使两幅图像在水平方向上大致对齐，减小同名特征点的搜索范围，提高配准效率，dx的计算方式如下式：其中，表示水平偏移量为d时的可见光边缘图像，NCC表示互相关一致性算子，表示两幅图像的相似程度；步骤4.2，针对红外图像特征点集Vir中的每个特征点p，其位于可见光边缘图像中的初始同名点位置为p'，其对应的同名点搜索区域为以p'为中心大小为w×h的长方形区域S，其中w＞h；步骤4.3，以多尺度加权NCC作为搜索同名特征点过程中的相似性衡量指标，提高匹配精确性同时保证匹配效率，即以两个尺寸的模板计算NCC，将其加权结合，计算公式如下：其中，p表示红外特征点，ps表示可见光边缘图像搜索区域内的一点，和/＞表示p周围F1×F1大小邻域和F2×F2大小邻域，/＞和/＞表示以同样方式构建的ps的邻域，D2表示2倍降采样算子，α和β表示权重因子，二者的取值范围为0＜β＜0.5＜α；对于最终搜索得到的同名特征点pcorrespond，其计算公式如下：其中，ps∈S，由此得到匹配的可见光图像特征点集Vvis。6.如权利要求5所述的一种基于几何约束下区域搜索的图像配准方法，其特征在于：计算图像X和Y之间的NCC的计算公式如下：其中，m和n分别表示两图像的宽和高，和/＞分别表示图像X和Y的均值，i和j表示图像上的坐标。7.如权利要求5所述的一种基于几何约束下区域搜索的图像配准方法，其特征在于：获得两个尺寸的模板的过程为，首先构建大尺寸模板，然后对大尺寸模板进行2倍下采样，以保留大模板内的主体结构信息，同时也不增加计算复杂度，然后构建小模板作为信息补充，弥补大模板下采样时丢失的特征点周围的信息，最后将用两个模板计算得到的NCC进行加权结合。8.如权利要求1所述的一种基于几何约束下区域搜索的图像配准方法，其特征在于：步骤5的具体实现方式如下；步骤5.1，根据已经匹配的点集Vir和Vvis，利用最小二乘法计算出初始仿射变换模型H；步骤5.2，根据变换模型H计算出红外图像中的特征点经过变换后在可见光图像中对应的点Vir'，计算公式如下：Vi'r＝Vir×H步骤5.3，计算所有匹配点的误差与总的RMSE，RMSE表示变换模型对整个点集的拟合程度，计算公式如下：其中，N表示匹配特征点对的数量；步骤5.4，剔除点集不在邻域范围内的特征点，重复步骤5.1、5.2和5.3，直到RMSE小于阈值。9.如权利要求8所述的一种基于几何约束下区域搜索的图像配准方法，其特征在于：步骤5.4中剔除点集不在5ⅹ5的邻域的特征点，阈值的取值为3。
说明书desc
技术领域本发明属于图像匹配领域，特别是涉及一种基于几何约束下区域搜索的图像配准方法。背景技术在电力巡检、视频监视、无人驾驶、机器人视觉等领域中，常利用红外和可见光双目成像，将红外和可见光图像进行信息互补，这样可以提高后续应用的性能，如提高检测、识别等任务的精度。有效利用红外和可见光互补信息的前提，是通过高效的配准将两幅图像进行对齐，因此，研究红外和可见光双目成像中红外和可见光图像配准具有重要意义。红外图像与可见光图像由于模态不同，图像存在着显著差异，配准难度大。红外图像根据目标的热辐射成像，能够排除光线和天气条件的影响，但通常分辨率较低，缺少纹理细节。相反地，可见光图像利用光反射成像，成像分辨率比较高，纹理细节丰富，明暗对比度高，但同时也更容易受到环境因素的影响。目前，已有的红外与可见光图像配准算法中，主要可以被分为基于区域、基于特征和基于学习三类。基于区域的配准方法通常给定预变换模型。利用相似性度量和优化方法来估计变换参数，通过优化总体成本函数来对齐两幅图像的公共区域。例如，Yu等人通过灰度加权窗口策略从红外和可见光图像中检测边缘结构，通过归一化互信息提高配准性能。Y.N.等人将红外和可见光图像转化为边缘图，使用仿射和自由形态变换来解释粗配准和精配准的几何关系，通过最大化互信息度量将红外和可见光图像进行配准。上述基于区域算法的算法很大程度受图像重叠区域图像内容的影响，红外和可见光之间严重的非线性强度差异，导致基于区域的方法配准精度不高，目前在实际中应用较少。基于特征的方法是在提取图像特征点的基础上，通过特征描述算子描述特征，利用相似度度量准则获得特征集合间的匹配关系达到配准的目的。目前应用最为广泛，也最为精确。例如，Wang等人提出了SURF-PIIFD-RPM的鲁棒点匹配框架，该方法结合SURF特征提取与部分强度不变特征描述符，利用单高斯鲁棒点匹配模型获得了更好的匹配性能。Jiang等人提出的CAO-C2F算法利用曲率尺度空间角点检测器轮廓中的特征点，借助SIFT描述符进行特征点的匹配，实现了红外与可见光电力图像的配准。Li等人提出了一种基于辐射变化不敏感特征的多模配准方法。在基于相位一致性得到的角点和边缘特征点上，建构造多个方向的最大索引图实现特征旋转不变性。这些算法在匹配常规红外和清晰的可见光图像时表现出了良好的性能。但当图像质量下降如暗光环境时，图像细节不清晰，特征点之间相似性减弱，配准性能则会产生明显下降。近年来，深度学习网络也被应用到了红外和可见光图像配准任务之中。例如，Wang等人提出了一种两阶段的对抗网络，包括模态转换和几何变换阶段，将可见光图像转换为红外图像并获得精确的配准图像；Moba等人提出了一种基于GAN网络的无监督的配准框架，在红外和可见光上同时训练图像模态转换网络和配准网络，借助图像模态转换进而通过使用成熟的单模态度量来训练网络。但由于红外可见光数据集少、GAN网络难以训练收敛等原因，深度学习在红外和可见光配准任务中仍受到局限。在红外和可见光双目相机中，由于两个相机相对位置固定，即红外和可见光相机成像的相对角度、位置等相对固定。而现有的红外和可见光配准算法没有考虑到两者相对位置固定的先验知识，在应用于红外可见光双目相机时，存在配准精度低，几何定位差异大等多模态配准的问题。发明内容本发明针对现有技术的不足，提供一种基于几何约束下区域搜索的图像配准方法。首先对红外相机和可见光相机进行双目标定，通过立体校正将两幅图像约束到同一水平高度，接着利用相位一致性特征提取红外和可见光的边缘图像，在边缘图上提取稳定的红外特征点，然后提出了两阶段的同名特征点搜索方法进行特征点搜索，先以归一化互相关作为相似度度量估计两幅图像的整体水平偏移，再提出多尺度加权NCC作为相似性度量方式，以红外图像特征点为基准在可见光边缘图中进行区域同名特征点搜索得到匹配点，最后通过迭代式细化的方式剔除匹配误差较大的点，得到更加精确的配准模型。为了达到上述目的，本发明提供的技术方案是：一种基于几何约束下区域搜索的图像配准方法，包括如下步骤：步骤1，红外和可见光图像立体校正：利用相机标定得到的红外和可见光相机的内参和外参，通过立体校正可将红外和可见光图像约束到同一高度之上；步骤2，基于相位一致性获取图像的边缘特征图：在步骤1校正后图像的基础上，计算红外和可见光图像的相位一致性相应图，并计算最大矩获得鲁棒的边缘特征图像，得到红外边缘图像Iiredge和可见光边缘图像Ivisedge；步骤3，红外边缘图像特征点提取：在红外边缘图像进行FAST特征点的提取，并剔除掉原红外图像中背景中的无用特征点，同时在设定的邻域范围内使用非极大值抑制策略，得到特征点分布更加均匀的特征点集Vir；步骤4，两阶段特征点搜索匹配：先以NCC为衡量相似性指标计算两边缘图整体水平偏移参数，进一步减少后续同名特征点的搜索范围，降低时间复杂度；接着以步骤3得到的红外特征点集Vir为基准，在可见光边缘图像的搜索区域内，提出多尺度加权NCC作为相似性衡量指标，搜索最佳匹配点得到匹配的可见光图像特征点集Vvis；步骤5，误匹配的剔除：首先通过最小二乘法建立所有匹配特征点的变换模型，然后计算所有匹配点的误差和均方根误差，剔除不在设定邻域范围内的匹配点，直到均方根误差小于设定的阈值。进一步的，步骤1的具体实现方式如下；借助不同角度的多张黑白棋盘格图片，利用最小二乘法计算红外和可见光相机的内参和外参，然后通过Fusiello提出的方法对图像进行立体校正，将红外和可见光的图像校正到同一高度，红外和可见光图像的立体校正的计算公式如下：I'ir＝rectifyI'vis＝rectify其中，Iir和Ivis表示未进行立体矫正的红外和可见光图像，Ii'r和Iv'is分别表示立体矫正后的红外和可见光图像，rectify表示校正函数，Kir和Kvis分别表示红外相机和可见光相机的内参，表示外参，R表示两个相机的相对旋转参数，T表示相对平移参数。进一步的，步骤2的具体实现方式如下；步骤2.1，采用Kevesi提出的基于相位一致性边缘检测算法分别提取和红外和可见光的边缘图，选取若干个方向和尺度的Log-Gabor小波变换，计算每个方向上的相位一致性图，其计算公式如下：PCir＝calPCPCvis＝calPC其中，calPC表示边缘提取函数；θi表示选取的Log-Gabor滤波器方向，θ1～θ6分别为，s1～s4表示四个频率尺度；步骤2.2，利用六个方向的相位一致性信息，通过矩分析方法得到PC图的最大矩M，计算公式如下：其中，PC图的最大矩M代表了图像的边缘特征，具有亮度和对比度不变性，若像素点处的最大矩M＞T，则该位置为边缘点，T表示边缘点检测阈值；对于红外和可见光异源图像，采用相同的阈值T得到细节程度相当的红外边缘图像Iiredge和可见光边缘图像Ivisedge。进一步的，步骤3的具体实现方式如下；步骤3.1，在红外边缘图Iiredge的基础上，进行基于FAST的特征点检测，基于此得到的候选特征点集VirCandidate；步骤3.2，保留候选特征点集VirCandidate中目标主体上的特征点，舍弃背景中无用的特征点，得到保留后的候选特征点集V′irCandidate，候选特征点集V′irCandidate上的任一特征点在立体矫正后的红外图像I′ir中的灰度大于I′ir的灰度均值；步骤3.3，以候选特征点集V′irCandidate中的任意一个特征点为中心，在5ⅹ5的邻域内采用非极大值抑制策略，只保留邻域范围内FAST特征响应最大的特征点，基于此得到分布较为均匀的特征点集Vir。进一步的，步骤4的具体实现方式如下；步骤4.1，以NCC作为相似度的度量方式，粗略估计红外图像边缘图像Iiredge和可见光图像边缘图像Ivisedge的水平偏移量dx，使两幅图像在水平方向上大致对齐，减小同名特征点的搜索范围，提高配准效率，dx的计算方式如下式：其中，表示水平偏移量为d时的可见光边缘图像，NCC表示互相关一致性算子，表示两幅图像的相似程度；步骤4.2，针对红外图像特征点集Vir中的每个特征点p，其位于可见光边缘图像中的初始同名点位置为p'，其对应的同名点搜索区域为以p'为中心大小为w×h的长方形区域S，其中w＞h；步骤4.3，以多尺度加权NCC作为搜索同名特征点过程中的相似性衡量指标，提高匹配精确性同时保证匹配效率，即以两个尺寸的模板计算NCC，将其加权结合，计算公式如下：其中，p表示红外特征点，ps表示可见光边缘图像搜索区域内的一点，和/＞表示p周围F1×F1大小邻域和F2×F2大小邻域，/＞和/＞表示以同样方式构建的ps的邻域，D2表示2倍降采样算子，α和β表示权重因子，二者的取值范围为0＜β＜0.5＜α；对于最终搜索得到的同名特征点pcorrespond，其计算公式如下：其中，ps∈S，由此得到匹配的可见光图像特征点集Vvis。进一步的，计算图像X和Y之间的NCC的计算公式如下：其中，m和n分别表示两图像的宽和高，和/＞分别表示图像X和Y的均值，i和j表示图像上的坐标。进一步的，获得两个尺寸的模板的过程为，首先构建大尺寸模板，然后对大尺寸模板进行2倍下采样，以保留大模板内的主体结构信息，同时也不增加计算复杂度，然后构建小模板作为信息补充，弥补大模板下采样时丢失的特征点周围的信息，最后将用两个模板计算得到的NCC进行加权结合。进一步的，步骤5的具体实现方式如下；步骤5.1，根据已经匹配的点集Vir和Vvis，利用最小二乘法计算出初始仿射变换模型H；步骤5.2，根据变换模型H计算出红外图像中的特征点经过变换后在可见光图像中对应的点Vir'，计算公式如下：V′ir＝Vir×H步骤5.3，计算所有匹配点的误差与总的RMSE，RMSE表示变换模型对整个点集的拟合程度，计算公式如下：其中，N表示匹配特征点对的数量；步骤5.4，剔除点集不在邻域范围内的特征点，重复步骤5.1、5.2和5.3，直到RMSE小于阈值。进一步的，步骤5.4中剔除点集不在5ⅹ5的邻域的特征点，阈值的取值为3。与现有技术相比，本发明的优点和有益效果：本发明针对相对位置固定的红外可见光双目成像应用场景，提出了一种几何约束下基于区域搜索的图像配准方法。算法利用相机标定信息进行立体校正，使红外可见光二者处于同一高度之上，接着利用相位一致性计算鲁棒的边缘图，在边缘图的基础上，提出两阶段同名特征点搜索方法完成精确高效红外可见光图像配准。通过与其他算法在不同场景上的数据进行实验，结果表明相较于其他异源图像配准算法，本专利方法能够适用于红外可见光双目成像的配准，在不同场景的图像都保证了特征点匹配数量和配准效果，并且能很好适应弱光环境下的图像配准工作，相对于其他算法取得了明显的优势。附图说明图1为本方法流程框图。具体实施方式下面结合附图和实施例对本发明的技术方案作进一步说明。如图1所示，一种基于几何约束下区域搜索的图像配准方法，包括如下步骤：步骤1：红外和可见光图像立体校正。利用相机标定得到的红外和可见光相机的内参和外参，通过立体校正可将红外和可见光图像约束到同一高度之上。步骤2：基于相位一致性获取图像的边缘特征图。在步骤1校正后图像的基础上，计算红外和可见光图像的相位一致性相应图，并计算其最大矩获得鲁棒的边缘特征图像。步骤3：红外边缘图特征点提取。在红外边缘图像进行FAST特征点的提取，并剔除掉原红外图像中背景中的无用特征点。同时使用非极大值抑制策略，使得到的特征点分布更加均匀。步骤4：两阶段特征点搜索匹配。先以NCC为衡量相似性指标计算两边缘图整体水平偏移参数。进一步减少后续同名特征点的搜索范围，降低时间复杂度。接着以步骤3得到的红外特征点为基准，在可见光边缘图的搜索区域内，提出多尺度加权NCC作为相似性衡量指标，搜索最佳匹配点。步骤5：误匹配的剔除。首先通过最小二乘法建立所有匹配特征点的变换模型，然后计算所有匹配点的误差和均方根误差，剔除误差较大的匹配点，迭代上述过程提高配准精度。进一步的，步骤1中的红外和可见光图像立体校正的具体实现方式如下；借助不同角度的多张黑白棋盘格图片，利用最小二乘法计算红外和可见光相机的内参和外参。通过Fusiello等人的方法对图像进行立体校正，将红外和可见光的图像校正到相近的水平高度。红外和可见光图像的立体校正的计算公式如下：I'ir＝rectifyI'vis＝rectify其中，Iir和Ivis表示未进行立体矫正的红外和可见光图像，Ii'r和Iv'is分别表示立体矫正后的红外和可见光图像。rectify表示校正函数，Kir和Kvis分别表示红外相机和可见光相机的内参，表示外参，R表示两个相机的相对旋转参数，T表示相对平移参数。步骤2中基于相位一致性获取图像的边缘特征图的具体实现方式如下；步骤2.1：采用Kevesi提出的基于相位一致性边缘检测算法分别提取和红外和可见光的边缘图。选取若干个方向和尺度的Log-Gabor小波变换，计算每个方向上的相位一致性图，其计算公式如下：PCir＝calPCPCvis＝calPC其中，calPC表示边缘提取函数；θi表示选取的Log-Gabor滤波器方向，θ1～θ6分别为，s1～s4表示四个频率尺度。步骤2.2：利用六个方向的相位一致性信息，通过矩分析方法得到PC图的最大矩M，计算公式如下：其中，PC图的最大矩M代表了图像的边缘特征，具有亮度和对比度不变性，若像素点处的最大矩M＞T，则该位置为边缘点，T表示边缘点检测阈值。对于红外和可见光异源图像，可采用相同的阈值T得到细节程度相当的红外边缘图像Iiredge和可见光边缘图像Ivisedge。进一步的，步骤3中所述的红外边缘图特征点提取的具体实现方式如下；针对热红外图像和可见光图像之间的配准，仅在红外边缘图上进行特征点检测。步骤3.1：在红外边缘图Iiredge的基础上，进行基于FAST的特征点检测，基于此得到的候选特征点集VirCandidate，VirCandidate结合了角点和边缘信息。步骤3.2：在处理红外特征点时，主要保留目标主体上的特征点，而舍弃背景中无用的特征点。保留的候选特征点集VirCandidate满足其在立体矫正后的红外图像I′ir中的灰度大于I′ir的灰度均值。步骤3.3：针对候选特征点集V′irCandidate，为了防止特征点过于聚集，导致配准结果偏向于局部区域，本文以候选特征点集中的任意一个特征点为中心，在5ⅹ5的邻域内采用非极大值抑制策略，只保留邻域内FAST特征响应最大的特征点，基于此得到分布较为均匀的特征点集Vir。进一步的，步骤4中所述的两阶段特征点搜索匹配的具体实现方式如下；考虑到在同一水平线上直接搜索同名特征点计算量偏大，本专利提出两阶段的同名特征点搜索方式，以红外特征点为基准在可见光边缘图中搜索同名特征点。步骤4.1：以NCC作为相似度的度量方式，粗略估计红外图像边缘图Iiredge和可见光图像边缘图Ivisedge的水平偏移量dx，使两幅图像在水平方向上大致对齐，减小同名特征点的搜索范围，提高配准效率，dx的计算方式如下式：其中，表示水平偏移量为d时的可见光边缘图像。NCC表示互相关一致性算子，表示两幅图像的相似程度。计算图像X和Y之间的NCC的计算公式如下：其中，m和n分别表示两图像的宽和高，和/＞分别表示图像X和Y的均值，i和j表示图像上的坐标。步骤4.2：针对红外图像特征点集Vir中的每个特征点p，其位于可见光边缘图中的初始同名点位置为p'。由于红外图像成像原理，边缘不清晰是其固有缺陷，在相机标定以及立体校正过程中，不能严格将同名点约束到同一高度之上，存在一定误差，因此对应的同名点搜索区域为以p′为中心大小为w×h的长方形区域S，即以长方形区域搜索，而不是仅在水平线上进行搜索，提高了准确性。S过大会影响效率，过小会影响准确性。步骤4.3：提出多尺度加权NCC作为搜索同名特征点过程中的相似性衡量指标，以提高匹配精确性同时保证匹配效率。即计算以两个尺寸的模板计算NCC，将其加权结合。具体来说首先构建大尺寸模板，然后将其进行下采样，这样保留了大模板内的主体结构信息，同时也不至于增加计算复杂度。然后构建小模板作为信息补充，弥补了大模板下采样时丢失的特征点周围的信息。最后将用两个模板计算得到的NCC进行加权结合，大模板包含更多的结构信息，用其计算的NCC衡量相似性更高，故其权值也更大。将双尺寸模板加权结合，提高了精确性，更加适用于边缘图像。计算公式如下：s.t.＝1其中，p表示红外特征点，ps表示可见光边缘图搜索区域内的一点，和/＞表示p周围F1×F1大小邻域和F2×F2大小邻域。/＞和/＞表示以同样方式构建的ps的邻域，D2表示2倍降采样算子。α和β表示权重因子，二者的取值范围为0＜β＜0.5＜α。对于最终搜索得到的同名特征点pcorrespond，其计算公式如下：其中，ps∈S。得到匹配的可见光图像特征点集Vvis。进一步的，步骤5中所述的误匹配的剔除的具体实现方式如下；采用迭代细化的方式剔除错误的匹配点，针对匹配后的特征点，进一步提高配准的精度，需要将错误匹配的一些点进行剔除，具体流程如下：步骤5.1：根据已经匹配的点集Vir和Vvis，利用最小二乘法计算出初始仿射变换模型H。步骤5.2：根据变换模型H计算出红外图像中的特征点经过变换后在可见光图像中对应的点Vir'，计算公式如下：V′ir＝Vir×H步骤5.3：计算所有匹配点的误差与总的RMSE，RMSE表示变换模型对整个点集的拟合程度，计算公式如下：其中，N表示匹配特征点对的数量。步骤5.4：剔除点集不在5ⅹ5的邻域的点，重复步骤5.1、5.2和5.3，直到RMSE小于阈值3。下面进行实验说明，本文实验采用自组的红外和可见光双目相机。红外相机采用高德plug 417测温型红外相机，分辨率为384ⅹ288。可见光相机使用FLIR公司生产的型号为BFS-U3-17S7M-C的工业灰点相机，分辨率为1600ⅹ1100。实验环境为：Intel Core i510200H CPU，16GB RAM；软件平台为：Matlab R2016b。为了评价本文方法配准的准确性，采用主观评价和客观评价结合的方式。主观评价通过观察配准后的红外可见光融合图像中目标的对齐程度直观地感受算法的配准效果。客观评价采用总匹配点对数NUM、匹配准确率的方法。为了验证本文算法针对红外和可见光双目图像配准任务有效性，选取了近年较为先进的三个异源图像配准算法SURF-PIIFD-RPM，CAO-C2F和RIFT与本方法进行对比试验。使用上述红外与可见光双目成像设备采集不同场景的三组图像共30对进行综合对比实验，数据分为三组，每组包含十对图像。第一组图像包含不同距离的以“人”为主体的图像。图像环境，光线条件较好，图像质量比较高，纹理相对丰富。第二组图像主要包含不同距离的以物为主体的图像，透明水壶装有热水，红外与可见光差异性更大，红外图像中水壶后面的图像信息完全看不见，而可见光图像中则可以看到透明水壶后面的场景内容，且图像纹理较差。第三组图像包含在弱光环境下的图像。在弱光环境下，红外图像由于是捕捉热源信息，成像质量基本不受影响，但依靠光反射成像的可见光图像的质量的大大下降，主体变得不再清晰，噪点也相应增多，配准难度增大。每组数据各算法客观评价指标平均值如表1所示。表1实验结果对比由表1可以看出本文算法在特征点匹配数量和匹配准确率上明显高于其他三个算法，其中SURF-PIIFD-RPM和CAO-C2F匹配的特征点较少，前者在第一组图像中平均特征点匹配数量仅5.7对，且准确率较低，这说明有着很大概率配准失败，在第二组纹理较弱的图像特征点匹配数量仅2.8对，基本配准失败。CAO-C2F算法在第一组图像中能匹配少量的特征点完成配准任务，但由于其在轮廓图中构建SIFT描述符，在第二组纹理较弱的图像中匹配准确率则明显下降。RIFT算法和本文算法都能够得到较为丰富的匹配特征点，且匹配准确率较高，二者能较好的配准图像，配准后的红外与可见光图像都能大体对齐。说明本文算法和RIFT算法面对常规情况下红外图像和可见光图像能够比较好地提取其共同特征并成功匹配特征点。但RIFT存在的一个问题是特征点分布过于集中，这会导致配准有一定的偏移风险。本方法由于是在红外边缘图上进行特征检测，在可见光边缘图上进行区域搜索的方式，相较于在点集中寻找匹配点，且保留的匹配点更多，准确性相对更高，并且本方法结合非极大值抑制策略，在得到大量匹配点的同时保持了较为均匀的分布。第三组图像主要针对的弱光环境下的图像。本文算法特征点匹配数量和准确率上相较于其他三个算法表现出显著的优越性。从表1可以看出，SURF-PIIFD-RPM和CAO-C2F算法特征点匹配数量仅有1.8对，无法完成配准任务。CAO-C2F算法特征点匹配数量和准确率都处于较低水平，说明其无法适用于弱光环境，多数图像的匹配准结果出现无法辨识的扭曲。RIFT由于需要通过可见光图像构建对应的描述子，在可见光质量大大下降的情况下，从表1可以看出得到匹配特征点数量明显下降，配准效果也随之下降，两张图像配准结果都产生了明显错位。本方法则体现出了较大优势，在质量下降的情况下，由于是通过立体校正将红外和可见光图像约束于同一高度，通过局部区域搜索的方式搜索匹配点，仅依靠局部有限的信息获取同名特征点，相对于常见的特征构建特征描述子后在整个点集中进行匹配需要的信息更少，对这种图像质量下降的情况更有优势，由表1可以看到依然能够得到丰富的匹配特征点。本文中所描述的具体实施例仅仅是对本发明精神作举例说明。本发明所属技术领域的技术人员可以对所描述的具体实施例做各种各样的修改或补充或采用类似的方式替代，但并不会偏离本发明的精神或者超越所附权利要求书所定义的范围。
