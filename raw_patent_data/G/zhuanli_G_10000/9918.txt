标题title
一种基于级联融合特征置信度加权的颜色恒常性方法
摘要abst
本发明公开了一种基于级联融合特征置信度加权的颜色恒常性方法，为无人驾驶、水下物体识别、三维物体重建等计算机视觉任务提供稳定的颜色特征，步骤为：在自然场景光源下拍摄图像以及视频，制作应用于颜色恒常性方法的数据集；根据光源颜色的特殊性发明基于级联融合特征置信度加权网络结构；使用数据集对网络结构进行二阶段训练；将估计出的场景光源从图像或者视频中移除，实现图像以及视频的颜色恒常性。本发明通过级联方式将图像中浅层边缘纹理特征与深层细粒度深层特征进行融合，充分利用图像中可以为光源估计提供更多信息的特征估计光源，解决了目前颜色恒常性方法在面对复杂环境时光源估计精确度低的问题，提高了颜色恒常性方法的精确性以及面对复杂环境时方法的稳健性。
权利要求书clms
1.一种基于级联融合特征置信度加权颜色恒常性方法，其特征在于，包括以下步骤：S1、在自然场景光源下拍摄图像以及视频，制作数据集；S2、设计级联融合特征置信度加权网络结构，将图像中的浅层边缘纹理特征与深层细粒度特征进行融合，充分利用图像中为光源估计提供更多信息的特征估计光源；S3、基于S1制作的数据集，对S2中设计的级联融合特征置信度加权网络结构进行二阶段训练，准确地估计的出场景光源；S4、将S3中估计出的场景光源从图像或者视频中移除，使图像恢复到标准光源下的颜色，实现图像及视频的颜色恒常性。2.根据权利要求1所述的方法，其特征在于，所述步骤S1包括以下步骤：S11：使用各种相机以及ColorChecker颜色检查器在多种自然场景下拍摄照片以及视频；S12：根据ColorChecker颜色检查器生成图像以及视频的场景光源信息，得到real_illum.mat图像以及视频相对应的场景光源信息文件；S13：将图像以及视频随机进行打乱，使多种相机以及多种场景下的数据均匀分布，得到最终的数据集；S14：将S13得到的数据集按照6:3:1的比例分为训练集、测试集、验证集，其中训练集用于训练级联融合特征置信度加权网络结构，使网络结构中的网络模型准确地估计出场景光源；测试集用于测试网络模型对光源估计的准确程度；验证集用于检验网络模型以及网络模型中的超参数的有效性，当网络模型不能准确估计光源时及时对网络模型进行修改。3.根据权利要求1所述的方法，其特征在于，所述步骤S2中，级联融合特征置信度加权网络结构为：一个n层的全卷积网络结构，分为特征提取模块、置信度加权模块和光源估计模块；特征提取模块使用卷积神经网络提取图像中的特征信息，通过级联的方式将图像中的浅层边缘纹理特征与深层细粒度特征进行融合；级联融合特征置信度加权网络包含10个卷积层，其中将第二个卷积层网络提取到的特征与第八个卷积层网络提取到的特征进行融合输入到第9层卷积神经网络中，将第4层网络结构提取到的特征与第六层网络结构提取到的特征进行融合输入到第七层网络结构中；第二个卷积层到第八个卷积层的每个卷积层都是1x1和3x3大小的卷积核组成的模块，将其称之为CC模块，CC模块包含三个卷积层，将其分别命名为CC_1,CC_2,CC_3，CC1由m个1x1大小的卷积核构成，CC2由n个1x1大小的卷积核构成，CC3由n个3x3大小的卷积核构成；置信度加权模块根据特征中包含的信息量赋予权重，区分出有用特征和噪音特征，解决光源估计模糊的问题，置信度加权模块由64个大小为6x6的卷积核构成；光源估计模块利用图像中对光源估计有用的特征信息，准确的估计出场景光源，光源估计模块由6个大小为1x1的卷积核构成。4.根据权利要求1所述的方法，其特征在于，所述步骤S3中包括以下分步骤：S31：对S1中的数据集进行数据增强，方法为：若数据集为视频，则先将视频抽取帧数制作成图像数据集，之后随机选择原始图像较短边的a～b倍的任意一点为顶点，选择正方形区域对图像进行裁剪，将选择到的图像随机旋转，并以c的概率对图像进行左右翻转，以d倍的概率对图像进行上下翻转，c和d取值范围0～1；S32：将S31数据增强后的图像修改为mxm的图像块作为级联融合特征置信度加权网络结构的输入；S33：将mxm的图像块输入到级联融合特征置信度加权网络结构中，得到照射在图像上的场景光源；S34：根据估计出的场景光源以及真实的场景光源设置级联融合特征置信度加权网络结构的损失函数；S35：根据损失函数，使用随机梯度下降和反向传播算法对级联融合特征置信度加权网络结构进行二阶段训练，通过对网络结构中的参数进行调整，建立偏色图像到场景光源的映射网络。5.根据权利要求4所述的方法，其特征在于，所述步骤S34中，级联融合特征置信度加权网络结构的损失函数L设置为：公式中，L表示损失值角度误差，表示数据集中的真实场景光源标签，表示估计出的场景光源，eg·eu表示真实场景光源与估计光源之间的内积操作，||·|‖表示向量的欧几里得范数，角度误差值代表估计出的场景光源与真实光源之间的接近程度，采用角度误差的均值、中位数、三均值、最优25％均值、最差25％均值和95th百分位数测量级联融合特征置信度加权网络结构的精确性和稳健性。6.根据权利要求4所述的方法，其特征在于，所述步骤S35中，级联融合特征置信度加权网络结构二阶段训练的具体步骤为：S351：使用ImageNet数据集对级联融合特征置信度加权网络结构进行训练，对网络模型参数中的参数进行初始化；S352：使用S1制作的数据集对级联融合特征置信度加权网络结构进行训练，在训练过程中将批大小batch-size设置为n1，学习率设置为n2，在网络训练中，学习率将按照比例进行衰减，网络训练过程中采用截断训练法。7.根据权利要求1所述的方法，其特征在于，所述步骤S4具体包括以下步骤：S4l：根据Ie＝IgD将原始有色偏图像进行校正，使图像恢复到标准光源下的颜色，实现图像的颜色恒常性，其中Ie表示自然场景下的图像，Ig表示标准光源下的图像，D表示自然场景光源；S42：对图像的亮度进行校正，统计出图像中RGB的最大值；S43：将图像中RGB的最大值调节到210-245范围，计算调整的比例系数k；S44：将图像中的其他像素值按照S43计算出的比例系数k进行调整，得到亮度校正后的标准光源下的图像，实现图像的颜色恒常性。
说明书desc
技术领域本发明涉及一种使用深度学习技术将图像或者视频恢复到标准光源下颜色的方法，属于人工智能、计算机视觉和图像处理领域，具体涉及一种基于级联融合特征置信度加权的颜色恒常性方法的设计，主要应用于计算机视觉中目标检测和识别的各种任务，特别是应用于水下图像以及视频的颜色校正和无人驾驶领域中的目标检测以及识别。背景技术颜色作为视觉信息中最为基础和直接的特征之一，已经被广泛应用于图像处理和计算机视觉领域。由于图像和视频成像过程中受到场景光照、物体表面的反射率以及成像传感器响应函数等多方面的影响。物体表面反射出的颜色会随着场景光源的变化而改变。颜色恒常性方法的目的是要消除场景中光照对物体表面颜色的影响，获取准确的物体颜色表达，为图像增强、目标分割、目标追踪、三维物体重建等计算机视觉任务提供稳定的颜色特征，这对于计算机视觉以及模式识别具有重要的理论意义和实际意义。颜色恒常性方法可以分为基于统计学的方法和基于学习的方法，基于统计学的方法利用图像的低阶特征信息，采用某种假设条件对光照进行估计。常用的基于统计学的方法主要包括灰度世界法、灰色阴影法和灰色边缘法等。这类方法的优点是计算速度快，但是对于不同场景内容和不同光照的图像，其适应具有局限性。基于学习的颜色恒常性方法通过机器学习对大量已知光照颜色的图像样本进行统计和学习，利用先验知识间接地对场景光照进行估计。色域映射法是基于学习的方法中具有代表性的一种颜色恒常性方法。此外，基于学习的方法还包括概率计算的方法。这类方法的共同特点是利用统计特性得到图像场景中所有可能的光照，对于给定的图像，通常将最能代表场景图像已知的光照作为估计的光照。相较于基于统计的方法，基于学习的方法增强了对复杂场景的处理能力，在多数情况下提高了颜色恒常性方法的精确性和泛化性。近年来，随着深度学习技术的飞速发展，许多基于深度学习的颜色恒常性方法被提出，基于深度学习的颜色恒常性方法通过卷积核提取图像中的潜在特征对场景光源进行估计，进一步提高了颜色恒常性方法的精确性。目前应用于颜色恒常性方法的卷积网络结构大多数是由分类或者识别任务的网络结构改进而来，应用于颜色恒常性方法的卷积网络结构虽然进一步提高了光源估计的准确性，但由于光源颜色的特殊性，颜色恒常性方法需要应用图像中可以为光源估计提供更多信息的局部特征估计光源，而目前应用于颜色恒常性方法的对提取到的所有特征信息平等对待，无法充分利用可以为光源估计提供更多信息的特征准确估计出光源。同时，目前应用于颜色恒常性方法的网络结构通过加深网络层数利用图像中细粒度的特征信息估计光源，忽略了图像中浅层边缘纹理特征信息对光源估计的重要性，导致应用于颜色恒常性方法的网络结构虽然具有强大的特征提取能力，但对光源条件的改变不敏感，具有光源不变性，不能对光源做出准确的估计。发明内容本发明的技术解决问题：克服现有技术的不足，提供一种级联融合特征置信度加权颜色恒常性方法，在压缩网络层数和网络模型参数的同时，通过级联的方式将图像中浅层的边缘纹理特征信息和深层的细粒度特征信息进行融合，充分利用图像中为光源估计提供更多信息的特征估计光源，提高了颜色恒常性的精确性以及面对复杂环境时算法的鲁棒性。本发明的技术方案为：一种级联融合特征置信度加权颜色恒常性方法，包括以下步骤：S1、在自然场景光源下拍摄图像以及视频，制作数据集；S2、设计级联融合特征置信度加权网络结构，将图像中的浅层边缘纹理特征与深层细粒度特征进行融合，充分利用图像中为光源估计提供更多信息的特征估计光源；S3、基于S1制作的数据集，对S2中设计的级联融合特征置信度加权网络结构进行二阶段训练，准确地估计的出场景光源；S4、将S3中估计出的场景光源从图像或者视频中移除，使图像恢复到标准光源下的颜色，实现图像及视频的颜色恒常性。所述步骤S1包括以下步骤：S11：使用各种相机以及ColorChecker颜色检查器在多种自然场景下拍摄照片以及视频；S12：根据ColorChecker颜色检查器生成图像以及视频的场景光源信息，得到real_illum.mat图像以及视频相对应的场景光源信息文件；S13：将图像以及视频随机进行打乱，使多种相机以及多种场景下的数据均匀分布，得到最终的数据集；S14：将S13得到的数据集按照6:3:1的比例分为训练集、测试集、验证集，其中训练集用于训练级联融合特征置信度加权网络结构，使网络结构中的网络模型准确地估计出场景光源；测试集用于测试网络模型对光源估计的准确程度；验证集用于检验网络模型以及网络模型中的超参数的有效性，当网络模型不能准确估计光源时及时对网络模型进行修改。所述步骤S2中，级联融合特征置信度加权网络结构为：一个n层的全卷积网络结构，分为特征提取模块、置信度加权模块和光源估计模块；特征提取模块使用卷积神经网络提取图像中的特征信息，通过级联的方式将图像中的浅层边缘纹理特征与深层细粒度特征进行融合；级联融合特征置信度加权网络包含10个卷积层，其中将第二个卷积层网络提取到的特征与第八个卷积层网络提取到的特征进行融合输入到第9层卷积神经网络中，将第4层网络结构提取到的特征与第六层网络结构提取到的特征进行融合输入到第七层网络结构中；第二个卷积层到第八个卷积层的每个卷积层都是1x1和3x3大小的卷积核组成的模块，将其称之为CC模块，CC模块包含三个卷积层，将其分别命名为CC_1,CC_2,CC_3，CC1由m个1x1大小的卷积核构成，CC2由n个1x1大小的卷积核构成，CC3由n个3x3大小的卷积核构成；置信度加权模块根据特征中包含的信息量赋予权重，区分出有用特征和噪音特征，解决光源估计模糊的问题，置信度加权模块由64个大小为6x6的卷积核构成；光源估计模块利用图像中对光源估计有用的特征信息，准确的估计出场景光源，光源估计模块由6个大小为1x1的卷积核构成。所述步骤S3中包括以下分步骤：S31：对S1中的数据集进行数据增强，方法为：若数据集为视频，则先将视频抽取帧数制作成图像数据集，之后随机选择原始图像较短边的a～b倍的任意一点为顶点，选择正方形区域对图像进行裁剪，将选择到的图像随机旋转，并以c的概率对图像进行左右翻转，以d倍的概率对图像进行上下翻转，c和d取值范围0～1；S32：将S31数据增强后的图像修改为mxm的图像块作为级联融合特征置信度加权网络结构的输入；S33：将mxm的图像块输入到级联融合特征置信度加权网络结构中，得到照射在图像上的场景光源；S34：根据估计出的场景光源以及真实的场景光源设置级联融合特征置信度加权网络结构的损失函数；S35：根据损失函数，使用随机梯度下降和反向传播算法对级联融合特征置信度加权网络结构进行二阶段训练，通过对网络结构中的参数进行调整，建立偏色图像到场景光源的映射网络。所述步骤S34中，级联融合特征置信度加权网络结构的损失函数L设置为：公式中，L表示损失值角度误差，表示数据集中的真实场景光源标签，表示估计出的场景光源，eg·eu表示真实场景光源与估计光源之间的内积操作，‖·‖表示向量的欧几里得范数，角度误差值代表估计出的场景光源与真实光源之间的接近程度，采用角度误差的均值、中位数、三均值、最优25％均值、最差25％均值和95th百分位数测量级联融合特征置信度加权网络结构的精确性和稳健性。所述步骤S35中，级联融合特征置信度加权网络结构二阶段训练的具体步骤为：S351：使用ImageNet数据集对级联融合特征置信度加权网络结构进行训练，对网络模型参数中的参数进行初始化；S352：使用S1制作的数据集对级联融合特征置信度加权网络结构进行训练，在训练过程中将批大小batch-size设置为n1，学习率设置为n2，在网络训练中，学习率将按照比例进行衰减，网络训练过程中采用截断训练法。所述步骤S4具体包括以下步骤：S41：根据Ie＝IgD将原始有色偏图像进行校正，使图像恢复到标准光源下的颜色，实现图像的颜色恒常性，其中Ie表示自然场景下的图像，Ig表示标准光源下的图像，D表示自然场景光源；S42：对图像的亮度进行校正，统计出图像中RGB的最大值；S43：将图像中RGB的最大值调节到210-245范围，计算调整的比例系数k；S44：将图像中的其他像素值按照S43计算出的比例系数k进行调整，得到亮度校正后的标准光源下的图像，实现图像的颜色恒常性。本发明的有益效果是：与目前现有的颜色恒常性方法相比，本发明的级联融合特征置信度加权颜色恒常性方法通过级联特征的方式将图像中的浅层边缘纹理特征与深层的细粒度特征信息进行融合，通过置信度加权方式，充分利用图像中可以为光源估计提供更多信息的特征估计光源，进一步提高了颜色恒常性方法的精确性以及面对复杂环境时算法的稳健性。同时，级联融合特征置信度加权网络通过1x1和3x3大小的卷积核相结合压缩了网络模型的参数，是更加轻量级的网络结构，提高了颜色恒常性方法的运算速度，降低了模型对存储容量的要求，可以满足嵌入式设备和移动端设备的要求。为无人驾驶、水下物体识别、三维物体重建等计算机视觉任务提供稳定的颜色特征。附图说明图1为本发明的一种级联融合特征置信度加权颜色恒常性方法流程图；图2为本发明的级联融合特征置信度加权颜色恒常性方法网络结构图；图3为本发明实施例提供的级联融合特征置信度加权颜色恒常性方法中CC模块网络结构图；图4为本发明实施例提供的制作的数据集示例图；图5为本发明二阶段训练法的网络训练步骤图；图6为本发明的网络训练损失值曲线图；图7为使用本发明提出的级联融合特征置信度加权颜色恒常性方法校正后的图像；图8为本发明实施例提供的级联融合特征置信度加权颜色恒常性方法与其他方法的效果对比图，a为输入到网络中的图像，b为本发明经过颜色校正后的图像，c为置信度加权图，d为标准光源下的图像，e为使用Grey-world方法校正后的图像，f为White-Patch方法校正后的图像，g为Shades-of-Grey方法校正后的图像，h为Grey-Edge方法校正后的图像。具体实施方式为了更好的理解发明的技术方案，现在将参考附图来对本发明的示例性实施方式进行详细的说明。如图1所示，本发明的一种基于级联融合特征置信度加权颜色恒常性方法，包括以下步骤S1～S4：S1、在自然场景光源下拍摄图像以及视频，制作应用于颜色恒常性方法的数据集。步骤S1包括以下分步骤S11～S13：S11：使用Canon EOS-1Ds Mark III、Canon EOS 600D、Samsung NX2000、SonySLT-A57、Nikon D405种型号的相机以及ColorChecker颜色检查器在花园、教室、马路等多种自然场景下拍摄照片以及视频。在拍摄数据集照片或者视频时，需要将ColorChecker色卡置于拍照现场用于检测场景光源，在拍摄之前将相机内所有关于对比度以及色彩的设置全部设置为默认值，并且也不设置锐化的选项，因为这样会对拍摄出来的色卡的颜色产生影响。ColorChecker色卡不需要填满取景器，只要保证相机可以拍到所有的色块即可。色卡需要位于构图中有代表性的部分而不是处于阴影中或者是在曝光过度的高光位置，同时，为了保证检测出场景光源的准确性，在自然跟可控制光线下拍摄色卡的时候需要调整好适当的角度，不要让光线直接通过色卡反射到镜头当中，也不要让物体反射的颜色投射到色卡上，这样有可能造成比较大的偏差，在选好场景并摆放好色卡之后进行图片或者视频拍摄。S12：根据ColorChecker颜色检查器生成图像以及视频的场景光源信息，得到real_illum.mat图像以及视频相对应的场景光源信息文件。在检测步骤S11拍摄出的照片以及视频的场景光源之前需要对图像或者视频的曝光度进行调整，防止图片过量或者过暗影响测量场景光源的准确性。选取步骤S11拍摄的照片，对照片中的像素进行直方图统计观察，将图像中的白色块的色值调整到210-245之间，而对于黑色块的要求，可以不必理会，因为对于宽容度比较大的机型来说，当白色块达到210-245的量度的时候，黑色块已经不太可能小于23了，调整像素值的目的在于让色卡中的色块达到理想的白点和黑点，提高统计场景光源的准确性。之后利用PM5软件生成相机的ICC文件，统计出拍摄图片的场景光源信息。用PhotoShop打开图像照片，用取色器对其中的黑色块取样，根据内置式的参照点，图像中红绿蓝彼此间插值应在7个单位内，并且色值应约为50。尽管黑色色块很深，由于它是退光色，因此不会被认为是纯黑色。对白色块进行同样程序，白色块应该是淡白色，而不是纯白色，其中红绿蓝色值各应约为245，之后检查色偏，选择中间灰色色块。红绿蓝的色值应约为128，相互之间不超过7点，保存更改的设定，将次设定应用于此设置拍摄的其他图像，得到标准光源下的图片以及视频。S13：将图片以及视频随机进行打乱，使其多种相机以及多种场景下的数据可以均匀分布。打乱时仍然需要图像信息以及S12步骤中测量出的场景广源信息以及标准光源下的图片相对应。S14：将S13得到的数据集按照6:3:1的比例分为训练集、测试集、验证集。分别保存到train、test、val文件下中。其中训练集用于训练级联融合特征置信度加权网络模型，使网络模型可以准确的估计出场景光源。测试集用于测试网络模型对光源估计的准确程度。验证集用于检验网络模型以及网络模型中的超参数的有效性，当网络模型不能准确估计光源时可以及时对网络模型进行修改。S2、根据光源颜色的特殊性设计级联融合特征置信度加权网络结构，将图像中的浅层边缘纹理特征与深层的细粒度特征进行融合，充分利用图像中可以为光源估计提供更多信息的特征估计光源。如图2所示，为本发明的级联融合特征置信度加权颜色恒常性方法网络结构图。网络结构包括10层，前8层网络结构充分提取图像中的特征信息，其中将第2层网络提取到的特征与第8层网络提取到的特征进行融合输入到第9层卷积神经网络中，将第3层网络提取到的特征与第7层网络提取到的特征进行融合输入到第8层网络结构中，将第4层网络结构提取到的特征与第六层网络结构提取到的特征进行融合输入到第7层网络结构中，通过这种级联方式将图像中的浅层边缘特征与深层细粒度特征进行融合，使网络结构可以同时利用浅层特征信息与细粒度特征信息估计光源，提高了颜色恒常性方法的精确性与稳定性。第九层以及第十层网络对提取到的特征信息进行置信度加权，充分利用图像中可以为光源估计提供更多信息的特征估计光源。网络结构包括10层，通过前八个卷积层充分提取图像中的特征信息，之后的两个卷积层对提取到的特征信息进行置信度加权并输出最终估计的场景光源。为了减少网络结构中的模型参数，网络结构中的第2-8卷积层使用1x1和3x3大小的卷积核的CC网络模块替代，CC网络模块的网络结构图如图3所示。CC网络模块使用1x1和3x3大小的卷积核组合而成，在充分提取图像中的特征信息的同时减少了网络模型的参数。每个CC网络模块包含三个卷积层，将其分别命名为cc_1,cc_2,cc_3。级联融合特征置信度加权网络卷积层1接受彩色图像的输入，由64个大小为3x3的卷积核组成。卷积层1后连接卷积核大小为3，步长为2的最大池化层，之后连接2个CC网络模块，2个CC网络模块中CC_1卷积核的个数为16，CC_2和CC_3的卷积核的大小为64，对输出使用卷积核大小为3，步长为2的最大池化。池化层后连接1个CC网络模块，该CC网络模块中CC_1的卷积核的个数为32，CC_2和CC_3的卷积核的个数为128，对输出使用卷积核大小为3，步长为2的最大池化。之后连接两个卷积层对提取到的特征进行置信度池化加权，第一个卷积层由64个大小为6x6的卷积核组成，第二个卷积层是由6个大小为1x1的卷积核组成，最后输出估计的场景光源。S3、通过S1制作的数据集对级联融合特征置信度加权网络结构进行二阶段训练，使网络结构能够准确估计出场景光源。步骤S3包括以下分步骤：S31：对S1中的数据集进行数据增强，方法为：若数据集为视频，则先将视频抽取帧数制作成图片数据集，之后随机选择原始图像较短边的a～b倍的任意一点为顶点，选择正方形区域对图像进行裁剪，本发明示例中a＝0.1，b＝1，将选择到的图像随机旋转，并以c的概率对图像进行左右翻转，本发明示例中c＝0.6，以d倍的概率对图像进行上下翻转，本示例中d＝0.5，数据集经过预处理后的图像如图4所示。本发明提出的数据增强方法进一步提高了颜色恒常性方法的精确性，增强了颜色恒常性方法在面对复杂场景光照时的鲁棒性。S32：将S31数据增强后的图片修改为mxm的图像块作为级联融合特征置信度加权网络结构的输入；调用PIL中的Image库函数对图像的尺寸大小调整为mxm，本实施例中m＝512。S33：将mxm的图像块输入到级联融合特征置信度加权网络结构中，本实施例中m＝512，级联融合特征置信度加权网络结构对输入到的图像进行特征提取，根据提取到的特征估计出照射在图片的场景光源。S34：根据估计出的场景光源以及真实的场景光源设置级联融合特征置信度加权网络的损失函数。本发明实例中，采用角度误差作为级联融合特征置信度加权网络结构的损失函数，公式为：其中表示数据集中的真实场景光源标签，表示使用本发明方法估计出的场景光源。eg·eu表示真实场景光源与估计光源之间的内积操作。||·||表示向量的欧几里得范数。角度误差值代表本发明所提出的方法估计出的场景光源与真实光源之间的接近程度。本发明主要对比光源颜色估计角度误差的均值、中位数、三均值、最优25％均值、最差25％均值和95th百分位数。其中角度误差均值用于估计方法的总体性能，中位数和三均值用于测试离散值对方法的影响，最差25％均值和95th百分位数衡量方法在面对复杂环境时的角度误差，其值越小说明方法的鲁棒性和稳健性越好。S35：根据损失函数，使用随机梯度下降和反向传播算法对级联融合特征置信度加权网络进行二阶段训练，通过对网络结构中的参数进行调整，建立偏色图像到场景光源的映射网络。二阶段训练法的网络训练步骤图如图5所示。在对网络进行训练的过程中，第一阶段使用ImageNet数据集对级联融合特征置信度加权网络进行训练，使其对网络模型中的参数进行初始化。第二阶段使用S1中制作好的数据集对网络进行训练，训练时选择超参数batch_size为n1，本发明实施例中n1＝16，学习率设置为n2，本发明示例中n2＝1e-4，在网络训练中，学习率将按照比例进行衰减，增加级联融合特征置信度加权网络结构的拟合能力，网络训练过程中采用截断训练法，当损失函数值趋于稳定时，网络结构自动停止训练，本发明实施例中，网络训练损失值曲线图如图6所示，从图6中可以看出，当循环迭代次数为10000时，损失值已经基本趋向于稳定，网络结构接近于收敛停止训练，级联融合特征置信度加权颜色恒常性方可以准确估计出光源。S4、将估计出的场景光源从图像或者视频中移除，使图像恢复到标准光源下的颜色，实现图像以及视频的颜色恒常性。进一步地，步骤S4包括以下分步骤：S41：根据Ie＝IgD将原始有色偏图像进行校正，使图像恢复到标准光源下的颜色，实现图像的颜色恒常性。其中Ie表示自然场景下的图像，Ig表示标准光源下的图像，D表示级联融合特征置信度加权网络结构估计出的自然场景光源，则标准光源下的图像Ig＝IeD-1。S42：对图像的亮度进行校正，统计出图像中RGB的最大值，对标准光源下的图像的亮度进行校正是为了可以让图像有更好的视觉效果。S43：将图像中RGB的最大值调节到210-245之间，计算调整的比例系数。S44：将图像中的其他像素值按照S43计算出的比例系数进行调整，得到亮度校正后的标准光源下的图片，实现图像的颜色恒常性方法。偏色图像经过颜色恒常性方法恢复到标准场景光源下的图像如图7所示。如图8所示，为本发明实施例提供的级联融合特征置信度加权颜色恒常性方法与其他方法的效果对比图，a为输入到网络中的图像，b为本发明经过颜色校正后的图像，c为置信度加权图，d为标准光源下的图像，e为使用Grey-world方法校正后的图像，f为White-Patch方法校正后的图像，g为Shades-of-Grey方法校正后的图像，h为Grey-Edge方法校正后的图像。将本发明与目前存在的颜色恒常性方法进行比较，从视觉效果上可以看出，在复杂场景光照环境下使用Grey-word方法进行校正后的图片会出现偏红的现象，使用white-patch方法和shades-of-Grey方法进行校正后的图像与标准光源下的图像存在着较大偏差。从b和d对比可以看出，使用本发明提出的颜色恒常性方法对图像进行校正后与标准光源下的图像十分接近。本发明提出级联融合颜色恒常性方法，将图像中的浅层边缘特征和深层细粒度特征进行融合得到更加丰富的特征信息，充分利用图像中可以为光源估计提供更多信息的特征估计光源，提高了颜色恒常性方法在面对复杂环境时的精确性，增强了颜色恒常性方法的鲁棒性。本领域的普通技术人员将意识到，这里所述的实施例是为了帮助读者理解本发明的原理，应该被理解为本发明的保护范围并不局限于这样的特别陈述和实施例。本领域的普通技术人员可以根据本发明公开的这些技术启示做出各种不脱离本发明实质的其它各种具体变形和组合，这些变形和组合仍然在本发明的保护范围内。
