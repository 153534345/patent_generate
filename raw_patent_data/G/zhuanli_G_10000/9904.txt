标题title
基于轮廓估计的无锚框目标跟踪方法
摘要abst
本发明公开了一种基于轮廓估计的无锚框目标跟踪方法。本发明提出的轮廓估计网络无需根据先验知识预先设置锚框，就能够直接求解出目标对象大致的外形轮廓，相较于矩形框，目标外形轮廓能够更加精确地描述目标状态；本发明还使用轮廓估计网络求解出的目标外形轮廓来更新目标模板特征，减少了目标模板特征中的背景信息，为后续的信息嵌入提供了更加精确的目标信息。在光照变化、运动模糊、平面内旋转和目标超出视角等极端的环境下，本发明方法依旧能够保持较高的精度。
权利要求书clms
1.一种基于轮廓估计的无锚框目标跟踪方法，其特征在于，包括如下步骤：步骤1，对于给定的模板图像，利用特征提取骨干网络进行特征提取，最终得到模板特征步骤2，对于给定的搜索图像，利用特征提取骨干网络进行特征提取，最终得到搜索图像特征步骤3，将步骤2与步骤3提取的特征输入图注意力模块进行信息嵌入得到响应图R；步骤4，将步骤3中的响应图输入轮廓估计网络，得到分类特征图、中心度特征图和回归特征图，通过计算得到最终的目标外形轮廓Cresult；步骤5，如果步骤2中的搜索图像与模板图像源自视频同一帧图像，那么利用步骤4中的目标外形轮廓进行模板特征更新，得到更新后的模板特征并覆盖步骤1中的模板特征。2.如权利要求1所述的一种基于轮廓估计的无锚框目标跟踪方法，其特征在于：步骤1和步骤2中特征提取骨干网络的具体描述如下，特征提取骨干网络使用孪生网络来提取图像特征，该网络由两个分支组成：一个提取目标模板特征的模板分支，一个提取搜索图像特征的搜索分支，并且这两个分支结构相同，共享网络权重，将目标模板图像z输入模板分支得到目标模板特征将搜索图像x输入搜索分支得到搜索图像特征然后嵌入两个分支的特征来获得响应图R。3.如权利要求1所述的基于轮廓估计的无锚框目标跟踪方法，其特征在于：步骤3中的图注意力模块的具体结构如下，模板特征经过一个线性变化矩阵Wz后，得到一个特征图Fm1，将该特征图Fm1经过一个矩阵变换得到特征图Fm2；搜索特征经过一个线性变化矩阵Wx后，得到一个特征图Fs1，将该特征图Fs1经过一个矩阵变换得到特征图Fs2；将上述过程中由模板特征得到的特征图Fm2与搜索特征得到特征图Fs2做矩阵乘法得到特征图Fms2，将特征图Fms2进行归一化得到F’ms2；将模板特征经过一个线性变化矩阵Wv和一个激活函数得到特征图Fm3，将该特征图Fm3经过一个矩阵变换得到特征图Fm4；将特征图Fm4与上述特征图F’ms2做矩阵乘法得到特征图F1；将搜索特征经过一个线性变化矩阵Wv和一个激活函数得到特征图Fs3，将该特征图Fs3与特征图F1进行矩阵变换后的特征图做矩阵拼接，将拼接结果经过一个卷积层和一个激活函数后得到最终的响应图。4.如权利要求1所述的一种基于轮廓估计的无锚框目标跟踪方法，其特征在于：图注意力模块的具体处理过程如下，将模板特征和搜索图像特征中任意一点视为一个节点Pnode，使用符号Vz表示模板特征中所有节点的集合，符号Vx表示搜索图像特征中所有节点的集合，符号eij表示节点i∈Vx和节点j∈Vz之间的相关得分，由于搜索区域中与模板局部特征越相似的位置越有可能为前景，因此该位置需要传递更多的目标信息，因此相关得分eij应该与两个节点的相似度成正比，定义eij的计算表示式为：其中和表示节点i和节点j的特征向量，Wx和Wz表示线性变换矩阵；为了自适应学习节点之间更好的表示，首先对节点特征做一个线性变换，然后再使用变换的节点特征的内积作为相似性的度量；为了平衡传输到搜索区域的信息量，对eij进行标准化：其中，k表示Vz中任意节点k，表示求解Vz中所有节点与节点i的相关得分后相加；aij表示根据节点j的信息跟踪器应该对节点i投入多少注意力，那么Vz中所有节点传递到Vx中第i个节点的聚合表示为：其中Wv表示线性变换矩阵；最后将聚合后的特征与节点特征进行融合，得到一个具有目标信息的更强大的特征表示：其中||表示向量拼接，并行计算所有的将其作为响应图用于后续的跟踪任务。5.如权利要求1所述的基于轮廓估计的无锚框目标跟踪方法，其特征在于：步骤4中的轮廓估计网络的具体结构如下，轮廓估计网络的输入是孪生骨干网络输出的响应图，轮廓估计网络由分类分支、中心度分支和回归分支组成，中心度分支通过在1×1的卷积分类头上并行增加一个1×1的卷积层得到，中心度分支和分类分支共用4个串行的卷积层和激活函数层；回归分支由4个串行的卷积层和激活函数层以及一个1×1的回归分支构成；响应图输入分类分支得到分类特征图，输入中心度分支得到中心度特征图，输入回归分支得到回归特征图，分类特征图中的任意一点都包含一个2维向量，该2维向量用于表示该点对应的搜索图像中相应位置的前景和背景的分类得分；同理，中心度特征图中的任意一点表示相应位置的中心度得分；回归特征图中的任意一点都包含一个36维向量，该36维向量表示相应位置在预设的36个角度上到目标外形轮廓距离。6.如权利要求1所述的一种基于轮廓估计的无锚框目标跟踪方法，其特征在于：步骤4中的轮廓估计网络的具体处理过程如下，轮廓估计网络的分类分支用于确定一个区域是属于前景还是背景；中心度分支用于抑制远离目标中心的异常值；回归分支用于回归在预设的36个角度上该点到目标轮廓距离；轮廓估计网络fC的输出可表示为：Fcls，Fcen，Freg＝fC其中Fcls表示分类特征图，Fcen表示中心度特征图，Freg表示回归特征图，通过轮廓估计网络的输出可以得出目标粗略的外形轮廓；将中心特征图乘以分类特征图所得结果中最大值对应的位置作为目标中心点，并将该最大值位置对应的回归特征图中相应位置的36维向量{d0，d1，d2…，d35}作为目标中心点在{0°，10°，20°，…，350°}这36个角度上到目标外形轮廓的距离；轮廓估计网络的最终输出是目标外形轮廓的中心点以及在预设的36个角度上中心点到目标外形轮廓的距离{d0，d1，d2…，d35}，根据中心点和距离计算出目标外形轮廓的36个坐标点，将这36个坐标点依次连接，最终组装成一个完整的目标外形轮廓Cresult，该目标外形轮廓可以更加精确地描述目标状态；其中各个坐标点的计算方式为：7.如权利要求1所述的一种基于轮廓估计的无锚框目标跟踪方法，其特征在于：步骤5模板更新的具体描述如下，根据轮廓估计网络输出的目标外形轮廓Cresult重置模板特征，定义矩阵M的大小为w×h，其中w、h分别为模板图像块的长宽，矩阵M的u行v列的元素muv赋值表达式为：将矩阵M投影到模板特征上得到M′，将矩阵M′中值为1的元素所在位置视为前景，值为0的元素所在位置视为背景，将矩阵M′与模板特征做元素间的乘法运算，则最终的模板特征为：
说明书desc
技术领域本发明属于计算机视觉技术领域，具体涉及数字图像的目标跟踪技术领域，特别是涉及一种基于轮廓估计的无锚框目标跟踪方法。背景技术目标跟踪是指给定视频第一帧中任意目标的位置和大小，求解出该目标在后续视频序列中的状态信息。目标跟踪的结果作为后续视频目标识别、场景分析和理解的输入，承担了计算机视觉系统中承上启下的作用。几十年来，目标跟踪领域已经涌现了众多优秀的算法，并且越来越多的研究人员开始投身目标跟踪算法的研究，使得目标跟踪算法的性能越来越好，更为广泛的应用到实际生活中。但由于目标自身状态以及目标所处环境的不断变化，建立一个通用的、鲁棒的目标跟踪算法仍然是一个具有挑战性的问题。对于非刚性物体或者与坐标轴成一定角度的刚性物体，使用矩形框来描述目标状态都会包含大量的背景信息；另外无论是多尺度匹配来适配目标的大小变化，还是基于锚框的目标状态估计方法，都为网络引入了大量的超参数。超参数的确定需要大量的专业知识和不断地调优，并且难以应对跟踪过程中可能出现的复杂的目标变化和环境变化。发明内容为了解决上述技术问题，本发明提出了一种基于轮廓估计的无锚框目标跟踪算法。本发明提出了轮廓估计网络无需根据先验知识预先设置锚框，就能够直接求解出目标对象大致的外形轮廓，相较于矩形框，目标外形轮廓能够更加精确地描述目标状态；本发明还使用轮廓估计网络求解出的目标外形轮廓来更新目标模板特征，减少了目标模板特征中的背景信息，为后续的信息嵌入提供了更加精确的目标信息。本发明的技术方案为一种基于轮廓估计的无锚框目标跟踪算法，包括如下步骤：步骤1，对于给定的模板图像，利用特征提取骨干网络进行特征提取，最终得到模板特征；步骤2，对于给定的搜索图像，利用特征提取骨干网络进行特征提取，最终得到搜索图像特征；步骤3，将步骤2与步骤3提取的特征输入图注意力模块进行信息嵌入得到响应图；步骤4，将步骤3中的响应图输入轮廓估计网络，得到分类特征图、中心度特征图和回归特征图，通过计算得到最终的目标外形轮廓；步骤5，如果步骤2中的搜索图像与模板图像源自视频同一帧图像，那么利用步骤4中的目标外形轮廓进行模板特征更新，得到更新后的模板特征并覆盖步骤1中的模板特征。进一步的，步骤1中的特征提取骨干网络的具体过程如下，特征提取骨干网络使用孪生网络结构来提取图像特征，该网络由两个分支组成：一个提取目标模板特征的模板分支，一个提取搜索图像特征的搜索分支。这两个分支具有相同的卷积神经网络结构，并且共享网络权重。将目标模板图像z输入模板分支得到目标模板特征进一步的，步骤2中特征提取骨干网络的具体过程如下，特征提取骨干网络使用孪生网络结构来提取图像特征，该网络由两个分支组成：一个提取目标模板特征的模板分支，一个提取搜索图像特征的搜索分支。这两个分支具有相同的卷积神经网络结构，并且共享网络权重。将搜索图像x输入搜索分支得到搜索图像特征进一步的，步骤3中的图注意力网络的具体结构如下，模板特征经过一个线性变化矩阵Wz后，得到一个特征图Fm1，将该特征图Fm1经过一个矩阵变换得到特征图Fm2；搜索特征经过一个线性变化矩阵Wx后，得到一个特征图Fs1，将该特征图Fs1经过一个矩阵变换得到特征图Fs2；将上述过程中由模板特征得到的特征图Fm2与搜索特征得到特征图Fs2做矩阵乘法得到特征图Fms2，将特征图Fms2进行归一化得到F’ms2；将模板特征经过一个线性变化矩阵Wv和一个激活函数得到特征图Fm3，将该特征图Fm3经过一个矩阵变换得到特征图Fm4；将特征图Fm4与上述特征图F’ms2做矩阵乘法得到特征图F1；将搜索特征经过一个线性变化矩阵Wv和一个激活函数得到特征图Fs3，将该特征图Fs3与特征图F1进行矩阵变换后的特征图做矩阵拼接，将拼接结果经过一个卷积层和一个激活函数后得到最终的响应图。进一步的，步骤3中的图注意力模块具体描述如下，将模板特征和搜索图像特征中任意一点视为一个节点Pnode，使用符号Vz表示模板特征中所有节点的集合，符号Vx表示搜索图像特征中所有节点的集合。符号eij表示节点i∈Vx和节点j∈Vz之间的相关得分，由于搜索区域中与模板局部特征越相似的位置越有可能为前景，因此该位置需要传递更多的目标信息，因此相关得分eij应该与两个节点的相似度成正比，定义eij的计算表示式为：其中和表示节点i和节点j的特征向量，Wx和Wz表示线性变换矩阵。为了自适应学习节点之间更好的表示，首先对节点特征做一个线性变换，然后再使用变换的节点特征的内积作为相似性的度量。为了平衡传输到搜索区域的信息量，对eij进行标准化：aij表示根据节点j的信息跟踪器应该对节点i投入多少注意力。那么Vz中所有节点传递到Vx中第i个节点的聚合表示为：其中Wv表示线性变换矩阵。最后将聚合后的特征与节点特征进行融合，得到一个具有目标信息的更强大的特征表示：其中||表示向量拼接。并行计算所有的将其作为响应图用于后续的跟踪任务。进一步的，步骤4中的轮廓估计网络具体描述如下，轮廓估计网络主要由三个分支组成：一个用于前景-背景估计的分类分支，一个抑制异常值的中心度分支和一个求解目标外形轮廓的回归分支。分类分支用于确定一个区域是属于前景还是背景；中心度分支用于抑制远离目标中心的异常值；回归分支用于回归在预设的36个角度上该点到目标轮廓距离。具体的，中心度分支通过在1×1的卷积分类头上并行增加一个1×1的卷积层得到，中心度分支和分类分支共用4个串行的卷积层和激活函数层；回归分支由4个串行的卷积层和激活函数层以及一个1×1的回归分支构成；响应图输入分类分支得到分类特征图，输入中心度分支得到中心度特征图，输入回归分支得到回归特征图，分类特征图中的任意一点都包含一个2维向量，该2维向量用于表示该点对应的搜索图像中相应位置的前景和背景的分类得分；同理，中心度特征图中的任意一点表示相应位置的中心度得分；回归特征图中的任意一点都包含一个36维向量，该36维向量表示相应位置在预设的36个角度上到目标外形轮廓距离。轮廓估计网络fC的输出可表示为：Fcls,Fcen,Freg＝fC其中Fcls表示分类特征图，Fcen表示中心度特征图，Freg表示回归特征图，通过轮廓估计网络的输出可以得出目标粗略的外形轮廓。将中心特征图乘以分类特征图所得结果中最大值对应的位置作为目标中心点，并将该最大值位置对应的回归特征图中相应位置的36维向量{d0,d1,d2…,d35}作为目标中心点在{0°,10°,20°,…,350°}这36个角度上到目标外形轮廓的距离。轮廓估计网络的最终输出是目标外形轮廓的中心点以及在预设的36个角度上中心点到目标外形轮廓的距离{d0,d1,d2…,d35}，根据中心点和距离计算出目标外形轮廓的36个坐标点，将这36个坐标点依次连接，最终组装成一个完整的目标外形轮廓Cresult，该目标外形轮廓可以更加精确地描述目标状态。其中各个坐标点的计算方式为：进一步的，步骤5中的模板特征更新具体描述如下，根据轮廓估计网络输出的目标外形轮廓Cresult重置模板特征。定义矩阵M的大小为w×h，其中w、h分别为模板图像块的长宽，矩阵M的u行v列的元素muv u行v列的元素muv赋值表达式为：将矩阵M投影到特征图上得到M′，将矩阵M′中值为1的元素所在位置视为前景，值为0的元素所在位置视为背景，将矩阵M′与特征图做元素间的乘法运算，则最终的模板特征为：本发明与现有技术相比，具有以下优点：本发明提出无锚框的目标状态估计方法，无需根据先验知识预先设置锚框的大小、数量以及长宽比，使用轮廓估计网络直接回归出目标对象大致的外形轮廓，减小因大量设置超参数对跟踪算法性能带来的消极影响；使用粗略的目标外形轮廓来描述目标状态，并且可以通过回归的目标轮廓求解出包围目标的最小外接矩形框或者坐标轴对齐的矩形框，来满足跟踪任务的不同输出需求；使用轮廓估计网络求解出的目标外形轮廓来更新目标模板特征，减少了目标模板特征中的背景信息，为后续的信息嵌入提供了更加精确的目标信息。附图说明图1是本发明实施例整体框架图。图2是本发明实施例图注意力模块结构图。图3是本发明实施例轮廓估计网络结构图。具体实施方式为了使本发明的目的、技术方案及优点更加清楚明白，以下结合附图及实施例，对本发明做进一步详细说明应当理解，此处描述的具体实施例仅用以解释本发明，并不用于限定本发明。基于轮廓估计的无锚框目标跟踪算法，其主要思想是：使用轮廓估计网络输出目标粗略的外形轮廓。相较于使用坐标轴对齐的矩形框来描述目标状态，通过使用外形轮廓来描述目标状态可以提供更多的目标状态信息，从而满足不同跟踪场景的需求；使用轮廓估计网络求解出的目标外形轮廓来更新目标模板特征，减少了目标模板特征中的背景信息，为后续的信息嵌入提供了更加精确的目标信息。如图1所示，本发明放的整体流程为；步骤1，对于给定的模板图像，利用特征提取骨干网络进行特征提取，最终得到模板特征；步骤2，对于给定的搜索图像，利用特征提取骨干网络进行特征提取，最终得到搜索图像特征；步骤3，将步骤2与步骤3提取的特征输入图注意力模块进行信息嵌入得到响应图；步骤4，将步骤3中的响应图输入轮廓估计网络，得到分类特征图、中心度特征图和回归特征图，通过计算得到最终的目标外形轮廓；步骤5，如果步骤2中的搜索图像与模板图像源自视频同一帧图像，那么利用步骤4中的目标外形轮廓进行模板特征更新，得到更新后的模板特征并覆盖步骤1中的模板特征。进一步的，步骤1和步骤2中的特征提取骨干网络具体描述如下，特征提取骨干网络使用孪生网络来提取图像特征，该网络由两个分支组成：一个提取目标模板特征的模板分支，一个提取搜索图像特征的搜索分支，并且这两个分支结构相同，共享网络权重。将目标模板图像z输入模板分支得到目标模板特征将搜索图像x输入搜索分支得到搜索图像特征然后嵌入两个分支的特征来获得响应图R。如图2所示，步骤3中的图注意力模块具体网络结构如下，模板特征经过一个线性变化矩阵Wz后，得到一个大小为13×13×256的特征图，将该特征图经过一个矩阵变换得到大小为256×169的特征图；搜索特征经过一个线性变化矩阵Wx后，得到一个大小为25×25×256的特征图，将该特征图经过一个矩阵变换得到大小为625×256的特征图；将上述过程中由模板特征得到的256×169的特征图与搜索特征得到的625×256特征图做矩阵乘法得到625×169特征图，将625×169的特征图进行归一化；将模板特征经过一个线性变化矩阵Wv和一个激活函数得到大小为13×13×256的特征图，将该特征图经过一个矩阵变换得到大小为169×256的特征图；将169×256特征图与上述625×169特征图做矩阵乘法得到625×256的特征图；将搜索特征经过一个线性变化矩阵Wv和一个激活函数得到大小为25×25×256的特征图，将该25×25×256的特征图与625×256特征图进行矩阵变换后的特征图做矩阵拼接，将拼接结果经过一个卷积层和一个激活函数后得到最终25×25×256的响应图。使用图注意力网络进行信息嵌入的主要思想是：将模板特征和搜索图像特征中任意一点视为一个节点Pnode，使用符号Vz表示模板特征中所有节点的集合，符号Vx表示搜索图像特征中所有节点的集合。符号eij表示节点i∈Vx和节点j∈Vz之间的相关得分，由于搜索区域中与模板局部特征越相似的位置越有可能为前景，因此该位置需要传递更多的目标信息，因此相关得分eij应该与两个节点的相似度成正比，定义eij的计算表示式为：其中和表示节点i和节点j的特征向量，Wx和Wz表示线性变换矩阵。为了自适应学习节点之间更好的表示，首先对节点特征做一个线性变换，然后再使用变换的节点特征的内积作为相似性的度量。为了平衡传输到搜索区域的信息量，对eij进行标准化：其中，k表示Vz中任意节点k，表示求解Vz中所有节点与节点i的相关得分后相加；aij表示根据节点j的信息跟踪器应该对节点i投入多少注意力。那么Vz中所有节点传递到Vx中第i个节点的聚合表示为：其中Wv表示线性变换矩阵。最后将聚合后的特征与节点特征进行融合，得到一个具有目标信息的更强大的特征表示：其中||表示向量拼接。并行计算所有的将其作为响应图用于后续的跟踪任务。如图3所示，步骤4中的轮廓估计网络具体网络结构如下，轮廓估计网络的输入是孪生骨干网络输出的25×25×256响应图，轮廓估计网络由分类分支、中心度分支和回归分支组成，中心度分支通过在1×1的卷积分类头上并行增加一个1×1的卷积层得到，中心度分支和分类分支共用4个串行的卷积层和激活函数层。回归分支由4个串行的卷积层和激活函数层以及一个1×1的回归分支构成。响应图输入分类分支得到大小为25×25×2分类特征图，输入中心度分支得到大小为25×25×1中心度特征图，输入回归分支得到大小为25×25×36回归特征图，分类特征图中的任意一点都包含一个2维向量，该2维向量用于表示该点对应的搜索图像中相应位置的前景和背景的分类得分；同理，中心度特征图中的任意一点表示相应位置的中心度得分；回归特征图中的任意一点都包含一个36维向量，该36维向量表示相应位置在预设的36个角度上到目标外形轮廓距离。轮廓估计网络的分类分支用于确定一个区域是属于前景还是背景；中心度分支用于抑制远离目标中心的异常值；回归分支用于回归在预设的36个角度上该点到目标轮廓距离。轮廓估计网络fC的输出可表示为：Fcls,Fcen,Freg＝fC其中Fcls表示分类特征图，Fcen表示中心度特征图，Freg表示回归特征图，通过轮廓估计网络的输出可以得出目标粗略的外形轮廓。将中心特征图乘以分类特征图所得结果中最大值对应的位置作为目标中心点，并将该最大值位置对应的回归特征图中相应位置的36维向量{d0,d1,d2…,d35}作为目标中心点在{0°,10°,20°,…,350°}这36个角度上到目标外形轮廓的距离。轮廓估计网络的最终输出是目标外形轮廓的中心点以及在预设的36个角度上中心点到目标外形轮廓的距离{d0,d1,d2…,d35}，根据中心点和距离计算出目标外形轮廓的36个坐标点，将这36个坐标点依次连接，最终组装成一个完整的目标外形轮廓Cresult，该目标外形轮廓可以更加精确地描述目标状态。其中各个坐标点的计算方式为：进一步的，步骤5中的模板更新具体描述如下，根据轮廓估计网络输出的目标外形轮廓Cresult重置模板特征。定义矩阵M的大小为w×h，其中w、h分别为模板图像块的长宽，矩阵M的u行v列的元素muv赋值表达式为：将矩阵M投影到模板特征上得到M′，将矩阵M′中值为1的元素所在位置视为前景，值为0的元素所在位置视为背景，将矩阵M′与模板特征做元素间的乘法运算，则最终的模板特征为：为了说明本发明的效果，提供在VOT2019数据集下本文算法与其他先进算法的指标比较以及消融实验的结果。黑色加粗标记的各项数值对应的算法表示该算法在该项指标下表现最好，斜体表示排名第二，灰色表示排名第三。如表1所示，本发明的算法名称缩写为AFCE，并且为了评估本发明提出的轮廓估计网络对算法性能的影响，使用输出矩形框的无锚框网络来代替本发明的轮廓估计网络，并在实验中命名为AFCE-box表示输出的矩形框；为了评估模板特征的更新给算法带来的影响，使用AFCE-no update表示没有使用本发明输出的目标轮廓来更新模板特征。在VOT2019数据集上，本发明AFCE相较于当前主流的ATOM算法的平均重叠期望提高了1.7％，精度提高了2.1％，鲁棒性在参与实验的算法排名第二。消融实验的结果证明了使用轮廓估计网络的AFCE算法在平均重叠期望、精确度和鲁棒性上相较于AFCE-box都有提升；本发明提出的更新模板特征能在一定程度上提高算法的性能，实验结果验证了本发明提出算法的有效性。表1本算法与其他先进算法平均重叠期望、精确度与鲁棒性比较本文中所描述的具体实施例仅仅是对本发明精神作举例说明。本发明所属技术领域的技术人员可以对所描述的具体实施例做各种各样的修改或补充或采用类似的方式替代，但并不会偏离本发明的精神或者超越所附权利要求书所定义的范围。
