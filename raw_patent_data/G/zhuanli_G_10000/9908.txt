标题title
基于深度强化学习的多用户多信道动态频谱接入方法
摘要abst
本发明公开了基于深度强化学习的多用户多信道动态频谱接入方法，包括以下步骤：首先初始化参数，其次观察当前频谱环境，然后，各次用户通过评估神经网络，得到在当前状态下所有动作的Q值，并依据策略选择下一步的动作；执行动作后，各次用户会获取回报，同时频谱环境会转入一个新状态；然后存储记忆，当记忆量累积到自定义的规模后，开始学习，更新评估神经网络参数；然后更新目标神经网络的参数；重复以上步骤直至收敛，获得最优的接入策略。本发明在频谱环境先验知识未知的条件下动态地调整频谱接入策略，在不干扰主用户通信质量的前提下，减少用户之间的碰撞，达到提升系统吞吐量的目的。
权利要求书clms
1.一种基于深度强化学习的多用户多信道动态频谱接入方法，其特征在于，包括以下步骤：步骤1、初始化参数包括授权信道数C，次用户数K，各次用户感知的信道数M，构建频谱环境；初始化次用户的深度Q网络包括评估神经网络和目标神经网络的训练参数：学习率α、折扣因子γ、初始探索率ε、全局学习步数step、记忆库容量Memory_size、目标神经网络的步数replace_step、激活函数；步骤2、观察当前频谱环境状态S：各次用户由状态感知模块感知频谱环境，每个次用户感知M个信道，其中M＜C，C为授权信道数；在此有限的感知能力条件下观察得到时隙t下当前频率环境状态S；步骤3、选择动作：各次用户根据当前频谱环境状态S，通过评估神经网络得到在当前频谱环境状态S下所有动作的Q值，并依据ε-greedy策略选择下一步的动作，各次用户选择的动作为a＝,k＝1,2,…,K，其中ak是次用户k在时隙t的动作，K为次用户数；步骤4、获取回报：执行动作a后，各次用户获取的回报为r＝，其中rk是次用户k在时隙t+1的回报；同时，频谱环境会转入下一步的频谱环境新状态S；其中，次用户k在时隙t获取的回报rk用公式表示如下：其中，o表示次用户k在执行动作ak后，收到的二进制应答信号，如果次用户k成功传输数据，o＝1，相反地，如果次用户k与主用户发生了碰撞，即传输失败，o＝0；ak＝0表示次用户k在时隙t没有选择任何信道接入，若ak＝n，n∈{1,2,...,C}，则表示次用户k在时隙t选择第n个信道接入；表示次用户k在信道n上获得的数据传输速率；步骤5、存储记忆到经验池中：将当前频谱环境状态S、各次用户选择的动作a、各次用户获取的回报r、下一步的频谱环境新状态S，以，a，r，S)的形式存储到经验池中；步骤6、重复步骤2至步骤5至经验池中记忆量累积到自定义的规模后，开始学习；计算评估神经网络的损失函数L，并进行反向传播更新评估神经网络参数，实现评估神经网络的训练；步骤7、更新目标神经网络的参数：根据自定义的更换步数，将目标神经网络的参数替换成评估神经网络的参数；步骤8、重复步骤2至步骤7直至收敛，迭代结束，获得最优的接入策略，使得在观测的时间段内次用户获得的总吞吐量达到最大。2.如权利要求1所述的基于深度强化学习的多用户多信道动态频谱接入方法，其特征在于，步骤2所述观察当前频谱环境状态S，包括以下步骤：步骤2.1、每个次用户分别从所有信道中随机选择M个信道作为下一步的感知信道；步骤2.2、次用户获取自身对所选择的M个信道的感知错误率，感知错误率由次用户根据自身的感知情况和最后的成功接入情况估计所得；步骤2.3、每个次用户分别对各自所选择的M个信道执行频谱感知，得到当前频谱环境状态S＝，t＝{1,2,…T}，其中T为总的观测时间间隙，Sk表示次用户k感知的时隙t的频谱环境状态，其中第m个元素表示次用户k对所选择的第m个信道感知的频谱环境状态，代表次用户k所选择的第m个信道时隙t时是空闲的，代表次用户k所选择的第m个信道时隙t时被主用户占用。3.如权利要求1所述的基于深度强化学习的多用户多信道动态频谱接入方法，其特征在于，步骤3所述ε-greedy策略具体为：a)以1-ε的概率选择最高Q值所对应的动作，即根据感知结果选择使得Q值最高的信道，其中初始探索率ε∈；b)以ε的概率随机采取一个动作来执行，即随机选择一个信道。4.如权利要求1所述的基于深度强化学习的多用户多信道动态频谱接入方法，其特征在于，步骤4所述的计算表达式如下：其中，Bn表示信道n的带宽；SINRk表示次用户k在信道n上收到的信号与干扰加噪声比。5.如权利要求4所述的基于深度强化学习的多用户多信道动态频谱接入方法，其特征在于，所述SINRk的表达式如下：当次用户k选择接入的信道n的真实状态是空闲时，并且信道n中没有其他次用户接入时，SINRk为：其中，为次用户k在信道n内的发射功率，hkk,n为次用户k发送端到次用户k接收端间信道n的衰落因子，表示次用户k接收端处信道n内的高斯噪声方差；若信道n中同时有其他次用户接入，则SINRk为：其中，指次用户j在信道n内的发射功率；hj,k指次用户j的发送端到次用户k的接收端间信道n的衰落因子。6.如权利要求1所述的基于深度强化学习的多用户多信道动态频谱接入方法，其特征在于，步骤6所述评估神经网络的损失函数L表达式如下：其中，E表示取期望值，γ为折扣因子，且γ∈；Qtarget是由目标神经网络获得的Q现实函数，θ-是目标神经网络的参数，Qeval是由评估神经网络获得的Q估计函数，θ是评估神经网络的参数，表示取能使得Qtarget值最大的动作a。
说明书desc
技术领域本发明属于无线通信技术领域，具体涉及基于深度强化学习的多用户多信道动态频谱接入方法。背景技术动态频谱接入技术作为认知无线电的核心技术之一，是一种新型的频谱共享方式，对于提高无线频谱资源的利用率有着重要意义。深度强化学习是强化学习和深度学习的结合，其不仅能够不断与变化无常的环境互动以获取知识，在处理动态系统问题上有着出色的性能，同时能够处理巨大的状态空间和复杂的计算。利用DRL解决DSA问题，不需要外部环境的先验信息，次用户能自主地通过不断地“试错学习”来适应动态变化的外部环境，逐渐了解无线环境的特征变化以及主用户在信道上的活动信息。这也特别适用于当周围频谱环境未知，或者环境信息获取不准确、不及时等的DSA场景。现有的基于DRL的DSA技术，多数是建立在次用户能够对所有信道进行完全准确的频谱感知以检测主用户的前提条件下，但如果所有次用户在每个时隙都对所有信道进行感知，会极大消耗次用户的能量，缩短次用户的生命周期。此外，受硬件条件限制或本地干扰、热噪声、多径衰落及隐藏终端等诸多现实因素的影响，次用户是有可能误检的。因此，在实际的动态频谱接入应用中，次用户通常在每个时隙只能选择部分信道进行频谱感知，且感知结果可能存在错误。发明内容发明目的：针对上述现有技术的不足，本发明提出基于深度强化学习的多用户多信道的动态频谱接入方法，在更贴合实际的场景下，应用DRL实现次用户与环境之间的交互，在频谱环境先验知识未知的条件下动态地调整频谱接入策略，在不干扰主用户通信质量的前提下，减少用户之间的碰撞，达到提升系统吞吐量的目的。技术方案：为实现上述目的，本发明的基于深度强化学习的多用户多信道动态频谱接入方法，包括以下步骤：步骤1、初始化参数包括授权信道数C，次用户数K，各次用户感知的信道数M，构建频谱环境；初始化次用户的深度Q网络包括评估神经网络和目标神经网络的训练参数：学习率α、折扣因子γ、初始探索率ε、全局学习步数step、记忆库容量Memory_size、目标神经网络的步数replace_step、激活函数；步骤2、观察当前频谱环境状态S：各次用户由状态感知模块感知频谱环境，每个次用户感知M个信道，其中M＜C，C为授权信道数；在此有限的感知能力条件下观察得到时隙t下当前频率环境状态S；步骤3、选择动作：各次用户根据当前频谱环境状态S，通过评估神经网络得到在当前频谱环境状态S下所有动作的Q值，并依据ε-greedy策略选择下一步的动作，各次用户选择的动作为a＝,k＝1,2,…,K，其中ak是次用户k在时隙t的动作，K为次用户数；步骤4、获取回报：执行动作a后，各次用户获取的回报为r＝，其中rk是次用户k在时隙t+1的回报；同时，频谱环境会转入下一步的频谱环境新状态S；其中，次用户k在时隙t获取的回报rk用公式表示如下：其中，o表示次用户k在执行动作ak后，收到的二进制应答信号，如果次用户k成功传输数据，o＝1，相反地，如果次用户k与主用户发生了碰撞，即传输失败，o＝0；ak＝0表示次用户k在时隙t没有选择任何信道接入，若ak＝n，n∈{1,2,...,C}，则表示次用户k在时隙t选择第n个信道接入；表示次用户k在信道n上获得的数据传输速率；步骤5、存储记忆到经验池中：将当前频谱环境状态S、各次用户选择的动作a、各次用户获取的回报r、下一步的频谱环境新状态S，以，a，r，S)的形式存储到经验池中；步骤6、重复步骤2至步骤5至经验池中记忆量累积到自定义的规模后，开始学习；计算评估神经网络的损失函数L，并进行反向传播更新评估神经网络参数，实现评估神经网络的训练；步骤7、更新目标神经网络的参数：根据自定义的更换步数，将目标神经网络的参数替换成评估神经网络的参数；步骤8、重复步骤2至步骤7直至收敛，迭代结束，获得最优的接入策略，使得在观测的时间段内次用户获得的总吞吐量达到最大。进一步的，步骤2所述观察当前频谱环境状态S，包括以下步骤：步骤2.1、每个次用户分别从所有信道中随机选择M个信道作为下一步的感知信道；步骤2.2、次用户获取自身对所选择的M个信道的感知错误率，感知错误率由次用户根据自身的感知情况和最后的成功接入情况估计所得；步骤2.3、每个次用户分别对各自所选择的M个信道执行频谱感知，得到当前频谱环境状态S＝，t＝{1,2,…T}，其中T为总的观测时间间隙，Sk表示次用户k感知的时隙t的频谱环境状态，其中第m个元素表示次用户k对所选择的第m个信道感知的频谱环境状态，代表次用户k所选择的第m个信道时隙t时是空闲的，代表次用户k所选择的第m个信道时隙t时被主用户占用。进一步的，步骤3所述ε-greedy策略具体为：a)以1-ε的概率选择最高Q值所对应的动作，即根据感知结果选择使得Q值最高的信道，其中初始探索率ε∈；b)以ε的概率随机采取一个动作来执行，即随机选择一个信道。进一步的，步骤4所述的计算表达式如下：其中，Bn表示信道n的带宽；SINRk表示次用户k在信道n上收到的信号与干扰加噪声比。进一步的，所述SINRk的表达式如下：当次用户k选择接入的信道n的真实状态是空闲时，并且信道n中没有其他次用户接入时，SINRk为：其中，为次用户k在信道n内的发射功率，hkk,n为次用户k发送端到次用户k接收端间信道n的衰落因子，表示次用户k接收端处信道n内的高斯噪声方差；若信道n中同时有其他次用户接入，则SINRk为：其中，指次用户j在信道n内的发射功率；hj,k指次用户j的发送端到次用户k的接收端间信道n的衰落因子。进一步的，步骤6所述评估神经网络的损失函数L表达式如下：其中，E表示取期望值，γ为折扣因子，且γ∈；Qtarget是由目标神经网络获得的Q现实函数，θ-是目标神经网络的参数，Qeval是由评估神经网络获得的Q估计函数，θ是评估神经网络的参数，表示取能使得Qtarget值最大的动作a。有益效果：本发明中与现有技术相比，具有以下有益效果：本发明中与现有技术相比，首先，设置了更加贴合实际的场景，在频谱环境先验知识未知，次用户只能在所处的环境中观察部分信道状态，且观察结果可能存在错误的前提下，采用深度Q网络来指导次用户做出决策，次用户通过不断与环境的交互学习来掌握主用户的活动情况，实现有效减少用户之间的碰撞冲突的目的；其次，引入了dropout，将其与多层感知器及DQN结合应用，与其他现有方法相比，在提高次用户平均成功接入率，减少次用户碰撞率以及增大次用户平均传输吞吐量上这三项性能上都有较优表现。附图说明图1为本发明的网络场景图；图2为本发明的流程图。具体实施例为了详细的说明本发明所述的技术方案，下面结合说明书附图及具体实施例做进一步的阐述。本发明考虑考虑如图1所示的主用户与次用户共存的认知无线电网络场景。假设网络中存在C个授权信道，每个授权信道被不同的主用户占用，授权信道有0和1两种工作状态，信道的状态转移用二状态Markov过程来模拟，次用户不知道主信道的状态转移信息。在一定的时间间隔内，各个信道统计特性都保持不变。主、次用户以overlay方式共享频谱，为了保护主用户的通信质量，避免次用户与主用户在同一时隙共同使用同一频段，K个次用户需要先感知授权信道的状态并寻找空闲信道来接入进行数据传输。在接入过程中，允许多个次用户接入同一信道，但每个次用户最多只能选择一个信道接入。此外，应用DRL中的典型方法DQN来指导次用户作出行为决策，采取以下动作：选择信道接入或者保持空闲状态；执行动作后，次用户相应的接收端会发送一个二进制应答信号，该信号能准确反映次用户是否成功传输数据。并引入dropout，使其与MLP、DQN结合应用。其中，dropout是一种缓解神经网络模型过拟合的有效手段，MLP是典型的人工神经网络，将二者与DQN结合应用后，随着训练的进行，次用户通过自主地学习实现减少与主、次用户之间的碰撞，增大平均吞吐量的目的。本发明的基于深度强化学习的多用户多信道动态频谱接入方法如图2所示，具体实施步骤如下：步骤1、初始化。初始化授权信道数C，次用户数K，各次用户感知的信道数M，构建频谱环境；初始化次用户的DQN训练参数，包括评估神经网络和目标神经网络。构建的频谱环境中，授权信道的状态转移用二状态Markov过程来模拟；其中，设置C＝8，K＝3；学习率α＝0.005，全局学习步数step＝280000，记忆库容量Memory_size＝2000，折扣因子γ＝0.9，初始探索率ε＝0.7，目标神经网络的步数replace_step＝400，激活函数为relu函数，dropout系数dropout_rate＝0.5。步骤2、观察当前频谱环境状态S。各次用户由状态感知模块感知频谱环境，每个次用户只能感知M个信道，C为授权信道数，且感知结果可能会出现错误，在此有限的感知能力条件下观察得到时隙t下当前频谱环境状态S。具体包括如下步骤：步骤2.1、每个次用户分别从所有信道中随机选择M个信道作为下一步的感知信道；步骤2.2、次用户获取自身对所选择的M个信道的错误感知率，感知错误率由次用户根据自身的感知情况和最后的成功接入情况估计所得，具体数值由运行商根据实际情况自行确定；步骤2.3、每个次用户分别对各自所选择的M个信道执行频谱感知，得到当前频谱环境状态S＝，t＝{1,2,…T}，其中T为总的观测时间间隙，Sk表示次用户k感知的时隙t的频谱环境状态，其中第m个元素表示次用户k对所选择的第m个信道感知的频谱环境状态，代表次用户k所选择的第m个信道时隙t时是空闲的，代表次用户k所选择的第m个信道时隙t时被主用户占用。步骤3、选择动作。各次用户根据观察到的当前频谱环境状态S，通过评估神经网络，得到在当前状态S下所有动作的Q值，依据ε-greedy策略选择下一步的动作：以1-ε的概率根据感知结果选择使得Q值最高的信道接入，或者以ε的概率随机选择一个信道接入，其中初始探索率ε∈。各个次用户的动作a＝,k＝1,2,…,K，其中ak是次用户k在时隙t的动作，K为次用户数；其中，ak＝n，n∈{1,2,...,C}表示次用户k在时隙t选择第n个信道接入，ak＝0表示次用户k在时隙t没有选择任何信道接入，保持空闲状态。步骤4、获取回报。执行动作a后，各次用户会获取的回报r＝，其中rk是次用户k在时隙t+1的回报；同时，频谱环境会转入下一步的频谱环境新状态S。如果次用户所选择的接入信道的实际状态并非空闲，正被主用户占用，则会收到一个负回报。此外，次用户应尽量选择没有同时被其他次用户选择的信道接入，以减少次用户之间的碰撞，提高系统吞吐量。在每个时隙t，次用户k单独通过深度Q网络采取动作ak＝n，执行动作后的回报设定成在信道n上可获得的数据速率：其中Bn表示信道n的带宽，取B＝1MHz；SINRk表示次用户k在信道n上收到的信号与干扰加噪声比。当次用户k选择接入的信道n的真实状态是空闲时，并且信道n中没有其他次用户接入时，SINRk为：其中，为次用户k在信道n内的发射功率，hkk,n为次用户k发送端到次用户k接收端间信道n的衰落因子，表示次用户k接收端处信道n内的高斯噪声方差；次用户k获取的数据速率为：若信道n中同时有其他次用户接入，则次用户k获取的数据速率为：其中，表示所有接入信道n的其他次用户对次用户k产生的干扰之和，指次用户j在信道n内的发射功率，取值可由运营商根据实际情况自行确定。hj,k指次用户j的发送端到次用户k的接收端间信道n的衰落因子，取值通过信道估计得到。在每个时隙t，次用户k在执行动作ak＝n后，收到的一个来自接收端的信号用o表示，该ACK信号可绝对准确地反映次用户是否成功传输数据，如果o＝1，表示次用户成功传输数据；相反地，如果次用户与主用户发生了碰撞，即传输失败，o＝0。概括来说，回报值rk的设定如下：各次用户的目的是希望在不知道授权信道状态转移信息，每个时隙不能对所有信道状态进行观察，并且观察结果不一定正确的前提下，找到一个最优接入策略，使得累积折扣回报Rk最大化。其中，γ为折扣因子，且γ∈；γt表示γ的t次方，T为总的观测时间间隙。步骤5、存储记忆到经验池中。将当前频谱环境S、次用户选择的动作a、次用户获取的回报r、下一步的频谱环境新状态S，即，a，r，S)存储到经验池中。步骤6、重复步骤2至步骤5至经验池中记忆量累积到自定义的规模2000个后，开始学习。学习过程具体是指通过评估神经网络、目标神经网络分别获得Q估计函数Qeval、Q现实函数Qtarget，利用Qeval和Qtarget计算评估神经网络的损失函数L，并进行反向传播更新参数，实现评估神经网络的训练。L表达式如下：其中，E表示取期望值，γ为折扣因子，且γ∈，用来衡量当前回报与未来回报的比重；θ-是目标神经网络的参数，θ是评估神经网络的参数，这些参数的取值由运营商根据实际情况自行确定，表示取能使得Qtarget值最大的动作a。步骤7、目标神经网络的参数更新。根据自定义的更换步数，将目标神经网络的参数替换成评估神经网络的参数。步骤8、重复步骤2至步骤7直至收敛，迭代结束，获得最优的接入策略，使得在观测的时间段内次用户的总吞吐量达到最大。本文中所描述的具体实施例仅仅是对本发明精神作举例说明。本发明所属技术领域的技术人员可以对所描述的具体实施例做各种各样的修改或补充或采用类似的方式替代，但并不会偏离本发明的精神或者超越所附权利要求书所定义的范围。
