标题title
一种自监督的图像翻译方法和系统
摘要abst
本发明公开了一种自监督的图像翻译方法和系统，本发明的主体结构为一个生成对抗网络，使用自监督训练的方式对该网络进行训练。在训练过程中，会先将训练用的图像进行特定操作，并利用分类器来预测该图像经过哪种特定操作，从而完成自监督的过程。此外，本发明还同时将该图像输入判别器进行生成‑判别的过程。为了使网络能够学习到细微部分的内容，本发明还将图像分割成多块，分别进行特定操作，这时分类会对每个块上进行的操作进行预测，这有助于模型学习到图像细微部分的内容。
权利要求书clms
1.一种自监督的图像翻译方法，其特征在于，包括以下步骤：1)将源图像x与目标翻译图像y作为一对训练数据，构建由若干对训练数据组成的训练集；2)构建PCGAN网络模型，包括生成器、判别器和分类器；将训练集中的源图像x作为生成器的输入，获得生成图像G；将生成图像G分割成n*m个大小相同的块，随机抽取若干块进行特定操作处理，并记录真实的随机特定操作矩阵，得到处理后的生成图像G*；将特定操作处理后的生成图像G*与原始生成图像G在通道维度上进行级联，作为第一级联图像；将生成图像G与训练集中的目标翻译图像y作为判别器的输入，获得生成器损失以及判别器损失；将训练集中的目标翻译图像y分割成n*m个大小相同的块，随机抽取若干块进行特定操作处理，并记录真实的随机特定操作矩阵，得到处理后的目标翻译图像y*；将特定操作处理后的目标翻译图像y*与原始的目标翻译图像y*在通道维度上进行级联，作为第二级联图像；将第一级联图像和第二级联图像作为分类器的输入，得到预测的随机特定操作矩阵，结合所述的真实的随机特定操作矩阵，获得分类器损失；3)将生成器损失、判别器损失和分类器损失之和作为总损失，对步骤2)构建的PCGAN网络模型进行训练，得到训练好的PCGAN网络模型；4)将待翻译的源图像作为训练好的PCGAN网络模型中的生成器的输入，将生成图像作为图像翻译结果。2.根据权利要求1所述的自监督的图像翻译方法，其特征在于，所述的特定操作处理为旋转、添加噪音、镜像反转中的任一一种。3.根据权利要求1所述的自监督的图像翻译方法，其特征在于，所述的随机特定操作矩阵是由0和1组成的二维矩阵，图像中的每一个分割好的块对应一个数值0或1，当数值为0时，表示不进行特定操作处理，当数值为1时，表示进行特定操作处理。4.根据权利要求1所述的自监督的图像翻译方法，其特征在于，所述的判别器损失为：LDgan＝log)+log))所述的生成器损失为：LGgan＝log))所述的分类器损失为：Lcls＝||Cy))-lPO||1+||Cy)))-lPO||1其中，LDgan表示判别器的损失值，LGgan表示生成器的损失值，Lcls表示分类器的损失值，DY表示判别器的输出结果，GXY表示生成器的输出结果，Cy表示分类器的输出结果，PO表示经过特定操作处理后的输出结果，x为源图像，y为目标翻译图像，X为源图像集合，Y为目标翻译图像集合，lPO表示真实的随机特定操作矩阵，cat表示级联操作。5.根据权利要求1所述的自监督的图像翻译方法，其特征在于，所述的图像翻译包括图像上色、图像风格化任务，所述的目标翻译图像是将源图像经过上色或风格化后的目标图像。6.根据权利要求1所述的自监督的图像翻译方法，其特征在于，所述的生成器采用编码-解码结构，依次包括两个卷积层、两个残差块和两个转置卷积层；所述的判别器和分类器采用FCN-8神经网络结构。7.一种自监督的图像翻译系统，其特征在于，用于实现权利要求1所述的图像翻译方法；所述的图像翻译系统包括：数据获取模块：用于获取训练数据集和待翻译的源图像；所述的训练数据集由若干对训练数据组成，每对训练数据包括源图像x与目标翻译图像y；PCGAN网络模型模块：包括生成-对抗网络模块、分类网络模块和特定操作处理模块；所述的生成-对抗网络模块用于获取源图像x的生成图像G，对生成图像G进行判别；所述的特定操作处理模块用于对生成图像G和目标翻译图像y分割成n*m个大小相同的块，随机抽取若干块进行特定操作处理，并记录真实的随机特定操作矩阵；以及用于对特定操作处理后的生成图像G*与原始生成图像G在通道维度上进行级联，作为第一级联图像，对特定操作处理后的目标翻译图像y*与原始的目标翻译图像y*在通道维度上进行级联，作为第二级联图像；所述的分类网络模块用于预测第一级联图像和第二级联图像的随机特定操作矩阵；训练模块：用于对PCGAN网络模型模块中的生成-对抗网络模块、分类网络模块进行训练。
说明书desc
技术领域本发明涉及计算机视觉、图像翻译、卷积神经网络技术领域，尤其涉及一种自监督的图像翻译模型方法和系统，可用于图像上色、风格化等图像翻译的子任务。背景技术目前有很多图像翻译的算法能够取得较为良好的效果，在各个子领域中取得不错的实际应用，如风格迁移、图像分割等。风格迁移是一个更变图像风格的任务，通过模型将输入图像的风格转变为指定风格，如将一副莫奈风格的图像转变为毕加索风格的图像而不改变其表达的内容。图像分割则试图将图像中的各个部分进行分割，用特定的像素值标注该像素值对应物体的类别，如车、人、树等类别。但图像翻译中存在图像数据量较少，生成图像部分区域不够精细等问题，这些问题会导致图像翻译模型难以达到预期的效果。针对上述问题，本发明提出了一个新的图像翻译模型，该模型采用了自监督训练的方式进行训练，自监督通过自我构建标注来弥补训练数据不足的问题，同时将图像分割成多个块，对每个块分别进行分类，这样可以激励网络提升细微部位的生成效果。发明内容本发明的目的为了提升图像翻译的性能，本发明将自监督训练应用到模型之上，提出了一种自监督的图像翻译模型方法和系统，应用于图像上色、风格化等图像翻译任务上。本发明采用的技术方案如下：本发明的其中一个目的在于提供一种自监督的图像翻译方法，包括以下步骤：1)将源图像x与目标翻译图像y作为一对训练数据，构建由若干对训练数据组成的训练集；2)构建PCGAN网络模型，包括生成器、判别器和分类器；将训练集中的源图像x作为生成器的输入，获得生成图像G；将生成图像G分割成n*m个大小相同的块，随机抽取若干块进行特定操作处理，并记录真实的随机特定操作矩阵，得到处理后的生成图像G*；将特定操作处理后的生成图像G*与原始生成图像G在通道维度上进行级联，作为第一级联图像；将生成图像G与训练集中的目标翻译图像y作为判别器的输入，获得生成器损失以及判别器损失；将训练集中的目标翻译图像y分割成n*m个大小相同的块，随机抽取若干块进行特定操作处理，并记录真实的随机特定操作矩阵，得到处理后的目标翻译图像y*；将特定操作处理后的目标翻译图像y*与原始的目标翻译图像y*在通道维度上进行级联，作为第二级联图像；将第一级联图像和第二级联图像作为分类器的输入，得到预测的随机特定操作矩阵，结合所述的真实的随机特定操作矩阵，获得分类器损失；3)将生成器损失、判别器损失和分类器损失之和作为总损失，对步骤2)构建的PCGAN网络模型进行训练，得到训练好的PCGAN网络模型；4)将待翻译的源图像作为训练好的PCGAN网络模型中的生成器的输入，将生成图像作为图像翻译结果。本发明的另一个目的在于提供一种自监督的图像翻译系统，用于实现上述的图像翻译方法；所述的图像翻译系统包括：数据获取模块：用于获取训练数据集和待翻译的源图像；所述的训练数据集由若干对训练数据组成，每对训练数据包括源图像x与目标翻译图像y；PCGAN网络模型模块：包括生成-对抗网络模块、分类网络模块和特定操作处理模块；所述的生成-对抗网络模块用于获取源图像x的生成图像G，对生成图像G进行判别；所述的特定操作处理模块用于对生成图像G和目标翻译图像y分割成n*m个大小相同的块，随机抽取若干块进行特定操作处理，并记录真实的随机特定操作矩阵；以及用于对特定操作处理后的生成图像G*与原始生成图像G在通道维度上进行级联，作为第一级联图像，对特定操作处理后的目标翻译图像y*与原始的目标翻译图像y*在通道维度上进行级联，作为第二级联图像；所述的分类网络模块用于预测第一级联图像和第二级联图像的随机特定操作矩阵；训练模块：用于对PCGAN网络模型模块中的生成-对抗网络模块、分类网络模块进行训练。与现有技术相比，本发明的优势在于：本发明采用一种自监督的模型，能够通过在训练中构建数据-标注关系来训练数据，这使得模型得到更充分的训练，有助于模型学习到数据之间内在的特征。该模型通过了分块的方式来对模型进行训练，这使得在训练过程中，模型需要对每个块都进行正确的分类，这有助于模型学习到图像细微部分的内容。附图说明图1是本发明提出的自监督图像翻译方法的流程框图。图2是本实施例SVHN→MNIST风格化实验结果；图3是本实施例Cityscapes数据集实验结果。具体实施方式下面结合附图对本发明做进一步的说明。本发明在图像翻译模型中融入了自监督的训练方式，在本实施例中，该模型是采用Python作为编程语言并使用Pytorch作为深度学习的框架搭建而成。具体实施方法如下：一、将源图像x与目标翻译图像y作为一对训练数据，构建由若干对训练数据组成的训练集；二、构建PCGAN网络模型，包括生成器、判别器和分类器；将训练集中的源图像x作为生成器的输入，获得生成图像G；将生成图像G分割成n*m个大小相同的块，随机抽取若干块进行特定操作处理，并记录真实的随机特定操作矩阵，得到处理后的生成图像G*；将特定操作处理后的生成图像G*与原始生成图像G在通道维度上进行级联，作为第一级联图像；将生成图像G与训练集中的目标翻译图像y作为判别器的输入，获得生成器损失以及判别器损失；将训练集中的目标翻译图像y分割成n*m个大小相同的块，随机抽取若干块进行特定操作处理，并记录真实的随机特定操作矩阵，得到处理后的目标翻译图像y*；将特定操作处理后的目标翻译图像y*与原始的目标翻译图像y*在通道维度上进行级联，作为第二级联图像；将第一级联图像和第二级联图像作为分类器的输入，得到预测的随机特定操作矩阵，结合所述的真实的随机特定操作矩阵，获得分类器损失；三、将生成器损失、判别器损失和分类器损失之和作为总损失，对步骤2)构建的PCGAN网络模型进行训练，得到训练好的PCGAN网络模型；四、将待翻译的源图像作为训练好的PCGAN网络模型中的生成器的输入，将生成图像作为图像翻译结果。在本发明的一项具体实施中，所述的特定操作处理为旋转、添加噪音、镜像反转中的任一一种。如图1所示，所述的随机特定操作矩阵是由0和1组成的二维矩阵，图像中的每一个分割好的块对应一个数值0或1，当数值为0时，表示不进行特定操作处理，当数值为1时，表示进行特定操作处理。矩阵的行列对应于图像的分块结果，例如将图像分割成n*m个大小相同的块，则随机特定操作矩阵就是由0和1组成的n*m的二维矩阵。本实施例中，生成器采用常见的编码解码结构：依次为两个卷积层、两个残差块和两个转置卷积层；判别器和分类器则采用常见的的卷积神经网络结构FCN-8，包含多个卷积层。下面为我们的PCGAN的损失函数的说明。所述的判别器损失如下，判别器的损失函数和原始GAN的损失一致，不过我们对判别器的输出采用了分块处理，这时我们的判别器输出为一个矩阵而非标量：LDgan＝log)+log))所述的生成器损失为，在原始GAN的基础上添加了分类器的结果对生成器的损失：LGgan＝log))+||Cy)))-lPO||1所述的分类器损失则是原始GAN中不存在的损失：LClS＝||Cy))-lpO||1+||cy)))-lPO||1其中，LDgan表示判别器的损失值，LGgan表示生成器的损失值，LClS表示分类器的损失值，DY表示判别器的输出结果，GXY表示生成器的输出结果，Cy表示分类器的输出结果，PO表示经过特定操作处理后的输出结果，x为源图像，y为目标翻译图像，X为源图像集合，Y为目标翻译图像集合，lPO表示真实的随机特定操作矩阵；Cat表示级联操作，按通道方向操作。在训练过程中，我们交替训练生成器、判别器以及分类器。本发明适用的图像翻译任务包括图像上色、图像风格化任务，所述的目标翻译图像是将源图像经过上色或风格化后的目标图像。与前述的自监督图像翻译方法的实施例相对应，本申请还提供了一种自监督图像翻译系统的实施例，其包括：数据获取模块：用于获取训练数据集和待翻译的源图像；所述的训练数据集由若干对训练数据组成，每对训练数据包括源图像x与目标翻译图像y；PCGAN网络模型模块：包括生成-对抗网络模块、分类网络模块和特定操作处理模块；所述的生成-对抗网络模块用于获取源图像x的生成图像G，对生成图像G进行判别；所述的特定操作处理模块用于对生成图像G和目标翻译图像y分割成n*m个大小相同的块，随机抽取若干块进行特定操作处理，并记录真实的随机特定操作矩阵；以及用于对特定操作处理后的生成图像G*与原始生成图像G在通道维度上进行级联，作为第一级联图像，对特定操作处理后的目标翻译图像y*与原始的目标翻译图像y*在通道维度上进行级联，作为第二级联图像；所述的分类网络模块用于预测第一级联图像和第二级联图像的随机特定操作矩阵；训练模块：用于对PCGAN网络模型模块中的生成-对抗网络模块、分类网络模块进行训练。关于上述实施例中的系统，其中各个单元或模块执行操作的具体方式已经在有关该方法的实施例中进行了详细描述，此处将不做详细阐述说明。对于系统实施例而言，由于其基本对应于方法实施例，所以相关之处参见方法实施例的部分说明即可。以上所描述的系统实施例仅仅是示意性的，其中所述作为PCGAN网络模型模块，可以是或者也可以不是物理上分开的。另外，在本发明中的各功能模块可以集成在一个处理单元中，也可以是各个模块单独物理存在，也可以两个或两个以上模块集成在一个单元中。上述集成的模块或单元既可以采用硬件的形式实现，也可以采用软件功能单元的形式实现，以根据实际的需要选择其中的部分或者全部模块来实现本申请方案的目的。为了验证本发明的效果，在多个图像翻译任务上进行了实验。实验如下：实施例1SVHN和MNIST是两个不同风格的图像数据集，每张图片包含一个数字，该实验尝试将SVHN风格的图像转换为MNIST风格图像。通过一个MNIST分类器判别转换后图像内数字的类别，一般而言，分类准确度越高代表生成器的能力越强。实验的图像结果如图2所示。实验的量化结果如表1所示。表1 SVHN→MNIST风格化实验结果可以看出本发明的模型得到的准确度为27.4％，相较于不使用自监督的基准模型而言有了5.0％的提升，与常用的distanceGAN模型相比，有了0.6％的提升。可以看出自监督能够显著提升图像翻译的效果。实施例2Cityscapes是一个多用途的图像数据集，内部包含了照片和图像分割后的真实数据，通过本发明的生成器将照片翻译为分割后的数据和真实数据比较，计算pixel acc、class acc和meanIoU三个指标的平均值。其中pixel acc为分类正确的像素点数和所有的像素点数的比例，class acc为每一类分类正确的像素点数和该类的所有像素点数的比例然后求平均，meanIoU计算每一类的IoU然后求平均，其中IoU为某类别的真实区域和模型产生的分割区域的交集除以并集所得。实验结果如图3所示，量化结果由表2所示：表2 Cityscapes数据集实验结果可以看出。本发明的模型取得了0.282的成绩，相较于基准模型有了0.023的提升，这足以证明我们提出的模型的有效性。
