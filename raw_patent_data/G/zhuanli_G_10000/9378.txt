标题title
基于改进RetinaNet的小肠淋巴瘤分割模型建立、分割方法及装置
摘要abst
本发明公开了一种基于改进RetinaNet的小肠淋巴瘤分割模型建立、分割方法及装置。本方法建造的分割模型基于RetinaNet网络模型，替换原有的FPN结构，使用多种方式非线性融合不同尺度特征的金字塔网络，并在主干网络当中加入通道注意力模块，提高模型对于不同形态尺度目标的特征提取能力，降低背景因素对训练造成的影响。结合了free‑anchor的方法，实现候选框与检测目标的自适应匹配，从而更好的针对不同形态的目标。相比于传统模型，本发明的分割模型在小肠淋巴瘤的分割上具有更好的性能。
权利要求书clms
1.一种基于改进RetinaNet的小肠淋巴瘤分割模型建立方法，其特征在于，包括如下步骤：步骤1：获取腹部切片图像数据集，对每张腹部切片图像进行标注，获得标签集；步骤2：建立RetinaNet模型，所述的RetinaNet模型包括主干网络、特征金字塔网络和检测网络，所述的主干网络包括四个主干块，每个主干块后连接有一个通道注意力模块，所述的主干网络用于提取不同尺度的特征图{C2，C3，C4，C5，C6，C7}，其中，C2、C3、C4和C5分别由不同的主干块输出，C6由C5进行下采样后获得，C7由C6进行下采样后获得；所述的特征金字塔网络用于对不同尺度的特征图进行特征增强得到增强特征图{P2，P3，P4，P5，P6，P7}，其中，P3、P4、P5、P6和P7分别由同层的C3，C4，C5，C6和C7增强后获得，P2由P3下采样和C2相加后获得；所述的检测网络设置在特征金字塔网络的每一层增强特征图之后，所述的检测网络包括回归器和分类器，所述的回归器用于生成锚框，所述分类器用于对锚框中的目标进行分类；步骤3：对RetinaNet模型进行预训练，以预训练后RetinaNet模型的参数进行初始化，采用腹部切片图像数据集作为训练集结合标签集对初始化后的RetinaNet模型进行训练，将训练好的RetinaNet模型作为小肠淋巴瘤分割模型。2.如权利要求1的基于改进RetinaNet的小肠淋巴瘤分割模型建立方法，其特征在于，所述的主干网络为ResNeXt101，所述的特征金字塔网络为NAS-FPN。3.如权利要求1的基于改进RetinaNet的小肠淋巴瘤分割模型建立方法，其特征在于，所述的增强特征图通过以下方法获得：每张增强特征图从不同尺度的特征图抽取两个特征图依次进行统一尺度、特征融合和卷积后，获得增强特征图。4.一种基于改进RetinaNet的小肠淋巴瘤分割方法，其特征在于，包括如下步骤：步骤一：获取待检测腹部切片图像；步骤二：将待检测腹部切片图像输入权利要求1～3中任一种基于改进RetinaNet的小肠淋巴瘤分割模型建立方法得到的小肠淋巴瘤分割模型，获得待检测腹部切片图像的分割结果。5.一种基于改进RetinaNet的小肠淋巴瘤分割装置，其特征在于，该装置包括处理器和用于存储能够在处理器上运行的多个功能模块的存储器，所述功能模块包括小肠淋巴瘤分割模型和分割模块；所述的小肠淋巴瘤分割模型采用如权利要求1～3中任一种基于改进RetinaNet的小肠淋巴瘤分割模型建立方法获得；所述的分割模块用于获取待检测腹部切片图像，将待检测腹部切片图像输入小肠淋巴瘤分割模型，获得待检测腹部切片图像的分割结果。6.一种存储介质，其上存储有计算机程序，其特征在于，该程序被处理器执行时实现如权利要求4的基于改进RetinaNet的小肠淋巴瘤分割方法。
说明书desc
技术领域本发明属于医学影像分割领域，具体涉及一种基于改进RetinaNet的小肠淋巴瘤分割模型建立、分割方法及装置。背景技术随着计算机硬件的发展，大规模存储数据成为了可能。大量的数据为神经网络模型提供了丰富的可供学习的资源。同时，图像处理器的发展，使得计算机可以快速的处理矩阵运算，极大的加快了模型的训练速度。这一系列的发展使得深度学习成为了目前图像识别领域的主流算法。深度学习与传统方法的区别在于，深度学习不需要人工提取特征，而是通过学习，自适应的提取图像中最显著的特征，避免了人工提取特征的差异对最终分类结果的影响。目前，越来越多深度学习的方法应用于医疗CT影像的诊断当中，并且取得了良好的效果。Yan等人提出了3DCE的网络结构，该结构利用了切片之间特征的空间关联性，将相邻切片按通道进行堆叠从而形成若干个三通道的数据模块，每个数据模块的中间通道含有标注的信息，这些数据模块送入网络将分别进行特征提取并进行特征融合，从而有利于模型检测效果的提升。Li等人提出了MVP-Net网络模型，该模型结合了临床诊断的经验，将同一切片转化为不同窗口类型和窗口宽度的数据类型，并通过不同的分支将转化后的数据分别送入网络中进行特征提取和特征融合，有效提高了模型的检测精度。然而，上述模型均是针对一些发生率较高肿瘤疾病的检测且其网络模型结构过于复杂，需要消耗很高的计算资源。目前，很少有人把目标检测的方法直接用于小肠淋巴瘤CT影像当中，若直接把现有技术应用于对小肠淋巴瘤的检测，效果并不理想。这是因为：小肠淋巴瘤作为小肠恶性肿瘤的一种，其形态结构十分复杂。根据其形态结构和病理类型可分为伯基特淋巴瘤、弥漫大B细胞性淋巴瘤和套细胞淋巴瘤等。介于小肠淋巴瘤形态结构复杂，尺度差异性大等因素，一些淋巴瘤难以有效的识别，主要存在的困难有以下几点：1)胃肠道自身环境的复杂。胃肠道中肠道的形状千变万化，且不同个体之间的差异性极大。除此之外，肠道四周还有骨骼、脂肪层、胰腺、肾脏和胃等组织和器官，会对肿瘤的识别造成干扰。2)肿瘤尺度差异性大。特别是一些较小肿瘤，其特征较为不明显，与周边肠道具有高度相似性。3)肿瘤形态特征多样。这些形态尺度的巨大差异给小肠淋巴瘤的正确分割带来了巨大的挑战。发明内容本发明的目的在于提供一种基于改进RetinaNet的小肠淋巴瘤分割模型建立、分割方法及装置，用以解决现有技术中的肿瘤与周围背景具有相似性，现有算法进行分割时易受到肿瘤周边背景信息的干扰导致分割精度不高，同时小肠淋巴瘤存在较大尺度形态差异性，现有方法对于不同尺度形态目标的特征提取能力不足等问题。为了实现上述任务，本发明采用以下技术方案：一种基于改进RetinaNet的小肠淋巴瘤分割模型建立方法，包括如下步骤：步骤1：获取腹部切片图像数据集，对每张腹部切片图像进行标注，获得标签集；步骤2：建立RetinaNet模型，所述的RetinaNet模型包括主干网络、特征金字塔网络和检测网络，所述的主干网络包括四个主干块，每个主干块后连接有一个通道注意力模块，所述的主干网络用于提取不同尺度的特征图{C2，C3，C4，C5，C6，C7}，其中，C2、C3、C4和C5分别由不同的主干块输出，C6由C5进行下采样后获得，C7由C6进行下采样后获得；所述的特征金字塔网络用于对不同尺度的特征图进行特征增强得到增强特征图{P2，P3，P4，P5，P6，P7}，其中，P3、P4、P5、P6和P7分别由同层的C3，C4，C5，C6和C7增强后获得，P2由P3下采样和C2相加后获得；所述的检测网络设置在特征金字塔网络的每一层增强特征图之后，所述的检测网络包括回归器和分类器，所述的回归器用于生成锚框，所述分类器用于对锚框中的目标进行分类；步骤3：对RetinaNet模型进行预训练，以预训练后RetinaNet模型的参数进行初始化，采用腹部切片图像数据集作为训练集结合标签集对初始化后的RetinaNet模型进行训练，将训练好的RetinaNet模型作为小肠淋巴瘤分割模型。进一步的，所述的主干网络为ResNeXt101，所述的特征金字塔网络为NAS-FPN。进一步的，所述的增强特征图通过以下方法获得：每张增强特征图从不同尺度的特征图抽取两个特征图依次进行统一尺度、特征融合和卷积后，获得增强特征图。一种基于改进RetinaNet的小肠淋巴瘤分割方法，包括如下步骤：步骤一：获取待检测腹部切片图像；步骤二：将待检测腹部切片图像输入任一种基于改进RetinaNet的小肠淋巴瘤分割模型建立方法得到的小肠淋巴瘤分割模型，获得待检测腹部切片图像的分割结果。一种基于改进RetinaNet的小肠淋巴瘤分割装置，该装置包括处理器和用于存储能够在处理器上运行的多个功能模块的存储器，所述功能模块包括小肠淋巴瘤分割模型和分割模块；所述的小肠淋巴瘤分割模型采用基于改进RetinaNet的小肠淋巴瘤分割模型建立方法获得；所述的分割模块用于获取待检测腹部切片图像，将待检测腹部切片图像输入小肠淋巴瘤分割模型，获得待检测腹部切片图像的分割结果。一种存储介质，其上存储有计算机程序，该程序被处理器执行时实现基于改进RetinaNet的小肠淋巴瘤分割方法。本发明与现有技术相比具有以下技术特点：本发明使用DepLesion数据集训练好的模型作为预训练模型。冻结浅层的参数，只对深层的参数进行微调，提升了模型对小肠淋巴瘤分割的效果。本发明采用多种方式非线性融合不同尺度特征的金字塔网络，该网络使用神经网络搜索算法得到。提高了模型对于不同形态尺度目标的特征提取能力。本发明在模型主干网络中引入了通道注意力模块，提高了模型对小肠淋巴瘤特征的提取能力，降低背景因素对训练造成的影响。本发明结合了free-anchor的方法，实现候选框与检测目标的自适应匹配，从而更好的针对不同形态的目标，提高了模型对肿瘤的定位和识别能力。附图说明图1为小肠淋巴瘤分割模型网络结构图；图2为预训练流程图；图3为主干块结构示意图；图4为通道注意力模块结构示意图；图5为实施例中的主干网络连接方式与参数设置；图6为特征金字塔网络结构示意图；图7为融合块组成示意图；图8为消融实验结果；图9为不同模型的实验的对比结果。具体实施方式首先对本发明中出现的技术词汇进行解释：RetinaNet：RetinaNet是由何凯明等人提出的单阶段目标检测模型。模型主要由特征金字塔和Focal loss两部分组成。该模型结构简单，同时对于正负样本的失衡问题具有较好的检测效果。ImageNet：是一个计算机视觉系统识别项目，是目前世界上图像识别最大的数据库，包含了1000个类别的1000多万张图片。DeepLesion数据库：由美国国立卫生研究院临床中心的团队开发该数据库中的图像包括多种病变类型，如肾脏病变，骨病变，肺结节和淋巴结肿大等。一共有30000多个病人的数据，并且对于每个病人的病灶区域都有详细的标注。锚框：锚框类似于候选框，用于圈定目标区域的位置。Free-Anchor：文献出处：Zhang X,Wan F,Liu C,et al.Learning to matchanchors for visual object detection.arXiv 2019.arXiv preprint cs.CV/1909.02466。在本实施例中公开了一种基于改进RetinaNet的小肠淋巴瘤分割模型建立方法，包括如下步骤：步骤1：获取腹部切片图像数据集，对每张腹部切片图像进行标注，获得标签集；步骤2：建立RetinaNet模型，所述的RetinaNet模型包括主干网络、特征金字塔网络和检测网络，所述的主干网络包括四个主干块，每个主干块后连接有一个通道注意力模块，所述的主干网络用于提取不同尺度的特征图{C2，C3，C4，C5，C6，C7}，其中，C2、C3、C4和C5分别由不同的主干块输出，C6由C5进行下采样后获得，C7由C6进行下采样后获得；所述的特征金字塔网络用于对不同尺度的特征图进行特征增强得到增强特征图{P2，P3，P4，P5，P6，P7}，其中，P3、P4、P5、P6和P7分别由同层的C3，C4，C5，C6和C7增强后获得，P2由P3下采样和C2相加后获得；所述的检测网络设置在特征金字塔网络的每一层增强特征图之后，所述的检测网络包括回归器和分类器，所述的回归器用于生成锚框，所述分类器用于对锚框中的目标进行分类；步骤3：对RetinaNet模型进行预训练，以预训练后RetinaNet模型的参数进行初始化，采用腹部切片图像数据集作为训练集结合标签集对初始化后的RetinaNet模型进行训练，将训练好的RetinaNet模型作为小肠淋巴瘤分割模型。具体的，步骤1中标注获得标签包括：采用COCO数据集定义的标签形式。COCO数据集标签采用xml格式的数据类型，与模型训练相关的字段信息如下所示：id用于代表训练图像中肿瘤的唯一标识。width和height用于表示肿瘤的大小,分别表示肿瘤检测框的宽度和高度。肿瘤检测框为上图医生标注的外接矩形。file_name表示影像切片的文件名。具体的，所述的主干网络为ResNeXt101，所述的特征金字塔网络为NAS-FPN。具体的，所述的增强特征图通过以下方法获得：NAS-FPN通过两种方式将不同尺度的特征图进行融合。两种方式分别为sum和global pooling。两种方式在进行特征融合前，均需要将抽取到的不同尺度的特征图调整到相同尺度的大小。sum是将调整后的两特征图逐元素相加。global pooling通过将调整后其中一个特征图通过全局最大值池化操作和sigmoid得到每个通道的注意力分值，将该注意力分值与另外一个特征图相乘，然后再将相乘得到的特征图与初始的特征图相加，获得增强特征图。具体的，NAS-FPN的结构如表1所示：表1NAS-FPN的组成结构输出特征图输入特征图1输入特征图2连接方式p4_1c6c4global poolingp4_2p4_1c4sump3p4_2c3sump4p3p4_2sump5_tempp4p3global poolingp5c5p5_tempsump7_tempp5p4_2global poolingp7c7p7_tempsump6p7p7global pooling其中c3，c4，c5，c6，c7代表了主干网络抽取的不同尺度的特征图。p3，p4，p5，p6，p7代表特征金字塔输出的特征图。输出特征图与原特征图尺寸是对应相等的。本文为了增加模型对于小目标的检测能力，还使用分辨率更高的p2层用于目标的检测，p2层是由p3层经过下采样直接与c2层相加得到。具体的，检测网络会在P2-P7每一层产生锚框，锚框的大小取决于P2-P7层的尺寸。数量为W×H×9。W和H分别表示特征图的宽和高。所述回归器用于对锚框进行微调，产生检测框的坐标。分类器对锚框中的目标进行分类，用于确定其具体的类别。P2-P7层每一层都有分类器和回归器。最终结果通过非极大值抑制得到。具体的，所述预训练包括：将具有标注的DeepLesion数据送入本方法使用的模型中进行训练，模型的参数随机初始化，直到模型的训练损失收敛停止训练，保存模型训练好的参数为.pth文件类型。具体的，步骤3训练时，将具有标注的小肠淋巴瘤数据送入模型中进行训练，参数初始化过程中会依次从预训练任务保存的文件中导入相对应的参数，冻结预训练阶段导入的参数，直到训练损失收敛，得到最终训练好的网络模型。具体的，步骤3进行训练时，损失函数为Free-Anchor。在本实施例中公开了一种基于改进RetinaNet的小肠淋巴瘤分割方法，包括如下步骤：步骤一：获取待检测腹部切片图像；步骤二：将待检测腹部切片图像输入小肠淋巴瘤分割模型，获得待检测腹部切片图像的分割结果。在本实施例中公开了一种基于改进RetinaNet的小肠淋巴瘤分割装置，该装置包括处理器和用于存储能够在处理器上运行的多个功能模块的存储器，所述功能模块包括小肠淋巴瘤分割模型和分割模块；所述的基于双重注意力机制的分割模型采用如权利要求2的基于双重注意力机制的分割模型建立方法获得；所述的分割模块用于获取待检测腹部切片图像，将待检测腹部切片图像输入小肠淋巴瘤分割模型，获得待检测腹部切片图像的分割结果。具体的，所述的分割结果为小肠淋巴瘤的病灶区域。本实施例还公开了一种存储介质，其上存储有计算机程序，该程序被处理器执行时实现基于改进RetinaNet的小肠淋巴瘤分割方法。实施例1本实施例使用pytorch作为实验的框架，使用RetinaNet作为基准网络模型。主干网络是ResNext101,输入图片尺寸大小为512×512，模型选用Adam优化器，初始学习率为0.00001。使用pytorch的工具类ReduceLROnPlateau来对训练过程中的学习率进行调整。其中patience设置为4，即模型连续四次迭代损失不下降就降低学习率。每次更新学习率时，将新的学习率变为上一次迭代学习率的80％。损失函数中，α设置为0.25，γ设置为2。迭代次数为18次。anchor尺度设置为。本实施例的腹部切片图像数据集共有34位带有标注的病人数据。其中26例病人用于训练，8例病人用于测试。此外还有58位医生确认患病，但没有进行标注的患者数据。带有标注的病人数据中，每一个患者的DICOM文件是由相应的设备对病患的腹部进行逐层的断面扫描，得到的一系列沿z轴堆叠的三维图像。每名患者切片平均数量为40张左右，多的数量可以达到80张。每名患者切片当中有一部分是有淋巴瘤的切片，这一部分切片经过了医生的标注。每个病患切片的格式为DICOM格式。医生标注肿瘤数据之后，产生的标注文件的格式也为DICOM格式。每个DICOM文件除了包含医学影像信息之外，还含有相应的DICOM数据头部信息。每个数据头部信息中包含了标识的相关信息。其中，病人淋巴瘤切片信息和医生标注信息中都含有唯一的标示信息，这些标示信息可以建立起病人淋巴瘤数据和医生标注数据一对一的映射关系，通过这一关系可以将经过医生标注后的淋巴瘤数据从患者的原始切片数据当中分离出去。本实施例使用了pydicom这个库来完成分离淋巴瘤数据的工作，最终得到医生标注好的淋巴瘤切片数据共954张。为了便于后续迁移学习的训练，我们将所有的DICOM格式文件转化为JPG格式。转化后的图片大小为512*512。本实施例使用已有标注数据训练好的模型，对未标注的患者数据进行检测。检测得到的结果选取置信度高的做为模型的训练数据。为了保证得到结果的准确性，选择三个不同网络结构的模型用于检测，通过比较各个模型的结果并使用手动筛查的方式来得到最终的标注结果，筛查主要依据了同一病人相邻切片之间的关联性。模型经过了两次迭代，每次迭代包括了上次训练通过筛查得到的数据。最终得到了标注数据603张，得到的数据将全部用于训练。用于训练的数据总计1353张，用于测试的数据154张。本实施例采用平均精度和召回率作为目标检测模型的主要评价指标。表1详细列举了计算上述指标需要的各项基本指标。表2检测指标所需的各项基本指标Recall表示模型对肿瘤的查全率，即实际存在的肿瘤当中，有多少肿瘤被模型检测到。Precision是模型对肿瘤检测的准确度，表示模型检测出来的肿瘤当中有多少肿瘤是正确的。AP值的大小通过PR曲线下的面积来表示。PR曲线是以recall值为横轴，precision值为纵轴得到的曲线。AP值越大，则模型的检测效果越好。为了便于计算，AP值通常由PR曲线上等间距的11个点计算平均值得到。Pascal VOC数据集通常使用AP0.5来反映检测结果的好坏，0.5表示的是检测结果与真实标注之间的IOU值，即IOU值大于0.5我们就认为其为正例。但从COCO数据集开始，目标检测逐渐采用AP{0.5:0.95}来评价检测结果。AP{0.5:0.95}是通过将0.5到0.95之间的IOU值，每间隔0.05就计算一次AP值，然后把得到的所有值取平均来计算得出。这种方式除了能够表示模型检测结果的好坏，还可以反映模型对于目标的定位能力。本实施例共分为两部分，第一部分是对模型各个组件采用消融实验的方式，已验证各个模块或组件之间的相互作用，以及它们对实验结果产生的影响。第二部分则是将模型与近几年提出的目标检测模型做对比，已验证本发明模型对小肠淋巴瘤检测的优越性。S代表引入通道注意力模块，Nms表示使用加入p2层的NMS-FPN网络结构。FA表示使用最佳Anchor匹配机制的训练方式。D表示使用DeepLesion预训练好的模型，冻结网络的第一阶段参数。本文的对比实验设置如表3所示，表中的“√”表示相应的模块被选择。如S-Nms-D表示引入通道注意力模块，使用加入p2层的NMS-FPN网络结构，并使用DeepLesion数据集做迁移学习。表格中的baseline表示原始RetinaNet网络模型，使用ImageNet数据集作预训练。表3模型设计方法SNmsFADbaselineD√S+D√√Nms+D√√FA+D√√Nms+D+FA√√√Nms+D+S√√√Nms+D+FA+S√√√√下表展示了不同对照组之间的结果，使用AP0.5，AP{0.5:0.95}，Recall0.5，Recall{0.5:0.95}来对实验结果进行评价。其中recall判决门限为0.5。实验结果如表4所示。表4消融实验结果从表4可以看出。初始的模型测试效果并不好，可能原因在于其使用的是自然图像的数据作预训练，这些图像与本文使用的医疗影像数据之间存在很大的差别。在使用DeepLesion数据集做预训练之后，模型的AP0.5提升了7.2％。说明医疗影像数据之间的迁移学习可以有效的提升模型的检测能力。在迁移学习的模型当中分别添加带p2层的NMS-FPN网络结构、通道注意力机制、最佳anchor匹配机制，三种模型AP0.5值分别提升了22.1％、5.3％和3.3％。说明三个模块均对初始模型有一定的提升作用。其中Nms+D模块提升效果最为明显，说明提高模型对于多尺度特征的提取能力对于增强模型的检测效果有十分重要的作用。Nms+D+FA与Nms+D+S相比，模型的AP{0.5:0.95}、Recall{0.5:0.95}值提升较为明显，说明最佳anchor匹配机制可以使模型学到更好的肿瘤特征，从而有效的提高模型对检测目标的定位能力。本发明模型相比于baseline在AP0.5、AP{0.5:0.95}、Recall0.5、Recall{0.5:0.95}检测指标上分别提升了32.4％、65.3％、21.8％、28.2％，说明本发明提出模型与原始模型相比有显著的效果提升。图8展示了消融实验的结果图，其中，a)为ground truth方法，b)为baseline方法，c)为D方法，d)为S+D方法，e)为Nms+D方法，f)为FA+D方法，g)为Nms+D+FA方法，h)为Nms+D+S方法，i)为Nms+D+FA+S方法。结合实验结果可以看出，在结合了三种模块之后，模型的检测效果有了明显的提升。具体提升体现在在结合了改进之后特征金字塔结构以后，模型对于一些较小的目标有了更好的识别能力。同时，注意力机制的引入使得模型避免了一些背景信息的干扰，模型的误检率得到了明显的下降。在结合了最佳anchor匹配机制之后，模型对于复杂形态的目标的检测以及一些肿瘤的定位能力有了明显的提升。为了进一步验证本文提出的模型的优越性，将本文模型与文献Yang Z,Liu S,HuH,et al.Reppoints:Point set representation for object detection//Proceedings of the IEEE/CVF International Conference on Computer Vision.2019:9657-9666进行比较。所有模型都使用DeepLesion数据做迁移学习，其中YOLOv3使用darknet53做主干结构，其他模型使用ResNext101做网络主干结构。表5展示了不同模型对比实验的结果。表5不同模型对比实验的结果图9展示了不同模型实验的对比结果。a)为GT方法，b)为FCOS方法，c)为Reppoint方法，d)为PANet方法，e)为LibraNe方法，f)为YOLOv3方法，g)为本方法。通过与近几年的一些检测模型进行比较，可以看出本文提出的模型在小肠淋巴瘤数据集上具有优越的检测能力。
