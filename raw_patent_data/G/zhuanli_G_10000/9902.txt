标题title
一种自适应确定目标尺寸和感受野大小的方法
摘要abst
本发明公开了一种自适应确定目标尺寸和感受野大小的方法，包括如下步骤：S1：定义九个候选框尺寸，计算真实目标框与候选框的交集面积，与它们的并集面积比，得到一个面积比值；S2：根据得到的候选框，计算出正候选框与真实框之间的偏移量offset与缩放因子；S3：从正候选框中选出得分最高的k个候选框，再进行一次面积计算，大于给定阈值的视为该正候选框与得分最高的其中一个候选框表示同一个目标故去掉。本发明在保证高运算效率以及低内存占有率的情况下保证了图像目标框的结果，通过RGB颜色差值的对比来进行分割，每个图片包含的像素点均有最大限制，保证了每张图片产生九×高×宽个候选框，保证了计算运行的效率。
权利要求书clms
1.一种自适应确定目标尺寸和感受野大小的方法，其特征在于，该方法包括如下步骤：Step1：对原始分辨率448*256的图片进行ResNet-50网络卷积操作提取特征图featuremaps，将卷积中的乘法换成加法操作,具体操作如下：其中，Y表示输出坐标为第t个通道的值，X表示输入坐标为的第k个通道的值，cin为原始输入图片的通道，F是过滤器，也为权值矩阵,过滤器大小为d*d，经过ResNet-50网络卷积得到28*16*256的特征图，用于区域候选框提取RPN和感兴趣区域池化ROIPooling共享；Step2:定义九个边界框尺寸，候选框尺寸如下：{,,,,,,,,}；Step3：选取公共数据集ImageNet，包括训练集和测试集，训练集中的图片由两部分组成：一是未做任何标注的图片，二是与图片对应的图片中真实目标框的坐标信息，选取ImageNet中部分训练集做实验数据，自行创建一个txt文本文件，存储训练集中真实目标框的坐标信息；Step4：根据ResNet-50提取特征图28*16*256标注的原始框，使用RPN提取其中的边界框，下面根据与真实框的映射每个位置增加一个偏移量offset：其中，p0表示输出的像素坐标，坐标表示为：R＝{,,,,,,,,},pn遍历R中的每一个点，Δpn表示偏移量，w为过滤器每个位置的权重；把原来的卷积过程分成两路，一路学习偏移量Δpn，得到2N*H*W的输出，N＝|R|表示R是前面公式表示的3*3矩阵，加绝对值表示获取矩阵中点的个数，也就是9，2N是有x、y两个方向的偏置，H、W分别为特征图的高和宽，Δpn是一个预设的小数，采用双线性插值法，获取特征图两个相邻斜对角左下、右上坐标之间的值，公式为：其中，f、f、f、f分别为四个坐标对应的值，f为插值后得到的值；使用3*3的滑动卷积窗口对特征图做卷积操作，得到28*16个向量，每个向量256维；对整个特征图做两次1*1的卷积，产生两块layer，一块是cls layer，维度为2*H*W，表示分类这块区域是前景或背景；另一块是reglayer，维度为4*H*W，表示预测出相对于原图偏移的Δx,Δy,Δw,Δh位置；Step5：对于cls layer分类，对前景和背景分别用正样本1和负样本0进行标签，计算原始标注框与边界框的交集面积I和并集面积U，得到一个面积比值IOU：IOU＝I/U对这个比值进行过滤，筛选出与任意一个原始标注框的IOU重叠部分大于0.7的边界框作为正样本标签，与任意一个原始标注框的IOU重叠部分小于0.3的边界框作为负样本标签，分类学习的损失函数为：其中，Lcls为回归损失函数，pi为anchor预测为目标的概率，只有两个值，pi＝0表示预测目标失败为背景框，pi＝1表示预测目标成功为目标框；表示训练集真实标注框：表示负标签，表示正标签；Step6：对于reg layer回归，通过不断训练收敛得到的特征图中点的四个值：xr、yr、hr、wr，表示预测的边界盒的四个坐标参数，与原始标注框坐标差值在预设范围内，使其收敛趋于原始标注框的坐标，回归损失函数为：其中，Lreg为回归损失函数，ti＝{xr，yr，wr，hr}表示预测的边界盒的四个坐标参数，是目标标注框的四个坐标参数，R为计算预测边界盒参数收敛于目标标注框参数的函数；Step7：通过step5和step6的分类和回归操作之后，对由边界框变成由RPN给出的候选框进行筛选；Step8：提出了ROI pooling感兴趣区域池化实现训练和测试的加速，并提高了检测的精度，感兴趣区域池化层有两个输入：一是经过基础网络卷积和池化后的固定大小的特征图；二是表示感兴趣区域ROI的N*5的矩阵，其中N表示感兴趣区域ROI的数目，第一列表示图像索引，之后四列表示图像感兴趣区域的左上角和右下角坐标的信息，技术方案如下：根据输入图像，将ROI映射到特征图对应位置；将映射后的区域划分为相同大小的部分，部分数量与输出的维度相同；对每个部分进行max pooling最大值池化操作。2.根据权利要求1所述的一种自适应确定目标尺寸和感受野大小的方法，其特征在于，所述非极大值抑制的过程如下：将所有框的得分排序，选中最高分及其对应的框；遍历其余的框，如果和当前最高分框的重叠面积大于一定阈值，将其删除；从未处理的框中继续选一个得分最高的，重复上述过程，直到将所有框按照上述方法处理完成。3.根据权利要求1或2所述的一种自适应确定目标尺寸和感受野大小的方法，其特征在于，所述Step7的筛选以如下三步进行筛选：第一步：通过候选框映射回到原图input image，映射关系可以用公式如下：对于卷积/池化层：pi＝si*pi+1+/2—padding)对于激活层：pi＝pi+1其中，pi表示第i层特征的中心点，si表示卷积窗口的步长，ki表示卷积窗口的大小，padding取“valid”＝0和“same”＝1两个值，当步长等于“valid”时，不作任何处理，当padding等于“same”时，保持宽度W和高度H和卷积前一样，由si步长引起的特征图宽度和高度的减少用padding补充0来补足；对以下几种情况的候选框进行剔除：1.候选框左侧水平坐标小于0；2.候选框右侧水平坐标大于原图宽度；3.候选框下侧垂直坐标小于0；4.候选框上侧垂直坐标大于原图高度；第二步：经过第一步的剔除，再对剩下的边框进行softmax打分，根据前景的anchorbox按照分数从高到低排序，筛选出两千个分数最高的候选框；第三步：将筛选出的两千个候选框进行NMS，即非极大值抑制，再次进行排序，最终选取得分最高的300个候选框作为最终候选框。
说明书desc
技术领域本发明涉及一种自适应确定目标尺寸和感受野大小的方法，属于计算机视觉和模式识别领域。背景技术图片是由W×H×3的像素点组成，其中W、H是图片的宽和高，3代表由红、绿、蓝组成3通道的颜色，代表图片中的任意一点，是位置坐标，rbg为该位置的颜色。目标检测分为两类，一类是two-stage，将物体识别和定位分为两个步骤，例如R-CNN、Fast R-CNN、Faster R-CNN；另一类是one-stage，适用于实时检测，例如Yolo、SDD、YoloV2。第一类准确度更高，但速度慢一些，第二类速度更快，但没有two-stage精确。本发明则是属于第一类two-stage。传统卷积网络的卷积核都是固定大小的尺寸，不能很好的适应几何形变，可变形卷积网络在位置坐标中加了一个偏移量Δp，能够自适应学习改变提取框的形状和位置，但是由于多加了一个训练参数，将会导致训练速度低下，为了提升网络的训练速度，减小资源消耗。RPN，本质上是基于过滤器的无差别object检测。RPN的输入特征图是Faster RCNN的公用特征图Feature map，取一个a*a的滑动窗口，对特征图中的k个候选框做卷积操作，根据每个候选框的得分和位置坐标来修改提取框，确定目标中心。而日常生活中大多数是不规则物体，矩形提取框不能很好描述目标。本发明受可变形卷积网络启发，在基础RPN的提取框上进行改进。需要对Featuremap提取几个候选框，在候选框中的每个位置增加一个偏移量，经过学习候选框则会移动到目标位置，候选框也会形成目标形状。以上网络的实现如果采用传统网络的输入矩阵与权值矩阵的乘积，因为增加了的一个位置参数，而使得计算量巨大。所以这里我们采用加法网络代替乘法网络，精度损失非常小，但速度提升一个量级。发明内容发明目的：本发明旨在使用加法网络提升two-stage目标检测的速度，使提取框更准确的描述目标。技术方案：为实现本发明的目的，本发明所采用的技术方案是：一种自适应确定目标尺寸和感受野大小的方法，该方法包括如下步骤：Step1：对原始分辨率448*256的图片进行ResNet-50网络卷积操作提取特征图featuremaps，将卷积中的乘法换成加法操作,具体操作如下：其中，Y表示输出坐标为第t个通道的值，X表示输入坐标为的第k个通道的值，cin为原始输入图片的通道，F是过滤器，也为权值矩阵,过滤器大小为d*d，经过ResNet-50网络卷积得到28*16*256的特征图，用于区域候选框提取RPN和感兴趣区域池化ROIPooling共享；Step2:定义九个边界框尺寸，候选框尺寸如下：{,,,,,,,,}；Step3:选取公共数据集ImageNet，包括训练集和测试集，训练集中的图片由两部分组成：一是未做任何标注的图片，二是与图片对应的图片中真实目标框的坐标信息。由于公共数据集ImageNet数据量巨大和实验环境限制，选取ImageNet中部分训练集做本实验数据。自行创建一个txt文本文件，存储训练集中真实目标框的坐标信息；Step4：根据ResNet-50提取特征图28*16*256标注的原始框，使用RPN提取其中的边界框，下面根据与真实框的映射每个位置增加一个偏移量offset：其中，p0表示输出的像素坐标，本文中过滤器大小为3*3，坐标表示为R＝{,,,,,,,,},pn遍历R中的每一个点，Δpn表示偏移量，w为过滤器每个位置的权重；把原来的卷积过程分成两路，一路学习偏移量Δpn，得到2N*H*W的输出，N＝|R|表示R是前面公式表示的3*3矩阵，加绝对值表示获取矩阵中点的个数，也就是9，2N是有x、y两个方向的偏置，H、W分别为特征图的高和宽，Δpn是一个预设的小数，采用双线性插值法，获取特征图两个相邻斜对角左下、右上坐标之间的值，公式为：其中，f、f、f、f分别为四个坐标对应的值，f为插值后得到的值；使用3*3的滑动卷积窗口对特征图做卷积操作，得到28*16个向量，每个向量256维；对整个特征图做两次1*1的卷积，产生两块layer，一块是cls layer，维度为2*H*W，表示分类这块区域是前景或背景；另一块是reg layer，维度为4*H*W，表示预测出相对于原图偏移的Δx,Δy,Δw,Δh位置；Step5：对于cls layer分类，对前景和背景分别用正样本1和负样本0进行标签，计算原始标注框与边界框的交集面积I和并集面积U，得到一个面积比值IOU：IOU＝I/U对这个比值进行过滤，筛选出与任意一个原始标注框的IOU重叠部分大于0.7的边界框作为正样本标签，与任意一个原始标注框的IOU重叠部分小于0.3的边界框作为负样本标签，分类学习的损失函数为：其中，Lcls为回归损失函数，pi为anchor预测为目标的概率，标注框：表示负标签，表示正标签；Step6：对于reg layer回归，通过不断训练收敛得到的特征图中点的四个值：xr、yr、hr、wr，表示预测的边界盒的四个坐标参数，与原始标注框坐标差值在预设范围内，使其收敛趋于原始标注框的坐标，回归损失函数为：其中，Lreg为回归损失函数，ti＝{xr，yr，wr，hr}表示预测的边界盒的四个坐标参数，是目标标注框的四个坐标参数；Step 7：通过step5和step6的分类和回归操作之后，对由边界框变成由RPN给出的候选框进行筛选；Step 8：提出了ROI pooling感兴趣区域池化实现训练和测试的加速，并提高了检测的精度，感兴趣区域池化层有两个输入：一是经过基础网络卷积和池化后的固定大小的特征图；二是表示感兴趣区域ROI的N*5的矩阵，其中N表示感兴趣区域ROI的数目，第一列表示图像索引，之后四列表示图像感兴趣区域的左上角和右下角坐标的信息，技术方案如下：根据输入图像，将ROI映射到特征图对应位置；将映射后的区域划分为相同大小的部分，部分数量与输出的维度相同；对每个部分进行max pooling最大值池化操作。进一步的，所述非极大值抑制的过程如下：将所有框的得分排序，选中最高分及其对应的框；遍历其余的框，如果和当前最高分框的重叠面积大于一定阈值，将其删除；从未处理的框中继续选一个得分最高的，重复上述过程，直到将所有框按照上述方法处理完成。进一步的，所述Step7的筛选以如下三步进行筛选：第一步：通过候选框映射回到原图input image，映射关系可以用公式如下：对于卷积/池化层：pi＝si*pi+1+/2—padding)对于激活层：pi＝pi+1其中，pi表示第i层特征的中心点，si表示卷积窗口的步长，ki表示卷积窗口的大小，padding取“valid”＝0和“same”＝1两个值，当步长等于“valid”时，不作任何处理，当padding等于“same”时，保持宽度W和高度H和卷积前一样，由于si步长引起的特征图宽度和高度的减少用padding补充0来补足；对以下几种情况的候选框进行剔除：1.候选框左侧水平坐标小于0；2.候选框右侧水平坐标大于原图宽度；3.候选框下侧垂直坐标小于0；4.候选框上侧垂直坐标大于原图高度；第二步：经过第一步的剔除，再对剩下的边框进行softmax打分，根据前景的anchor box按照分数从高到低排序，筛选出两千个分数最高的候选框；第三步：将筛选出的两千个候选框进行NMS，即非极大值抑制，再次进行排序，最终选取得分最高的300个候选框作为最终候选框。附图说明图1表示的是本发明的技术方案的流程图；图2表示的是本发明。具体实施方式本发明提出一种自适应确定目标尺寸和感受野大小的方法，该方法包括如下步骤：Step1：对原始分辨率448*256的图片进行ResNet-50网络卷积操作提取特征图featuremaps，将卷积中的乘法换成加法操作,具体操作如下：其中，Y表示输出坐标为第t个通道的值，X表示输入坐标为的第k个通道的值，cin为原始输入图片的通道，F是过滤器，也为权值矩阵,过滤器大小为d*d，经过ResNet-50网络卷积得到28*16*256的特征图，用于区域候选框提取RPN和感兴趣区域池化ROIPooling共享；Step2:定义九个边界框尺寸，候选框尺寸如下：{,,,,,,,,}；Step3:选取公共数据集ImageNet，包括训练集和测试集，训练集中的图片由两部分组成：一是未做任何标注的图片，二是与图片对应的图片中真实目标框的坐标信息。由于公共数据集ImageNet数据量巨大和实验环境限制，选取ImageNet中部分训练集做本实验数据。自行创建一个txt文本文件，存储训练集中真实目标框的坐标信息；Step4：根据ResNet-50提取特征图28*16*256标注的原始框，使用RPN提取其中的边界框，下面根据与真实框的映射每个位置增加一个偏移量offset：其中，p0表示输出的像素坐标，本文中过滤器大小为3*3，坐标表示为R＝{,,,,,,,,},pn遍历R中的每一个点，Δpn表示偏移量，w为过滤器每个位置的权重；把原来的卷积过程分成两路，一路学习偏移量Δpn，得到2N*H*W的输出，N＝|R|表示R是前面公式表示的3*3矩阵，加绝对值表示获取矩阵中点的个数，也就是9，2N是有x、y两个方向的偏置，H、W分别为特征图的高和宽，Δpn是一个预设的小数，采用双线性插值法，获取特征图两个相邻斜对角左下、右上坐标之间的值，公式为：其中，f、f、f、f分别为四个坐标对应的值，f为插值后得到的值；使用3*3的滑动卷积窗口对特征图做卷积操作，得到28*16个向量，每个向量256维；对整个特征图做两次1*1的卷积，产生两块layer，一块是cls layer，维度为2*H*W，表示分类这块区域是前景或背景；另一块是reg layer，维度为4*H*W，表示预测出相对于原图偏移的Δx,Δy,Δw,Δh位置；Step5：对于cls layer分类，对前景和背景分别用正样本1和负样本0进行标签，计算原始标注框与边界框的交集面积I和并集面积U，得到一个面积比值IOU：IOU＝I/U对这个比值进行过滤，筛选出与任意一个原始标注框的IOU重叠部分大于0.7的边界框作为正样本标签，与任意一个原始标注框的IOU重叠部分小于0.3的边界框作为负样本标签，分类学习的损失函数为：其中，Lcls为回归损失函数，pi为anchor预测为目标的概率，标注框：表示负标签，表示正标签；Step6：对于reg layer回归，通过不断训练收敛得到的特征图中点的四个值：xr、yr、hr、wr，表示预测的边界盒的四个坐标参数，与原始标注框坐标差值在预设范围内，使其收敛趋于原始标注框的坐标，回归损失函数为：其中，Lreg为回归损失函数，ti＝{xr，yr，wr，hr}表示预测的边界盒的四个坐标参数，是目标标注框的四个坐标参数；Step 7：通过step5和step6的分类和回归操作之后，对由边界框变成由RPN给出的候选框进行筛选；Step 8：提出了ROI pooling感兴趣区域池化实现训练和测试的加速，并提高了检测的精度，感兴趣区域池化层有两个输入：一是经过基础网络卷积和池化后的固定大小的特征图；二是表示感兴趣区域ROI的N*5的矩阵，其中N表示感兴趣区域ROI的数目，第一列表示图像索引，之后四列表示图像感兴趣区域的左上角和右下角坐标的信息，技术方案如下：根据输入图像，将ROI映射到特征图对应位置；将映射后的区域划分为相同大小的部分，部分数量与输出的维度相同；对每个部分进行max pooling最大值池化操作。所述非极大值抑制的过程如下：将所有框的得分排序，选中最高分及其对应的框；遍历其余的框，如果和当前最高分框的重叠面积大于一定阈值，将其删除；从未处理的框中继续选一个得分最高的，重复上述过程，直到将所有框按照上述方法处理完成。所述Step7的筛选以如下三步进行筛选：第一步：通过候选框映射回到原图input image，映射关系可以用公式如下：对于卷积/池化层：pi＝si*pi+1+/2—padding)对于激活层：pi＝pi+1其中，pi表示第i层特征的中心点，si表示卷积窗口的步长，ki表示卷积窗口的大小，padding取“valid”＝0和“same”＝1两个值，当步长等于“valid”时，不作任何处理，当padding等于“same”时，保持宽度W和高度H和卷积前一样，由于si步长引起的特征图宽度和高度的减少用padding补充0来补足；对以下几种情况的候选框进行剔除：1.候选框左侧水平坐标小于0；2.候选框右侧水平坐标大于原图宽度；3.候选框下侧垂直坐标小于0；4.候选框上侧垂直坐标大于原图高度；第二步：经过第一步的剔除，再对剩下的边框进行softmax打分，根据前景的anchor box按照分数从高到低排序，筛选出两千个分数最高的候选框；第三步：将筛选出的两千个候选框进行NMS，即非极大值抑制，再次进行排序，最终选取得分最高的300个候选框作为最终候选框。
