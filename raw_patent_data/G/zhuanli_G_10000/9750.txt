标题title
目标检测中神经网络后处理实现方法、装置、终端及介质
摘要abst
本发明公开了一种目标检测中神经网络后处理实现方法、装置、终端及介质所述方法包括：根据logistic分段函数的多项式形式及分段区间，将所述多项式的浮点数类型系数转为定点数类型系数，得到待测数据；将所述待测数据输入至分类计算单元进行并行计算及流水式计算；其中，所述分类计算单元包括延迟数据链及与所述定点数类型系数对应的计算数据链。本发明提供的目标检测中神经网络后处理实现方法，能够提高产品的可移植性，在保证精度的同时占用较少的资源，进而提升了计算效率。
权利要求书clms
1.一种目标检测中神经网络后处理实现方法，其特征在于，包括：根据logistic分段函数的多项式形式及分段区间，将所述多项式的浮点数类型系数转为定点数类型系数，得到待测数据；将所述待测数据输入至分类计算单元进行并行计算及流水式计算；其中，所述分类计算单元包括延迟数据链及与所述定点数类型系数对应的计算数据链。2.根据权利要求1所述的目标检测中神经网络后处理实现方法，其特征在于，所述并行计算包括：所述延迟数据链与所述计算数据链之间的并行计算；所述延迟数据链中各模块之间的并行计算；所述计算数据链中各模块之间的并行计算。3.根据权利要求1所述的目标检测中神经网络后处理实现方法，其特征在于，所述流水式计算为：所述计算数据链中的各模块进行不间断进行计算及输出，直至所有所述待测数据计算完毕。4.根据权利要求1所述的目标检测中神经网络后处理实现方法，其特征在于，所述计算数据链中的每个模块用于进行加法或乘法运算。5.根据权利要求1所述的目标检测中神经网络后处理实现方法，其特征在于，还包括：将logistic回归函数化简为logistic分段函数；对所述logistic分段函数进行拟合，得到所述logistic分段函数的多项式形式。6.根据权利要求1-5任一项所述的目标检测中神经网络后处理实现方法，其特征在于，所述后处理实现方法基于FPGA。7.一种目标检测中神经网络后处理实现装置，其特征在于，包括：数据获取模块，用于根据logistic分段函数的多项式形式及分段区间，将所述多项式的浮点数类型系数转为定点数类型系数，得到待测数据；并行计算模块，用于将所述待测数据输入至分类计算单元进行并行计算及流水式计算；其中，所述分类计算单元包括延迟数据链及与所述定点数类型系数对应的计算数据链。8.根据权利要求7所述的目标检测中神经网络后处理实现装置，其特征在于，还包括模型构建单元，用于，将logistic回归函数化简为logistic分段函数；对所述logistic分段函数进行拟合，得到所述logistic分段函数的多项式形式。9.一种终端设备，其特征在于，包括：一个或多个处理器；存储器，与所述处理器耦接，用于存储一个或多个程序；当所述一个或多个程序被所述一个或多个处理器执行，使得所述一个或多个处理器实现如权利要求1至6任一项所述的目标检测中神经网络后处理实现方法。10.一种计算机可读存储介质，其上存储有计算机程序，其特征在于，所述计算机程序被处理器执行实现如权利要求1至6任一项所述的目标检测中神经网络后处理实现方法。
说明书desc
技术领域本发明涉及人工智能及深度学习技术领域，具体涉及一种目标检测中神经网络后处理实现方法、装置、终端及介质。背景技术在人工智能领域中，目标检测是计算机视觉和数字图像处理中比较热门的一个方向，能够广泛应用于工业检测，自动驾驶，安防监控等很多领域。其中，目标检测即检测图像中的物体类别及其在图像中的位置，往往基于神经网络依次进行预处理、特征提取及后处理等操作。在目前的神经网络应用中，大部分还是基于计算机平台，通过大型服务器完成训练及推断，而有小部分处理则是通过移动平台来实现，例如开发ASIC芯片，或在FPGA设计神经网络等，最终实现大大降低成本且方便使用的目的。然而，现有的基于FPGA实现的CNN神经网络的目标检测方案还尚未成熟，主要原因在于成本较高，即要求使用的FPGA芯片满足片上内存资源大、计算模块资源多、逻辑资源丰富、甚至带有CPU核等条件。因此，对于目标检测的后处理部分通常利用CPU处理，但是这种做法又会增加CPU和FPGA的交互复杂性，且会导致系统整体功耗增加。发明内容本发明的目的在于提供一种目标检测中神经网络后处理实现方法、装置、终端及介质，以解决现有目标检测过程中的神经网络后处理存在的成本高、交互复杂，系统能耗大的问题。为了克服上述现有技术中的缺陷，本发明提供了一种目标检测中神经网络后处理实现方法，包括：根据logistic分段函数的多项式形式及分段区间，将所述多项式的浮点数类型系数转为定点数类型系数，得到待测数据；将所述待测数据输入至分类计算单元进行并行计算及流水式计算；其中，所述分类计算单元包括延迟数据链及与所述定点数类型系数对应的计算数据链。进一步地，所述并行计算包括：所述延迟数据链与所述计算数据链之间的并行计算；所述延迟数据链中各模块之间的并行计算；所述计算数据链中各模块之间的并行计算。进一步地，所述流水式计算为：所述计算数据链中的各模块进行不间断进行计算及输出，直至所有所述待测数据计算完毕。进一步地，所述计算数据链中的每个模块用于进行加法或乘法运算。进一步地，所述目标检测中神经网络后处理实现方法，还包括：将logistic回归函数化简为logistic分段函数；对所述logistic分段函数进行拟合，得到所述logistic分段函数的多项式形式。进一步地，所述后处理实现方法基于FPGA。本发明还提供了一种目标检测中神经网络后处理实现装置，包括：数据获取模块，用于根据logistic分段函数的多项式形式及分段区间，将所述多项式的浮点数类型系数转为定点数类型系数，得到待测数据；并行计算模块，用于将所述待测数据输入至分类计算单元进行并行计算及流水式计算；其中，所述分类计算单元包括延迟数据链及与所述定点数类型系数对应的计算数据链。进一步地，所述目标检测中神经网络后处理实现装置，还包括模型构建单元，用于，将logistic回归函数化简为logistic分段函数；对所述logistic分段函数进行拟合，得到所述logistic分段函数的多项式形式。本发明还提供了一种终端设备，包括：一个或多个处理器；存储器，与所述处理器耦接，用于存储一个或多个程序；当所述一个或多个程序被所述一个或多个处理器执行，使得所述一个或多个处理器实现如上任一项所述的目标检测中神经网络后处理实现方法。本发明还提供了一种计算机可读存储介质，其上存储有计算机程序，所述计算机程序被处理器执行实现如上任一项所述的目标检测中神经网络后处理实现方法。相对于现有技术，本发明的有益效果在于：本发明公开了一种目标检测中神经网络后处理实现方法，包括根据logistic分段函数的多项式形式及分段区间，将所述多项式的浮点数类型系数转为定点数类型系数，得到待测数据；将所述待测数据输入至分类计算单元进行并行计算及流水式计算；其中，所述分类计算单元包括延迟数据链及与所述定点数类型系数对应的计算数据链。本发明提供的目标检测中神经网络后处理实现方法，基于单芯片FPGA进行设计，提高了方法的可移植性，更好的实现了IP化、产品化；通过分段拟合logistic函数得到多项式形式，保证了分类计算结果精度的同时占用了较少资源；通过并行计算与流水式计算相结合，使得数据源源不断的输入输出，无需特征缓存机制，大大提升了计算效率。附图说明为了更清楚地说明本发明的技术方案，下面将对实施方式中所需要使用的附图作简单地介绍，显而易见地，下面描述中的附图仅仅是本发明的一些实施方式，对于本领域普通技术人员来讲，在不付出创造性劳动的前提下，还可以根据这些附图获得其他的附图。图1为本发明某一实施例提供的目标检测中神经网络后处理实现方法的流程示意图；图2为本发明某一实施例提供的目标检测过程的原理示意图；图3为本发明某一实施例提供的目标检测后处理分类计算单元的结构示意图；图4为图3中分类计算单元中各个独立的数据链结构示意图；图5为本发明某一实施例提供的目标检测中神经网络后处理实现装置的结构示意图。具体实施方式下面将结合本发明实施例中的附图，对本发明实施例中的技术方案进行清楚、完整地描述，显然，所描述的实施例仅仅是本发明一部分实施例，而不是全部的实施例。基于本发明中的实施例，本领域普通技术人员在没有作出创造性劳动前提下所获得的所有其他实施例，都属于本发明保护的范围。应当理解，文中所使用的步骤编号仅是为了方便描述，不对作为对步骤执行先后顺序的限定。应当理解，在本发明说明书中所使用的术语仅仅是出于描述特定实施例的目的而并不意在限制本发明。如在本发明说明书和所附权利要求书中所使用的那样，除非上下文清楚地指明其它情况，否则单数形式的“一”、“一个”及“该”意在包括复数形式。术语“包括”和“包含”指示所描述特征、整体、步骤、操作、元素和/或组件的存在，但并不排除一个或多个其它特征、整体、步骤、操作、元素、组件和/或其集合的存在或添加。术语“和/或”是指相关联列出的项中的一个或多个的任何组合以及所有可能组合，并且包括这些组合。术语解释：CNN：是一类包含卷积计算且具有深度结构的前馈神经网络，是深度学习的代表算法之一。卷积神经网络具有表征学习能力，能够按其阶层结构对输入信息进行平移不变分类，因此也被称为“平移不变人工神经网络”。CPU：中央处理器FPGA：现场可编程门阵列第一方面：请参阅图1，本发明某一实施例提供了一种目标检测中神经网络后处理实现方法，包括：S10、根据logistic分段函数的多项式形式及分段区间，将所述多项式的浮点数类型系数转为定点数类型系数，得到待测数据；S20、将所述待测数据输入至分类计算单元进行并行计算及流水式计算；其中，所述分类计算单元包括延迟数据链及与所述定点数类型系数对应的计算数据链。在本实施例中，需要说明的是，目标检测即检测图像中的物体类别及其在图像中的位置，其往往包含以下几个阶段：预处理--特征提取--后处理。其中，预处理是尽可能在不改变图像所携特征前提下，使得每张图像的表观特性尽可能一致，便于特征提取处理；特征提取一般是通过相应网络层次架构CNN算法进行元素特征的提取和类别的分类；后处理即对提取的特征数据进行分类计算、筛选等操作。目前，对于预处理和特征提取阶段，通常是在FPGA上实现，而针对后处理阶段，主要是在CPU进行，如图2所示。出于成本和方便性的考虑，又提出了基于移动平台实现后处理，例如在ASIC芯片上实现，但是做专用ASIC芯片需要比较长的时间周期和成本来完成，相对来讲利用FPGA设计神经网络则会减少开发周期、降低成本，并且拥有更好的灵活性。但是，现有的基于FPGA实现的CNN目标检测的方案还不是很成熟，主要问题在成本比较高，例如使用的FPGA芯片要求片上内存资源大、计算模块资源多、逻辑资源丰富、甚至带有CPU核，若采用CPU处理，则会增加CPU和FPGA的交互复杂性，进而导致系统整体功耗增加。因此，在本实施例中，主要基于FPGA从优化角度出发，将后处理的分类计算单元独立出来成为一个模块并在FPGA中实现，可以占用较少的逻辑资源并且拥有较高的性能，使得整个架构的性能得到提升。具体地，在步骤S10中，主要是获取分类计算的待测数据，首先分类计算使用的是logistic回归模型。其中，logistic回归模型的主要目的是将数据压缩到一个区间，f表示为概率值，定义其公式为：其中，ex为指数函数，将上述函数进行化简，即有：当x≥0时，且有f＝1-f；当x＜0时，f＝1-f；由此可知，该logistic回归函数的概率函数可以化简为：根据上述公式可以发现当x趋近于无限大时，f趋于1，当x趋于无限小时，f趋于0。在某一实施例中，由于目标检测神经网络算法后处理阶段的数据比较集中，因此根据数据的集中程度，为公式设定一个分段区间的临界范围，例如：取x＝7和x＝-7为此公式的边界；由此可知：当x＞7时，有f＝1；当x＜-7时，有f＝0。进一步地，将公式写成分段函数的形式：需要说明的是，ex函数不容易直接在FPGA实现，因此需要对公式在每段区间内进行拟合，即在每一小段区间内用高次方程式来代替原函数，而拟合后的函数基本由乘、加、减运算组成，在FPGA中既可选用乘法器和逻辑单元共同完成，也可以只采用逻辑单元来完成。具体地，下面为x在区间的分段拟合公式，得到公式，然后结合公式和就能得到区间公式即多项式形式的概率函数，在FPGA中更容易实现。以上公式每个变量的前面的系数已经为固定数值，但是其都为浮点数，而在FPGA中计算定点数比较方便且浪费较少逻辑资源，所以需要将这些浮点数类型系数转为定点数类型系数以方便用FPGA进行计算。具体地，设x3前面的系数为A，x2的系数为B，x的系数为C，最后的常数为D。系数A的数值都在1以下，所以定点数的整数位可以是0位，一位符号位，剩下都是小数位，并且考虑到FPGA的DSP的乘法位宽，例如DSP位宽25×18，所以系数的定点数位宽设置为25位，系数位宽可以根据具体使用的乘法器的位宽来调整，并且逻辑乘法器替代硬核乘法器dsp。进一步地，此定点数的定义为1位符号位，0位整数位，24位小数位，以A为-0.01943举例，符号位为1，小数位为-0.01943*2^24，得到的小数数值补码为24’hFB06A3,故此浮点数转为定点数的数值为25’h1FB06A3。进一步地，系数B、C的浮点数转定点数方法同A一样。而D为最后的加数常数，例如x为16位，那么D的位宽可以设置为41位，并且符号位1位，整数位6位，34位小数位，位宽和小数位位宽都是可以调整的，前提是整数位宽满足能足够表示系数的整数部分，小数位位宽可以尽量不丢失原小数部分的精度，浮点数转定点数的方法同A系数。由于x在区间共分为14个小区间，故A、B、C、D系数每个都有14个，将计算好的A、B、C、D定点数的补码数值如下表所示：表1 A、B、C、D定点数的补码数值A0:25'h1fb_06a3B0:25'h1ff_d8aeC0:25'h040_0496D0:41'h002_0000_0000A1:25'h1fd_25eeB1:25'h1fc_7ed0C1:25'h041_da7bD1:41'h001_fe9e_1b08A2:25'h1ff_b353B2:25'h1f4_e65cC2:25'h049_7accD2:41'h001_f44b_b1afA3:25'h001_4af5B3:25'h1ed_e00dC3:25'h053_d902D3:41'h001_dfc6_540dA4:25'h001_c433B4:25'h1eb_2420C4:25'h059_1dbdD4:41'h001_d237_8ab1A5:25'h001_96faB5:25'h1ec_8217C5:25'h055_92b8D5:41'h001_de74_299eA6:25'h001_3405B6:25'h1f0_00a8C6:25'h04b_0dd8D6:41'h002_08b9_7785A7:25'h000_d456B7:25'h1f3_e964C7:25'h03d_6580D7:41'h002_4875_4f37A8:25'h000_8aefB8:25'h1f7_563bC8:25'h02f_b939D8:41'h002_913b_e22eA9:25'h000_5839B9:25'h1fa_01cdC9:25'h023_c01aD9:41'h002_d8e7_5793A10:25'h000_370dB10:25'h1fb_f291C10:25'h01a_1188D10:41'h003_194a_f4f1A11:25'h000_2214B11:25'h1fd_4de8C11:25'h012_a066D11:41'h003_4fb7_e910A12:25'h000_14f9B12:25'h1fe_3a7eC12:25'h00d_1b71D12:41'h003_7bc7_f77bA13:25'h000_0c74B13:25'h1fe_d86fC13:25'h009_1bc5D13:41'h003_9e54_b48d进一步地，得到所有待测数据后执行步骤S20，将所述待测数据输入至分类计算单元进行并行计算及流水式计算。在这之前，需要先建立分类计算单元，需要说明的是，为完成上述分段多项式的计算，而每一个多项式是Ax3+Bx2+Cx+D的结构，如果利用一个周期完成这个多项式的计算，那么由于计算的复杂性会导致时钟频率就会极低，那么整体的性能也很低。如果分多个顺序的模块来处理，会使得需要额外的存储器来存储数据，并且数据的处理和数据的读写过程也较为复杂。因此建立如图3所示的分类计算单元：具体地，本单元在计算时将整个计算过程做分段，并且可以流水式工作，为了让每个模块的计算工作都相对简单，所以每个模块的功能只是两个数据的乘或加，例如MULT模块只做两个数据的乘法，乘完的数据送到后面一个模块继续计算，而本模块则接受新的数据计算，最上面的一条数据线为delay模块，负责将数据延迟固定的时钟周期以配合计算模块工作，第二条数据线计算的为Ax3，经过三个乘法模块，最后的加法模块作用为加上其他几项式子的结果，第三条数据线计算Bx2，第四条数据线计算Cx，第五条线为D的数据处理，在数据流流动计算之后，所有的模块都在并行工作、处理不同的数据，这样的分段流水式架构也可以使得整体的性能提高很多。由于目标识别算法后处理的数据一般是需要几层的数据结果，所以在此模块之前会有一个较大的存储器单元，当前面的几层数据都计算处理完毕并都存储到存储器单元，但是在本单元中，数据从存储器读出，数据是源源不断的输入到本模块进行计算处理，且本模块的计算结果输出用作边界框去重单元的输入，并不需要等待其他数据，所以是源源不断的输出，这样也会使得本模块的流水式结构优点最大化。进一步地，对利用该分类计算单元计算内容进行说明：1)DIN进入各个mux模块，通过DIN的数值选择对应的系数。1.1)如果DIN的数值在区间，则选择对应数值的公式系数1.2)如果DIN的数值在区间，则取DIN绝对值选择对应的公式系数，并且输出flag_neg为1代表DIN为负数。1.3)如果DIN的数值为小于-7，则可以不用选择公式系数，将数值小于-7的flag置1，flag_or_neg＝1。1.4)如果DIN的数值为大于7，则可以不用选择公式系数，将数值大于7的flag置1。flag_or_pos＝1。2)A、B、C系数分别进入第一个乘法模块进行与x的乘法运算，D则经过delay模块，输出与其他三个乘法模块输出同步。3)A、B乘法输出结果分别为Ax、Bx，分别在进入乘法模块与x相乘得到Ax2和Bx2，C乘法输出与经过delay模块的D系数进入加法模块相加得到Cx+D。4)Ax2进入乘法模块与x相乘得到Ax3，Bx2与进入加法模块相加得到Bx2+Cx+D。5)Ax3与进入加法模块相加得到Ax3+Bx2+Cx+D。6)最后一步为判断几个数值的flag，并决定输出DOUT。6.1)若flag_or_neg为1则将DOUT赋值为浮点数0，即定点数16’h00006.2)若flag_or_pos为1则将DOUT赋值为浮点数1，即定点数16’h40006.3)若flag_neg为1则DOUT＝16’h4000-6.4)若几个flag都为0，，则DOUT为Ax3+Bx2+Cx+D可以理解的是，图中的flag包含上述的几个flag数值，参与计算的x为DIN的绝对值，且整体的计算都是并行且流水的，例如计算第一个乘法模块A*x和B*x都是并行执行的，计算Ax2的时候，前面的乘法模块同时在算下一个输入的Ax，不需要等待。以其中一条路径为例：路径MUX_A---MULT---MULT---MULT---ADD---MUX输出，这里面每一个模块都是有多个时钟周期的处理数据的时间，每个模块都可以同步工作，例如当MUX_A的数据输出到第一个MULT后，MULT就可以开始工作了，此时MUX_A又输入的新的数据做另一个数据的处理，同理，当这一整条路径上的模块都开始工作后，那么它们都是并行的，并且数据可以不断的从外面输入到MUX_A。各个模块在并行工作的时候互不干扰，即实现流水式的数据处理，保证了优秀的性能。进一步的，在本实施例中，对于分类计算单元的各个模块进行说明：1)MUX_A的作用为判断DIN的大小决定flag_neg、flag_or_neg、flag_or_pos的数值以及选择系数A的数值，系数A的数值从A0-A13中选择，delay cycle为1；MUX_B、MUX_C及MUX_D的作用为判断DIN的大小选择对应系数的数值。2)MULT为25乘16的乘法器，此乘法器可以选择用dspip来完成，delay cycle为4。3)ADD为41+41的加法器，同样，此加法器可以选择dspip来完成，delay cycle为4。4)Delay Unit为延迟模块，为输入信号做固定延迟然后输出，1cycle表明延迟一个时钟周期输出，4cycle表明延迟4个周期输出。5)MUX模块即根据前面的flag决定DOUT。进一步的，如图4所示，图4的分别给出了A、B、C系数参与运算的数据路径：由可知，MULT0的输出为Ax，MULT1的输出为Ax2，MULT2的输出为Ax3，ADD0的输出为Ax3+Bx2+Cx+D；其中，MULT0的输出为Ax，41位位宽，而MULT1要求Ax的输入为25位宽，所以在此接口中间需要对MULT0的输出做拼接位的处理，MULT1的输入等于{Ax，Ax}，此25位位宽定点数包含1位符号位、6位整数位、18位小数位。从MULT1到MULT2的接口同样需要做类似的处理，MULT2的输入等于{Ax2，Ax2}。ADD0的输入为41位位宽，其中一个输入Ax3为41位位宽，其中一位符号位、19位整数位、21位小数位，不需要做改变，而另一个输入为Bx2+Cx+D，位宽为42位，其中1位符号位、14位整数位、26位小数位，需要向Ax3整数位对齐并且将位宽限制到41位，所以{BX2_CX_D，5′h0，BX2_CX_D}即为ADD0的另一个输入。图为B系数参与运算的数据路径，MULT3的输出为Bx，MULT4的输出为Bx2，ADD1的输出为Bx2+Cx+D；从MULT3到MULT4的接口也需要做拼接位的处理，MULT4的输入等于{Bx，Bx}。ADD1的输入为41位位宽，其中一个输入Bx2为41位位宽，其中一位符号位、13位整数位、27位小数位，不需要做改变，而另一个输入Cx+D的位宽为42位，其中1位符号位、7位整数位、34位小数位，需要向Bx2整数位对齐并且将位宽限制到41位，所以{CX_D，6′h0，CX_D}即为ADD1的另一个输入。图为C系数参与运算的数据路径，MULT5的输出为Cx，ADD2的输出为Cx+D；ADD2的输入为41位位宽，Cx为41位位宽，其中一位符号位、7位整数位、33位小数位，而ADD2另一个输入为D，其位宽为41位，其中一位符号位、6位整数位、34位小数位，需要将两个输入的整数位对齐，其中CX向D整数对齐，所以D不做改变并作为ADD2的一个输入，而{CX，CX，1′b0}作为ADD2的另一个输入。此外，由于输入的一般是量化后的数据，因此输出也是量化后的值。通过这样计算占用资源很少，可批量部署在大规模并行应用的场景中。本发明实施例提供的目标检测中神经网络后处理实现方法，基于单芯片FPGA进行设计，提高了方法的可移植性，更好的实现了IP化、产品化；通过分段拟合logistic函数得到多项式形式，保证了分类计算结果精度的同时占用了较少资源；通过并行计算与流水式计算相结合，使得数据源源不断的输入输出，无需特征缓存机制，大大提升了计算效率。第二方面：请参阅图5，本发明某一实施例还提供了一种目标检测中神经网络后处理实现装置，包括：数据获取模块01，用于根据logistic分段函数的多项式形式及分段区间，将所述多项式的浮点数类型系数转为定点数类型系数，得到待测数据；并行计算模块02，用于将所述待测数据输入至分类计算单元进行并行计算及流水式计算；其中，所述分类计算单元包括延迟数据链及与所述定点数类型系数对应的计算数据链。本发明实施例提供的目标检测中神经网络后处理实现装置，基于单芯片FPGA进行设计，提高了方法的可移植性，更好的实现了IP化、产品化；通过分段拟合logistic函数得到多项式形式，保证了分类计算结果精度的同时占用了较少资源；通过并行计算与流水式计算相结合，使得数据源源不断的输入输出，无需特征缓存机制，大大提升了计算效率。在某一实施例中，所述目标检测中神经网络后处理实现装置，还包括模型构建单元，用于将logistic回归函数化简为logistic分段函数及对所述logistic分段函数进行拟合，得到所述logistic分段函数的多项式形式。通过函数的多项式形式，使其更容易在FPGA实现。第三方面：本发明某一实施例还提供了一种终端设备，包括：一个或多个处理器；存储器，与所述处理器耦接，用于存储一个或多个程序；当所述一个或多个程序被所述一个或多个处理器执行，使得所述一个或多个处理器实现如上所述的目标检测中神经网络后处理实现方法。处理器用于控制该终端设备的整体操作，以完成上述的目标检测中神经网络后处理实现方法的全部或部分步骤。存储器用于存储各种类型的数据以支持在该终端设备的操作，这些数据例如可以包括用于在该终端设备上操作的任何应用程序或方法的指令，以及应用程序相关的数据。该存储器可以由任何类型的易失性或非易失性存储设备或者它们的组合实现，例如静态随机存取存储器，电可擦除可编程只读存储器，可擦除可编程只读存储器，可编程只读存储器，只读存储器，磁存储器，快闪存储器，磁盘或光盘。终端设备可以被一个或多个应用专用集成电路、数字信号处理器、数字信号处理设备、可编程逻辑器件、现场可编程门阵列、控制器、微控制器、微处理器或其他电子元件实现，用于执行如上述任一项实施例所述的目标检测中神经网络后处理实现方法，并达到如上述方法一致的技术效果。本发明某一实施例还提供了一种包括程序指令的计算机可读存储介质，该程序指令被处理器执行时实现如上述任一项实施例所述的目标检测中神经网络后处理实现方法的步骤。例如，该计算机可读存储介质可以为上述包括程序指令的存储器，上述程序指令可由终端设备的处理器执行以完成如上述任一项实施例所述的目标检测中神经网络后处理实现方法，并达到如上述方法一致的技术效果。以上所述是本发明的优选实施方式，应当指出，对于本技术领域的普通技术人员来说，在不脱离本发明原理的前提下，还可以做出若干改进和润饰，这些改进和润饰也视为本发明的保护范围。
