标题title
一种基于多维关系对齐的无监督视觉表征学习的图像分类方法
摘要abst
本发明提供一种基于多维关系对齐的无监督视觉表征学习的图像分类方法，包括：步骤1，获取预训练图像数据以及增广视图；步骤2，构建包括在线编码器和离线编码器的双分支网络，将增广视图分别输入在线编码器和离线编码器得到特征以及负样本；步骤3，定义增广视图的特征与负样本的关系矩阵，并采用交叉对齐策略构建关系对齐损失；步骤4，设计多维关系对齐损失并进行无监督预训练；步骤5，通过添加分类器构成图像分类网络；步骤6，微调图像分类网络；步骤7，利用微调后的图像分类网络执行图像分类任务。本发明将关系对齐作为无监督视觉表征学习的核心，其在不引入任何不可靠约束的情况下，深入探索了样本之间的相似度关系。
权利要求书clms
1.一种基于多维关系对齐的无监督视觉表征学习的图像分类方法，其特征在于，包括如下步骤：步骤1，获取预训练图像数据，并对预训练图像数据进行图像增广，得到两个不同的增广视图；步骤2，构建包括在线编码器和离线编码器的双分支网络，将所述两个不同的增广视图分别输入在线编码器和离线编码器得到两个不同的增广视图的特征；其中，将离线编码器以往迭代输出的特征作为负样本；步骤3，定义两个不同的增广视图的特征与负样本的关系矩阵，并采用交叉对齐策略构建关系对齐损失；步骤4，基于步骤3构建的关系对齐损失，设计多维关系对齐损失作为最终的预训练损失，并利用最终的预训练损失对步骤2构建的双分支网络进行无监督预训练；步骤5，在经过无监督预训练后的双分支网络中添加一个分类器构成一个经过无监督预训练的图像分类网络；步骤6，获取目标图像分类数据集，并将步骤5得到的图像分类网络在目标图像分类数据集上进行微调；步骤7，利用步骤6微调后的图像分类网络执行图像分类任务。2.根据权利要求1所述的基于多维关系对齐的无监督视觉表征学习的图像分类方法，其特征在于，步骤1中所述图像增广的方法包括随机裁剪、随机水平翻转、随机颜色抖动、随机灰度化以及高斯模糊。3.根据权利要求1所述的基于多维关系对齐的无监督视觉表征学习的图像分类方法，其特征在于，步骤2中构建的包括在线编码器和离线编码器的双分支网络为：所述在线编码器和离线编码器均由一个特征提取网络和一个多层感知机构成；其中，所述在线编码器使用梯度反传更新，而离线编码器是在线编码器的一个移动平均，即：θofft＝m*θofft-1+*θont其中，θont表示在线编码器在第t步迭代时的网络参数，θofft表示离线编码器在第t步迭代时的网络参数，m是一个超参数。4.根据权利要求1所述的基于多维关系对齐的无监督视觉表征学习的图像分类方法，其特征在于，步骤2中采用一个队列来动态存储离线编码器以往迭代输出的特征作为负样本。5.根据权利要求1所述的基于多维关系对齐的无监督视觉表征学习的图像分类方法，其特征在于，步骤3包括如下子步骤：定义两个不同的增广视图T1、T2的特征与负样本的关系矩阵1P、2P分别为：其中，k表示负样本，kj表示第j个负样本，1≤j≤N，N表示负样本数量；T1、T2分别表示两个增广视图T1、T2中的第i个图像；1zi、2zi分别表示T1、T2的特征；τ是一个超参数；R表示实数矩阵，RB×N表示维度为B×N的实数矩阵，1P∈RB×N以及2P∈RB×N表示1P和2P是一个维度为B×N的实数矩阵；以关系对齐作为双分支网络的约束，即：其中，是当前两个增广视图T1、T2的期望，CE是软标签的交叉熵损失，2R是期望的当前增广视图T2与负样本之间的关系矩阵；采用交叉对齐策略构建关系对齐损失：训练过程中，在第t步迭代时，在线编码器在优化过程利用梯度反传更新关系矩阵1P趋近于2Rt-1：离线编码器优化期望的关系矩阵2Rt：其最小值近似于：2Rt←DiagμDiag其中，αB、βN分别是维度为B、N的尺度归一化列向量，Diag表示构建的对角矩阵；μ是一个超参数；最后采用交叉对称策略来构建最终的关系对齐损失：其中，1R是期望的当前增广视图T1与负样本之间的关系矩阵。6.根据权利要求5所述的基于多维关系对齐的无监督视觉表征学习的图像分类方法，其特征在于，步骤3中采用交叉对齐策略构建关系对齐损失时最小值近似的方法为：通过在线编码器的后端额外添加一个多层感知机来近似7.根据权利要求1所述的基于多维关系对齐的无监督视觉表征学习的图像分类方法，其特征在于，步骤4中设计多维关系对齐损失的方法为：将高维特征空间分解为几个低维子空间的笛卡尔积，然后将步骤3构建的关系对齐损失分别在每个子空间中进行关系对齐，从而得到多维关系对齐损失。8.根据权利要求7所述的基于多维关系对齐的无监督视觉表征学习的图像分类方法，其特征在于，步骤4中设计多维关系对齐损失的方法为：给定一个D维的特征向量将D维的高维空间分解为G个低维子空间的笛卡尔积，特征向量在每个子空间的投影表示为：其中，是在第g个子空间中的投影；在第g个子空间中的关系对齐损失为：最终的多维关系对齐损失LMDRA由各子空间对齐损失的平均构成：9.根据权利要求1所述的基于多维关系对齐的无监督视觉表征学习的图像分类方法，其特征在于，步骤6中将步骤5得到的图像分类网络在目标图像分类数据集上进行微调的损失函数为标准的交叉熵损失：其中，M为目标图像分类数据集中的图像数量，Pic为目标图像分类数据集中第i个图像的预测概率，c是第i个图像所属的类别。10.根据权利要求9所述的基于多维关系对齐的无监督视觉表征学习的图像分类方法，其特征在于，所述目标图像分类数据集中的图像具有分类标注。
说明书desc
技术领域本发明涉及图像分类技术领域，具体而言，涉及一种基于多维关系对齐的无监督视觉表征学习的图像分类方法。背景技术随着深度学习在计算机视觉的普及，基于卷积神经网络的图像分类方法基本达到了人类水平的表现，但是训练神经网络需要庞大的数据，获取数据的标记是耗时耗力的。无监督视觉表征学习是目前计算机视觉领域最具挑战性的课题之一，其主要任务是根据给定的无人工标注的图片，从数据本身学习，以获得对下游任务有益的特征表示。在图像分类任务中，最近无监督视觉表征学习展现出了惊人的应用前景，由于其不依赖人工标注，因此可以收集数量巨大的数据供其预训练，来获得具有语义信息的通用性特征，然后迁移到目标数据集以获得更好的分类性能，这对于图像分类的发展有非常重要的意义。早期的无监督视觉表征学习方法通常会基于数据自身设计启发式的辅助任务，然后借由解决辅助任务学习的过程学习通用的视觉特征表示。相对位置判别辅助任务，它首先从输入图像中提取几个图像补丁，然后训练卷积神经网络来预测任意两个补丁之间的空间位置关系。旋转预测辅助任务，它首先将输入图像旋转0°、90°、180°、270°中的任意一个角度，然后训练卷积神经网络来预测图像的旋转角度。图像着色辅助任务，它首先将原始图像灰度化，然后训练卷积神经网络来对灰度图像着色，将高级语义信息编码到嵌入信息中。图像修补辅助任务，它首先将抹去输入图像的一个局部区域，然后利用一种上下文编码器，根据像素之间的相关性来生成原始图像的缺失内容。然而，这些手工设计的辅助任务通常只能捕捉图像的底层特征，不能关注到图像的语义信息上。除此之外，它们也很容易被一些无关特征所干扰，例如水印对于旋转预测辅助任务，仅关注水印的位置就可以判断图像旋转地角度。在可解释性方面，它们也存在很大地问题。与这些基于启发式辅助任务的方法相比，当下的对比学习体现出巨大的优势和广阔的前景。目前，基于实例判别辅助任务的对比学习是无监督视觉表征学习方法的主流，它将每个样本作为一个独特的类，在特征空间中其应该与自己的增广相似，而与其他样本不同。为了囊括大量的负样本，SimCLR设置了一个大的batchsize，将当前batch中的每个样本当中一个单独的个体执行对比损失。PIRL利用一个存储器来存储负样本，从而将batchsize大小与负样本数量解耦。MoCo使用一个队列代替存储器作为存储介质，实时更新负样本；此外，他们引入动量编码器，这是查询编码器基于动量的移动平均，以确保负样本的一致性。PCL将聚类融合到对比学习中，并将其建模为一个EM算法框架，步骤E通过K-means算法寻找包含数据语义信息的原型，在步骤M中添加原型判别，即同一图像的不同增广应该属于同一原型，而远离其他原型，通过改进的对比损失训练卷积神经网络。SwAV采用类似的原型分配思想来改进对比学习，但是它使用软分配。这些方法虽然取得了不错的效果，但都存在一些缺陷。基于实例判别的方法在不考虑当前样本与负样本之间相关性的情况下将它们分离，这是一种不可靠的约束，这会导致网络丢失当前样本与其中一些负样本之间相似的语义信息，例如当一些负样本与当前样本具有相同的语义类别，强行在特征空间中拉远它们会致使网络忽略它们的语义相似性，因此无法有效地建立起样本间复杂的相关关系。在已有的对比学习基础上增加聚类思想的方法将特征空间中相似的样本聚为一个类，由此避免了拉远相似的样本，但这种方法严重依赖可靠的特征相似性。然而，在无监督表征学习中，相似的特征并不一定具有相似的语义信息，因此，聚类判别依然带来了不可靠的约束。发明内容本发明旨在提供一种基于多维关系对齐的无监督视觉表征学习的图像分类方法，以解决现有无监督视觉表征学习方法在学习过程中引入了不可靠的约束，导致无法有效地建立样本之间关系，造成在迁移到图像分类任务中时引入了偏置的技术问题。本发明提供的一种基于多维关系对齐的无监督视觉表征学习的图像分类方法，其特征在于，包括如下步骤：步骤1，获取预训练图像数据，并对预训练图像数据进行图像增广，得到两个不同的增广视图；步骤2，构建包括在线编码器和离线编码器的双分支网络，将所述两个不同的增广视图分别输入在线编码器和离线编码器得到两个不同的增广视图的特征；其中，将离线编码器以往迭代输出的特征作为负样本；步骤3，定义两个不同的增广视图的特征与负样本的关系矩阵，并采用交叉对齐策略构建关系对齐损失；步骤4，基于步骤3构建的关系对齐损失，设计多维关系对齐损失作为最终的预训练损失，并利用最终的预训练损失对步骤2构建的双分支网络进行无监督预训练；步骤5，在经过无监督预训练后的双分支网络中添加一个分类器构成一个经过无监督预训练的图像分类网络；步骤6，获取目标图像分类数据集，并将步骤5得到的图像分类网络在目标图像分类数据集上进行微调；步骤7，利用步骤6微调后的图像分类网络执行图像分类任务。进一步的，步骤1中所述图像增广的方法包括随机裁剪、随机水平翻转、随机颜色抖动、随机灰度化以及高斯模糊。进一步的，步骤2中构建的包括在线编码器和离线编码器的双分支网络为：所述在线编码器和离线编码器均由一个特征提取网络和一个多层感知机构成；其中，所述在线编码器使用梯度反传更新，而离线编码器是在线编码器的一个移动平均，即：θofft＝m*θofft-1+*θont其中，θont表示在线编码器在第t步迭代时的网络参数，θofft表示离线编码器在第t步迭代时的网络参数，m是一个超参数。进一步的，步骤2中采用一个队列来动态存储离线编码器以往迭代输出的特征作为负样本。进一步的，步骤3包括如下子步骤：定义两个不同的增广视图T1、T2的特征与负样本的关系矩阵1P、2P分别为：其中，k表示负样本，kj表示第j个负样本，1≤j≤N，N表示负样本数量；T1、T2分别表示两个增广视图T1、T2中的第i个图像；1zi、2zi分别表示T1、T2的特征；τ是一个超参数；R表示实数矩阵，RB×N表示维度为B×N的实数矩阵，1P∈RB×N以及2P∈RB×N表示1P和2P是一个维度为B×N的实数矩阵；以关系对齐作为双分支网络的约束，即：其中，是当前两个增广视图T1、T2的期望，CE是软标签的交叉熵损失，2R是期望的当前增广视图T2与负样本之间的关系矩阵；采用交叉对齐策略构建关系对齐损失：训练过程中，在第t步迭代时，在线编码器在优化过程利用梯度反传更新关系矩阵1P趋近于2Rt-1：离线编码器优化期望的关系矩阵2Rt：其最小值近似于：2Rt←DiagμDiag其中，αB、βN分别是维度为B、N的尺度归一化列向量，Diag表示构建的对角矩阵；μ是一个超参数；最后采用交叉对称策略来构建最终的关系对齐损失：进一步的，步骤3中采用交叉对齐策略构建关系对齐损失时最小值近似的方法为：通过在线编码器的后端额外添加一个多层感知机来近似进一步的，步骤4中设计多维关系对齐损失的方法为：将高维特征空间分解为几个低维子空间的笛卡尔积，然后将步骤3构建的关系对齐损失分别在每个子空间中进行关系对齐，从而得到多维关系对齐损失。进一步的，步骤4中设计多维关系对齐损失的方法为：给定一个D维的特征向量将D维的高维空间分解为G个低维子空间的笛卡尔积，特征向量在每个子空间的投影表示为：其中，是在第g个子空间中的投影；在第g个子空间中的关系对齐损失为：最终的多维关系对齐损失LMDRA由各子空间对齐损失的平均构成：其中，1R是期望的当前增广视图T1与负样本之间的关系矩阵。进一步的，步骤6中将步骤5得到的图像分类网络在目标图像分类数据集上进行微调的损失函数为标准的交叉熵损失：其中，M为目标图像分类数据集中的图像数量，Pic为目标图像分类数据集中第i个图像的预测概率，c是第i个图像所属的类别。进一步的，所述目标图像分类数据集中的图像具有分类标注。综上所述，由于采用了上述技术方案，本发明的有益效果是：1、本发明的基于多维关系对齐的无监督视觉表征学习的图像分类方法中，将关系对齐作为无监督视觉表征学习的核心，其在不引入任何不可靠约束的情况下，深入探索了样本之间的相似度关系。从而能够解决现有无监督视觉表征学习方法在学习过程中引入了不可靠的约束，导致无法有效地建立样本之间关系，造成在迁移到图像分类任务中时引入了偏置的技术问题。2、本发明的基于多维关系对齐的无监督视觉表征学习的图像分类方法中，为了进一步有效地解决关系对齐问题，本发明设计了一种交叉对齐策略，其中对齐步骤和关系探索步骤分别进行了优化。此外，本发明在关系探索步骤中采用一个均衡约束来防止退化解。3、本发明的基于多维关系对齐的无监督视觉表征学习的图像分类方法中，为了更好地捕捉样本之间的复杂关系，本发明提出多维关系对齐，它从多个维度进行关系对齐。4、本发明的基于多维关系对齐的无监督视觉表征学习的图像分类方法中，在无监督预训练阶段学习到了包含样本间复杂关系的表征，这非常有利于提高图像分类的性能。附图说明为了更清楚地说明本发明实施例的技术方案，下面将对实施例中的附图作简单地介绍，应当理解，以下附图仅示出了本发明的某些实施例，因此不应被看作是对范围的限定，对于本领域普通技术人员来讲，在不付出创造性劳动的前提下，还可以根据这些附图获得其他相关的附图。图1为本发明实施例的基于多维关系对齐的无监督视觉表征学习的图像分类方法的流程图。图2为本发明实施例构建的双分支网络结构示意图。具体实施方式为使本发明实施例的目的、技术方案和优点更加清楚，下面将结合本发明实施例中的附图，对本发明实施例中的技术方案进行清楚、完整地描述，显然，所描述的实施例是本发明一部分实施例，而不是全部的实施例。通常在此处附图中描述和示出的本发明实施例的组件可以以各种不同的配置来布置和设计。因此，以下对在附图中提供的本发明的实施例的详细描述并非旨在限制要求保护的本发明的范围，而是仅仅表示本发明的选定实施例。基于本发明中的实施例，本领域普通技术人员在没有做出创造性劳动前提下所获得的所有其他实施例，都属于本发明保护的范围。实施例如图1所示，本实施例提出一种基于多维关系对齐的无监督视觉表征学习的图像分类方法，包括如下步骤：步骤1，获取预训练图像数据，并对预训练图像数据进行图像增广，得到两个不同的广视图；具体地：获取预训练图像数据S1，本实施例中，该预训练图像数据S1不需要人工标注；对获取的预训练图像数据S1进行图像增广，所述图像增广的方法包括：随机裁剪、随机水平翻转、随机颜色抖动、随机灰度化以及高斯模糊；由此对于预训练图像数据S1中任意一批输入图像x＝{x1,…,xB}，B是当前批数量，对其施加两次图像增广T1、T2，分别得到两个不同的增广图像T1、T2。步骤2，构建包括在线编码器和离线编码器的双分支网络，将所述两个不同的增广视图分别输入在线编码器和离线编码器得到两个不同的增广视图的特征；其中，将离线编码器以往迭代输出的特征作为负样本；具体地：构建包括在线编码器和离线编码器的双分支网络；如图2所示，所述在线编码器和离线编码器均由一个特征提取网络和一个多层感知机构成；其中，所述在线编码器使用梯度反传更新，而离线编码器是在线编码器的一个移动平均，即：θofft＝m*θofft-1+*θont其中，θont表示在线编码器在第t步迭代时的网络参数，θofft表示离线编码器在第t步迭代时的网络参数，同理，θofft-1表示离线编码器在第t-1步迭代时的网络参数，m是一个超参数。这样的双分支网络能够避免网络得到一个坍塌解，即无论输入什么图像数据，双分支网络都会映射到一个常数向量。将所述两个不同的增广视图分别输入在线编码器和离线编码器得到两个不同的增广视图的特征；为了与大量的样本计算相关关系，本实施例采用一个队列来动态存储离线编码器以往迭代输出的特征作为负样本。由于前述的超参数m是一个非常小的数，这保证了离线编码器的慢更新，因此所述负样本之间具有一致性，即同一图像在一定迭代步数内经由离线编码器映射得到的特征是不变的，这也保证了与负样本对比特征具有可靠性。步骤3，定义两个不同的增广视图的特征与负样本的关系矩阵，并采用交叉对齐策略构建关系对齐损失；具体地：定义两个不同的增广视图T1、T2的特征与负样本的关系矩阵1P、2P分别为：其中，k表示负样本，kj表示第j个负样本，1≤j≤N，N表示负样本数量；T1、T2分别表示两个增广视图T1、T2中的第i个图像；1zi、2zi分别表示T1、T2的特征；τ是一个超参数；R表示实数矩阵，RB×N表示维度为B×N的实数矩阵，1P∈RB×N以及2P∈RB×N表示1P和2P是一个维度为B×N的实数矩阵。以关系对齐作为双分支网络的约束，即：其中，ET1,T2是当前两个增广视图T1、T2的期望，CE是软标签的交叉熵损失，2R是期望ET1,T2的当前增广视图T2与负样本之间的关系矩阵，是一组需要离线编码器优化的参数。由于离线编码器没有进行梯度反传更新，因此LRA的优化可以看作是一个交替的优化过程。采用交叉对齐策略构建关系对齐损失训练过程中，在第t步迭代时，在线编码器在优化过程利用梯度反传更新关系矩阵1P趋近于2Rt-1：离线编码器优化期望的关系矩阵2Rt：其最小值近似于：2Rt←DiagμDiag其中，αB、βN分别是维度为B、N的尺度归一化列向量，Diag表示构建的对角矩阵，如Diag即在B维的向量αB的基础上构建一个B×B的对角矩阵，该对角矩阵Diag的主对角线元素由向量αB的元素组成，其余元素为0；Diag即在N维的向量βN的基础上构建一个N×N的对角矩阵，该对角矩阵Diag的主对角线元素由向量βN的元素组成，其余元素为0；μ是一个超参数。在实际中，ET2几乎无法求得，因此本实施例在在线编码器的后端额外添加一个多层感知机来近似ET2；最后，本实施例采用流行的交叉对称策略来构建最终的关系对齐损失：其中，1R是期望的当前增广视图T1与负样本之间的关系矩阵，1R与2R一样，也是一组需要离线编码器优化的参数。步骤4，基于步骤3构建的关系对齐损失，设计多维关系对齐损失作为最终的预训练损失，并利用最终的预训练损失对步骤2构建的双分支网络进行无监督预训练；为了从多个维度来探究样本之间的关系，本实施例将高维特征空间分解为几个低维子空间的笛卡尔积，然后将步骤3构建的关系对齐损失分别在每个子空间中进行关系对齐，从而得到多维关系对齐损失。即，给定一个D维的特征向量将D维的高维空间分解为G个低维子空间的笛卡尔积，特征向量在每个子空间的投影表示为：其中，是在第g个子空间中的投影；在第g个子空间中的关系对齐损失为：最终的多维关系对齐损失LMDRA由各子空间对齐损失的平均构成：步骤5，在经过无监督预训练后的双分支网络中添加一个分类器构成一个经过无监督预训练的图像分类网络；即步骤6对双分支网络使用多维关系对齐损失进行无监督预训练后，以在线编码器的特征提取网络为核心，在其后端添加一个分类器，以构成一个经过无监督预训练的图像分类网络，来进一步迁移到图像分类任务中。步骤6，获取目标图像分类数据集，并将步骤5得到的图像分类网络在目标图像分类数据集上进行微调；获取的目标图像分类数据集S2，一般比步骤1获取的预训练图像数据S1小很多，该目标图像分类数据集S2中的图像具有分类标注。将步骤5得到的图像分类网络在目标图像分类数据集上进行微调的损失函数为标准的交叉熵损失：其中，M为目标图像分类数据集S2中的图像数量，Pic为目标图像分类数据集S2中第i个图像的预测概率，c是第i个图像所属的类别。相比直接在目标图像分类数据集S2上进行图像分类训练，本实施例能够获得更好的图像分类效果。除此之外，如果目标图像分类数据集S2是预训练图像数据S1的一个子集，本发明能够获得与在预训练图像数据S1上进行图像分类训练相比拟的性能。步骤7，利用步骤6微调后的图像分类网络执行图像分类任务。以下为具体示例：选取现有的公开数据库，由于无监督表征学习适用于大量的无标注数据，为验证本发明的有效性，此处选用经典的公开数据库ISLVRC 2012为预训练图像数据S1，该数据库共有1000类目标，训练集图片1281167张，验证集图片50000张。无监督预训练阶段，对输入的训练集图片施加图像增广，分别经由在线编码器和离线编码器得到对应的特征，并和队列存储的负样本一起计算多维关系对齐损失来进行训练。该步骤的主要关键点如下：1、采用的深度学习框架为pytorch；2、在构建多层感知机时，中间映射维度为4096，输出维度为256；3、多维关系对齐损失中，选择将最终的高维空间分解为4个子空间，超参数m、τ和μ分别设置为0.99、0.04和0.05；4、优化器选择LARS，学习率设置为4.8，batchsize设置为512，梯度累计为8个间隔，最大迭代epoch数为200；在无监督预训练后的双分支网络的在线编码器的特征提取网络后添加一个分类器得到经过无监督预训练的图像分类网络，然后以1％或10％的ISLVRC 2012数据为目标图像分类数据集S2。以经过无监督预训练的图像分类网络在目标图像分类数据集S2上进行强监督分类训练。该步骤的主要关键点如下：1.采用的深度学习框架为pytorch；2.优化器选择SGD，学习率设置为0.3，最大迭代epoch数为100；利用微调后的图像分类网络在验证集上测试，以最终的分类性能作为学习质量的评估标准。综上所述，本发明具有如下技术效果：1、本发明的基于多维关系对齐的无监督视觉表征学习的图像分类方法中，将关系对齐作为无监督视觉表征学习的核心，其在不引入任何不可靠约束的情况下，深入探索了样本之间的相似度关系。从而能够解决现有无监督视觉表征学习方法在学习过程中引入了不可靠的约束，导致无法有效地建立样本之间关系，造成在迁移到图像分类任务中时引入了偏置的技术问题。2、本发明的基于多维关系对齐的无监督视觉表征学习的图像分类方法中，为了进一步有效地解决关系对齐问题，本发明设计了一种交叉对齐策略，其中对齐步骤和关系探索步骤分别进行了优化。此外，本发明在关系探索步骤中采用一个均衡约束来防止退化解。3、本发明的基于多维关系对齐的无监督视觉表征学习的图像分类方法中，为了更好地捕捉样本之间的复杂关系，本发明提出多维关系对齐，它从多个维度进行关系对齐。4、本发明的基于多维关系对齐的无监督视觉表征学习的图像分类方法中，在无监督预训练阶段学习到了包含样本间复杂关系的表征，这非常有利于提高图像分类的性能。以上所述仅为本发明的优选实施例而已，并不用于限制本发明，对于本领域的技术人员来说，本发明可以有各种更改和变化。凡在本发明的精神和原则之内，所作的任何修改、等同替换、改进等，均应包含在本发明的保护范围之内。
