标题title
基于差异性神经表示模型的事件触发词检测方法
摘要abst
本发明基于差异性神经表示模型的事件触发词检测方法，所述方法包括：构建差异性神经表示模型，包括编码模块、对比学习模块和混合边界模块，所述的编码模块用于将句子中的每个单词生成高维向量空间中的表示，所述的对比学习模块，用于加大触发词内部组成单词与外部其他单词之间表示的差距，所述的混合边界模块，用于引导模型更好地区分触发词边界上的单词；利用训练好的差异性神经表示模型，对每个单词预测是否属于某一个触发词的起始位置或者结束位置，然后通过组合预测的开始位置和结束位置输出所有可能的触发词。本发明提出的学习框架提高了区分触发词内部和外部单词的能力，在多触发词识别中显著优于其他方法。
权利要求书clms
1.基于差异性神经表示模型的事件触发词检测方法，其特征在于，所述方法包括：步骤1，构建差异性神经表示模型，包括编码模块、对比学习模块和混合边界模块，所述的编码模块用于将句子中的每个单词生成高维向量空间中的表示，所述的对比学习模块，用于加大触发词内部组成单词与外部其他单词之间表示的差距，所述的混合边界模块，用于引导模型更好地区分触发词边界上的单词；步骤2，在所述的编码模块中，通过使用预训练BERT模型将句子的每个单词嵌入到高维向量空间中的上下文词向量表示中，以便提供包含语义特征的输入，同时，结合预定义事件类型的外部知识，进一步丰富单词表示中包含的信息；步骤3，在所述的对比学习模块中，捕获有助于区别触发词单词和句子中其他单词的特征来改进单词表示，通过最大化来自原始句子的单词表示和来自相似含义的扩充句子的单词表示的一致性；步骤4，在所述的混合边界模块中，通过将触发词的边界词的表示与其相邻词的表示进行混合，即可得到混合表示，然后，设计标记方案来构造用于混合表示的标签，利用额外的伪标记数据来训练与基本分类器一起工作的新分类器，新分类器有助于基本分类器对触发词片段和事件类型的判定，由此，提高差异性神经表示模型捕获触发词片段边界特征的能力；步骤5，利用训练好的差异性神经表示模型，对每个单词预测是否属于某一个触发词的起始位置或者结束位置，然后通过组合预测的开始位置和结束位置输出所有可能的触发词。2.根据权利要求1所述的基于差异性神经表示模型的事件触发词检测方法，其特征在于，在所述的编码模块中，基于BERT的语言表示模型被用作编码器，所述的BERT由12个相同的Transformer块的堆栈组成，每个块处理词嵌入、位置嵌入和段嵌入，在所有块依次计算出三种类型的嵌入之后，BERT输出它们的总和作为表示，同时，在编码模块中，利用预定义的触发词类型作为外部知识来增强BERT中的自注意机制，只使用上层事件类别作为外部知识，将所有上层事件类别与每个句子连接起来，具体形式如下：sentenceUT1…UTn,其中，表示BERT中起始位置标记，sentence表示输入的特定句子，表示BERT中间隔符标记，UT是upper-type的缩写，表示事件的上层类型，n是数据集中的上层事件类别的数量。3.根据权利要求2所述的基于差异性神经表示模型的事件触发词检测方法，其特征在于，所述的对比学习模块采用以下对比学习方法步骤：步骤201，随机选取句子除了触发单词以及停用词之外的单词；步骤202，通过NLTK的WordNet选择要替换的词的对应同义词对原单词进行替换，以生成句子；步骤203，将生成的句子发送到具有相同参数的编码模块，所得的触发词的单词表示被视为正样本；步骤204，对于每个单词表示E∈Rd，其中R表示维度为d的实数空间，通过激活函数，表示为：C＝ReLU) 其中，ReLU是非线性激活函数，f是全连网络以将E转化为特定维度的输出，获得进一步的单词表示；步骤204，进一步的单词表示用作损失函数的输入。4.根据权利要求3所述的基于差异性神经表示模型的事件触发词检测方法，其特征在于，所述的混合边界模块中，给定一个句子和一个触发词，L表示触发词的开始位置的单词表示，R表示触发词的结束位置的单词表示，Nl表示该单词到该离触发词开始最近的单词表示，Nr表示该单词到该离触发词结束位置最近的单词表示，Ml表示开始位置的单词混合表示，Mr表示结束位置的单词混合表示；α∈和β∈是用于调整组合中两个分量的权重的参数；使用线性组合，有：Ml＝α·L+·Nl,Mr＝β·R+·Nr,对于Ml和Mr的混合表示，设计了两种标记方案来构造相应的标签，第一种尝试减轻识别触发词的要求，并为其构建软标签，用公式表示为：ml＝α·1+·0＝α, mr＝β·1+·0＝β, 其中α和β分别来自等式和，第二种标记目的是增强对触发词的要求，并为它们构造甚难标签，即，ml＝mr＝0，一旦将相邻单词的表示与触发词的表示融合在一起，就认为混合表示已损坏，并用0标记新的单词表示；所述的混合边界模块基于混合表示来预测每个单词的标签，具体地，将每个单词分为n个类，其中n是事件类型的数量，然后根据每种类型预测标签，对于每个句子，分别有两个相同的开始位置和结束位置分类器,每个单词的分类器的详细操作如下，其中是从句子中识别出第i个单词并将其分类为触发词的开始位置对于所有事件类型的概率，是从句子中识别出第i个单词并将其分类为触发词的结束位置对于所有事件类型的概率，sigmoid是非线性激活函数，Ei是第i个单词在句子中的单词表示，Wl和Wr是神经网络中的可训练权重，而bl和br是偏差项。5.根据权利要求3或4所述的基于差异性神经表示模型的事件触发词检测方法，其特征在于，在差异性神经表示模型训练的过程中的综合损失函数为：其中，和分别表示开始和结束位置对比学习模块计算所得的损失值，和分别表示开始和结束位置混合边界模块计算所得的损失值，而λ∈是超参数，用于控制损失值的数量级；混合边界模块的损失值计算公式如下：其中，表示混合边界学习过程产生的损失值，Pm和Lm分别是通过混合边界模块预测的单词和真实标签的概率，γ∈是一个超参数，用于平衡两个部分的权重；其中，损失遵循二进制交叉熵损失函数，计算公示为：其中，表示经由二进制交叉熵损失函数计算得出的损失值，P表示句子中单词的预测概率，L表示真实标签的集合；T是事件类型的集合，S是选定的句子，|·|表示特定对象的数量，1≤k≤n，n为事件类型的数量；所述的对比学习模块的损失值计算公式如下：其中，表示对比学习模块计算得出的损失值，exp表示自然数e为底的指数，log表示自然对数，Sim的相似度函数评估两个表示的相关性，C是由式产生的输出；Ω是句子中的一组单词，而Θ是其中的触发词的集合，ΩΘ表示单词集合中不包含触发词；Cθ表示激活后的触发词的表示，Cω表示激活后的另一个词的表示，而Cθ'表示激活后的由扩充语句生成的触发词θ的表示。
说明书desc
技术领域本发明涉及自然语言处理中的事件检测技术领域，尤其涉及基于差异性神经表示模型的事件触发词检测方法。背景技术从文本中检索、抽取事件实例在自动问答、对话系统等自然语言相关任务中发挥着关键作用，而其中首先要完成的工作就是事件检测。事件检测致力于解决两个方面的问题：1)识别触发词，触发词是一类用以指使文本中特定事件的词语，包括但不限于单个动词、名词或者词组；2)判定分类，通过触发词及相关文本判定该触发词所属类别。由于ED有利于自然语言处理中的许多下游应用，如问答、时空事件信息检索和机器阅读理解，ED引起了研究人员的广泛注意。具体来说，现有的方法中存在结合特征工程技术来手工构造特征；为解决数据的稀缺，采用了数据增强技术来增加训练数据的规模；以及基于最近神经网络的发展，引入潜在词表示，以更好地执行ED。在ED的两个子任务之间，触发词识别的结果是触发词分类的基础。然而，正确识别触发词并非易事，因为当前数据稀缺成为ED中一个不可忽略的问题，这就需要模型能够更精准地判定句子中触发词的文本边界。然而，如果模型未关注单词的表示，会使得词向量包含的语义信息过于模糊，进而导致检测触发词的边界成为了一个棘手的挑战。在这种情况下，如果模型过于“谨慎”，它会倾向于做有把握的预测，可能忽略部分触发词，从而错过某些事件；而如果模型“大胆”，它可能会引入许多预测噪声，进而增大探测触发词边界的困难。本实施例将该问题定义为事件检测中的触发词片段检测问题。这个问题严重影响了ED的表现。首先，现有的ED方法会产生许多假阴性的情况，其准确率远高于召回率。其次，错误分析显示，83％以上的错案被认为是由该问题引起的。在这种情况下，PLMEE，一种具有代表性的最先进方法，不仅错误预测了触发词的数量，而且混淆了触发词的特定边界。此外，当前的ED方法忽略了触发词片段检测的问题，并且在识别事件触发词时缺乏专门的处理方法。发明内容本发明旨在至少解决现有技术中存在的技术问题。为此，本发明提出了基于差异性神经表示模型的事件触发词检测方法。所述方法从文本中学习差异性神经表示模型，有了DNR，模型期望能够精准地识别每个触发词，并正确标记其片段。为了实现这一目标，本发明方法提出了一个基于神经信息抽取的经典解决方案的新框架，该框架利用了两种有前景的技术：1)对比学习策略，它扩大了触发词内部单词和外部句子中其他单词表示之间的差异，2)混合边界策略，该策略训练该模型以区分邻近触发词的边界词为目标。基于差异性神经表示模型的事件触发词检测方法，所述方法包括以下步骤：步骤1，构建差异性神经表示模型，包括编码模块、对比学习模块和混合边界模块，所述的编码模块用于将句子中的每个单词生成高维向量空间中的表示，所述的对比学习模块，用于加大触发词内部组成单词与外部其他单词之间表示的差距，所述的混合边界模块，用于引导模型更好地区分触发词边界上的单词；步骤2，在所述的编码模块中，通过使用预训练BERT模型将句子的每个单词嵌入到高维向量空间中的上下文词向量表示中，以便提供包含语义特征的输入，同时，结合预定义事件类型的外部知识，进一步丰富单词表示中包含的信息；步骤3，在所述的对比学习模块中，捕获有助于区别触发词单词和句子中其他单词的特征来改进单词表示，通过最大化来自原始句子的单词表示和来自相似含义的扩充句子的单词表示的一致性；步骤4，在所述的混合边界模块中，通过将触发词的边界词的表示与其相邻词的表示进行混合，即可得到混合表示，然后，设计标记方案来构造用于混合表示的标签，利用额外的伪标记数据来训练与基本分类器一起工作的新分类器，新分类器有助于基本分类器对触发词片段和事件类型的判定，由此，提高差异性神经表示模型捕获触发词片段边界特征的能力；步骤5，利用训练好的差异性神经表示模型，对每个单词预测是否属于某一个触发词的起始位置或者结束位置，然后通过组合预测的开始位置和结束位置输出所有可能的触发词。具体地，在所述的编码模块中，基于BERT的语言表示模型被用作编码器，所述的BERT由12个相同的Transformer块的堆栈组成，每个块处理词嵌入、位置嵌入和段嵌入，在所有块依次计算出三种类型的嵌入之后，BERT输出它们的总和作为表示，同时，在编码模块中，利用预定义的触发词类型作为外部知识来增强BERT中的自注意机制，只使用上层事件类别作为外部知识，将所有上层事件类别与每个句子连接起来，具体形式如下：sentenceUT1···UTn,其中，表示BERT中起始位置标记，sentence表示输入的特定句子，表示BERT中间隔符标记，UT是upper-type的缩写，表示事件的上层类型，n是数据集中的上层事件类别的数量。更进一步地，所述的对比学习模块采用以下对比学习方法步骤：步骤201，随机选取句子除了触发单词以及停用词之外的单词；步骤202，通过NLTK的WordNet选择要替换的词的对应同义词对原单词进行替换，以生成句子；步骤203，将生成的句子发送到具有相同参数的编码模块，所得的触发词的单词表示被视为正样本；步骤204，对于每个单词表示E∈Rd，其中Rd表示维度为d的实数空间，通过激活函数，表示为：C＝ReLU), 其中，ReLU是非线性激活函数，f是全连网络以将E转化为特定维度的输出，获得进一步的单词表示；步骤204，进一步的单词表示用作损失函数的输入。更进一步地，所述的混合边界模块中，给定一个句子和一个触发词，L表示触发词的开始位置的单词表示，R表示触发词的结束位置的单词表示，Nl表示该单词到该离触发词开始最近的单词表示，Nr表示该单词到该离触发词结束位置最近的单词表示，Ml表示开始位置的单词混合表示，Mr表示结束位置的单词混合表示；α∈和β∈是用于调整组合中两个分量的权重的参数；使用线性组合，有：Ml＝α·L+·Nl, Mr＝β·R+·Nr, 对于Ml和Mr的混合表示，设计了两种标记方案来构造相应的标签，第一种尝试减轻识别触发词的要求，并为其构建软标签，用公式表示为：ml＝α·1+·0＝α, mr＝β·1+·0＝β, 其中α和β分别来自等式和，第二种标记目的是增强对触发词的要求，并为它们构造甚难标签，即，ml＝mr＝0，一旦将相邻单词的表示与触发词的表示融合在一起，就认为混合表示已损坏，并用0标记新的单词表示；所述的混合边界模块基于混合表示来预测每个单词的标签，具体地，将每个单词分为n个类，其中n是事件类型的数量，然后根据每种类型预测标签，对于每个句子，分别有两个相同的开始位置和结束位置分类器,每个单词的分类器的详细操作如下，其中是从句子中识别出第i个单词并将其分类为触发词的开始位置对于所有事件类型的概率，是从句子中识别出第i个单词并将其分类为触发词的结束位置对于所有事件类型的概率，sigmoid是非线性激活函数，Ei是第i个单词在句子中的单词表示，Wl和Wr是神经网络中的可训练权重，而bl和br是偏差项。具体地，在差异性神经表示模型训练的过程中的综合损失函数为：其中，和分别表示开始和结束位置对比学习模块计算所得的损失值，和分别表示开始和结束位置混合边界模块计算所得的损失值，而λ∈是超参数，用于控制损失值的数量级；混合边界模块的损失值计算公式如下：其中，表示混合边界学习过程产生的损失值，Pm和Lm分别是通过混合边界模块预测的单词和真实标签的概率，γ∈是一个超参数，用于平衡两个部分的权重；其中，损失遵循二进制交叉熵损失函数，计算公示为：其中，表示经由二进制交叉熵损失函数计算得出的损失值，P表示句子中单词的预测概率，L表示真实标签的集合；T是事件类型的集合，S是选定的句子，|·|表示特定对象的数量，1≤k≤n，n为事件类型的数量；所述的对比学习模块的损失值计算公式如下：其中，表示对比学习模块计算得出的损失值，exp表示自然数e为底的指数，log表示自然对数，Sim的相似度函数评估两个表示的相关性，C是由式产生的输出；Ω是句子中的一组单词，而Θ是其中的触发词的集合，ΩΘ表示单词集合中不包含触发词；Cθ表示激活后的触发词的表示，Cω表示激活后的另一个词的表示，而Cθ'表示激活后的由扩充语句生成的触发词θ的表示。与现有方法相比，本发明方法的优点在于：提出了一个新的针对ED问题的学习框架DNR，包括两个创新设计的模块——对比学习和混合边界，提高了区分触发词内部和外部单词的能力；本发明方法是第一个在ED中引入对比学习和混合边界学习的思想，这是与ED的SOTA解决方案正交的；在标准数据集上的大量实验表明，DNR模型在解决触发词片段识别问题方面是有效的，并且在多触发词识别中显著优于其他方法。附图说明图1是本发明实施例中的典型事例图；图2示出了本发明实施例的框架流程示意图；图3示出了本发明实施例的对比学习示意图；图4示出了本发明实施例的混合边界示意图。具体实施方式为了使本发明的目的、技术方案和优点更加清楚，下面将结合附图对本发明作进一步地详细描述，显然，所描述的实施例仅仅是本发明一部份实施例，而不是全部的实施例。基于本发明中的实施例，本领域普通技术人员在没有做出创造性劳动前提下所获得的所有其它实施例，都属于本发明保护的范围。应当理解，此处所描述的具体实施例仅仅用以解释本发明，并不用于限定本发明。本实施例遵循自动内容提取共享任务中的术语。事件提及是描述事件的短语或句子，包括触发词和相应的组成要素；触发词是最清楚地表达事件提及的一些单词。ACE上ED的标准任务包括事件触发词识别和相应的类型分类。考虑图1中的示例。“death penalty”是一个事件触发词，其事件类型由较高类型的“Justice”和子类型“Execute”组成，从而形成组合类型“Justice：Execute”。因此，给定该句子，ED将预测：1)“death penalty”是事件触发词，其事件类型为“Justice：Execute”；2)“convicted”是事件触发，其事件类型为“Justice：Convict”。模型框架为了处理ED，本实施例在基于神经信息提取的ED框架之上构建了解决方案。如图2所示，黑色模块说明了神经信息提取的基本工作流程：给定一个句子作为输入，采用预训练的BERT模型为每个单词生成高维向量空间中的表示，然后将这些表示依次输入二分类器。对于每个单词，模型将预测其是否属于某个触发词的1)起始位置或者2)结束位置。使用这些分类标签，最终通过组合预测的开始位置和结束位置输出所有可能的触发词。图2为DNR整体框架示意图，直角矩形的模块描述了遵循了神经信息抽取的主流解决方案的SOTA框架；圆角矩形的附加组件是两个与现有框架正交的设计。为了使它能够正确处理触发范围检测问题，本实施例设计了两个新的模块来升级框架。简而言之，DNR模型由三个组件组成：编码模块，对比学习模块和混合边界模块。在编码模块中，本实施例通过使用预训练BERT模型将句子的每个单词嵌入到高维向量空间中的上下文词向量表示中，以便为其他模块提供包含语义特征的输入。为了进一步丰富单词表示中包含的信息，本实施例结合了一些来自预定义事件类型的外部知识。在对单词进行编码时，设计了对比学习模块，通过捕获有助于区别触发词单词和句子中其他单词的特征来改进单词表示。在对比学习中，通过最大化来自原始句子的单词表示和来自相似含义的扩充句子的单词表示的一致性，本实施例期望调整后的单词表示在识别触发词方面更具区分性。在编码模块之后提供混合边界模块，以进一步提高DNR模型捕获触发词片段边界特征的能力。通过将触发词的边界词的表示与其相邻词的表示进行混合，即可得到混合表示。然后，本实施例计了两种标记方案来构造用于混合表示的标签，利用额外的伪标记数据来训练与基本分类器一起工作的另一个分类器。新分类器有助于基本分类器对触发词片段和事件类型的判定。可以看出，这两个新模块都旨在缓解数据短缺的问题，同时学习对ED更好的表示。此外，它们与基于神经信息提取的ED框架无缝协作，并且与该框架下开发的方法正交。这意味着可以利用它们来增强一些现有方法，例如PLMEE编码模块在DNR模型中，基于BERT的语言表示模型被用作编码器。BERT由12个相同的Transformer块的堆栈组成，每个块处理词嵌入、位置嵌入和段嵌入。在所有块依次计算出三种类型的嵌入之后，BERT输出它们的总和作为表示。本实施例观察到包含事件的句子通常很短。在这种情况下，从纯文本中获取的信息可能会受到限制，这可能会削弱BERT的学习过程。因此，本实施例建议利用预定义的触发词类型作为外部知识来增强BERT中的自注意机制。但是，事件类型在数据集中的分布是不平衡的，并且属于同一上层事件类型中事件类型之间的相似性相对较高，例如Conflict：Demonstrate和Conflict：Attack。因此，本实施例选择只使用上层事件类别作为外部知识，将所有上层事件类别与每个句子连接起来。具体来说，DNR模型的每个输入均采用以下形式：sentenceUT1···UTn,其中，表示BERT中起始位置标记，sentence表示输入的特定句子，表示BERT中间隔符标记，UT是upper-type的缩写，表示事件的上层类型，n是数据集中的上层事件类别的数量。该部件设计使编码模块在学习对单词进行编码时可以更好地关注类型信息，本实施例的实验证明了其有效性。对比学习模块图3为对比学习示意图。灰色方形向量代表触发词的原始表示，黑色方形向量代表触发词单词从增强句子中获得的表示，灰色圆形向量代表句子中其他单词的表示。对比学习的基本思想是设计策略以充分利用原始数据集的特征，而无需引入外部数据/知识。它已被证明可以有效地丰富许多任务中的表示，包括知识图表示学习，预训练语言模型训练和图像分类等。由于数据稀疏性是ED中的一个显著问题，因此本实施例有动机去探索对比学习的潜在应用，以改善事件文本的表示学习。在对比学习算法中，样本有三种类型：锚点、正样本和负样本。例如，如果将“death”用作锚点，表示它是目标触发词，则该句子中的其他词可被视为负样本，即它们不是触发词。该算法执行以通过将负样本与正样本进行对比来学习单词表示。通常，将与锚点具有相同标签/类别的实例作为正样本。回想一下神经信息抽取的基本框架。在本实施例的例子中，标签为0/1，表示一个单词是触发词的开始位置或者结束位置。例如，“death”和“convicted”具有相同的标签1，因为它们都位于触发词的起始位置。但是，直接使用具有相同标签的单词来构造肯定样本会使得单词表示变得更加棘手，因为这会使得模型错误地认为“death”是“convicted”的正样本，然而“death”和“convicted”本身具有完全不同的语义含义。事实上，不恰当的选择正样本甚至会使单词在高维向量空间中向相反的方向学习，这对ED的性能影响很大。鉴于此，除了相同标签的约束之外，正样本还需要与句子中的锚点表现出相似的语义。为了实现这个目的，本实施例利用了一种方法，即EDA-SR，该方法能够产生与给定句子具有相同含义的新句子，两个句子的差异仅体现在具体词汇的使用上。最初提出EDA-SR是通过同义替换某些单词来增加NLP训练过程中的句子数量，尽管结果表明单词序列发生了变化，但增强后的句子仍具有相同的语义。具体到本实施例中，首先，随机选取句子除了触发单词以及诸如“a”和“the”之类的停用词之外的单词。然后，通过NLTK的WordNet选择要替换的词的对应同义词对原单词进行替换。因此，图1中句子将被转化为“The proceedings could sentence thedeath penalty if Tom is convicted”。然后，将生成的句子发送到具有相同参数的编码模块。随后，所得的触发词的单词表示被视为正样本。为了提高模块的泛化能力，本实施例不直接应用从上述模块获取的每个单词表示E∈Rd，其中Rd表示维度为d的实数空间，而是需要首先通过激活函数。数学上C＝ReLU), 其中，ReLU是非线性激活函数，f是全连网络以将E转化为特定维度的输出。这些单词表示进一步用作损失函数的输入，以强制模型增大触发词和其他词在高维向量空间中的表示，这将使得不同单词的表示变得更加可区分，从而有助于更好地识别触发词片段。混合边界模块图4为混合边界示意图。黑体字表示事件触发词。方形向量经圆形边界向量混合得到，标签背景的黑色、灰色与向量的颜色对应。尽管对比学习模块试图在触发词的内部和外部之间产生对比表示，但它们可能仍然不足以处理棘手的边界情况，有时这可能是最具有挑战性的问题。在本实施例设计了另一个模块，以针对每个触发词的相邻单词进一步解析每个触发词的开始和结束位置。传统方法通过二进制分类来解决触发词识别任务。也就是说，将触发词的开始和结束位置标记为1，将其他字词标记为0。然而，该解决方案会导致训练数据中标签的稀疏性，因为触发词的真实边界词比其他触发词少得多，进而导致数据分布不平衡。换句话说，上述标记方案会进一步恶化触发词片段检测问题，并且不可避免地阻碍了ED的性能。受Mixup的启发，本实施例提出了混合边界来生成带有伪标签的额外的单词表示，以解决该问题。最初提出Mixup是在不引入外部数据的情况下扩展数据规模，其基本思想是将数据集中不同类别的两个图像随机混合，并生成一个新标签，要求模型识别混合图像中不同类别的百分比。与图像不同，自然语言中的单词是离散的，不能轻易以文字形式混合使用。因此，本实施例将问题转化为高维向量空间中的单词表示。如图4所示，对于触发词“deathpenalty”，本实施例将起始词“death”的单词表示与触发词之外的相邻词语“the”的单词表示混合在一起，以及结尾词“penalty”及其相邻词的表示，它们分别产生了“death”和“penalty”的混合表示。在数学上，使用线性组合，本实施例有Ml＝α·L+·Nl, Mr＝β·R+·Nr, 给定一个句子和一个触发词，L表示触发词的开始位置的单词表示，Nl表示该单词到该离触发词开始最近的单词表示，Ml表示开始位置的单词混合表示；α∈和β∈是用于调整组合中两个分量的权重的参数。对于Ml和Mr的混合表示，本实施例设计了两种标记方案来构造相应的标签。第一种尝试减轻识别触发词的要求，并为其构建soft labeling。用公式表示为，ml＝α·1+·0＝α, mr＝β·1+·0＝β, 其中，ml与mr分别表示开始和结束位置混合向量的新标签，α和β分别来自等式和。通过这种设计，DNR模型能够判断混合单词表示正确性的程度。由于程度取决于触发词表示在混合表示中的百分比，因此DNR模型更多地关注触发词的相关特征。第二个目的是增强对触发词的要求，并为它们构造even harder labeling。即，ml＝mr＝0。一旦将相邻单词的表示与触发词的表示融合在一起，本实施例就认为该混合已损坏，并用0标记新的单词表示。这种更加困难的标记迫使DNR模型更多地关注相邻词的相关特征，同样有助于确认触发词片段的边界。在示例句中因为“death”和“penalty”都是触发词，混合边界忽略了它们之间的差异。该优点使DNR模型更容易将“death”和“penalty”标识为触发词的边界，从而有效地缓解了触发词片段检测问题。该模块的最后一个组件是基于混合表示来预测每个单词的标签。先前的研究通常依赖于一个模型来识别所有事件触发词，然后采用另一种模型来将所识别的触发词分类为某种事件类型。此范式易受误差累计的影响，并且未完全考虑事件触发词与事件类型之间的相关信息。ED的另一个独特问题是，一个句子中可能出现多个触发词，并且一个触发词可能具有多个事件类型。为了解决这些问题，受PLMEE的启发，本实施例提出了一个带有单词级多标签分类器的组合模型。具体来说，本实施例将每个单词分为n个类，其中n是事件类型的数量，然后根据每种类型预测标签。对于每个句子，分别有两个相同的开始位置和结束位置分类器。每个单词的分类器的详细操作如下，其中是从句子中识别出第i个单词并将其分类为触发词的开始位置的概率，sigmoid是非线性激活函数，Ei是第i个单词在句子中的单词表示，Wl是神经网络中的可训练权重，而bl和br是偏差项。模型训练与预测总体而言，DNR模型遵循多任务学习框架，因此以端到端的方式训练所有模块。特别地，为了扩大锚点和负样本之间的差异并丰富锚的表示形式，本实施例通过以下方法定义了锚及其相关正负样本的损失函数：其中，表示对比学习模块计算得出的损失值，exp表示自然数e为底的指数，log表示自然对数，Sim的相似度函数评估两个表示的相关性，在这项研究中使用余弦相似度。C是由等式产生的输出；Ω是句子中的一组单词，而Θ是其中的触发词的集合；Cθ表示激活后的触发词的表示，而Cθ'表示激活后的由扩充语句生成的触发词θ的表示。对于混合边界模块，预测任务本质上是词级别的二分类任务。因此，损失遵循二进制交叉熵损失函数。数学公示为，其中，表示经由BCE计算得出的损失值，P表示句子中单词的预测概率，L表示真实标签的集合；T是事件类型的集合，S是选定的句子，1≤k≤n。为了帮助训练DNR模型，在训练过程中保留了原始El和Er及其标签。此外，本实施例应用方程式和来计算混合边界任务中的概率，并将损失定义为，其中，表示混合边界学习过程产生的损失值，Pm和Lm分别是通过混合边界模块预测的单词和真实标签的概率；γ∈是一个超参数，用于平衡两个部分的权重。最后，本实施例获得了DNR模型的综合损失，并在同一训练框架中学习了所有可训练参数。即，其中，表示DNR训练过程中的加权损失值，和分别表示开始和结束位置对比学习模块计算所得的损失值，和分别表示开始和结束位置混合边界模块计算所得的损失值，而λ∈是超参数，用于控制损失值的数量级。训练了DNR模型后，只有基本编码模块可用于预测。也就是说，给定一个测试语句，它将语句中的单词编码到一个高维向量空间中，然后将其用于触发词识别和分类。实验设定数据集。本实施例对两个标准数据集进行评估：2005年的自动内容提取数据集和TAC2015的事件块数据集。关于这两个数据集的统计描述如表1所示。ACE2005：它是事件相关任务中使用最广泛的数据集，包含599个文档。所有事件都被标记为8种类型和33种子类型。本实施例评估了33种组合类型分类。根据先前的研究，本实施例将599个文档分为529个训练文档，30个验证文档和40个测试文档。TAC2015：文本分析会议是每年组织的一系列评估研讨会。本实施例使用TAC KBP2015事件要素抽取赛道的数据。由于竞赛提供了训练文档和测试文档，因此本实施例从训练集中随机选择了26个文档以构建验证集。表1数据集分析指标。本实施例遵循事件检测的标准评估指标，该指标有两个方面：识别和分类。如果事件触发词的片段与真实触发词匹配，则可以正确识别事件触发词；如果事件触发词和对应的事件类型与真实触发词、类别均匹配，则认为正确分类事件触发词。本实施例在所有评估中报告了微-平均精度，召回率和F1分数。基线。采用以下12种方法进行比较：基于特征的方法：涉及三种代表性方法。CrossEvent利用复杂功能的文档信息，MaxEnt仅采用人工设计的特征，Combined-PSL使用概率软逻辑模型来利用全局信息。基于增强的方法：涉及四种代表方法。GMLATT采用门控式跨语言注意机制来利用多语言数据传递的补充信息，PLMEE提出了事件生成和评估方法，以扩大训练数据的规模，AD-DMBERT使用对抗模型来获取更多训练数据，DRMM采用了一种替代性的双重关注机制来将图像信息有效地集成到ED中。基于神经的方法：涉及五种代表性方法。DMCNN使用CNN自动提取特征，GCN-ED使用图卷积网络来捕获语法信息，JMEE利用多语言信息来进行更准确的上下文建模，DISTILL引入了Δ学习方法来提炼泛化知识，HPNet构建了一个分层的策略网络，以鼓励模型学习更好的潜在功能。总体结果表2 ACE2005上的总体结果除DNR的结果外，其他结果均引自原始论文。黑体表示效果最好。在所有任务中，DNR模型均优于对比的方法，并且在所有指标方面均达到了SOTA性能，这证明了本实施例所提出模块的优越性和解决触发词片段检测问题的有效性。特别是，在触发词识别任务中，DNR模型达到F1的85.2％，分别比基于最佳增强的方法PLMEE和基于最佳表示的方法HPNet高1.0％和6.0％。对于类型分类的任务，就F1而言，DNR模型要赶超PLMEE1.1％，对HPNet赶超4.0％。对于所有子任务，DNR模型都倾向于实现更高的召回率，而不是精度。例如，识别任务中的召回率和精度分别为85.7％和84.8％，分类任务中的召回率和精度分别为82.4％和81.2％，这与所有其他方法相反。为了解释这些结果，本实施例调查了召回率低的原因，发现句子中的许多触发词难以识别。在这种情况下，所有其他模型都倾向于“谨慎地”做出否定预测，从而导致假阴性问题。相反，本实施例设计的对比学习模块和混合边界模块可帮助DNR模型执行更多“积极”的预测，从而增加召回率。在基于增强的方法中，尽管该分支中方法的性能相对较好，但生成的样本不精确和不平衡会导致过拟合的问题。这个问题使得模型只能在训练数据中出现过的样本上表现良好，但是缺乏泛化能力，导致了最终预测精度高但召回率低。与基于增强的方法相比，DNR模型不需要额外/外部的数据源。在基于表示的方法中，为ED任务设计了许多复杂的结构，这也导致了过拟合问题。与基于表示的方法相比，DNR模型不依赖复杂的结构。值得注意的是，在2019年之前提出的方法大部分未使用BERT，而PLMEE和本实施例的方法则采用了BERT作为编码模块的基础。因此，效果的显著提升可能部分归因于BERT。表3 TAC2015上的总体结果“TOP”指的是在比赛中取得的最佳结果，而除DNR之外的其他结果都是从原始论文中引用的。黑体表示效果最好。如表3所示，可以观察到，TAC2015上的结果与分布大致与ACE2005相似。DNR模型的性能大大优于其他所有对比方法。本领域技术人员应明白，本申请的实施例可提供为方法、系统或计算机程序产品。因此，本申请可采用完全硬件实施例、完全软件实施例或结合软件和硬件方面的实施例的形式。而且，本申请可采用在一个或多个其中包含有计算机可用程序代码的计算机可用存储介质上实施的计算机程序产品的形式。
