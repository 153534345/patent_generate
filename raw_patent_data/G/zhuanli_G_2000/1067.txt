标题title
一种单交叉口信号控制模型迁移至目标环境的方法
摘要abst
本发明属于智能控制领域，具体涉及一种单交叉口信号控制模型迁移至目标环境的方法，本专利将控制模型从源训练环境迁移到目标环境，首先搭建信号控制模型的DQN深度强化学习框架；其次对控制模型的迁移环境进行交叉口参数匹配以及DQN参数校准，判断是否满足目标环境；然后基于控制模型在源训练环境下得到的先验知识，对目标环境中原始控制模型的神经网络权重进行初始化设置，得到迁移至目标环境的控制模型；最后在目标环境下对控制模型优化训练，待模型收敛后，停止优化训练。实验表明可以节省在控制模型迁移至新环境中，可以减少训练控制模型的时间成本，同时优化训练后的控制模型各项评价指标更好。
权利要求书clms
1.一种单交叉口信号控制模型迁移至目标环境的方法，其特征在于，包括以下步骤：S1.搭建单交叉口信号控制模型的DQN深度强化学习框架；S2.对控制模型的迁移环境进行交叉口参数匹配以及DQN参数校准，将控制模型迁移至目标环境；S3.目标环境下对控制模型优化训练；S4.检测周期内交通流特征参数的异常天数比例是否超过阈值，如果是，则继续步骤S3，否则，不对控制模型进行优化训练。2.根据权利要求1所述的一种单交叉口信号控制模型迁移至目标环境的方法，其特征在于，步骤S1中：S11.构建交通环境和控制模型；S12.定义DQN的参数：交通状态、动作、奖励。3.根据权利要求1所述的一种单交叉口信号控制模型迁移至目标环境的方法，其特征在于，步骤S2中：S21.判断迁移环境交叉口参数：进口道数量、观测数据、进口道支持转向、独立左转车道数是否都满足匹配条件；若是，则初步满足交叉口参数匹配；S22.选取交叉口参数匹配的迁移环境，分别对DQN参数动作和交通状态校准；S23.若步骤S22的DQN参数通过校准，则迁移环境为目标环境。4.根据权利要求3所述的一种单交叉口信号控制模型迁移至目标环境的方法，其特征在于，步骤S21中：交叉口参数匹配条件为：同时满足进口道数与源训练环境进口道数一致、交叉口进口道除右转外可转向范围是否包括源训练环境所需转向范围、进口道可获取观测数据包源控制模型所需交通状态、独立左转车道数大于等于源训练环境的独立左转车道数。5.根据权利要求3所述的一种单交叉口信号控制模型迁移至目标环境的方法，其特征在于，步骤S22中：动作校准具体方法为：判断迁移环境交叉口结构渠化与信号机是否支持控制模型的动作，若支持则通过动作校准。6.根据权利要求3所述的一种单交叉口信号控制模型迁移至目标环境的方法，其特征在于，步骤S22中交通状态校准具体方法为：校核目标交叉口可提取到的交通状态类型及维度是否与控制模型输入所需的交通状态类型及维度一致，如果是，则满足交通状态校准。7.根据权利要求1所述的一种单交叉口信号控制模型迁移至目标环境的方法，其特征在于，步骤S2中将控制模型迁移至目标环境中的具体方法为：基于控制模型在源训练环境下得到的先验知识，对目标环境中原始控制模型的神经网络权重进行初始化设置，初始化设置后的原始控制模型即为迁移至目标环境的控制模型。8.根据权利要求1所述的一种单交叉口信号控制模型迁移至目标环境的方法，其特征在于，步骤S3中，对控制模型优化训练的具体步骤包括：S31.初始化控制模型神经网络参数；S32.将实时交通状态输入到控制模型的神经网络中，控制模型根据神经网络输出的Q值在动作集合中以策略选择动作a；S33.信号机执行动作a，控制相位变化，相位实时状态作用于交叉口环境中使交通状态发生变化，将当前交通状态和下个时间步的交通状态/＞、动作a、奖励值/＞作为一个四元组/＞样本存储在经验池中;S34.控制模型获取实时交通状态以及奖励函数值进行选择动作a的同时，随机在经验池中抽取小批量样本作为训练数据，用所述训练数据来训练更新神经网络的权重值;S35.重复上述S31-S34步骤，检测控制模型训练过程的DQN奖励函数值，直至奖励函数值的标准差变化小于阈值，则控制模型收敛，结束控制模型的优化训练。9.根据权利要求1所述的一种单交叉口信号控制模型迁移至目标环境的方法，其特征在于，步骤S4中：检测周期内交通流特征包括检测交通流量TF或各进口道左转车辆转向比例R。
说明书desc
技术领域本发明属于智能控制领域，具体涉及一种单交叉口信号控制模型迁移至目标环境的方法。背景技术由于城市道路空间及承载力有限，随着交通需求的增大，道路上会产生一系列诸如交通拥堵、交通事故等众多交通问题，给城市造成严重经济损失，制约城市的可持续发展，而交通拥堵已然成为了众多城市的普遍问题。城市交通灯的控制随着交通路网的规模扩大，难度也越来越大，而且，交通环境的多边形，需要一种能够快速适应环境的方法来解决交通拥堵问题。为此大量研究采用深度学习的感知能力，通过与Q学习算法结合，即深度强化学习框架，能够从高维数据中学习训练得到有效的控制策略，有效的降低了车辆的等待时间。但是将采用DQN框架，如果对于每个交叉口都训练出一套相应的信号控制模型，重新训练标定模型参数需要花费大量的时间成本，并且当交通环境发生变化的情况下无法进行微调和适应。除此之外，如果直接将采用DQN方法训练好的控制模型直接迁移至新环境，训练环境与新环境之间存在差异，包括交叉口参数不匹配以及控制模型所需的参数不匹配，这些差异可能导致在新环境中控制模型表现不佳。发明内容为解决现有技术中的不足，本发明提出了一种单交叉口信号控制模型迁移至目标环境的方法，可以在模型迁移至新环境中，可以节约大量针对新交叉口训练专用控制模型的时间和人力成本；可以根据检测环境变化优化控制模型，具有良好的场景适应能力。为了达到上述目的，本发明采用的技术方案是一种单交叉口信号控制模型目标环境迁移的方法，包括以下步骤：S1.搭建单交叉口信号控制模型的DQN深度强化学习框架；S2.对控制模型的迁移环境进行交叉口参数匹配以及DQN参数校准，将控制模型迁移至目标环境；S3.目标环境下对控制模型优化训练；S4.检测周期内交通流特征参数的异常天数比例是否超过阈值，如果是，则继续步骤S3，否则，不对控制模型进行优化训练。优选的，步骤S1中：S11.构建交通环境和控制模型；S12.定义DQN的参数：交通状态、动作、奖励；优选的，步骤S2中：S21.判断迁移环境交叉口参数：进口道数量、观测数据、进口道支持转向、独立左转车道数是否都满足匹配条件；若是，则初步满足交叉口参数匹配；S22.选取交叉口参数匹配的迁移环境，分别对DQN参数动作和交通状态校准；S23.若步骤S22的DQN参数通过校准，则迁移环境为目标环境。优选的，步骤S21中：交叉口参数匹配条件为：同时满足进口道数与源训练环境进口道数一致、交叉口进口道除右转外可转向范围是否包括源训练环境所需转向范围、进口道可获取观测数据包源控制模型所需交通状态、独立左转车道数大于等于源训练环境的独立左转车道数。优选的，步骤S22中：动作校准具体方法为：判断迁移环境交叉口结构渠化与信号机是否支持控制模型的动作，若支持则通过动作校准。优选的，步骤S22中交通状态校准具体方法为：校核目标交叉口可提取到的交通状态类型及维度是否与控制模型输入所需的交通状态类型及维度一致，如果是，则满足交通状态校准。优选的，步骤S2中将控制模型迁移至目标环境中的具体方法为：基于控制模型在源训练环境下得到的先验知识，对目标环境中原始控制模型的神经网络权重进行初始化设置，初始化设置后的原始控制模型即为迁移至目标环境的控制模型；优选的，步骤S3中，对控制模型优化训练的具体步骤包括：S31.初始化控制模型神经网络参数；S32.将实时交通状态输入到控制模型的神经网络中，控制模型根据神经网络输出的Q值在动作集合中以 策略选择动作a；S33.信号机执行动作a，控制相位变化，相位实时状态作用于交叉口环境中使交通状态发生变化，将当前交通状态和下个时间步的交通状态/＞、动作a、奖励值/＞作为一个四元组/＞样本存储在经验池中;S34.控制模型获取实时交通状态以及奖励函数值进行选择动作a的同时，随机在经验池中抽取小批量样本作为训练数据，用所述训练数据来训练更新神经网络的权重值;S35.重复上述S31-S34步骤，检测控制模型训练过程的DQN奖励函数值，直至奖励函数值的标准差变化小于阈值，则控制模型收敛，结束控制模型的优化训练。优选的，步骤S4中：检测周期内交通流特征包括检测交通流量TF或各进口道左转车辆转向比例R。与现有技术相比，本申请的优点如下：迁移至目标环境中的控制模型的相比目标环境中的原始控制模型，在相同环境下，控制模型的收敛速度更快，有效的节约了训练时间成本，并且各项评价指标更好；迁移至目标环境的控制模型经过优化训练后比没有优化训练在相同环境下的，各项评价指标更好。控制模型通过检测交通流特征参数变化，及时优化控制模型，具有良好的环境适应能力。附图说明图1基于DQN框架的单交叉口信号控制原理示意图图2 为本申请流程图。图3为相位选择的集合。图4为神经网络初始化示意图。图5为控制模型优化训练过程的原理图。图6为训练过程控制模型M1、M2奖励函数值对比图。具体实施方式以下详细说明都是例示性的，旨在对本申请提供进一步的说明。除非另有指明，本文使用的所有技术和科学术语具有与本申请所属技术领域的普通技术人员通常理解的相同含义。需要注意的是，这里所使用的术语仅是为了描述具体实施方式，而非意图限制根据本申请的示例性实施方式。本实施例提供了一种单交叉口信号控制模型迁移至目标环境的方法，交通信号控制模型基于深度强化学习框架搭建，基于DQN框架的单交叉口信号控制原理示意图如图1所示， DQN框架包括智能体，交通环境，信号机，信号机主要执行智能体的动作，控制交通灯变化。DQN将控制交通灯的变化的控制模型抽象为智能体，定义交通环境的代表特征为状态，智能体通过感知交通环境的变化，根据智能体的策略在动作集中选择动作，信号机执行动作，控制交通灯变化，交通灯变化会导致交通环境发生改变会，每个动作会有对应的奖励函数进行反馈，智能体则从奖励函数中进行学习，优化自己的动作。单交叉口信号控制模型迁移至目标环境的方法其流程图如图2所示，该方法具体包括如下步骤：S1.搭建单交叉口信号控制模型的DQN深度强化学习框架；S11.构建交通环境和控制模型本实施例的交通环境基于利用微观交通仿真平台SUMO搭建，交通环境主要包括交叉口模型，信号机。交通环境分为源训练环境和迁移环境，区别在于交叉口参数不同。表1 交叉口参数交叉口类型进口道数量观测数据进口道支持转向独立左转车道交叉口04最大排队长度直行、左转、右转1迁移交叉口14最大排队长度、车辆平均速度直行、左转2迁移交叉口24车辆平均速度直行、右转0迁移交叉口33最大排队长度直行、左转、右转1如表1交叉口参数所示，为搭建的控制模型源训练和迁移环境的单交叉口模型参数。交叉口类型中，交叉口0为待迁移控制模型的源训练环境的交叉口参数，迁移交叉口1-3为待匹配的迁移环境的交叉口参数，代表三种不同类型迁移环境交叉口示例，主要区别在于进口道数量不同、可获取观测数据不同、进口道支持转向不同、转向车道不同以及独立左转车道数不同。搭建控制模型包括：待迁移控制模型和无源控制模型：待迁移控制模型采用Q网络算法搭建，在交叉口0模型的交通环境中通过DQN框架训练优化；其余迁移环境的控制模型，同样都采用Q网络算法搭建，但是无优化训练，为了做区分，这里定义为无源控制模型M1。实施例通过SUMO的TraCI接口连接Python软件，实现交通环境和控制模型的实时交互功能。S12.定义DQN的参数：交通状态、动作、奖励对于基于DQN框架的交通信号灯控制模型而言，交通状态是交通环境的表征。DQN的交通状态定义为最大车辆排队长度。由于交叉口中右转流向车辆不受交叉口信号控制，因此只取每个方向进口道直行流向与左转流向车道的最大排队长度作为交通状态。以交叉口0模型为例，控制模型的交通状态输入由8个流向的最大排队长度数值8维数据组成：,/＞~/＞为不同的状态类型，分别代表北向南、北向东、南向北、南向西、西向东、西向北、东向西、东向南。交通信号灯的控制模型接收到当前的交通状态，从可选择的动作集合中选择最佳动作，信号机执行动作a，控制相位变化。以交叉口0模型为例，如图3所示，相位包括南北左转、南北直行、东西左转和东西直行，分别用表示，按照/＞的相序变化, 并构成相位集合/＞。控制模型的动作集合A={1,0}，动作以a表示，a∈A，控制模型根据交叉口交通状态，选择当前时刻动作a，当a=0时，表示交叉口保持当前相位不变，当a=1时，执行完黄灯的过度时间yt以及运行完预设的绿灯时间gt后根据相序切换到下一相位。DQN的奖励定义为交叉口范围内车辆均延误时间的相反数。奖励值反应控制模型在做出动作a后的实际影响，奖励函数的选取在很大程度上影响控制模型的最终性能。本发明的目的是提升单交叉口车辆通行效率，减少交叉口车辆延误时间，因此设置交叉口范围内车均延误时间的相反数为奖励函数，表达式为：/＞其中，是权重系数；/＞指在/＞时刻每个车道/＞的车均延误时间。S2.对控制模型的迁移环境进行交叉口参数匹配以及DQN参数校准，将控制模型迁移至目标环境；此过程S21-S22控制模型均指待迁移控制模型，待迁移控制模型不能迁移至所有的环境，因此在迁移至目标环境之前，需要对所有的迁移环境进行匹配，能匹配的迁移环境即目标环境。S21.判断迁移环境交叉口参数：进口道数量、观测数据、进口道支持转向、独立左转车道数是否满足匹配条件；若都满足，则初步满足交叉口参数匹配；迁移环境交叉口参数是否匹配，需要根据进口道数量、观测数据、进口道支持转向、独立左转车道数为交叉口参数判断条件。当四个交叉口参数都匹配时，则完成初步筛选。具体判断方法如下：“进口道数量”：判断交叉口进口道数与源训练环境进口道数是否一致，若不一致则该交叉口参数不匹配。根据该判断条件，交叉口3与交叉口0不一致，因此该交叉口满足要求。“观测数据”：判断交叉口环境可获取的数据种类是否包括源训练环境所需数据种类，若不包括，则该交叉口参数不匹配。根据该判断条件，迁移交叉口2的观测数据不包含交叉口0的所需的“最大排队长度”，因此迁移交叉口2不满足要求。“进口道支持转向”：判断交叉口进口道可转向范围除右转外是否包括源训练环境所需转向范围，若不包括，则该交叉口参数不匹配。根据该条件要求，迁移交叉口2不具有左转车道，则迁移交叉口2不满足要求。“独立左转车道数”：判断独立左转车道数是否大于等于源训练环境的独立左转车道数，若否，该交叉口参数不匹配。根据该条件，迁移交叉口2不满足要求。根据以上判断条件，“迁移交叉口1”的结构参数符合控制模型迁移要求，可以匹配控制模型。除此之外，还需要进行对动作校准和设置以及进行状态校准和设置。S22.选取交叉口参数匹配的迁移环境，分别对DQN参数包括动作和交通状态校准；动作校准：在实际控交叉口环境下信号灯切换方式以及切换逻辑受该交叉口的结构渠化与信号机影响，当迁移到实际交叉口场景下时需要判断交叉口结构渠化与信号机是否支持控制模型的动作，若不支持则不能迁移至该交叉口。实施例中迁移的新环境都是基于仿真平台，因此默认“迁移交叉口1”环境支持该控制模型动作，动作设置与控制模型训练时设置相同。交通状态校准：校核目标交叉口可提取到的交通状态类型及维度是否与控制模型输入所需的交通状态类型及维度一致。按照交通状态校准要求，控制模型的源训练环境输入所需的交通状态包括8种状态类型，“迁移交叉口1”同样具有4个进口道，且进口道支持转向支持左转和直行，因此同样可以提取北向南、北向东、南向北、南向西、西向东、西向北、东向西、东向南8个交通状态类型，因此其可以转换为控制模型的交通状态输入的8种状态类型相同的8维数据：/＞作为控制模型的输入。因此迁移交叉口1满足交通状态校核。经过上述的交叉口参数匹配及DQN参数校准后，“迁移交叉口1”符合控制模型的环境迁移要求，即为目标环境，将控制模型迁移至该交叉口进行优化训练。控制模型迁移至目标环境的具体方法为：基于控制模型在源训练环境下得到的先验知识，对目标环境的原始控制模型M1的神经网络权重进行初始化设置，得到迁移至目标环境的控制模型，为了作区分，定义为M2。目标环境中控制模型的神经网络参数初始化流程示意图如图4所示，提取源环境的控制模型的神经网络ps中网络节点间连接权重，再提取新环境的控制模型的神经网络pt的节点结构，将目标环境神经网络的节点ni 和nj的连接权重按照源环境控制模型神经网络对应节点 ψ和 ψ的权重进行连接，i和j代表相邻的不同的层，n代表层中第n个节点，就得到了利用控制模型训练后的先验知识进行初始化的目标环境下控制模型的神经网络pt ，此时，目标环境下的控制模型相当于源训练环境下的控制模型迁移而来。S3.将对控制模型优化训练；基于DQN框架采用Q网络算法搭建的控制模型，在作用于交通环境控制信号灯之前，需要在目标环境中进行优化训练，有利于控制模型对交通控制达到更好的控制效果。对控制模型优化训练过程的原理图如图5所示。为了对比控制模型迁移至目标环境中对目标环境中的适应效果，在相同环境—目标环境中分别采用原始控制模型即无源控制模型M1和采用迁移至目标环境的控制模型M2进行优化训练对比，初始输入相同的交通流量为6000pcu/h，设置相同训练参数，如下表2仿真训练参数所示。表2 仿真训练参数超参数初始化值仿真时长6000迭代回合数episode200Iteration4经验池容量50000批量处理大小batch size600学习率3e-4折扣系数0.9S31.初始化控制模型神经网络参数；初始化控制模型经网络参数，主要是对神经网络权重的初始化设置。控制模型优化训练过程中，原始控制模型M1的神经网络的权重初始化过程是完全随机的，而采用迁移至目标环境的控制模型M2，已经在迁移过程中基于控制模型在源训练环境下得到的先验知识初始化。S32. 将实时交通状态输入到控制模型的神经网络中，控制模型根据神经网络输出的Q值在动作集合中以策略选择动作a；初始化神经网络模型以后，控制模型优化整体框架如图4所示。观测仿真交叉口环境，从中获取当前交叉口环境实时状态数据s，将实时状态输入到经过参数初始化的神经网络中，控制模型根据神经网络输出的Q值在动作集合中 策略选择动作a，控制相位变化，相位实时变化作用于交叉口环境中使其交通状态发生变化。S33.信号机执行动作a，控制相位变化，相位实时状态作用于交叉口环境使交通状态发生变化，将当前交通状态和下个时间步的交通状态/＞、动作a、奖励值/＞作为一个四元组/＞样本存储在经验池中;S34.控制模型获取实时交通状态以及奖励函数值进行选择动作a的同时，随机在经验池中抽取小批量样本作为训练数据，用所述训练数据来训练更新神经网络的权重值;在实施列中采用固定迭代回合数200，以奖励函数值的标准差变化小于1%作为收敛判断条件。如果收敛则控制模型优化训练完成。S35.重复上述S31-S34步骤，检测控制模型训练过程的DQN奖励函数值，直至奖励函数值的标准差变化小于阈值，则控制模型收敛，结束控制模型的优化训练。S4.检测周期内交通环境流特征参数异常比例是否超过阈值，如果是，则返回步骤S3，否则，不对控制模型进行优化。现实交叉口交通流特征及变化规律并不是稳定不变的，受种种现实因素影响会导致交叉口的交通流特征参数变化，交通流特征参数包括交通流量TF和各进口道左转车辆比例R，这两个特征参数直接反应了控制模型的控制效果，如果这两个特征参数越大，则反应交通越拥堵，需要对控制模型进行优化训练，可以提高控制模型对环境的适应能力。如果高峰小时交通流量TF超过设定值TF*的30%，则交通流量TF异常或者左转车辆转向比例R的值超过设定值R*的30%，则左转车辆比例R异常。因此当控制模型迁移至目标环境完成控制模型的优化训练后，检测该交叉口交通流特征以10天为一个统计周期，如果检测到交通流量TF异常和左转车辆比例R异常在10天中有超过7天，需重新对控制模型开启优化训练。实验结果分析：两种控制模型训练过程中的奖励函数变化过程对比如图6所示，图例中虚线和实线分别代表控制模型M1和M2奖励值函数的变化情况。可以看出控制模型M2在优化过程中的奖励函数在75轮以后标准差小于1%可以达到接近稳定的状态，而控制模型M1需要训练到175轮左右才能达到标准差小于1%，即控制模型M2收敛速度更快，说明控制模型M2能更快的适应新的交叉口环境，即可以减少优化训练控制模型的时间成本。两个模型在相同的训练环境下经过同样的200训练轮次后均达到收敛，将控制模型M2与原始控制模型M1在训练环境下进行控制效果测试对比，研究两个模型对于同一个交叉口环境的控制效果，如表3优化后控制模型M1、M2控制效果对比。可以看出控制模型M2比控制模型M1的各项评价指标效果都更好，尤其可以减少车辆最大排队长度。表3 优化后控制模型M1、M2控制效果对比评价指标控制模型M1控制模型M2平均车速26.1127.32平均停车延误时间15.4012.51平均损失时间47.5039.69最大排队长度185.73157.78交叉口运行平均车辆数963.37963.07将控制模型M2分别直接对目标环境进行控制和优化训练后对目标环境进行控制，其控制效果如表4模型M2自身优化前后控制效果对比。控制模型在经历了优化训练后更加适应了新的环境，相较于优化训练之前，各项评价指标均有明显的提高，从而实现了对新环境更好的控制效果。表4 控制模型M2自身优化前后控制效果对比评价指标控制模型M2优化后控制模型M2优化前平均车速26.6425.89平均停车延误时间12.7217.24平均损失时间42.3146.73最大排队长度169.87193.56交叉口运行平均车辆数949.18963.17以上所述仅为本申请的优选实施例而已，并不用于限制本申请，对于本领域的技术人员来说，本申请可以有各种更改和变化。凡在本申请的精神和原则之内，所作的任何修改、等同替换、改进等，均应包含在本申请的保护范围之内。
