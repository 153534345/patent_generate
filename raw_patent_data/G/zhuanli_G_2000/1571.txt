标题title
一种直播实时人脸替换的方法、设备及存储介质
摘要abst
本发明涉及人脸替换技术领域。一种直播实时人脸替换的方法包括获取第一人脸模型；对第一人脸模型进行区域划分，得到N个第一人脸区域；根据N个第一人脸区域对应的权重值进行排序，得到权重值由小到大顺序排列的N’个第一人脸区域；获取直播视频流中的第一帧图像，得到第一帧图像中的第二人脸；根据N个第一人脸区域，对第二人脸进行区域划分，得到M个第二人脸区域，其中，M个第二人脸区域与N个第一人脸区域相匹配；根据N’个第一人脸区域对M个第二人脸区域进行逐步替换，得到目标人脸，其中，目标人脸，表示第二人脸中至少部分替换成第一人脸；将目标人脸应用到直播视频流，得到直播实时人脸替换。
权利要求书clms
1.一种直播实时人脸替换的方法，其特征在于，方法包括：获取第一人脸模型；对第一人脸模型进行区域划分，得到N个第一人脸区域；根据所述N个第一人脸区域对应的权重值进行排序，得到所述权重值由小到大顺序排列的N’个第一人脸区域；获取直播视频流中的第一帧图像，得到所述第一帧图像中的第二人脸；根据所述N个第一人脸区域，对所述第二人脸进行区域划分，得到M个第二人脸区域，其中，所述M个第二人脸区域与所述N个第一人脸区域相匹配；根据所述N’个第一人脸区域对M个第二人脸区域进行逐步替换，得到目标人脸，其中，所述目标人脸，表示所述第二人脸中至少部分替换成所述第一人脸；将所述目标人脸应用到所述直播视频流，得到所述直播实时人脸替换。2.根据权利要求1所述的直播实时人脸替换的方法，其特征在于，所述获取第一人脸模型的步骤，包括：获取第一人脸的不同姿态、表情和光照的多个第一图像；利用生成对抗网络对多个所述第一图像中的面部特征点进行标定和对齐，确定面部特征点位置的一致性，其中，所述生成对抗网络包括训练生成器网络和训练判别器网络；在所述训练生成器网络中加入随机噪声，得到第一训练图像，其中，所述第一训练图像表示在所述第一人脸图像中加入随机噪声得到的所述第一人脸的图像；所述训练判别器网络，对所述第一训练图像进行判别，得到判别结果；根据所述判别结果，调整所述训练生成器网络，得到第二训练图像，所述第二训练图像，表示在所述第一人脸图像中加入随机噪声得到的所述第一人脸的图像；根据所述判别结果，调整所述训练判别器网络，并对所述第二训练图像进行判别，得到所述第一人脸模型。3.根据权利要求1所述的直播实时人脸替换的方法，其特征在于，所述对第一人脸模型进行区域划分，得到N个第一人脸区域的步骤，包括：获取所述第一人脸模型的面部特征点；根据所述面部特征点的分布，对所述面部特征点进行区域划分，得到所述N个第一人脸区域。4.根据权利要求3所述的直播实时人脸替换的方法，其特征在于，所述根据所述N个第一人脸区域对应的权重值进行排序，得到权重值由小到大顺序排列的N’个第一人脸区域的步骤，包括：根据每个所述第一人脸区域包含的面部特征点的权重均值，得到每个所述第一人脸区域的权重值；根据所述N个第一人脸区域对应的所述权重值进行由小到大的排序，得到所述权重值由小到大顺序排列的N’个第一人脸区域。5.根据权利要求1所述的直播实时人脸替换的方法，其特征在于，所述获取直播视频流中的第一帧图像，得到所述第一帧图像中的第二人脸的步骤，包括：在直播视频过程中，获取所述直播视频流中的第一帧图像，其中，所述第一帧图像，表示所述直播视频流中的某一帧图像；对所述第一帧图像进行人脸识别，得到所述第一帧图像中的所述第二人脸。6.根据权利要求1所述的直播实时人脸替换的方法，其特征在于，所述根据所述N个第一人脸区域，对所述第二人脸进行区域划分，得到M个第二人脸区域的步骤，包括：将所述N个第一人脸区域和所述第二人脸分别镜像至坐标系中，分别得到所述N个第一人脸区域和所述第二人脸对应的坐标；根据每个所述第一人脸区域的坐标对所述第二人脸对应的坐标进行划分匹配，得到所述M个第二人脸区域。7.根据权利要求1所述的直播实时人脸替换的方法，其特征在于，所述根据所述N’个第一人脸区域对M个第二人脸区域进行逐步替换，得到目标人脸的步骤，包括：根据所述N’个第一人脸区域的权重值由小到大的顺序，逐步与所述M个第二人脸区域进行替换，得到逐步替换的所述第二人脸；根据逐步替换的所述第二人脸，得到具有替换顺序的目标人脸。8.根据权利要求7所述的直播实时人脸替换的方法，其特征在于，所述将所述目标人脸应用到所述直播视频流，得到所述直播实时人脸替换的步骤，包括：将具有替换顺序的所述目标人脸，逐步应用到所述直播视频流，得到逐步替换成目标人脸的直播视频流；在逐步替换成目标人脸的直播视频流中，待所述第二人脸完全被所述目标人脸替换，得到所述直播实时人脸替换。9.一种计算机设备，包括存储器和处理器，所述存储器存储有计算机程序，其特征在于，所述处理器执行所述计算机程序时实现权利要求1至7中任一项所述的直播实时人脸替换的方法。10.一种计算机存储介质，其上存储有计算机程序，其特征在于，所述计算机程序被处理器执行时实现权利要求1至7中任一项所述的直播实时人脸替换的方法的步骤。
说明书desc
技术领域本发明涉及人脸替换技术领域，尤其是涉及一种直播实时人脸替换的方法、设备及存储介质。背景技术换脸技术是一种人工智能图像处理技术，能够将一个人的脸部信息提取出来，然后将其与另一个人的脸部信息进行匹配，从而生成一个新的具有两者特征结合的人脸图像。在近几年，随着深度学习技术的发展，基于神经网络的人脸合成算法已经逐渐成为主流。但是，目前的换脸技术，在直播视频过程切换时，仍然会被观看者所感知，由于人眼具有视觉暂留，即使目前的大多人脸替换方法，在增加算力，不断提高人脸切换的速度时，仍然会因人眼视觉暂留的原因，使得用户感知明显。发明内容本发明提供一种直播实时人脸替换的方法、设备及存储介质，用于解决现有的人脸替换过程中，视觉暂留的问题。本申请第一方面提供一种直播实时人脸替换的方法，方法包括：获取第一人脸模型；对第一人脸模型进行区域划分，得到N个第一人脸区域；根据所述N个第一人脸区域对应的权重值进行排序，得到所述权重值由小到大顺序排列的N’个第一人脸区域；获取直播视频流中的第一帧图像，得到所述第一帧图像中的第二人脸；根据所述N个第一人脸区域，对所述第二人脸进行区域划分，得到M个第二人脸区域，其中，所述M个第二人脸区域与所述N个第一人脸区域相匹配；根据所述N’个第一人脸区域对M个第二人脸区域进行逐步替换，得到目标人脸，其中，所述目标人脸，表示所述第二人脸中至少部分替换成所述第一人脸；将所述目标人脸应用到所述直播视频流，得到所述直播实时人脸替换。可实施的一些方式中，所述获取第一人脸模型的步骤，包括：获取第一人脸的不同姿态、表情和光照的多个第一图像；利用生成对抗网络对多个所述第一图像中的面部特征点进行标定和对齐，确定面部特征点位置的一致性，其中，所述生成对抗网络包括训练生成器网络和训练判别器网络；在所述训练生成器网络中加入随机噪声，得到第一训练图像，其中，所述第一训练图像表示在所述第一人脸图像中加入随机噪声得到的所述第一人脸的图像；所述训练判别器网络，对所述第一训练图像进行判别，得到判别结果；根据所述判别结果，调整所述训练生成器网络，得到第二训练图像，所述第二训练图像，表示在所述第一人脸图像中加入随机噪声得到的所述第一人脸的图像；根据所述判别结果，调整所述训练判别器网络，并对所述第二训练图像进行判别，得到所述第一人脸模型。可实施的一些方式中，所述对第一人脸模型进行区域划分，得到N个第一人脸区域的步骤，包括：获取所述第一人脸模型的面部特征点；根据所述面部特征点的分布，对所述面部特征点进行区域划分，得到所述N个第一人脸区域。可实施的一些方式中，所述根据所述N个第一人脸区域对应的权重值进行排序，得到权重值由小到大顺序排列的N’个第一人脸区域的步骤，包括：根据每个所述第一人脸区域包含的面部特征点的权重均值，得到每个所述第一人脸区域的权重值；根据所述N个第一人脸区域对应的所述权重值进行由小到大的排序，得到所述权重值由小到大顺序排列的N’个第一人脸区域。可实施的一些方式中，所述获取直播视频流中的第一帧图像，得到所述第一帧图像中的第二人脸的步骤，包括：在直播视频过程中，获取所述直播视频流中的第一帧图像，其中，所述第一帧图像，表示所述直播视频流中的某一帧图像；对所述第一帧图像进行人脸识别，得到所述第一帧图像中的所述第二人脸。可实施的一些方式中，所述根据所述N个第一人脸区域，对所述第二人脸进行区域划分，得到M个第二人脸区域的步骤，包括：将所述N个第一人脸区域和所述第二人脸分别镜像至坐标系中，分别得到所述N个第一人脸区域和所述第二人脸对应的坐标；根据每个所述第一人脸区域的坐标对所述第二人脸对应的坐标进行划分匹配，得到所述M个第二人脸区域。可实施的一些方式中，所述根据所述N’个第一人脸区域对M个第二人脸区域进行逐步替换，得到目标人脸的步骤，包括：根据所述N’个第一人脸区域的权重值由小到大的顺序，逐步与所述M个第二人脸区域进行替换，得到逐步替换的所述第二人脸；根据逐步替换的所述第二人脸，得到具有替换顺序的目标人脸。可实施的一些方式中，所述将所述目标人脸应用到所述直播视频流，得到所述直播实时人脸替换的步骤，包括：将具有替换顺序的所述目标人脸，逐步应用到所述直播视频流，得到逐步替换成目标人脸的直播视频流；在逐步替换成目标人脸的直播视频流中，待所述第二人脸完全被所述第一人脸替换，得到所述直播实时人脸替换。本申请第二方面提供一种计算机设备，包括存储器和处理器，所述存储器存储有计算机程序，所述处理器执行所述计算机程序时实现前述的直播实时人脸替换的方法。本申请第三方面提供一种计算机存储介质，其上存储有计算机程序，所述计算机程序被处理器执行时实现前述的直播实时人脸替换的方法的步骤。本发明有益效果：本申请提供一种直播实时人脸替换的方法、设备及存储介质，首先，获取第一人脸模型；再对第一人脸模型进行区域划分，得到N个第一人脸区域；其次，根据N个第一人脸区域对应的权重值进行排序，得到权重值由小到大顺序排列的N’个第一人脸区域；然后，获取直播视频流中的第一帧图像，得到第一帧图像中的第二人脸；接下来，根据N个第一人脸区域，对第二人脸进行区域划分，得到M个第二人脸区域；最后，根据N’个第一人脸区域对M个第二人脸区域进行逐步替换，得到目标人脸；最终，将目标人脸应用到直播视频流，得到直播实时人脸替换。通过上述方法，对第一人脸模型的划分，再利用划分的第一人脸模型对第二人脸进行逐步替换，也就是说，在直播视频播放的过程中，逐步的将第二人脸替换成第一人脸模型，这样，在逐步替换的过程中，用户对人脸替换的感知较小，甚至感知不到第二人脸被替换，有效减少了人脸突换时，对用户的感知影响。附图说明为了更清楚地说明本发明具体实施方式或现有技术中的技术方案，下面将对具体实施方式或现有技术描述中所需要使用的附图作简单地介绍，显而易见地，下面描述中的附图是本发明的一些实施方式，对于本领域普通技术人员来讲，在不付出创造性劳动的前提下，还可以根据这些附图获得其他的附图。图1为本发明一种直播实时人脸替换的方法的流程图。具体实施方式下面将结合实施例对本发明的技术方案进行清楚、完整地描述，显然，所描述的实施例是本发明一部分实施例，而不是全部的实施例。基于本发明中的实施例，本领域普通技术人员在没有做出创造性劳动前提下所获得的所有其他实施例，都属于本发明保护的范围。在本发明的描述中，需要理解的是，术语"中心"、"纵向"、"横向"、"长度"、"宽度"、"厚度"、"上"、"下"、"前"、"后"、"左"、"右"、"竖直"、"水平"、"顶"、"底"、"内"、"外"、"顺时针"、"逆时针"等指示的方位或位置关系为基于附图所示的方位或位置关系，仅是为了便于描述本发明和简化描述，而不是指示或暗示所指的装置或元件必须具有特定的方位、以特定的方位构造和操作，因此不能理解为对本发明的限制。此外，术语"第一"、"第二"仅用于描述目的，而不能理解为指示或暗示相对重要性或者隐含指明所指示的技术特征的数量。由此，限定有"第一"、"第二"的特征可以明示或者隐含地包括一个或者更多个所述特征。在本发明的描述中，"多个"的含义是两个或两个以上，除非另有明确具体的限定。此外，术语“安装”、“相连”、“连接”应做广义理解，例如，可以是固定连接，也可以是可拆卸连接，或一体地连接；可以是机械连接，也可以是电连接；可以是直接相连，也可以通过中间媒介间接相连，可以是两个元件内部的连通。对于本领域的普通技术人员而言，可以具体情况理解上述术语在本发明中的具体含义。下面对本申请中涉及的一些名词进行解释，以便清楚了解本申请的方案。生成对抗网络，是由两个神经网络模型组成的框架，一个是生成器网络，另一个是判别器网络。GAN的目标是通过训练两个网络之间的对抗过程来生成逼真的、与真实数据相似的新样本。基于模型拟合的方法，是指将面部特征点位置问题建模为一个最小化拟合误差的优化问题，通过求解最优化问题来得到面部特征点的位置。基于ASM的方法，使用Active Shape Model模型对人脸特征点进行对齐。ASM是一种对于由PCA构成的模型，可以通过人脸训练集来学习出模型以及每个特征点的权重以及方差等参数，然后利用这些参数对目标人脸进行匹配。ASM方法能够较好地克服变形，同时具有很高的对齐精度和效率。Active Shape Model模型，是一种基于形状建模的方法，用于对人脸或其他物体的轮廓进行识别和匹配。该模型通过对训练集中的轮廓数据进行主成分分析，得到特征向量和特征值，构建一个能够描述轮廓变化的统计模型。在测试阶段，ASM可以自动调整模型参数，以适应新的输入图像。专家评分法，一种常用的定量研究方法，通过专家对面部特征点进行打分、排名和评级等方式，从而得出面部特征点的权重。Haar Cascade，是指基于Haar小波的面部特征点检测方法，利用级联分类器和AdaBoost算法来快速准确地定位人脸位置和面部特征点。HOG，是指基于局部方向梯度直方图的特征提取方法，比HaarCascade更加精准。３DDFA，是指基于3D深度学习技术的人脸检测与面部特征点定位方法，能够对人脸进行姿态估计、形状恢复和纹理重建。深度卷积神经网络，是指一种在计算机视觉和图像处理领域中广泛应用的深度学习模型。它通过组合多个卷积层、池化层和全连接层来实现对图像特征的学习和提取。目前，换脸技术，已经能够实现真人的换脸，例如，在视频中将A的人脸，换成B的人脸。在换脸技术越发成熟的当下，大多技术强调的是换脸的速度，以及换脸后的真实感。由于人眼在观看图片的过程中，会有视觉暂留现象，这种现象导致在观看电影时，虽然观看的每张图像均为独立的，但是，当每秒能够显示24帧甚至以上帧数时，会使得用户感觉这1秒中的视频为连贯的，这正是利用了人眼具有视觉暂留的这一特点。但是，也正是因为这一特点，导致在换脸时感觉突兀，这主要是因为人眼对于连续变化的图像有一定的持续感知能力。本申请提供一种直播实时人脸替换的方法。本申请第一方面提供一种直播实时人脸替换的方法，方法包括：如图1所示，S100，获取第一人脸模型。其中，若想要在直播时，实时的人脸替换，首先要得到第一人脸模型，这样，方便在直播时对人脸进行实时替换。具体地，获取第一人脸模型包括步骤S101至S106。S101，获取第一人脸的不同姿态、表情和光照的多个第一图像。其中，首先确定要更换的第一人脸，第一人脸可以为主播的人脸，也可以为其他人的人脸。需要说明地是，第一人脸为主播的人脸可以是为了提升直播效果，例如，主播在直播时，往往会精心打扮，例如，使用化妆品遮盖皱纹等，而这种打扮显然会花费较长的时间，而主播并不能保证每次都在直播前进行精心打扮。再此情况下，可以通过摄像设备获取精心打扮的主播的脸部图像信息，即第一人脸具有的不同姿态、表情和光照的多个第一图像。以便根据不同姿态、表情和光照的多个第一图像得到第一人脸的不同角度和表情的信息，方便建立的第一人脸模型更加的逼真。S102，利用生成对抗网络对多个第一图像中的面部特征点进行标定和对齐，确定面部特征点位置的一致性。其中，生成对抗网络包括训练生成器网络和训练判别器网络。具体地，利用生成对抗网络对多个第一图像中的面部特征点进行标定和对齐，这样，使得每一张第一图像的面部特征点位置的一致性。从而保证了每张第一图像中面部特征点对应的如眼睛、鼻子和嘴巴等这些位置及形状的一致性，将多个第一图像中第一人脸的姿态和位置调整为一致，能够提高人脸识别的准确性。接下来，根据两张第一图像之间面部特征点的变化差别，得出第一人脸的表情变化动作等信息。也就是说，利用标定和对齐，可以得到第一人脸的面部姿态信息，即面部在图像中的角度和旋转信息，以便生成对抗网络对第一人脸动作的估计。另外，通过标定面部特征点，可以量化和描述面部表情的变化，进而实现对表情的分析和识别。需要说明地是，对面部特征点进行标定可以通过对面部特征点进行标定进行面部特征点的标定。面部特征点对齐可以通过基于ASM的方法的方法来对齐。S103，在训练生成器网络中加入随机噪声，得到第一训练图像。其中，第一训练图像表示在第一人脸图像中加入随机噪声得到的第一人脸的图像。S104，训练判别器网络，对第一训练图像进行判别，得到判别结果。S105，根据判别结果，调整训练生成器网络，得到第二训练图像。其中，第二训练图像，表示在第一人脸图像中加入随机噪声得到的第一人脸的图像。S106，根据判别结果，调整训练判别器网络，并对第二训练图像进行判别，得到第一人脸模型。其中，利用训练生成器网络在S103步骤中加入随机噪声，从而得到第一训练图像，也就是说，这一第一训练图像是包含有随机噪声的第一人脸图像。接下来，将第一训练图像，输入训练判别器网络，以便训练判别器网络对第一训练图像进行判别，得到判别结果，这一判别结果可以为识别出第一训练图像中的噪声，也可以为无法识别出第一训练图像中的噪声两种情况，当识别出第一训练图像中的噪声，说明第一人脸模型已经完成；当无法识别出第一训练图像中的噪声时，说明第一人脸模型仍然需要训练。这样，需要对训练判别器网络进行参数的调整，其中，参数的调整可以理解为对初始的第一人脸模型进行调整，这一过程，可理解为对初始的第一人脸模型的不断完善。也就是说，训练判别器网络参数调整后能够识别出这一随机噪声。然后，再调整训练生成器网络得到第二训练图像，利用第二训练图像，再次对训练判别器网络进行训练。这时，第二训练图像可以为第一训练图像，以便调整参数后的训练判别器网络是否能够识别出第一训练图像中的噪声。第二训练图像也可以加入相对于第一训练图像中随机噪声不同的噪声。通过上述方法对训练判别器网络训练多次，当训练生成器网络每次加入的噪声均能够被训练判别器网络识别时，即可说明初始的第一人脸模型训练完成，得到了最终的第一人脸模型。S200，对第一人脸模型进行区域划分，得到N个第一人脸区域。其中，由于第二人脸替换成第一人脸这一过程中，常规的替换容易让用户感到突兀，因此，将第一人脸模型进行区域划分，划分成N个第一人脸区域，这样，在后续步骤中，进行逐个区域的人脸替换，会在较大程度上降低用户对于人脸替换的感知程度，减少突兀感，或无突兀感。具体地，得到N个第一人脸区域包括步骤S201 和S202。S201，获取第一人脸模型的面部特征点。S202，根据面部特征点的分布，对面部特征点进行区域划分，得到N个第一人脸区域。其中，利用前述步骤提到的得到面部特征点的方法，得到了面部特征点。接下来，根据面部特征点变换对面部影响变化的大小赋予面部特征点权重。示例性地，眼睛和嘴的变换对面部影响较大，也就是说，眼睛和嘴的变换用户感知最为明显，因此，眼睛和嘴对应的面部特征点赋予较高的权重，而其他的位置，例如，腮部和额头的变换对面部影响相较于眼睛和嘴影响较小，因此，赋予腮部和额头较低的权重。具体地，得到面部的整体区域后，确定面部的整体区域中的额区、眼部区、鼻部区、眉毛区、脸颊区、嘴唇区、下巴区和颈部区，从而得到N个第一人脸区域，这里的N表示区域的数量。示例性地，额区：从发际线到眉毛上缘之间的区域，包括前额和额头。眼部区：包括眼窝、上下眼睑、眼球、以及睫毛和眼周。鼻部区：包括鼻背、鼻翼、鼻尖和鼻孔部位。眉毛区：位于眼窝上方，从眉毛上缘到眼窝下缘之间的区域。脸颊区：包括上颌骨和下颌骨之间的区域，涵盖双颊和侧脸。嘴唇区：包括上下嘴唇和口周围。下巴区：位于下颌骨和下唇之间的区域。颈部区：从下颌骨延伸到锁骨之间的区域。其中，颈部区，可以根据需要选择是否需要替换。另外，额区、眼部区、鼻部区、眉毛区、脸颊区、嘴唇区、下巴区和颈部区之间的边界，可以根据生理结构和面部特征来确定，例如，眼部区和脸颊区的边界处存在肌肉的话，可以根据面部的生理特征，将肌肉划分至相应地区域，这样，在后续步骤中进行区域替换时，可以将肌肉划分的区域同步替换。再例如，脸部存在痦子、纹身或疤痕等，可以通过通过专家评分法，将痦子、纹身或疤痕等单独划分成一个区域，因痦子、纹身或疤痕在脸部时，容易被用户观察到，因此，将痦子对应的区域增加权重，在以区域的权重作为替换顺序时，将会在延迟替换痦子区域。需要说明地是，额区、眼部区、鼻部区、眉毛区、脸颊区、嘴唇区、下巴区和颈部区的大小可以根据实际的情况进行调整，本申请对此并不加以限定。另外，面部划分的额区、眼部区、鼻部区、眉毛区、脸颊区、嘴唇区、下巴区和颈部区这些区域中，还可以根据需要，作为父区域，然后，对父区域进行多个子区域的划分，进一步的减少用户对换脸的感知。也就是说，针对父区域的替换时，逐步替换子区域，从而完成父区域的替换。子区域的替换顺序，也是根据各个父区域下，每个子区域对应的权重来替换，若权重相同，则以子区域连续性为优先级进行替换。S300，根据N个第一人脸区域对应的权重值进行排序，得到权重值由小到大顺序排列的N’个第一人脸区域。其中，得到权重值由小到大顺序排列的N’个第一人脸区域具体包括步骤S301和S302。S301，根据每个第一人脸区域包含的面部特征点的权重均值，得到每个第一人脸区域的权重值。S302，根据N个第一人脸区域对应的权重值进行由小到大的排序，得到权重值由小到大顺序排列的N’个第一人脸区域。其中，面部特征点可以通过面部特征点检测算法进行面部特征提取，例如，通过HOG、３DDFA、深度卷积神经网络或Haar Cascade等方式进行面部特征提取。面部特征点对应的权重值，可以根据深度卷积神经网络形成的深度学习模型，通过训练大规模的面部数据集来学习面部特征点的位置和权重。这样，将本申请的面部应用于深度学习模型即可得到面部特征点的位置和对应的权重。也就是说，本申请对于面部特征点的提取及对应的权重计算使用的是常规的方法，本申请对此并不加以限定。接下来，计算每个第一人脸区域所包含的权重均值，也就是说，一个第一人脸区域中包含5个面部特征点，并且知道5个面部特征点的权重的情况下，取这5个面部特征点的平均值，作为这一个第一人脸区域的权重值。再将N个第一人脸区域对应的权重值进行由小到大的排序，然后，即可得到权重值由小到大顺序排列的N’个第一人脸区域，这里N’与N的数量对应。S400，获取直播视频流中的第一帧图像，得到第一帧图像中的第二人脸。其中，第一帧图像为直播视频流中具有第二人脸的的图像。具体地，得到第一帧图像中的第二人脸包括步骤S401和S402。S401，在直播视频过程中，获取直播视频流中的第一帧图像。其中，第一帧图像，表示直播视频流中的某一帧图像。S402，对第一帧图像进行人脸识别，得到第一帧图像中的第二人脸。其中，第一帧图像可以为直播视频流中某一时刻的图像，例如2分钟、30分钟等，本申请对此并不加以限定。在得到第一帧图像后，对第一帧图像中的人脸特征进行识别，得到第一帧图像中的第二人脸数据。其中，第一帧图像中的人脸特征进行识别可以利用前述的面部特征点识别所使用的方法，本申请对此并不加以限定。需要说明地是，第二人脸为将要通过第一人脸替换的人脸，也就是说，当第一人脸为精心打扮的人脸时，至少部分特征会与第二人脸相同，因此，利用第一人脸得到的特征点与第一帧图像中识别到的多张人脸匹配，即可得到第二人脸。第二人脸若与第一人脸并非同一人时，需要识别出第一帧图像中的多个人脸，然后，在多个识别出的人脸中，选择需要替换的人脸，作为第二人脸。以便在直播视频流的第一帧图像之后的视频流中，对第二人脸进行替换。S500，根据N个第一人脸区域，对第二人脸进行区域划分，得到M个第二人脸区域。其中，M个第二人脸区域与N个第一人脸区域相匹配。具体地，得到M个第二人脸区域包括步骤S501和S502。S501，将N个第一人脸区域和第二人脸分别镜像至坐标系中，分别得到N个第一人脸区域和第二人脸对应的坐标。S502，根据每个第一人脸区域的坐标对第二人脸对应的坐标进行划分匹配，得到M个第二人脸区域。其中，在前述步骤中得到了N个第一人脸区域以及第二人脸后，分别将二者置于同一坐标系中，这样，就能够分别得到N个第一人脸区域以及第二人脸对应的坐标。接下来，根据坐标系得到第一人脸区域的边缘坐标，以及第二人脸的边缘坐标。然后，将第一人脸区域的边缘坐标与第二人脸的边缘坐标进行匹配，这一过程中，若第一人脸区域的面积大于第二人脸的面积时，需要对第一人脸区域进行缩放调整，以便尽量与第二人脸的面积匹配。然后，对第二人脸进行面部特征点的提取，提取方式，可使用前述步骤中提到的面部特征点提取方式。接下来，将第二人脸区域与第一人脸区域的面部特征点进行标定和对齐。使得对第二人脸的某一区域替换时，能够在第二人脸中找到找到对应位置。也就是说，将N个第一人脸区域中每个第一人脸区域与第二人脸区域进行对应，从而得到第二人脸的M个第二人脸区域。例如，第一人脸区域为1至N个，第二人脸区域为1至M个，并且，1至N个第一人脸区域与1至M个第二人脸区域一一对应。S600，根据N’个第一人脸区域对M个第二人脸区域进行逐步替换，得到目标人脸。其中，目标人脸，表示第二人脸中至少部分替换成第一人脸。具体地，得到目标人脸包括步骤S601至S602。S601，根据N’个第一人脸区域的权重值由小到大的顺序，逐步与M个第二人脸区域进行替换，得到逐步替换的第二人脸。S602，根据逐步替换的第二人脸，得到具有替换顺序的目标人脸。其中，在前述步骤中得到1至N个第一人脸区域与1至M个第二人脸区域一一对应的情况下，在直播视频的第一帧图像之后的直播过程中，根据预设的时间，以N’个第一人脸区域的权重值由小到大的顺序，对M个第二人脸区域进行逐步的替换，此处的逐步应理解为一个。需要说明地是，M个第二人脸区域中当前进行替换的一个区域，与上一个被替换的区域间隔预设的时间，这一预设的时间可以根据需要设定，例如，设定为30秒，这样，间隔30秒替换M个第二人脸区域中的一个区域。也就是说，具有替换顺序的目标人脸表示1至M个第二人脸区域依据权重值由小到大的顺序逐步替换成目标人脸。根据预设的时间将第二人脸替换成目标人脸的过程，相较于现有的一次即可完成的人脸替换，本申请将这一过程划分成了多次人脸区域替换，且多次人脸区域替换为有时间间隔的替换，这种替换方式，可以在一定程度上节省算力。S700，将目标人脸应用到直播视频流，得到直播实时人脸替换。其中，得到直播实时人脸替换包括步骤S701和S702。S701，将具有替换顺序的目标人脸，逐步应用到直播视频流，得到逐步替换成目标人脸的直播视频流；S702，在逐步替换成目标人脸的直播视频流中，待第二人脸完全被第一人脸替换，得到直播实时人脸替换。其中，在直播视频流的第一帧图像之后，根据预设的时间，逐步的对直播视频中的第二人脸进行区域性的替换成目标人脸，最终得到直播实时人脸替换。也就是说，在第一帧图像之后的直播视频中，经过一段时间的人脸区域替换，最终将在直播视频中将呈现第一人脸，而在两个预设的时间之间的间隔期间，直播视频流中呈现处第二人脸部分被第一人脸替换的图像。这一过程是缓慢的，且不易被用户所察觉的，降低了用户对于人脸替换的突兀感。在一些实施例中，第一人脸为主播的人脸时，若第一人脸相对于直播视频时，主播的第二人脸，可能会出现皮肤亮度的不同，因此，在步骤S100至S700中，使将替换区域的肤色与未替换区域的肤色保持相同，并在步骤S700之后，还包括步骤S800。S800，在设定的时间段内，逐步调整第一人脸的肤色，经过设定的时间段后，得到与第一人脸模型的肤色相同的第一人脸的肤色。例如第一人脸模型的肤色对应的是100，而当前的第一人脸的肤色为0，将预设的时间段划分为100个时间点，每个时间点调整一次第一人脸的肤色，例如第1个时间点，将第一人脸的肤色由0调整至1。这样，经过设定的时间段后，可使得第一人脸的肤色与第一人脸模型的肤色相同。需要说明地是，在步骤S100至S700中，若第二人脸与第一人脸模型为同一人时，可以将第一人脸模型中精心打扮的面部替换成第二人脸。若第二人脸与第一人脸模型非同一人时，执行S100至S700的步骤即可。本申请第二方面提供一种计算机设备，包括存储器和处理器，存储器存储有计算机程序，处理器执行计算机程序时实现前述的直播实时人脸替换的方法。本申请第三方面提供一种计算机存储介质，其上存储有计算机程序，计算机程序被处理器执行时实现前述的直播实时人脸替换的方法的步骤。在本发明实施例的描述中，所属技术领域的技术人员应当知道，本发明实施例可以实现为方法、装置、电子设备及计算机可读存储介质。因此，本发明实施例可以具体实现为以下形式：完全的硬件、完全的软件、硬件和软件结合的形式。此外，在一些实施例中，本发明实施例还可以实现为在一个或多个计算机可读存储介质中的计算机程序产品的形式，该计算机可读存储介质中包含计算机程序代码。上述计算机可读存储介质可以采用一个或多个计算机可读存储介质的任意组合。计算机可读存储介质包括：电、磁、光、电磁、红外或半导体的系统、装置或器件，或者以上任意的组合。计算机可读存储介质更具体的例子包括：便携式计算机磁盘、硬盘、随机存取存储器、只读存储器、可擦除可编程只读存储器、闪存、光纤、光盘只读存储器、光存储器件、磁存储器件或以上任意组合。在本发明实施例中，计算机可读存储介质可以是任意包含或存储程序的有形介质，该程序可以被指令执行系统、装置、器件使用或与其结合使用。上述计算机可读存储介质包含的计算机程序代码可以用任意适当的介质传输，包括：无线、电线、光缆、射频或者以上任意合适的组合。可以以汇编指令、指令集架构指令、机器指令、机器相关指令、微代码、固件指令、状态设置数据、集成电路配置数据或以一种或多种程序设计语言或其组合来编写用于执行本发明实施例操作的计算机程序代码，程序设计语言包括面向对象的程序设计语言，例如：Java、Smalltalk、C++，还包括常规的过程式程序设计语言，例如：C语言或类似的程序设计语言。计算机程序代码可以完全的在用户计算机上执行、部分的在用户计算机上执行、作为一个独立的软件包执行、部分在用户计算机上部分在远程计算机上执行以及完全在远程计算机或服务器上执行。在涉及远程计算机的情形中，远程计算机可以通过任意种类的网络，包括：局域网或广域网，可以连接到用户计算机，也可以连接到外部计算机。本发明实施例通过流程图和/或方框图描述所提供的方法、装置、电子设备。应当理解，流程图和/或方框图的每个方框以及流程图和/或方框图中各方框的组合，都可以由计算机可读程序指令实现。这些计算机可读程序指令可以提供给通用计算机、专用计算机或其他可编程数据处理装置的处理器，从而生产出一种机器，这些计算机可读程序指令通过计算机或其他可编程数据处理装置执行，产生了实现流程图和/或方框图中的方框规定的功能/操作的装置。也可以将这些计算机可读程序指令存储在能使得计算机或其他可编程数据处理装置以特定方式工作的计算机可读存储介质中。这样，存储在计算机可读存储介质中的指令就产生出一个包括实现流程图和/或方框图中的方框规定的功能/操作的指令装置产品。也可以将计算机可读程序指令加载到计算机、其他可编程数据处理装置或其他设备上，使得在计算机、其他可编程数据处理装置或其他设备上执行一系列操作步骤，以产生计算机实现的过程，从而使得在计算机或其他可编程数据处理装置上执行的指令能够提供实现流程图和/或方框图中的方框规定的功能/操作的过程。本发明实施例的说明书和权利要求书中的术语“第一”和“第二”等是用于区别不同的对象，而不是用于描述对象的特定顺序。例如，第一目标对象和第二目标对象等是用于区别不同的目标对象，而不是用于描述目标对象的特定顺序。在本发明实施例中，“示例性的”或者“例如”等词用于表示作例子、例证或说明。本发明实施例中被描述为“示例性的”或者“例如”的任何实施例或设计方案不应被解释为比其它实施例或设计方案更优选或更具优势。确切而言，使用“示例性的”或者“例如”等词旨在以具体方式呈现相关概念。在本发明实施例的描述中，除非另有说明，“多个”的含义是指两个或两个以上。例如，多个处理单元是指两个或两个以上的处理单元；多个系统是指两个或两个以上的系统。最后应说明的是：以上各实施例仅用以说明本发明的技术方案，而非对其限制；尽管参照前述各实施例对本发明进行了详细的说明，本领域的普通技术人员应当理解：其依然可以对前述各实施例所记载的技术方案进行修改，或者对其中部分或者全部技术特征进行等同替换；而这些修改或者替换，并不使相应技术方案的本质脱离本发明各实施例技术方案的范围。
