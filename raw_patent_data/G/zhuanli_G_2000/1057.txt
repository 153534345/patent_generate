标题title
基于自注意力机制的DWT域鲁棒视频水印方法及系统
摘要abst
本发明公开了一种基于自注意力机制的DWT域鲁棒视频水印方法及系统，方法包括：读取待添加水印的视频；采用训练好的基于自注意力机制的DWT域鲁棒视频水印网络将水印嵌入待添加水印的视频中，输出含水印视频。本发明能够获得良好的水印不可见性，保证了含水印视频的质量，同时，提高了方法的鲁棒性。
权利要求书clms
1.基于自注意力机制的DWT域鲁棒视频水印方法，其特征在于，包括：读取待添加水印的视频；采用训练好的基于自注意力机制的DWT域鲁棒视频水印网络将水印嵌入待添加水印的视频中，输出含水印视频。2.根据权利要求1所述的基于自注意力机制的DWT域鲁棒视频水印方法，其特征在于，基于自注意力机制的DWT域鲁棒视频水印网络的训练方法，包括：初始化基于自注意力机制的DWT域鲁棒视频水印网络；设置基于自注意力机制的DWT域鲁棒视频水印网络的训练过程；设置基于自注意力机制的DWT域鲁棒视频水印网络的损失函数与各自的权重；根据设置好的训练过程并结合损失函数及权重，将随机生成的QR码嵌入到读取的训练视频，即载体视频中，生成含水印视频；利用攻击层，对含水印视频进行攻击，再做水印提取操作，输出水印提取结果；计算载体视频与含水印视频之间的损失，并计算从攻击后的含水印视频中提取的水印与原始嵌入的水印之间的损失，调整基于自注意力机制的DWT域鲁棒视频水印网络的参数，直到总损失满足预设的要求。3.根据权利要求2所述的基于自注意力机制的DWT域鲁棒视频水印方法，其特征在于，初始化基于自注意力机制的DWT域鲁棒视频水印网络，包括：设置嵌入网络、攻击层和提取网络；所述嵌入网络包括：一个预处理模块，用于对输入的待添加水印的视频作DWT变换、对原始水印进行空间复制操作；一个时空特征提取模块，包括一个2D卷积层和一个3D卷积层，2D卷积层输出的结果作为密集特征融合模块的输入，3D卷积层输出的结果作为自注意力卷积层的输入；在密集特征融合模块中，包括三个由3D卷积层组成的密集连接块；接下来通过四个3D卷积层降低特征通道，得到水印残差；在自注意力卷积层中，设置了两个3D卷积层，通过运算得到注意力掩膜；将水印残差、注意力掩膜与强度因子α三者相乘并加到预处理模块的输出上，最后相加的结果输入到一个后处理模块得到基于自注意力机制的DWT域鲁棒视频水印网络的输出，即含水印视频；所述攻击层包括：H.264/AVC压缩攻击、裁剪攻击、缩放攻击、帧删除、高斯模糊攻击和高斯噪声攻击；其中，H.264/AVC压缩攻击的crf为28，裁剪攻击中保留视频帧原尺寸的60%，缩放攻击将视频帧原尺寸放大到1.2倍或缩小为0.8倍，帧删除攻击中去除50%数量的视频帧，高斯模糊攻击的kernel_size为3×3，高斯噪声攻击的σ为0.03；所述提取网络包括：一个预处理模块，用于对输入作DWT变换；一个时空特征提取模块，包括一个2D卷积层和一个3D卷积层，时空特征提取模块的输出作为密集特征提取模块的输入；在密集特征提取模块中，包括三个由3D卷积层组成的密集连接块；接下来通过四层3D自适应平均化池降低特征通道；最后对降维后的特征进行空间维度平均，得到提取网络的输出，即提取的水印。4.根据权利要求3所述的基于自注意力机制的DWT域鲁棒视频水印方法，其特征在于，所述攻击层使用可微代理模型模拟不可微的H.264/AVC压缩攻击；可微代理模型基于U-Net结构，为各个视频帧生成残差图，并添加到输入视频帧上；可微代理模型被预训练好并冻结参数后进行使用。5.根据权利要求3所述的基于自注意力机制的DWT域鲁棒视频水印方法，其特征在于，设置基于自注意力机制的DWT域鲁棒视频水印网络的训练过程，包括：将大小为512×512，帧数为9的训练视频，与32×32的随机QR码作为水印图像输入到水印嵌入网络；提取出训练视频的U通道送入预处理模块进行二级DWT变换，得到每个帧大小为128×128的低频子带LL2；同时，32×32大小的水印在预处理模块中进行空间复制，其中将水印在水平方向复制四次后的结果再在垂直方向复制四次，得到大小为128×128的空间复制后水印；将经过预处理后的训练视频U通道，即九个LL2送入时空特征提取模块中，输出尺寸为9×128×128×64的时空特征；将时空特征与空间复制后的水印在通道上进行拼接，输入到密集特征融合模块的第一个密集连接块中，运算结果与输入在通道上拼接得到尺寸为9×128×128×129的特征，作为第一个密集连接块的输出；将第一个密集连接块的输出与空间复制后的水印在通道上再次拼接，作为第二个密集连接块的输入，运算结果与输入在通道上拼接得到尺寸为9×128×128×194的输出；第三个密集连接块重复前一个块的操作，最终输出尺寸为9×128×128×259的特征，即密集特征融合模块将时空特征与水印信息融合后的含水印特征；将尺寸为9×128×128×64的含水印特征输入到四个3D卷积层进行特征通道降维，得到尺寸为9×128×128×1的水印残差；使用自注意力卷积层，将时空特征提取模块输出的时空特征映射到两个新的特征空间，分别作为Quary和Key；同尺寸的Quary和Key进行转置乘法运算，得到注意力权重，并对权重进行Softmax归一化与特征通道平均，输出尺寸为9×128×128×1的注意力掩膜；将水印残差、注意力掩膜与强度因子α相乘，添加到预处理模块输出的九个大小为128×128的低频子带LL2上，得到九个含水印信息的低频子带LL2；在后处理模块中，将含水印信息的低频子带LL2与各自原始的低频子带LL2进行替换，并作逆DWT变换得到含水印信息的视频帧U通道，接着将视频帧Y、V通道与含水印信息的U通道拼接，得到含水印视频；将含水印视频送入攻击层，在H.264/AVC压缩攻击、裁剪攻击、缩放攻击、帧删除攻击、高斯模糊攻击和高斯噪声攻击这六种攻击中随机选择一种，对含水印视频进行攻击，输出攻击后的含水印视频；将攻击后的含水印视频输入到提取网络，并提取出其U通道；此U通道首先经过预处理模块，作两级DWT变换取出其中的低频子带LL2，其尺寸大小为9×128×128×1；将得到的低频子带LL2输入到时空特征提取模块中，输出尺寸为9×128×128×64的时空特征；将时空特征输入到密集特征提取模块中的第一个密集连接块，运算结果与输入在通道上拼接得到尺寸为9×128×128×128的特征，作为第一个密集连接块的输出，并输入到第二个密集连接块；重复在第一个密集连接块中的通道拼接操作，第二个密集连接块输出尺寸为9×128×128×192的特征，第三个密集连接块输出尺寸为9×128×128×256的特征，即密集特征提取模块从时空特征中提取出来的含水印特征；将含水印特征输入到四层3D自适应平均化池，降低时间通道与特征通道的维度，输出的结果尺寸为1×128×128×1；最后在此结果的空间维度上作平均，得到尺寸为1×32×32×1的输出，即提取的水印。6.根据权利要求5所述的基于自注意力机制的DWT域鲁棒视频水印方法，其特征在于，载体视频Vin与含水印视频VW之间的均方损失函数LQ表示为：，其中，Hc和Wc分别表示载体视频的高和宽，T表示视频的帧数，和/＞分别表示载体视频和含水印视频中的像素；原始水印Win与提取水印Wext之间的均方损失函数LW表示为：，其中，Hw和Ww分别表示原始水印的高和宽，和/＞分别表示原始水印和提取水印中的像素；基于自注意力机制的DWT域鲁棒视频水印网络的总损失函数Ltotal表示为：，其中，和/＞为调节均方损失函数LQ与均方损失函数LW之间的权重的超参数。7.根据权利要求5所述的基于自注意力机制的DWT域鲁棒视频水印方法，其特征在于，基于自注意力机制的DWT域鲁棒视频水印网络输出含水印视频后，对含水印视频进行攻击，并对攻击后的含水印视频进行水印提取，获得提取水印，所述提取水印用于与原始水印比较并计算损失，从而调整基于自注意力机制的DWT域鲁棒视频水印网络的参数和/或评价视频水印的不可见性结果与抗攻击鲁棒性。8.基于自注意力机制的DWT域鲁棒视频水印系统，其特征在于，包括：视频读取模块，用于读取待添加水印的视频；水印添加模块，用于采用训练好的基于自注意力机制的DWT域鲁棒视频水印网络将水印嵌入待添加水印的视频中，输出含水印视频。9.一种计算机可读存储介质，其上存储有计算机程序，其特征在于，该计算机程序被处理器执行时，实现如权利要求1~7中任一所述的基于自注意力机制的DWT域鲁棒视频水印方法。
说明书desc
技术领域本发明属于视频水印技术领域，具体涉及一种基于自注意力机制的DWT域鲁棒视频水印方法及系统。背景技术数字视频已成为社交媒体主流的信息载体，如何保护视频的版权信息也受到了越来越多人的关注。鲁棒视频水印方法是一种用于保护视频内容版权的重要技术。含水印视频的质量，即水印不可见性，与含水印视频被攻击后提取水印的精度，即方法对攻击的鲁棒性，是评估鲁棒视频水印方法的两个重要指标。现有的鲁棒视频水印方法难以在不可见性和鲁棒性上同时给出有竞争力的实验结果，其原因在于：传统水印方法中，没有考虑视频帧间丰富时域特征，嵌入系数的选择仍有待优化；基于深度学习的方法中，没有结合频域相关的先验知识，使得方法难以在水印不可见性和方法对攻击鲁棒性之间取得高效平衡。发明内容为解决现有技术中的不足，本发明提供一种基于自注意力机制的DWT域鲁棒视频水印方法及系统，能够获得良好的水印不可见性，保证了含水印视频的质量，同时，提高了方法的鲁棒性。为达到上述目的，本发明所采用的技术方案是：第一方面，提供一种基于自注意力机制的DWT域鲁棒视频水印方法，包括：读取待添加水印的视频；采用训练好的基于自注意力机制的DWT域鲁棒视频水印网络将水印嵌入待添加水印的视频中，输出含水印视频。进一步地，基于自注意力机制的DWT域鲁棒视频水印网络的训练方法，包括：初始化基于自注意力机制的DWT域鲁棒视频水印网络；设置基于自注意力机制的DWT域鲁棒视频水印网络的训练过程；设置基于自注意力机制的DWT域鲁棒视频水印网络的损失函数与各自的权重；根据设置好的训练过程并结合损失函数及权重，将随机生成的QR码嵌入到读取的训练视频，即载体视频中，生成含水印视频；利用攻击层，对含水印视频进行攻击，再做水印提取操作，输出水印提取结果；计算载体视频与含水印视频之间的损失，并计算从攻击后的含水印视频中提取的水印与原始嵌入的水印之间的损失，调整基于自注意力机制的DWT域鲁棒视频水印网络的参数，直到总损失满足预设的要求。进一步地，初始化基于自注意力机制的DWT域鲁棒视频水印网络，包括：设置嵌入网络、攻击层和提取网络；所述嵌入网络包括：一个预处理模块，用于对输入的待添加水印的视频作DWT变换、对原始水印进行空间复制操作；一个时空特征提取模块，包括一个2D卷积层和一个3D卷积层，2D卷积层输出的结果作为密集特征融合模块的输入，3D卷积层输出的结果作为自注意力卷积层的输入；在密集特征融合模块中，包括三个由3D卷积层组成的密集连接块；接下来通过四个3D卷积层降低特征通道，得到水印残差；在自注意力卷积层中，设置了两个3D卷积层，通过运算得到注意力掩膜；将水印残差、注意力掩膜与强度因子α三者相乘并加到预处理模块的输出上，最后相加的结果输入到一个后处理模块得到基于自注意力机制的DWT域鲁棒视频水印网络的输出，即含水印视频；所述攻击层包括：H.264/AVC压缩攻击、裁剪攻击、缩放攻击、帧删除、高斯模糊攻击和高斯噪声攻击；其中，H.264/AVC压缩攻击的crf为28，裁剪攻击中保留视频帧原尺寸的60%，缩放攻击将视频帧原尺寸放大到1.2倍或缩小为0.8倍，帧删除攻击中去除50%数量的视频帧，高斯模糊攻击的kernel_size为3×3，高斯噪声攻击的σ为0.03；所述提取网络包括：一个预处理模块，用于对输入作DWT变换；一个时空特征提取模块，包括一个2D卷积层和一个3D卷积层，时空特征提取模块的输出作为密集特征提取模块的输入；在密集特征提取模块中，包括三个由3D卷积层组成的密集连接块；接下来通过四层3D自适应平均化池降低特征通道；最后对降维后的特征进行空间维度平均，得到提取网络的输出，即提取的水印。进一步地，所述攻击层使用可微代理模型模拟不可微的H.264/AVC压缩攻击；可微代理模型基于U-Net结构，为各个视频帧生成残差图，并添加到输入视频帧上；可微代理模型被预训练好并冻结参数后进行使用。进一步地，设置基于自注意力机制的DWT域鲁棒视频水印网络的训练过程，包括：将大小为512×512，帧数为9的训练视频，与32×32的随机QR码作为水印图像输入到水印嵌入网络；提取出训练视频的U通道送入预处理模块进行二级DWT变换，得到每个帧大小为128×128的低频子带LL2；同时，32×32大小的水印在预处理模块中进行空间复制，其中将水印在水平方向复制四次后的结果再在垂直方向复制四次，得到大小为128×128的空间复制后水印；将经过预处理后的训练视频U通道，即九个LL2送入时空特征提取模块中，输出尺寸为9×128×128×64的时空特征；将时空特征与空间复制后的水印在通道上进行拼接，输入到密集特征融合模块的第一个密集连接块中，运算结果与输入在通道上拼接得到尺寸为9×128×128×129的特征，作为第一个密集连接块的输出；将第一个密集连接块的输出与空间复制后的水印在通道上再次拼接，作为第二个密集连接块的输入，运算结果与输入在通道上拼接得到尺寸为9×128×128×194的输出；第三个密集连接块重复前一个块的操作，最终输出尺寸为9×128×128×259的特征，即密集特征融合模块将时空特征与水印信息融合后的含水印特征；将尺寸为9×128×128×64的含水印特征输入到四个3D卷积层进行特征通道降维，得到尺寸为9×128×128×1的水印残差；使用自注意力卷积层，将时空特征提取模块输出的时空特征映射到两个新的特征空间，分别作为Quary和Key；同尺寸的Quary和Key进行转置乘法运算，得到注意力权重，并对权重进行Softmax归一化与特征通道平均，输出尺寸为9×128×128×1的注意力掩膜；将水印残差、注意力掩膜与强度因子α相乘，添加到预处理模块输出的九个大小为128×128的低频子带LL2上，得到九个含水印信息的低频子带LL2；在后处理模块中，将含水印信息的低频子带LL2与各自原始的低频子带LL2进行替换，并作逆DWT变换得到含水印信息的视频帧U通道，接着将视频帧Y、V通道与含水印信息的U通道拼接，得到含水印视频；将含水印视频送入攻击层，在H.264/AVC压缩攻击、裁剪攻击、缩放攻击、帧删除攻击、高斯模糊攻击和高斯噪声攻击这六种攻击中随机选择一种，对含水印视频进行攻击，输出攻击后的含水印视频；将攻击后的含水印视频输入到提取网络，并提取出其U通道；此U通道首先经过预处理模块，作两级DWT变换取出其中的低频子带LL2，其尺寸大小为9×128×128×1；将得到的低频子带LL2输入到时空特征提取模块中，输出尺寸为9×128×128×64的时空特征；将时空特征输入到密集特征提取模块中的第一个密集连接块，运算结果与输入在通道上拼接得到尺寸为9×128×128×128的特征，作为第一个密集连接块的输出，并输入到第二个密集连接块；重复在第一个密集连接块中的通道拼接操作，第二个密集连接块输出尺寸为9×128×128×192的特征，第三个密集连接块输出尺寸为9×128×128×256的特征，即密集特征提取模块从时空特征中提取出来的含水印特征；将含水印特征输入到四层3D自适应平均化池，降低时间通道与特征通道的维度，输出的结果尺寸为1×128×128×1；最后在此结果的空间维度上作平均，得到尺寸为1×32×32×1的输出，即提取的水印。进一步地，载体视频Vin与含水印视频VW之间的均方损失函数LQ表示为：，其中，Hc和Wc分别表示载体视频的高和宽，T表示视频的帧数，和/＞分别表示载体视频和含水印视频中的像素；原始水印Win与提取水印Wext之间的均方损失函数LW表示为：，其中，Hw和Ww分别表示原始水印的高和宽，和/＞分别表示原始水印和提取水印中的像素；基于自注意力机制的DWT域鲁棒视频水印网络的总损失函数Ltotal表示为：，其中，和/＞为调节均方损失函数LQ与均方损失函数LW之间的权重的超参数。进一步地，基于自注意力机制的DWT域鲁棒视频水印网络输出含水印视频后，对含水印视频进行攻击，并对攻击后的含水印视频进行水印提取，获得提取水印，所述提取水印用于与原始水印比较并计算损失，从而调整基于自注意力机制的DWT域鲁棒视频水印网络的参数和/或评价视频水印的不可见性结果与抗攻击鲁棒性。第二方面，提供一种基于自注意力机制的DWT域鲁棒视频水印系统，包括：视频读取模块，用于读取待添加水印的视频；水印添加模块，用于采用训练好的基于自注意力机制的DWT域鲁棒视频水印网络将水印嵌入待添加水印的视频中，输出含水印视频。第三方面，提供一种计算机可读存储介质，其上存储有计算机程序，该计算机程序被处理器执行时，实现如第一方面所述的基于自注意力机制的DWT域鲁棒视频水印方法。与现有技术相比，本发明所达到的有益效果：本发明通过采用训练好的基于自注意力机制的DWT域鲁棒视频水印网络将水印嵌入待添加水印的视频中，输出含水印视频；本发明能够获得良好的水印不可见性，保证了含水印视频的质量，同时，提高了方法的鲁棒性。附图说明图1是本发明实施例提供的一种基于自注意力机制的DWT域鲁棒视频水印方法的主要流程示意图；图2是本发明实施例中基于自注意力机制的DWT域鲁棒视频水印网络的端到端训练框架图；图3是本发明实施例中嵌入网络框架图；图4是本发明实施例中提取网络框架图；图5是本发明实施例中模拟H.264/AVC压缩攻击的可微代理模型框架图；图6是载体视频帧、对应的含水印视频帧和两者差异的可视化结果；图7是本发明实施例中基于自注意力机制的DWT域鲁棒视频水印网络的网络参数详细配置；图8是本发明实施例中可微代理模型的网络参数详细配置；图9是在不同分辨率下，使用本发明方法生成含水印视频的质量；图10是本发明所述方法对不同强度攻击的鲁棒性 /REC)。具体实施方式下面结合附图对本发明作进一步描述。以下实施例仅用于更加清楚地说明本发明的技术方案，而不能以此来限制本发明的保护范围。实施例一：一种基于自注意力机制的DWT域鲁棒视频水印方法，包括：读取待添加水印的视频；采用训练好的基于自注意力机制的DWT域鲁棒视频水印网络将水印嵌入待添加水印的视频中，输出含水印视频。本实施例所述基于自注意力机制的DWT域鲁棒视频水印方法，如图1所示，包括以下几个步骤：步骤1：读取训练视频，即载体视频。步骤2：初始化基于自注意力机制的DWT域鲁棒视频水印网络的网络结构，其中包括：嵌入网络、提取网络与攻击层；DWT域鲁棒视频水印网络的初始化如下：嵌入网络：在此子网络中，首先设置了一个预处理模块，用于对输入作DWT变换，另外还对原始水印进行空间复制操作；接下来是一个时空特征提取模块，其中包括一个2D卷积层和一个3D卷积层，输出的结果作为密集特征融合模块和自注意力卷积层的输入；在密集特征融合模块中，包括三个由3D卷积层组成的密集连接块；接下来通过四个3D卷积层降低特征通道，得到水印残差；在自注意力卷积层中，设置了两个3D卷积层，通过运算得到注意力掩膜；将水印残差、注意力掩膜与强度因子α三者相乘并加到预处理模块的输出上，最后相加的结果输入到一个后处理模块得到嵌入网络的输出，即含水印视频。攻击层：此层包括H.264/AVC压缩攻击、裁剪攻击、缩放攻击、帧删除、高斯模糊攻击和高斯噪声攻击。其中H.264/AVC压缩攻击的crf为28，裁剪攻击中保留视频帧原尺寸的60%，缩放攻击将视频帧原尺寸放大到1.2倍或缩小为0.8倍，帧删除攻击中去除50%数量的视频帧，高斯模糊的kernel_size为3×3，高斯噪声的σ为0.03。对于训练集中的每个载体视频，每一次batch都会随机选择一种攻击，使得网络在训练时适应这些攻击并能够提取水印。特别地，可微代理模型被用于模拟不可微的H.264/AVC压缩攻击。可微代理模型基于U-Net结构，为各个视频帧生成残差图，并添加到输入视频帧上得到接近真实H.264/AVC压缩后的视频帧。该代理模型在训练时输入的视频长度为9帧，大小为512×512，被预训练好并冻结参数后放入攻击层中使用。可微代理模型网络框架如图5所示，其中的细节如图8所示。提取网络：在此子网络中，首先设置了一个预处理模块，用于对输入作DWT变换；接下来是一个时空特征提取模块，其中包括一个2D卷积层和一个3D卷积层，输出的结果作为密集特征提取模块的输入；在密集特征提取模块中，包括三个由3D卷积层组成的密集连接块；接下来通过四层3D自适应平均化池降低特征通道；最后对降维后的特征进行空间维度平均，得到提取网络的输出，即提取的水印。基于自注意力机制的DWT域鲁棒视频水印网络的网络细节如图7所示，其中b为batch size。可微代理模型的网络参数如图8所示。步骤3：设置嵌入网络与提取网络的损失函数与各自的权重；为了提升水印的不可见性，即生成的含水印视频要在像素级别上与载体视频越接近越好，方法中通过最小化均方损失函数来调整嵌入网络的参数，使得生成的水印视频具有良好的视觉质量。载体视频Vin与含水印视频VW之间的均方损失函数LQ具体表示为：，其中，Hc和Wc分别表示载体视频的高和宽，T表示视频的帧数，和/＞分别表示载体视频和含水印视频中的像素。为了提高方法对攻击的鲁棒性，即含水印视频经过攻击后，提取网络仍然可以准确地提取出水印，方法中通过最小化原始水印与提取水印之间的均方损失函数来调整嵌入网络与提取网络的参数，使得嵌入网络可以将水印嵌入到视频帧中不易被破坏的区域，提取网络可以利用失真的特征还原出水印。原始水印Win与提取水印Wext之间的均方损失函数LW具体表示为：，其中，Hw和Ww分别表示原始水印的高和宽，和/＞分别表示原始水印和提取水印中的像素。综上所述，模型的总损失函数Ltotal包括载体视频与含水印视频之间的均方损失函数LQ和原始水印与提取水印之间的均方损失函数LW。端到端训练时，为两者设置了不同的权重，来平衡水印的不可见性与方法对攻击的鲁棒性，具体表示为：，其中，和/＞为调节均方损失函数LQ与均方损失函数LW之间的权重的超参数。步骤4：设置基于自注意力机制的DWT域鲁棒视频水印网络的训练过程；根据设置好的训练过程并结合损失函数及权重，提取载体视频的U通道送入网络中进行训练；读取随机生成的QR码水印图像，嵌入到读取的训练视频，即载体视频中，生成含水印视频；训练的流程如图2所示。将QR码水印图像通过水印嵌入方法，嵌入到载体视频中，生成含水印视频：使用1个实例并结合下图3所示，将一个大小为512×512，帧数为9的训练视频，与32×32的随机QR码作为水印图像输入到水印嵌入网络；首先，提取出训练视频的U通道送入预处理模块进行二级DWT变换，得到每个帧大小为128×128的低频子带LL2；同时，32×32大小的水印在预处理模块中进行空间复制，其中将水印在水平方向复制四次后的结果再在垂直方向复制四次，得到大小为128×128的空间复制后水印；将经过预处理后的训练视频U通道，即九个低频子带LL2送入时空特征提取模块中，输出尺寸为9×128×128×64的时空特征；将时空特征与空间复制后的水印在通道上进行拼接，输入到密集特征融合模块的第一个密集连接块中，运算结果与输入在通道上拼接得到尺寸为9×128×128×129的特征，作为第一个密集连接块的输出；将第一个密集连接块的输出与空间复制后的水印在通道上再次拼接，作为第二个密集连接块的输入，运算结果与输入在通道上拼接得到尺寸为9×128×128×194的输出；第三个密集连接块重复前一个块的操作，最终输出尺寸为9×128×128×259的特征，即密集特征融合模块将时空特征与水印信息融合后的含水印特征；将尺寸为9×128×128×64的含水印特征输入到四个3D卷积层进行特征通道降维，得到尺寸为9×128×128×1的水印残差；使用自注意力卷积层，将时空特征提取模块输出的时空特征映射到两个新的特征空间，分别作为Quary和Key；同尺寸的Quary和Key进行转置乘法运算，得到注意力权重，并对权重进行Softmax归一化与特征通道平均，输出尺寸为9×128×128×1的注意力掩膜；将水印残差、注意力掩膜与强度因子α相乘，添加到预处理模块输出的九个大小为128×128的低频子带LL2上，得到九个含水印信息的低频子带LL2；在后处理模块中，将含水印信息的低频子带LL2与各自原始的低频子带LL2进行替换，并作逆DWT变换得到含水印信息的视频帧U通道，接着将视频帧Y、V通道与含水印信息的U通道拼接，得到含水印视频。将含水印视频通过水印攻击方法，生成被信号处理攻击后的含水印视频：接着上述的实例，在得到含水印的视频之后，该水印视频被送入到攻击层，且每一次batch都会随机选择一种攻击类型，得到攻击后的含水印视频；具体为：将含水印视频送入攻击层，在H.264/AVC压缩攻击、裁剪攻击、缩放攻击、帧删除攻击、高斯模糊攻击和高斯噪声攻击这六种攻击中随机选择一种，对含水印视频进行攻击，输出攻击后的含水印视频。将攻击后的含水印视频通过水印提取方法，输出提取的水印：如下图4所示，提取出被攻击后的含水印视频的U通道，输入到提取网络；此U通道首先经过预处理模块，作两级DWT变换取出其中的低频子带LL2，其尺寸大小为9×128×128×1；将得到的低频子带LL2输入到时空特征提取模块中，输出尺寸为9×128×128×64的时空特征；将时空特征输入到密集特征提取模块中的第一个密集连接块，运算结果与输入在通道上拼接得到尺寸为9×128×128×128的特征，作为第一个密集连接块的输出，并输入到第二个密集连接块；重复在第一个密集连接块中的通道拼接操作，第二个密集连接块输出尺寸为9×128×128×192的特征，第三个密集连接块输出尺寸为9×128×128×256的特征，即密集特征提取模块从时空特征中提取出来的含水印特征；将含水印特征输入到四层3D自适应平均化池，降低时间通道与特征通道的维度，输出的结果尺寸为1×128×128×1；最后在此结果的空间维度上作平均，得到尺寸为1×32×32×1的输出，即提取的水印。步骤5：结合步骤3计算载体视频与含水印视频之间的均方损失函数，原始水印与提取水印之间的均方损失函数，并通过减少总的损失来调整优化网络参数，直到总损失满足预设的要求。步骤6：读取测试视频，输入到已经训练好的基于自注意力机制的DWT域鲁棒视频水印网络中，进行水印嵌入，输出含水印视频，接着攻击含水印视频并进行水印提取，输出最终水印提取的结果，即获得提取水印，提取水印用于与原始水印比较并计算损失，从而调整基于自注意力机制的DWT域鲁棒视频水印网络的参数和/或评价视频水印的不可见性结果与抗攻击鲁棒性。训练好的网络在Kinetics600数据集上进行测试，以PSNR与SSIM作为水印不可见性的评价指标。图9中给出了在不同分辨率下，该方法生成的含水印视频在视频质量上的测试结果，可以看出该方法在不可见性上的优越性。这主要是因为：根据人眼视觉系统，人眼对亮度通道Y比对色度通道U、V更加敏感，本方法选择在不易被人眼察觉的视频帧U通道中进行嵌入；嵌入网络中使用了自注意力机制，根据视频帧U通道低频分量的特征，调节水印残差中对系数修改的分布与强度，使得水印嵌入在高不可见性的系数上；载体视频与水印视频之间的视频质量均方损失函数也使得网络在训练过程中，使嵌入网络生成在像素级别上与载体视频接近的含水印视频。图6展示了载体视频帧与其对应的含水印视频帧的可视化结果，第一行是四个不同的载体视频帧；第二行是第一行的视频帧使用本发明所述方案添加水印后的含水印视频帧，第三行是第二行与第一行对应视频帧之间的差异；第三行展示了前两者在像素级别上的差异。以提取准确率ACC与扫码成功率REC作为方法对不同攻击鲁棒性的评价指标。图10中给出了在不同分辨率下的实验结果。从本发明所述方法中对攻击层中不同强度的攻击，以及攻击层从未涉及到的攻击的鲁棒性，可以看出本发明所述方法在鲁棒性上的优越性。这主要是因为：水印在空间上进行复制，且多次拼接到特征通道上以达到冗余嵌入；攻击层使得网络在训练过程中，将水印嵌入在稳定的系数上，并可从被攻击的系数上提取出水印信息；视频压缩攻击会丢弃视频帧的高频信息，本方法将水印嵌入在低频分量上，使得方法对压缩攻击具有强鲁棒性。不仅对训练阶段出现的六种攻击的不同攻击强度进行鲁棒测试，并且对训练阶段没有出现过的攻击如MPEG-4压缩攻击和H.265/HEVC压缩攻击进行了测试，均获得了较好的综合评估性能。实施例二：基于实施例一所述的一种基于自注意力机制的DWT域鲁棒视频水印方法，本实施例提供一种基于自注意力机制的DWT域鲁棒视频水印系统，包括：视频读取模块，用于读取待添加水印的视频；水印添加模块，用于采用训练好的基于自注意力机制的DWT域鲁棒视频水印网络将水印嵌入待添加水印的视频中，输出含水印视频。实施例三：基于实施例一所述的一种基于自注意力机制的DWT域鲁棒视频水印方法，本实施例提供一种计算机可读存储介质，其上存储有计算机程序，该计算机程序被处理器执行时，实现如实施例一所述的基于自注意力机制的DWT域鲁棒视频水印方法。以上所述仅是本发明的优选实施方式，应当指出，对于本技术领域的普通技术人员来说，在不脱离本发明技术原理的前提下，还可以做出若干改进和变形，这些改进和变形也应视为本发明的保护范围。
