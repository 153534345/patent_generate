标题title
一种基于AI算法的Kafka异常监控方法及装置
摘要abst
本发明公开了一种基于AI算法的Kafka异常监控方法及装置，包括：采集指标数据，将指标数据依据类型进行划分，得到至少一个目标指标数据；选取与目标指标数据匹配的目标异常检测模型，将目标指标数据发送给所述目标异常检测模型，得到目标指标数据的异常监控结果。上述过程中，首先对指标数据依据数据类型进行划分，得到至少一个目标指标数据，针对每个目标指标数据采用对应的目标异常检测模型进行异常检测，一种类型的数据对应一种检测模型，相较于传统检测过程中，所有数据基于一个固定的阈值进行告警，导致监控结果的准确率低，不但进行了数据细分还进行了模型细分，提高了监控结果的准确性，避免了小问题演变成大故障的可能。
权利要求书clms
1.一种基于AI算法的Kafka异常监控方法，其特征在于，包括：采集Kafka集群中的指标数据，其中，所述指标数据为生产者数据、消费者数据、分区数据、集群数据和性能数据中的至少一种类型；将所述指标数据依据类型进行划分，得到至少一个目标指标数据；选取与所述目标指标数据匹配的目标异常检测模型，其中，所述目标异常检测模型为消费者异常检测模型、生产者异常检测模型、分区异常检测模型、集群异常检测模型和性能异常检测模型中的至少一种，所述目标异常检测模型通过构建和训练得到；将所述目标指标数据发送给所述目标异常检测模型，得到所述目标指标数据的异常监控结果。2.根据权利要求1所述的方法，其特征在于，所述目标异常检测模型的构建过程包括：获取指标数据样本，其中，所述指标数据样本包括：指标数据和样本标签，所述样本标签为正常数据或者异常数据；对所述指标数据样本进行特征分析，确定所述指标数据样本的状态，所述状态包括：周期、漂移和平稳；确定所述指标数据样本的概率密度函数，基于所述概率密度函数确定所述指标数据样本的分布规律，其中，所述分布规律为低偏态对称分布、中偏态对称分布和高偏态对称分布中的一种；基于所述分布规律确定检测算法，基于所述检测算法和所述状态构建所述目标异常检测模型。3.根据权利要求2所述的方法，其特征在于，所述目标异常检测模型的训练过程包括：将所述指标数据样本划分为训练集、验证集和测试集；基于所述训练集和所述验证集对所述目标异常检测模型进行训练，获取与所述目标异常检测模型对应的损失函数；若所述损失函数收敛，基于所述测试集对所述目标异常检测模型进行测试。4.根据权利要求1所述的方法，其特征在于，将所述目标指标数据发送给所述目标异常检测模型，得到所述目标指标数据的异常监控结果包括：对所述目标指标数据进行时序漂移检测，得到漂移异常得分；对所述目标指标数据进行时序平稳性分析，得到平稳性异常得分；对所述目标指标数据进行时序周期性分析，得到周期性异常得分；对所述目标指标数据进行偏度计算，得到偏度异常得分；获取所述漂移异常得分，所述平稳性异常得分、所述周期性异常得分和所述偏度异常得分的权重，基于所述权重和各个异常得分确定异常监控结果。5.根据权利要求1所述的方法，其特征在于，还包括：将所述指标数据进行预处理，得到第一目标指标数据；对所述第一目标指标数据进行数据增强处理，得到第二目标指标数据。6.一种基于AI算法的Kafka异常监控装置，其特征在于，包括：采集模块，用于采集Kafka集群中的指标数据，其中，所述指标数据为生产者数据、消费者数据、分区数据、集群数据和性能数据中的至少一种类型；划分模块，用于将所述指标数据依据类型进行划分，得到至少一个目标指标数据；选取模块，用于选取与所述目标指标数据匹配的目标异常检测模型，其中，所述目标异常检测模型为消费者异常检测模型、生产者异常检测模型、分区异常检测模型、集群异常检测模型和性能异常检测模型中的至少一种，所述目标异常检测模型通过构建和训练得到；检测模块，用于将所述目标指标数据发送给所述目标异常检测模型，得到所述目标指标数据的异常监控结果。7.根据权利要求6所述的装置，其特征在于，还包括：获取模块，用于获取指标数据样本，其中，所述指标数据样本包括：指标数据和样本标签，所述样本标签为正常数据或者异常数据；分析模块，用于对所述指标数据样本进行特征分析，确定所述指标数据样本的状态，所述状态包括：周期、漂移和平稳；确定模块，用于确定所述指标数据样本的概率密度函数，基于所述概率密度函数确定所述指标数据样本的分布规律，其中，所述分布规律为低偏态对称分布、中偏态对称分布和高偏态对称分布中的一种；确定和构建模块，用于基于所述分布规律确定检测算法，基于所述检测算法和所述状态构建所述目标异常检测模型。8.根据权利要求7所述的装置，其特征在于，还包括：划分模块，用于将所述指标数据样本划分为训练集、验证集和测试集；训练和获取模块，用于基于所述训练集和所述验证集对所述目标异常检测模型进行训练，获取与所述目标异常检测模型对应的损失函数；测试模块，用于若所述损失函数收敛，基于所述测试集对所述目标异常检测模型进行测试。9.根据权利要求6所述的装置，其特征在于，所述检测模块包括：检测单元，用于对所述目标指标数据进行时序漂移检测，得到漂移异常得分；第一分析单元，用于对所述目标指标数据进行时序平稳性分析，得到平稳性异常得分；第二分析单元，用于对所述目标指标数据进行时序周期性分析，得到周期性异常得分；计算单元，用于对所述目标指标数据进行偏度计算，得到偏度异常得分；获取和确定单元，用于获取所述漂移异常得分，所述平稳性异常得分、所述周期性异常得分和所述偏度异常得分的权重，基于所述权重和各个异常得分确定异常监控结果。10.根据权利要求6所述的装置，其特征在于，还包括：预处理模块，用于将所述指标数据进行预处理，得到第一目标指标数据；增强模块，用于对所述第一目标指标数据进行数据增强处理，得到第二目标指标数据。
说明书desc
技术领域本发明涉及数据处理技术领域，尤其涉及一种基于AI算法的Kafka异常监控方法及装置。背景技术Kafka是一种分布式消息队列系统，广泛应用于大数据处理和实时流数据处理等场景。然而，由于消息队列的复杂性和动态变化的环境，可能会出现各种异常情况，如消息堆积、延迟、消费者异常等，给系统的稳定性和可靠性带来挑战。由于kafka对稳定性要求较高，对异常容忍度非常低。因此，快速的Kafka异常发现、定位和止损就变得越来越重要。针对异常监控的问题，传统的固定阈值告警方式，需要依赖专家经验进行规则配置，不能根据不同业务场景灵活动态调整阈值，监控结果的准确率低，容易让小问题演变成大故障。发明内容有鉴于此，本发明提供了一种基于AI算法的Kafka异常监控方法及装置，用以解决现有技术中传统的固定阈值告警方式，需要依赖专家经验进行规则配置，不能根据不同业务场景灵活动态调整阈值，容易让小问题演变成大故障的问题。具体方案如下：一种基于AI算法的Kafka异常监控方法，包括：采集Kafka集群中的指标数据，其中，所述指标数据为生产者数据、消费者数据、分区数据、集群数据和性能数据中的至少一种类型；将所述指标数据依据类型进行划分，得到至少一个目标指标数据；选取与所述目标指标数据匹配的目标异常检测模型，其中，所述目标异常检测模型为消费者异常检测模型、生产者异常检测模型、分区异常检测模型、集群异常检测模型和性能异常检测模型中的至少一种，所述目标异常检测模型通过构建和训练得到；将所述目标指标数据发送给所述目标异常检测模型，得到所述目标指标数据的异常监控结果。上述的方法，可选的，所述目标异常检测模型的构建过程包括：获取指标数据样本，其中，所述指标数据样本包括：指标数据和样本标签，所述样本标签为正常数据或者异常数据；对所述指标数据样本进行特征分析，确定所述指标数据样本的状态，所述状态包括：周期、漂移和平稳；确定所述指标数据样本的概率密度函数，基于所述概率密度函数确定所述指标数据样本的分布规律，其中，所述分布规律为低偏态对称分布、中偏态对称分布和高偏态对称分布中的一种；基于所述分布规律确定检测算法，基于所述检测算法和所述状态构建所述目标异常检测模型。上述的方法，可选的，所述目标异常检测模型的训练过程包括：将所述指标数据样本划分为训练集、验证集和测试集；基于所述训练集和所述验证集对所述目标异常检测模型进行训练，获取与所述目标异常检测模型对应的损失函数；若所述损失函数收敛，基于所述测试集对所述目标异常检测模型进行测试。上述的方法，可选的，将所述目标指标数据发送给所述目标异常检测模型，得到所述目标指标数据的异常监控结果包括：对所述目标指标数据进行时序漂移检测，得到漂移异常得分；对所述目标指标数据进行时序平稳性分析，得到平稳性异常得分；对所述目标指标数据进行时序周期性分析，得到周期性异常得分；对所述目标指标数据进行偏度计算，得到偏度异常得分；获取所述漂移异常得分，所述平稳性异常得分、所述周期性异常得分和所述偏度异常得分的权重，基于所述权重和各个异常得分确定异常监控结果。上述的方法，可选的，还包括：将所述指标数据进行预处理，得到第一目标指标数据；对所述第一目标指标数据进行数据增强处理，得到第二目标指标数据。一种基于AI算法的Kafka异常监控装置，包括：采集模块，用于采集Kafka集群中的指标数据，其中，所述指标数据为生产者数据、消费者数据、分区数据、集群数据和性能数据中的至少一种类型；划分模块，用于将所述指标数据依据类型进行划分，得到至少一个目标指标数据；选取模块，用于选取与所述目标指标数据匹配的目标异常检测模型，其中，所述目标异常检测模型为消费者异常检测模型、生产者异常检测模型、分区异常检测模型、集群异常检测模型和性能异常检测模型中的至少一种，所述目标异常检测模型通过构建和训练得到；检测模块，用于将所述目标指标数据发送给所述目标异常检测模型，得到所述目标指标数据的异常监控结果。上述的装置，可选的，还包括：获取模块，用于获取指标数据样本，其中，所述指标数据样本包括：指标数据和样本标签，所述样本标签为正常数据或者异常数据；分析模块，用于对所述指标数据样本进行特征分析，确定所述指标数据样本的状态，所述状态包括：周期、漂移和平稳；确定模块，用于确定所述指标数据样本的概率密度函数，基于所述概率密度函数确定所述指标数据样本的分布规律，其中，所述分布规律为低偏态对称分布、中偏态对称分布和高偏态对称分布中的一种；确定和构建模块，用于基于所述分布规律确定检测算法，基于所述检测算法和所述状态构建所述目标异常检测模型。上述的装置，可选的，还包括：划分模块，用于将所述指标数据样本划分为训练集、验证集和测试集；训练和获取模块，用于基于所述训练集和所述验证集对所述目标异常检测模型进行训练，获取与所述目标异常检测模型对应的损失函数；测试模块，用于若所述损失函数收敛，基于所述测试集对所述目标异常检测模型进行测试。上述的装置，可选的，所述检测模块包括：检测单元，用于对所述目标指标数据进行时序漂移检测，得到漂移异常得分；第一分析单元，用于对所述目标指标数据进行时序平稳性分析，得到平稳性异常得分；第二分析单元，用于对所述目标指标数据进行时序周期性分析，得到周期性异常得分；计算单元，用于对所述目标指标数据进行偏度计算，得到偏度异常得分；获取和确定单元，用于获取所述漂移异常得分，所述平稳性异常得分、所述周期性异常得分和所述偏度异常得分的权重，基于所述权重和各个异常得分确定异常监控结果。上述的装置，可选的，还包括：预处理模块，用于将所述指标数据进行预处理，得到第一目标指标数据；增强模块，用于对所述第一目标指标数据进行数据增强处理，得到第二目标指标数据。与现有技术相比，本发明包括以下优点：本发明公开了一种基于AI算法的Kafka异常监控方法及装置，包括：采集指标数据，将指标数据依据类型进行划分，得到至少一个目标指标数据；选取与目标指标数据匹配的目标异常检测模型，将目标指标数据发送给所述目标异常检测模型，得到目标指标数据的异常监控结果。上述过程中，首先对指标数据依据数据类型进行划分，得到至少一个目标指标数据，针对每个目标指标数据采用对应的目标异常检测模型进行异常检测，一种类型的数据对应一种检测模型，相较于传统检测过程中，所有数据基于一个固定的阈值进行告警，导致监控结果的准确率低，不但进行了数据细分还进行了模型细分，提高了监控结果的准确性，避免了小问题演变成大故障的可能。附图说明为了更清楚地说明本发明实施例或现有技术中的技术方案，下面将对实施例或现有技术描述中所需要使用的附图作简单地介绍，显而易见地，下面描述中的附图仅仅是本发明的一些实施例，对于本领域普通技术人员来讲，在不付出创造性劳动的前提下，还可以根据这些附图获得其他的附图。图1为本发明实施例公开的一种基于AI算法的Kafka异常监控方法流程图；图2为本发明实施例公开的一种模型构建流程示意图；图3为本发明实施例公开的一种多模型训练流程示意图；图4为本发明实施例公开的一种异常检测流程示意图；图5为本发明实施例公开的一种基于AI算法的Kafka异常监控装置结构框图。具体实施方式下面将结合本发明实施例中的附图，对本发明实施例中的技术方案进行清楚、完整地描述，显然，所描述的实施例仅仅是本发明一部分实施例，而不是全部的实施例。基于本发明中的实施例，本领域普通技术人员在没有做出创造性劳动前提下所获得的所有其他实施例，都属于本发明保护的范围。本发明公开了一种基于AI算法的Kafka异常监控方法及装置，应用于对kafka 集群的异常情况的监控过程中，其中，Kafka是一种高吞吐量、分布式的消息队列系统，由Apache软件基金会开发和维护。它主要用于处理大规模数据流和实时流式处理。由于kafka对稳定性要求较高，对异常容忍度非常低。因此，快速的Kafka异常发现、定位和止损就变得越来越重要。针对异常监控的问题，传统的固定阈值告警方式，需要依赖专家经验进行规则配置，不能根据不同业务场景灵活动态调整阈值，监控结果的准确率低，容易让小问题演变成大故障。为了解决上述问题，本发明利用AI算法的能力，结合Kafka的关键指标数据，构建异常检测模型，以实现对Kafka消息队列的智能监控。通过实时采集和分析数据，模型能够准确地识别消费者、生产者、分区、集群和性能方面的异常行为和异常情况，为运维人员提供重要的监控和预警信息，帮助其快速发现和解决问题，保障Kafka消息队列的正常运行。所述方法的执行流程如图1所示，包括步骤：S101、采集Kafka集群中的指标数据，其中，所述指标数据为生产者数据、消费者数据、分区数据、集群数据和性能数据中的至少一种类型；本发明实施例中，通过采集模块agent从Kafka集群采集时间序列数据的指标数据，如消息的生产和消费速率、消费者位移的提交情况、分区的偏移量、集群Zookeeper的连接状态、ISR的数量以及异常日志报错等监控指标数据。所述指标数据生产者数据、消费者数据、分区数据、集群数据和性能数据中的至少一种类型。S102、将所述指标数据依据类型进行划分，得到至少一个目标指标数据；本发明实施例中，依据类型进行指标数据的划分可以通过两种方式：方式一：预先为所述指标数据分配类型标识，每一种类型对应一种类型标识，基于类型标识确定当前指标数据所属目标指标数据；方式二：设置预设关键词，将预设关键词与对应的类型建立关联，若所述指标数据中存在对应的预设关键词，基于所述预设关键词查找与其对应类型的目标指标数据，进一步的，也可以采用其它优选的划分方法，本发明实施例中不进行具体的限定。S103、选取与所述目标指标数据匹配的目标异常检测模型，其中，所述目标异常检测模型为消费者异常检测模型、生产者异常检测模型、分区异常检测模型、集群异常检测模型和性能异常检测模型中的至少一种，所述目标异常检测模型通过构建和训练得到；本发明实施例中，所述目标异常检测模型可以为消费者异常检测模型、生产者异常检测模型、分区异常检测模型、集群异常检测模型和性能异常检测模型中的至少一种，所述目标异常检测模型通过构建和训练得到，其中，所述目标异常检测模型的构建过程包括:预先获取指标数据样本，其中，所述指标数据样本包括：指标数据和样本标签，所述样本标签为正常数据或者异常数据。所述指标数据样本的规律主要呈现三种状态：周期、漂移和平稳。针对周期性变化，是指标会由于早晚高峰或是一些定时任务引起规律性波动。属于数据的内在规律性波动，模型应该具备识别出周期性成分，检测上下文异常的能力。对于不存在长期趋势成分的时序指标而言，当指标数据存在周期性成分的情况下，∫ffdx⩽∫ffdx=∫f2dx，其中T代表的是时序的周期跨度。可通过计算自相关图，即计算出t取不同值时∫ffdx的值，然后通过分析自相关峰的间隔来确定周期性，主要的流程包括以下几个步骤：a、提取趋势成分，分离出残差序列。使用移动平均法提取出长期趋势项，跟原序列作差得到残差序列。提取趋势成分和分离残差序列是对时序数据进行预处理的一部分，旨在将数据中的长期趋势成分和短期波动成分分离开来，以便更好地进行周期性变化的检测。具体处理过程如下：1. 移动平均法：移动平均法是一种常用的平滑技术，用于提取时序数据中的长期趋势项。该方法通过计算数据点周围一定窗口大小内的平均值来平滑数据，减少数据中的噪声和短期波动。窗口大小可以根据具体情况选择，通常取奇数值，如3、5、7等。例如，对于一个长度为N的时序数据，如果窗口大小为3，则第一个平均值为前三个数据的平均，第二个平均值为第二、三、四个数据的平均，以此类推。这样就可以得到一个平滑的数据序列，表示时序数据的长期趋势。2. 残差序列计算：将原始时序数据与通过移动平均法得到的趋势序列相减，即可得到残差序列。残差序列表示原始数据中除去长期趋势成分后的短期波动成分。这些短期波动可能包含了周期性变化的成分。通过这样的预处理步骤，时序数据中的长期趋势和短期波动成分被分离开来，有助于更好地进行周期性变化的检测。周期性变化的识别可以通过计算自相关图，观察自相关峰的间隔来确定是否存在周期性，并对周期性成分进行进一步的异常检测和上下文异常的判定。b、计算残差的循环自相关序列。通过循环移动残差序列后，与残差序列进行向量点乘运算来计算自相关序列。计算残差的循环自相关序列可以通过以下具体处理过程实现：1. 提取趋势成分：首先，使用移动平均法或其他趋势提取方法提取出原始时序数据的长期趋势成分，得到一个平滑的趋势序列。2. 计算残差：将原始时序数据与趋势序列相减，得到残差序列。这些残差数据表示原始数据中除去长期趋势成分后的短期波动。3. 计算循环自相关序列：对残差序列进行循环移动，并计算每个循环位置上的自相关。具体步骤如下：a. 对残差序列进行循环移动：从残差序列的第一个数据点开始，将序列循环移动一个单位，并计算每次移动后的向量。b. 计算向量点乘运算：将每次移动后的残差序列向量与原始残差序列进行点乘运算，得到每次移动后的相关系数。c. 将得到的相关系数保存为循环自相关序列。4. 重复以上步骤：不断重复步骤3，直到循环移动回到残差序列的起始位置为止，即完成了计算循环自相关序列的过程。循环自相关序列的计算可以帮助识别时序数据中的周期性变化。在循环自相关序列中，如果存在明显的周期性，那么相关系数会在某些位置上显示较高的值，反映出数据中的周期性模式。通过观察循环自相关序列中的相关系数变化，可以判断是否存在周期性变化，从而帮助进一步进行异常检测和上下文异常的判定。c、根据自相关序列的峰值坐标来确定周期T。提取自相关序列的一系列局部最高峰，取横坐标的间隔为周期。确定周期T的具体过程如下：1. 计算循环自相关序列：按照上述步骤，通过循环移动残差序列，计算得到循环自相关序列。该序列中的每个值都表示在不同的移动位置上的自相关系数。2. 提取自相关序列的局部最高值：在循环自相关序列中，寻找局部最高值，即值比相邻的左右两个值都大的数据点。这些局部最高值表示残差序列中可能存在的周期性。3. 确定周期T：根据提取得到的局部最高值的坐标，计算这些坐标之间的间隔。这些间隔即代表可能的周期T。周期T应该是这些间隔的平均值或者出现频率最高的值。4. 设定阈值：在确定周期T时，可以设定一个阈值来过滤掉不显著的周期性，只有当局部最高值的自相关系数超过阈值时，才被认为是有效的周期T。通过以上过程，可以从循环自相关序列中找到可能的周期T，即时序数据中存在的周期性变化。周期T的确定可以帮助分析时序数据的周期性规律，从而更好地进行异常检测和上下文异常的识别。在实际应用中，根据具体数据的特点和需求，可以调整阈值和周期T的确定方式，以得到更准确的结果。进一步的周期提取流程如下：首先提取趋势成分，分离出残差序列，提取残差具体可以通过剔除趋势的方式实现，然后，计算残差的循环自相关序列进行循环位移，最后，根据自相关序列的峰值坐标来确定周期T，计算相关图，提取周期T，进行阈值校验。针对漂移的处理过程，对于待建模的序列，通常要求它不存在明显的长期趋势或是存在全局漂移的现象，否则生成的模型通常无法很好地适应指标的最新走势。将时间序列随着时间的变化出现均值的显著变化或是存在全局突变点的情况，统称为漂移的场景。为了能够准确地捕捉时间序列的最新走势，需要在建模前期判断历史数据中是否存在漂移的现象。全局漂移和周期性序列均值漂移；kafka集群指标受业务活动等复杂因素影响，很多数据会有非周期性的变化，而建模需要容忍这些变化。因此，区别于经典的变点检测问题，在异常检测场景下，只需要检测出历史上很平稳，之后出现数据漂移的情况。综合算法性能和实际表现，使用了基于中位数滤波的漂移检测方法，主要的流程包含以下几个环节：中位数平滑a.根据给定窗口的大小，提取窗口内的中位数来获取时序的趋势成分。b.窗口需要足够大，以避免周期因素影响，并进行滤波延迟矫正。本发明实施例中，滤波延迟矫正的处理过程如下：窗口大小选择：首先需要确定中位数平滑的窗口大小，即在多少个数据点内计算中位数。窗口大小的选择对平滑效果和延迟矫正都有影响。如果窗口太小，平滑效果会较差，而且可能受到周期因素的影响；如果窗口太大，延迟矫正的效果可能会受到影响。中位数平滑：在给定的窗口大小内，计算窗口内数据点的中位数。中位数是将数据点按升序排列后，位于中间位置的值。这样，中位数平滑可以有效地消除异常值的影响，因为异常值在排序后不会对中位数产生明显的影响。滤波延迟矫正：在应用中位数平滑后，需要对平滑后的数据进行延迟矫正，以消除平滑引入的滞后效应。由于中位数平滑是基于窗口内数据点的中位数计算得出的，平滑后的数据点实际上是处于窗口的中间位置。因此，在计算中位数平滑后的数据时，会引入一定的延迟。为了矫正这种延迟效应，需要将平滑后的数据点时间戳向前或向后进行调整，以使其更接近原始数据的时间戳。滤波延迟矫正的目的是消除平滑引入的延迟，使平滑后的数据更加准确地反映原始数据的变化趋势，从而更好地进行趋势分析和异常检测。在实际应用中，滤波延迟矫正的具体处理方式可以根据实际需求和数据特点进行调整和优化c.使用中位数而非均值平滑的原因在于为了规避异常样本的影响。判断平滑序列是否递增或是递减a.中位数平滑后的序列数据，若每个点都大于前一个点，则序列为递增序列。b.如果序列存在严格递增或是严格递减的性质，则指标明显存在长期趋势，此时可提前终止。本发明实施例中，针对严格递增或者递减的界定确定过程如下：在中位数平滑后的序列数据中，严格递增和严格递减可以通过以下方式进行界定：1. 严格递增序列：如果序列中的每个数据点都严格大于前一个数据点，即满足 f＞f，其中 f 表示第 i 个数据点的值，f 表示第 i-1 个数据点的值，那么该序列被认定为严格递增序列。2. 严格递减序列：如果序列中的每个数据点都严格小于前一个数据点，即满足 f＜f，其中 f 表示第 i 个数据点的值，f 表示第 i-1 个数据点的值，那么该序列被认定为严格递减序列。在进行判断时，需要对平滑后的序列中的相邻数据点进行逐个比较。如果满足以上条件，就可以判定为严格递增或严格递减序列。这种判断可以帮助识别出指标的明显长期趋势，从而在递增或递减的情况下，可以提前终止特定的计算或分析过程，避免不必要的计算，提高计算效率。遍历平滑序列，利用如下两个规则来判断是否存在漂移的现象a.当前样本点左边序列的最大值小于当前样本点右边序列的最小值，则存在突增漂移。b.当前样本点左边序列的最小值大于当前样本点右边序列的最大值，则存在突降漂移。针对平稳性变化，对于一个时序指标，如果其在任意时刻，它的性质不随观测时间的变化而变化，认为这条时序是具备平稳性的。因此，对于具有长期趋势成分亦或是周期性成分的时间序列而言，它们都是不平稳的。对于一条给定时间范围指标的历史数据而言，认为在同时满足如下条件的情况下，时序是平稳的：最近1天的时序数据通过检验获得的p值小于0.05。最近5天的时序数据通过检验获得的p值小于0.05。通过对部分指标数据样本的抽样验证，它们的概率密度函数符合如下情况的分布：低偏态对称分布、中偏态对称分布、高偏态分布；偏态分布具体的确定过程如下：通过观察数据的频率分布图或直方图来区分，使用以下方式来判断数据的偏态分布：1. 观察频率分布图或直方图：绘制数据的频率分布图或直方图，并观察其形状。如果数据在左侧呈现较长的尾部，可能是负偏态；如果数据在右侧呈现较长的尾部，可能是正偏态；如果两侧尾部相对平衡，可能是无偏态。2. 计算偏度：偏度是描述数据偏斜程度的统计量。偏度为0表示数据分布无偏态，大于0表示正偏态，小于0表示负偏态。可以通过统计软件或编程库计算数据的偏度。3. 绘制箱形图：箱形图可以直观地显示数据的分布情况，包括数据的中位数、上下四分位数和异常值。观察箱形图可以帮助判断数据是否偏斜。针对低偏态对称分布：频率分布图或直方图显示数据的尾部较为平缓，没有明显的长尾；数据的偏度接近于0，即数据的左偏倚和右偏倚相对平衡；箱形图显示数据的上下四分位数相对均衡，没有明显的异常值。中偏态对称分布：频率分布图或直方图显示数据的左右两侧尾部相对平衡，没有明显的长尾；数据的偏度接近于0，即数据的左偏倚和右偏倚相对平衡；箱形图显示数据的上下四分位数相对均衡，没有明显的异常值。高偏态分布：频率分布图或直方图显示数据的右侧尾部较长，左侧尾部相对平缓；数据的偏度为正值，即数据呈现右偏态；箱形图显示数据的上四分位数与下四分位数的距离较大，可能有明显的异常值。针对上述的分布，对不同数据的分布分别采用了不同的检测算法：低偏态对称分布：采用绝对中位差，对称分布下实用性搞、偏态分布下实用性底、正态性要求高、异常容忍度高。中等偏态分布：采用箱形图，对称分布下实用性搞、偏态分布下实用性中、正态性要求中、异常容忍度高。高偏态分布：采用极值理论，对称分布下实用性中、偏态分布下实用性高、正态性要求底、异常容忍度底。进一步的，在确定了所述检测算法以后，基于所述检测算法和所述状态构建所述目标异常检测模型，其中，构建所述目标异常检测模型主要涵盖以下几个分支环节：时序漂移检测、时序平稳性分析、时序周期性分析和偏度计算。时序漂移检测使用LSTM模型来检测时序数据中的漂移情况。将指标数据样本中的指标数据作为输入时序，通过训练LSTM模型来学习指标数据的时序特征。通过比较实际值与LSTM模型的预测值，可以检测出时序漂移的异常情况。如果检测存在漂移的场景，则需要根据检测获得的漂移点t来切割输入时序，使用漂移点后的时序样本作为后续建模流程的输入，记为S={Si}，其中i＞t。具体的处理过程如下：数据采集与预处理：指标数据样本中的指标数据是按照时间顺序记录的，每个数据点都有一个时间戳与之对应，将该数据作为时序数据。时序漂移检测：使用LSTM模型来检测时序数据中的漂移情况。LSTM是一种循环神经网络的变种，它可以学习数据的时序特征。3. 切割输入时序：如果检测到存在时序漂移的场景，则根据检测获得的漂移点t来切割输入时序。这样，可以使用漂移点后的时序样本作为后续建模流程的输入，记为S={Si}，其中i＞t。4. 其他特征分析：根据预处理的数据进行特征分析，发现时序数据的变化规律。对不同的数据分布情况，采用不同的检测算法，如绝对中位差、箱形图或极值理论。时序平稳性分析如果指标数据样本中的指标数据满足平稳性检验，计算每个数据点与其邻近数据点的差值，并计算差值的绝对中位差。通过箱形图或是绝对中位差的方式来进行LSTM建模。时序周期性分析存在周期性的情况下，将周期跨度记为T，将输入时序根据跨度T进行切割，针对各个时间索引j∈{0,1⋯,T−1}所组成的数据桶进行建模流程。不存在周期性的情况下，针对全部输入时序作为数据桶进行建模流程。LSTM模型可以学习时序数据的周期性模式，并对异常周期进行检测。本发明实施例中，对异常周期进行检测的处理过程如下：切割时序数据：首先，在进行时序周期性分析之前，需要确定时序数据中是否存在周期性。如果存在周期性，将周期跨度记为T，然后将输入时序S根据跨度T进行切割。具体来说，将时序数据切割成多个数据桶，每个数据桶包含连续的T个时间索引，分别记为S0, S1,..., ST-1。这样，每个数据桶都代表了一个周期。建模流程：针对各个时间索引j∈{0,1, ⋯,T−1}所组成的数据桶，分别进行建模流程。对于每个数据桶，可以使用LSTM模型来学习时序数据的周期性模式。LSTM是一种循环神经网络，适用于处理序列数据，它可以捕捉到序列中的时间依赖性和周期性。通过训练LSTM模型，可以学习正常周期内的模式和规律。异常周期检测：在训练完成后，将实时采集到的数据分别输入到对应的LSTM模型中。如果输入数据与LSTM模型学习到的周期性模式相符，可以认为该数据属于正常周期。如果输入数据与模型学习到的周期性模式不一致，可能代表发生了异常周期。通过比较实际值和LSTM模型的预测值，可以检测出异常周期的存在。偏度计算时序指标转化为概率分布图，计算分布的偏度，若偏度的绝对值超过阈值，则通过极值理论进行建模输出阈值。若偏度的绝对值小于阈值，则通过箱形图或是绝对中位差的方式进行建模输出阈值。针对阈值是用来判断数据分布是否有偏的界限。在偏度计算中，可以设置一个阈值，用来判断偏度的绝对值是否超过该阈值。如果偏度的绝对值超过阈值，表示数据分布有明显的不对称性，即偏态分布；如果偏度的绝对值小于阈值，表示数据分布相对对称，即对称分布或低偏态对称分布。阈值的确定可以根据具体的应用场景和数据特点来进行调整。通常，阈值的选择是根据经验和实际需求来确定的。在实际应用中，可以通过试验和观察数据的分布情况，调整阈值的大小，以达到较好的异常检测效果。其中，偏度的具体计算过程如下：1. 计算指标数据样本中指标数据的均值和标准差：首先，计算数据的均值μ和标准差σ。2. 计算数据的偏度：然后，使用以下公式计算数据的偏度：偏度 = Σ / 其中，Xi是指标数据点的值，μ是均值，σ是标准差，n是指标数据样本的数量。总结来说，偏度的计算是通过计算数据分布的不对称程度来衡量数据的统计量。通过设置阈值来判断数据分布是否有明显的不对称性，从而进行偏态分布或对称分布的异常检测。阈值的选择可以根据实际需求来进行调整。模型构建的流程图如图2所示，首先进行时序漂移检测，检测之后进行时序样本选择，选择之后分别进行时序平稳分析和时序周期分析，针对时序周期分析，若存在其周期，窗口聚合操作，数据按照周期分桶，针对在各个数据通进行偏度计算，若不存在其周期，直接进行偏度计算，若偏度为高偏度，基于极值理论进行模型产出，若为中等偏度，基于箱型图进行模型产出，若为低偏度，基于绝对中位数偏差进行模型产出。针对时序平稳性分析，通过箱形图或是绝对中位数偏差的方式来进行模型产出、所述目标异常检测模型的训练过程包括:将所述指标数据样本划分为训练集、验证集和测试集，具体的划分过程如下：首先确定所述指标数据样本的划分原则，可以基于如下原则进行指标数据样本的划分，包括：1. 随机性：数据集的拆分应该是随机的，以确保样本的随机性和无偏性。这样可以避免训练集、验证集和测试集中的样本分布有偏差，使得模型对新数据的泛化性能更好。2. 样本平衡：应确保训练集、验证集和测试集中各类样本的数量相对平衡，避免某个类别的样本过多或过少对模型的训练和评估造成影响。3. 时间顺序：对于时序数据，可以考虑按时间顺序拆分数据集，例如将较早的数据用于训练，中间时期的数据用于验证，最新的数据用于测试。这样可以更好地模拟模型在未来数据上的性能。根据数据集拆分的原则，将数据集按照一定的比例拆分为训练集、验证集和测试集。比例如下：1. 训练集：用于模型的训练和参数优化。通常占据总数据集的大部分比例，例如60%~80%。2. 验证集：用于模型的调优和选择最佳模型。验证集通常用于调整模型的超参数，以避免模型在训练集上过拟合。通常占据总数据集的一小部分比例，例如 10%~20%。3. 测试集：用于最终评估模型的性能。测试集是模型在真实场景下的泛化能力的评估标准。模型在测试集上的性能是评估模型优劣的关键指标。通常占据总数据集的较小比例，例如 10%~20%。数据集拆分的具体比例可以根据具体的问题和数据规模进行调整。在实践中，常见的拆分比例是 60%-80% 的训练集、10%-20% 的验证集和 10%-20% 的测试集。使用标注的异常数据样本和正常数据样本，通过监督学习的方式训练神经网络模型。根据验证集的表现进行模型的调优。样本训练数据存在hive数据仓库中；通过任务管理模块以任务队列方式启动模型训练，从hive数据仓库中读取训练数据，按照消费者、生产者、分区、集群、性能不同的数据集,读取配置表取参数，将训练模型保存于搜索服务器ES，支持自动和手动触发训练，通过定时读取模型库的方式，进行模型加载和更新。将构建好的训练集、验证集输入到消费者异常检测模型、生产者异常检测模型、分区异常检测模型、集群异常检测模型和性能异常检测模型中基于所述训练集和所述验证集对所述目标异常检测模型进行训练，获取与所述目标异常检测模型对应的损失函数，若所述损失函数收敛，基于所述测试集对所述目标异常检测模型进行测试。以时序漂移检测训练过程为例，将处理后的时序数据作为输入序列，通过目标异常检测模型来学习数据的时序特征。训练过程中，目标异常检测模型会学习正常时序数据的模式和规律。一旦数据发生漂移，目标异常检测模型可能无法准确预测数据的下一个状态，导致预测误差较大。因此，通过比较实际值与目标异常检测模型的预测值，可以检测出时序漂移的异常情况。整体的训练流程如图3所示，首先Kafka Agent数据采集，数据预处理，处理数据后，存入HIV额数据，同时进行数据集差分，基于得到的训练数据基于规定的训练任务，依据生产者、消费者、分区、集群和性能保存模型，优选的，通过ES保存模型，读取参数或者修改参数后，传递给任务管理，任务管理通过定时训练或者手动训练方式的创建训练任务，将训练任务存储到任务队列，对任务队列的训练任务进行训练。S104、将所述目标指标数据发送给所述目标异常检测模型，得到所述目标指标数据的异常监控结果。本发明实施例中，在训练完成后，对所述目标指标数据进行时序平稳性分析，得到平稳性异常得分，在这一步中，目标异常检测模型用于检测时序数据中的漂移情况。模型会学习正常的时序模式，如果实际数据与模型的预测值出现显著偏离，就可能意味着时序数据发生了漂移。模型将输出一个漂移的异常分数或概率。之后，对所述目标指标数据进行时序平稳性分析，得到平稳性异常得分，在这一步中，通过计算时序数据点与邻近数据点的差值，以及这些差值的绝对中位差，可以确定时序数据是否保持平稳。如果数据不平稳，可能意味着存在异常。这个步骤输出一个平稳性异常分数或概率。然后，对所述目标指标数据进行时序周期性分析，得到周期性异常得分 ，如果存在周期性，将时序数据切割成不同的时间段，每个时间段代表一个周期。模型会学习正常周期内的模式。在实际数据中，如果周期性模式被打破，模型可能会检测到异常。这个步骤输出一个周期性异常分数或概率。最后，通过计算时序数据的分布偏度，可以评估数据分布的偏移情况。偏度值大于阈值可能表示异常。这个步骤输出一个偏度异常分数或概率。综合这些异常得分，模型可以做出决策，判断当前的生产者行为是否异常。不同步骤的异常得分可能会以一定的权重进行组合，将各个模型的输出异常分数乘以对应的权重，并对加权后的异常分数进行求和，得到最终的异常检测结果。这个加权平均的结果可以表示为一个综合的异常得分。如果该分数超过了预定的阈值，系统可能会发出警报，通知运维人员进行进一步的检查和处理，其中，针对权重，权重表示了模型对最终结果的贡献程度。权重可以根据模型在验证集上的性能表现、准确率等指标来确定，也可以基于经验或者具体情况进行设定，本发明实施例不进行具体限定。通过模型加权融合的方式，可以将多个模型的优势结合在一起，从而提高异常检测的准确性和稳定性。这种融合方法可以更好地发现和识别Kafka消息队列中的异常行为，帮助运维人员快速发现和解决问题，确保系统的正常运行。将训练好的目标异常检测模型部署到服务器中，通过agent实时采集 kafka集群的指标数据，通过数据预处理后放入消息队列，基于Flink实时流处理，消费消息队列的消息进行在线检测，实现7*24小时实时监控。本发明公开了一种基于AI算法的Kafka异常监控方法，包括：采集指标数据，将指标数据依据类型进行划分，得到至少一个目标指标数据；选取与目标指标数据匹配的目标异常检测模型，将目标指标数据发送给所述目标异常检测模型，得到目标指标数据的异常监控结果。上述过程中，首先对指标数据依据数据类型进行划分，得到至少一个目标指标数据，针对每个目标指标数据采用对应的目标异常检测模型进行异常检测，一种类型的数据对应一种检测模型，相较于传统检测过程中，所有数据基于一个固定的阈值进行告警，导致监控结果的准确率低，不但进行了数据细分还进行了模型细分，提高了监控结果的准确性，避免了小问题演变成大故障的可能。本发明实施例中还包括：得到所述目标指标数据以后，对所述目标指标数据进行预处理，得到第一目标指标数据，其中，预处理的过程包括：对采集到的目标指标数据进行清洗，去除重复数据、缺失数据和异常数据。以确保数据的质量和准确性。并将数据集的数据格式和数据类型进行单位和标准化处理，例如，将文本型数据转换为数值型数据等。进一步，针对所述第一目标指标数据，对所述第一目标指标数据进行数据增强处理，得到第二目标指标数据。数据增强的处理过程如下：因为所述第一目标指标数据大多是正向数据，而神经网络模型训练需要正向负向数据均衡，因此需要做数据增强处理。导入历史上发生的线上事故时的Kafka集群中的指标数据和错误日志的数据作为反向数据。确保数据集中包含有标注的异常样本和正常样本，以便进行监督学习。本发明实施例中，所述监督算法包括：实时流程和离线流程两部分，具体的示意图如图4，其中实时流程包括：Kafka Agent数据采集、数据预处理、消息队列、实时数据流和监测告警以及加载模型进行实时检测，其中，所述实时检测包括：生产者异常检测、消费者异常检测、分区异常检测、集群异常检测和性能异常检测；所述离线流程包括：历史数据，对所述历史数据进行预处理，数据预处理包括：缺失值填充、数据平滑和数据聚合处理，预处理后进行时序分类，所述时序分类包括：周期性识别、平稳性校验和时序统计分析，之后进行时序建模，其中，所述时序建模包括：绝对中位差、箱型图和极值理论，之后进行模型存储并传递给实时流程中的加载模型过程。本发明实施例中采用了基于AI算法的方法，能够自动学习和识别Kafka消息队列的异常行为。相较于传统的基于规则和模式匹配的方法，基于AI算法的方法更具智能化和适应性，能够处理复杂多变的Kafka环境。实时采集Kafka消息队列的关键指标数据，并利用AI算法构建异常检测模型，实现对Kafka消息队列的智能监控。通过实时监控和检测，能够及时发现消费者、生产者、分区、集群和性能方面的异常行为和异常情况。支持消费者、生产者、分区、集群和性能等多个维度的异常检测。这种多维度的监控能够全面覆盖Kafka消息队列的各个方面，帮助运维人员快速定位问题并采取相应的措施。通过AI算法构建的异常检测模型，能够准确识别异常行为和异常情况，为运维人员提供及时的监控和预警信息。准确的监控和预警能够帮助运维人员快速发现问题并采取相应的应对措施，确保Kafka消息队列的稳定性和可靠性。基于上述的一种基于AI算法的Kafka异常监控方法，本发明实施例中还提供了一种基于AI算法的Kafka异常监控装置，所述装置的结构框图如图5所示，包括：采集模块201、划分模块202、选取模块203和检测模块204。其中，所述采集模块201，用于采集Kafka集群中的指标数据，其中，所述指标数据为生产者数据、消费者数据、分区数据、集群数据和性能数据中的至少一种类型；所述划分模块202，用于将所述指标数据依据类型进行划分，得到至少一个目标指标数据；所述选取模块203，用于选取与所述目标指标数据匹配的目标异常检测模型，其中，所述目标异常检测模型为消费者异常检测模型、生产者异常检测模型、分区异常检测模型、集群异常检测模型和性能异常检测模型中的至少一种，所述目标异常检测模型通过构建和训练得到；所述检测模块204，用于将所述目标指标数据发送给所述目标异常检测模型，得到所述目标指标数据的异常监控结果。本发明公开了一种基于AI算法的Kafka异常监控装置，包括：采集指标数据，将指标数据依据类型进行划分，得到至少一个目标指标数据；选取与目标指标数据匹配的目标异常检测模型，将目标指标数据发送给所述目标异常检测模型，得到目标指标数据的异常监控结果。上述过程中，首先对指标数据依据数据类型进行划分，得到至少一个目标指标数据，针对每个目标指标数据采用对应的目标异常检测模型进行异常检测，一种类型的数据对应一种检测模型，相较于传统检测过程中，所有数据基于一个固定的阈值进行告警，导致监控结果的准确率低，不但进行了数据细分还进行了模型细分，提高了监控结果的准确性，避免了小问题演变成大故障的可能。本发明实施例中，所述监控装置还包括：获取模块、分析模块、确定模块和确定和构建模块。其中，所述获取模块，用于获取指标数据样本，其中，所述指标数据样本包括：指标数据和样本标签，所述样本标签为正常数据或者异常数据；所述分析模块，用于对所述指标数据样本进行特征分析，确定所述指标数据样本的状态，所述状态包括：周期、漂移和平稳；所述确定模块，用于确定所述指标数据样本的概率密度函数，基于所述概率密度函数确定所述指标数据样本的分布规律，其中，所述分布规律为低偏态对称分布、中偏态对称分布和高偏态对称分布中的一种；所述确定和构建模块，用于基于所述分布规律确定检测算法，基于所述检测算法和所述状态构建所述目标异常检测模型。本发明实施例中，所述监控装置还包括：划分模块、训练和获取模块和测试模块。其中，所述划分模块，用于将所述指标数据样本划分为训练集、验证集和测试集；所述训练和获取模块，用于基于所述训练集和所述验证集对所述目标异常检测模型进行训练，获取与所述目标异常检测模型对应的损失函数；所述测试模块，用于若所述损失函数收敛，基于所述测试集对所述目标异常检测模型进行测试。本发明实施例中，所述检测模块204包括：检测单元、第一分析单元、第二分析单元、计算单元和获取和确定单元。其中，所述检测单元，用于对所述目标指标数据进行时序漂移检测，得到漂移异常得分；所述第一分析单元，用于对所述目标指标数据进行时序平稳性分析，得到平稳性异常得分；所述第二分析单元，用于对所述目标指标数据进行时序周期性分析，得到周期性异常得分；所述计算单元，用于对所述目标指标数据进行偏度计算，得到偏度异常得分；所述获取和确定单元，用于获取所述漂移异常得分，所述平稳性异常得分、所述周期性异常得分和所述偏度异常得分的权重，基于所述权重和各个异常得分确定异常监控结果。本发明实施例中，所述监控装置还包括：预处理模块和增强模块。其中，所述预处理模块，用于将所述指标数据进行预处理，得到第一目标指标数据；所述增强模块，用于对所述第一目标指标数据进行数据增强处理，得到第二目标指标数据。本领域内的技术人员应明白，本申请的实施例可提供为方法、系统、或计算机程序产品。因此，本申请可采用完全硬件实施例、完全软件实施例、或结合软件和硬件方面的实施例的形式。而且，本申请可采用在一个或多个其中包含有计算机可用程序代码的计算机可用存储介质上实施的计算机程序产品的形式。本申请是参照根据本申请实施例的方法、设备、和计算机程序产品的流程图和／或方框图来描述的。应理解可由计算机程序指令实现流程图和／或方框图中的每一流程和／或方框、以及流程图和／或方框图中的流程和／或方框的结合。可提供这些计算机程序指令到通用计算机、专用计算机、嵌入式处理机或其他可编程数据处理设备的处理器以产生一个机器，使得通过计算机或其他可编程数据处理设备的处理器执行的指令产生用于实现在流程图一个流程或多个流程和／或方框图一个方框或多个方框中指定的功能的装置。这些计算机程序指令也可存储在能引导计算机或其他可编程数据处理设备以特定方式工作的计算机可读存储器中，使得存储在该计算机可读存储器中的指令产生包括指令装置的制造品，该指令装置实现在流程图一个流程或多个流程和／或方框图一个方框或多个方框中指定的功能。这些计算机程序指令也可装载到计算机或其他可编程数据处理设备上，使得在计算机或其他可编程设备上执行一系列操作步骤以产生计算机实现的处理，从而在计算机或其他可编程设备上执行的指令提供用于实现在流程图一个流程或多个流程和／或方框图一个方框或多个方框中指定的功能的步骤。在一个典型的配置中，计算设备包括一个或多个处理器 、输入/输出接口、网络接口和内存。存储器可能包括计算机可读介质中的非永久性存储器，随机存取存储器和/或非易失性内存等形式，如只读存储器或闪存。存储器是计算机可读介质的示例。计算机可读介质包括永久性和非永久性、可移动和非可移动媒体可以由任何方法或技术来实现信息存储。信息可以是计算机可读指令、数据结构、程序的模块或其他数据。计算机的存储介质的例子包括，但不限于相变内存 、静态随机存取存储器 、动态随机存取存储器 、其他类型的随机存取存储器 、只读存储器 、电可擦除可编程只读存储器 、快闪记忆体或其他内存技术、只读光盘只读存储器、数字多功能光盘  或其他光学存储、磁盒式磁带，磁带磁磁盘存储或其他磁性存储设备或任何其他非传输介质，可用于存储可以被计算设备访问的信息。按照本文中的界定，计算机可读介质不包括暂存电脑可读媒体，如调制的数据信号和载波。还需要说明的是，术语“包括”、“包含”或者其任何其他变体意在涵盖非排他性的包含，从而使得包括一系列要素的过程、方法、商品或者设备不仅包括那些要素，而且还包括没有明确列出的其他要素，或者是还包括为这种过程、方法、商品或者设备所固有的要素。在没有更多限制的情况下，由语句“包括一个……”限定的要素，并不排除在包括要素的过程、方法、商品或者设备中还存在另外的相同要素。本领域技术人员应明白，本申请的实施例可提供为方法、系统或计算机程序产品。因此，本申请可采用完全硬件实施例、完全软件实施例或结合软件和硬件方面的实施例的形式。而且，本申请可采用在一个或多个其中包含有计算机可用程序代码的计算机可用存储介质上实施的计算机程序产品的形式。以上仅为本申请的实施例而已，并不用于限制本申请。对于本领域技术人员来说，本申请可以有各种更改和变化。凡在本申请的精神和原理之内所作的任何修改、等同替换、改进等，均应包含在本申请的权利要求范围之内。
