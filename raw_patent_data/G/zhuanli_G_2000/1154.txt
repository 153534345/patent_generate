标题title
一种基于稠密匹配算法的构件表面位移场检测方法
摘要abst
本发明公开了一种基于稠密匹配算法的构件表面位移场检测方法，属于机器视觉技术领域，包括以下步骤：S1：采集图像或视频数据；S2：对数据进行预处理；S3：使用改进的LoFTR模型得到稠密匹配特征点对坐标；S4：计算每对特征点的位移，提供插值反演出位移场。本发明可以实现在实际工程中便捷地检测构件表面位移场，使用方便，不需要繁琐的准备工作；采用相机作为检测仪器，非接触式测量，且成本较低。
权利要求书clms
1.一种基于稠密匹配算法的构件表面位移场检测方法，其特征在于：包括以下步骤：S1：采集图像或视频数据；S2：对数据进行预处理；S3：使用改进的LoFTR模型得到稠密匹配特征点对坐标；S4：计算每对特征点的位移，提供插值反演出位移场。2.根据权利要求1所述的基于稠密匹配算法的构件表面位移场检测方法，其特征在于：步骤S1中，使用普通消费级相机或工业相机对构件表面进行视频录制或多张相片拍摄。3.根据权利要求1所述的基于稠密匹配算法的构件表面位移场检测方法，其特征在于：步骤S2所述对数据进行预处理，具体包括：若输入数据为视频，对视频以固定频率进行抽帧得到固定时间间隔的图像；对视频抽帧得到的图像或输入的多张图像进行高斯去噪。4.根据权利要求1所述的基于稠密匹配算法的构件表面位移场检测方法，其特征在于：当图像视野范围不满足条件时，构件表面进行扫描式拍摄，获取多幅图像，通过图像拼接，扩大图像的视野范围。5.根据权利要求1所述的基于稠密匹配算法的构件表面位移场检测方法，其特征在于：所述改进的LoFTR模型是一种适用于进行稀疏纹理区域内特征点稠密匹配的深度神经网络模型，特征点检测与匹配任务是检测并匹配两帧图像中对应于同一真实点的像素点，稠密匹配任务则是在此基础上尽可能地提高匹配点的数量与密度；所述改进的LoFTR模型包括用于提取特征的卷积模块、用于寻找大致匹配点对的粗匹配Transformer模块和用于提升匹配点精度的细匹配Transformer模块；所述卷积模块先将原图依次降采样为初始分辨率的1/2、1/4、1/8，再上采样为1/4、1/2、1，在上采样过程中，与相应分辨率的降采样所得特征图进行特征融合；所述粗匹配Transformer模块将卷积模块得到的特征图进行编码与匹配，得到整像素匹配点；所述细匹配Transformer模块用于以粗匹配得到的每对像素点为中心取一小窗口，对所述小窗口进行优化，得到亚像素的匹配点。6.根据权利要求5所述的基于稠密匹配算法的构件表面位移场检测方法，其特征在于：所述改进的LoFTR模型在编码器中集成有更高分辨率的上采样层。7.根据权利要求6所述的基于稠密匹配算法的构件表面位移场检测方法，其特征在于：在匹配模块中引入空间一致性约束，剔除错误的匹配特征点对。8.根据权利要求1所述的基于稠密匹配算法的构件表面位移场检测方法，其特征在于：将输入分块为多个特定分辨率的子图，对于每个子图分别输入改进的LoFTR模型中得到匹配结果，再将所有子图的匹配结果转换到原图的统一坐标系中。9.根据权利要求8所述的基于稠密匹配算法的构件表面位移场检测方法，其特征在于：在对输入图像分块时，通过设置重叠部分以考虑构件可能存在的变形。10.根据权利要求1所述的基于稠密匹配算法的构件表面位移场检测方法，其特征在于：所述改进的LoFTR模型的训练步骤如下：首先在通用图像数据集上训练得到预训练模型，然后在钢板图像数据集上微调得到最终模型。
说明书desc
技术领域本发明属于机器视觉领域技术领域，具体涉及一种基于稠密匹配算法的构件表面位移场检测方法。背景技术在结构健康检测或是实际工程和实验中经常需要测量构件表面的形变，通过形变可以反映构件的工作状态。形变通常通过位移、应变等数据进行表征，目前常用的位移测量方法包括位移计、应变片重建位移场、数字图像相关技术、激光扫描等。位移计、应变片属于接触式测量，需要将传感器布置在待测构件的特定测点处，同时只能得到测点处的数据，在空间上离散，需要通过反演算法再得到整体的位移场。数字图像相关法属于非接触式测量，通过相机拍摄构件表面的相片即可得到目标构件的连续位移场。其仪器简单、精度高，但在测量前需要对待检测的构件表面喷涂散斑，因此并不适用于实际的检测，并且散斑喷涂的质量会对位移场检测结果产生较大影响。激光扫描也属于非接触式测量，具有更高的精度以及便捷的操作，并且能得到连续位移场，但其测量仪器的成本更高，不适用于实际工程测量。发明内容有鉴于此，本发明的目的在于提供一种基于稠密匹配算法的构件表面位移场检测方法。为达到上述目的，本发明提供如下技术方案：一种基于稠密匹配算法的构件表面位移场检测方法，包括以下步骤：S1：采集图像或视频数据；S2：对数据进行预处理；S3：使用改进的LoFTR模型得到稠密匹配特征点对坐标；S4：计算每对特征点的位移，提供插值反演出位移场。进一步，步骤S1中，使用普通消费级相机或工业相机对构件表面进行视频录制或固定时间间隔的相片拍摄。进一步，步骤S2所述对数据进行预处理，具体包括：若输入数据为视频，对视频以固定频率进行抽帧得到固定时间间隔的图像；对视频抽帧得到的图像或输入的多张图像进行高斯去噪。进一步，当图像视野范围不满足条件时，构件表面进行扫描式拍摄，获取多幅图像，通过图像拼接，扩大图像的视野范围。进一步，所述改进的LoFTR模型是一种用于进行稀疏纹理区域内的特征点稠密匹配的深度神经网络模型，特征点检测与匹配任务是检测并匹配两帧图像中对应于同一真实点的像素点，稠密匹配任务则是在此基础上尽可能地提高匹配点的数量与密度；所述改进的LoFTR模型包括用于提取特征的卷积模块、用于寻找大致匹配点对的粗匹配Transformer模块和用于提升匹配点精度的细匹配Transformer模块；所述卷积模块先将原图依次降采样为初始分辨率的1/2、1/4、1/8，再上采样为1/4、1/2、1，在上采样过程中，与相应分辨率的降采样所得特征图进行特征融合；所述粗匹配Transformer模块将卷积模块得到的特征图进行编码与匹配，得到整像素匹配点；所述细匹配Transformer模块用于以粗匹配得到的每对像素点为中心取一小窗口，对所述小窗口进行优化，得到亚像素的匹配点。进一步，所述改进的LoFTR模型在编码器中集成有更高分辨率的上采样层。进一步，在匹配模块中引入空间一致性约束，剔除错误的匹配特征点对。进一步，将输入分块为多个特定分辨率的子图，对于每个子图分别输入改进的LoFTR模型中得到匹配结果，再将所有子图的匹配结果转换到原图的统一坐标系中。进一步，在对输入图像分块时，通过设置重叠部分以考虑构件可能存在的变形。进一步，所述改进的LoFTR模型的训练步骤如下：首先在通用图像数据集上训练得到预训练模型，然后在钢板图像数据集上微调得到最终模型。本发明的有益效果在于：本发明可以实现在实际工程中便捷地检测构件表面位移场，使用方便，不需要繁琐的准备工作；采用相机作为检测仪器，非接触式测量，且成本较低。本发明的其他优点、目标和特征将在随后的说明书中进行阐述，并且在某种程度上对本领域技术人员而言是显而易见的，或者本领域技术人员可以从本发明的实践中得到教导。本发明的目标和其他优点可以通过下面的说明书来实现和获得。附图说明为了使本发明的目的、技术方案和有益效果更加清楚，本发明提供如下附图进行说明：图1为本发明所述基于稠密匹配算法的构件表面位移场检测方法流程图；图2为本发明所述改进的特征提取编码器结构图。具体实施方式本发明提出了一种能够便捷检测实际工程中的结构或构件表面位移场的算法。采用相机作为检测仪器，采集构件在受到外力作用时的连续图像或视频，将两帧图像进行特征点匹配，即可得到构件上该点在此时刻的位移，当特征点足够稠密时，即可得到构件表面的位移场。由于构件表面存在大量纹理稀疏区域，使得传统特征点检测与匹配的结果不理想，本发明引入了机器视觉中稀疏纹理区域的稠密匹配算法，该算法为卷积模块与Transformer模块结合的深度神经网络模型，能够对构件表面的相邻两帧进行稠密的特征点匹配，从而输出构件表面位移场。本发明的结构组成和工作原理如图1所示，包括以下步骤：1、数据采集使用普通消费级相机或工业相机对构件表面进行视频录制或固定时间间隔的相片拍摄。2、数据预处理若输入数据为视频，对于视频以固定频率进行抽帧得到固定时间间隔的图像。对于视频抽帧得到的图像或输入的多张图像进行高斯去噪。3、图像拼接当图像视野范围较小时，可选择对于构件表面进行扫描式拍摄，获取多幅图像，通过图像拼接得到一幅大视野图像。4、改进的LoFTR模型是一种用于稀疏纹理区域内特征点稠密匹配的深度神经网络模型，特征点检测与匹配任务是检测并匹配两帧图像中对应于同一真实点的像素点，由于稀疏纹理区域缺乏明显特征点，LoFTR模型弥补了传统模型在稀疏纹理区域难以进行特征点匹配的不足。为了使模型在构件表面的图像有较好的表现，得到更为稠密的匹配特征点对从而输出位移场，本发明对LoFTR模型进行了如下的改进：修改特征提取编码器结构，如附图2所示，在编码器中集成更高分辨率的上采样层，大量增加可以参与特征匹配的像素数，以此提高匹配特征点对数。模型主要包含三部分：用于提取特征的卷积模块、用于寻找大致匹配点对的粗匹配Transformer模块和用于提升匹配点精度的细匹配Transformer模块。卷积模块为先将原图依次降采样为初始分辨率的1/2、1/4、1/8，再上采样为1/4、1/2、1，在上采样过程中，与相应分辨率的降采样所得特征图进行特征融合。粗匹配Transformer模块将卷积模块得到的特征图进行编码与匹配，得到整像素匹配点。以粗匹配得到的每对像素点为中心取一小窗口，对于该小窗口通过细匹配Transformer模块进行编码以及优化，得到亚像素的匹配点。Transformer模块均采用8头注意力机制，由4次重复的自注意力、交叉注意力形成。在匹配模块中引入空间一致性约束，剔除错误的匹配特征点对，提高匹配准确度与输出位移场的精度。由于局部区域内像素点的位移变化连续，每个像素点的位移变化受到周围像素点位移变化的约束，而错误的特征匹配点则不满足此约束，通过该约束可以剔除错误匹配点对。由于模型接受固定分辨率的图像输入，而输出位移场的分辨率与输入图像的分辨率保持一致，若直接将高分辨率的输入图像降采样为该低分辨率，则损失图像信息，大大降低了输出位移场的分辨率。因此将输入分块为多个特定分辨率的子图，对于每个子图分别输入模型中得到匹配结果，再将所有子图的匹配结果转换到原图的统一坐标系中。考虑到子图上的像素可能由于构件变形，在下一帧时部分像素可能运动到该子图范围外，因此在对输入图像分块时，通过设置重叠部分以考虑构件可能存在的变形。对于改进的LoFTR模型，训练由两步进行。首先在通用图像数据集Scannet上训练得到预训练模型，然后在钢板图像数据集上微调得到最终模型。5、输出位移场在LoFTR模型中输出稠密的匹配特征点对坐标，计算每对特征点的位移，通过插值反演出位移场。最后说明的是，以上优选实施例仅用以说明本发明的技术方案而非限制，尽管通过上述优选实施例已经对本发明进行了详细的描述，但本领域技术人员应当理解，可以在形式上和细节上对其作出各种各样的改变，而不偏离本发明权利要求书所限定的范围。
