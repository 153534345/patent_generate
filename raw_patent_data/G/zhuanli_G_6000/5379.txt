标题title
一种卷积计算方法、卷积计算装置及其应用
摘要abst
本发明提供一种卷积计算方法、卷积计算装置及其应用，卷积计算方法包括：启动工作阶段、平稳工作阶段和结束工作阶段；在启动工作阶段，输入特征图缓存单元按行缓存每个输入特征图中的数据，当每个输入特征图中的缓存数据行数均达到kernel_size行时，行卷积运算单元开始进行卷积运算；在平稳工作阶段，当输入特征图缓存单元缓存完每个输入特征图中的新一行数据后，行卷积运算单元进行卷积运算，并输出每个输出特征图新一行的卷积运算结果；在结束工作阶段，行卷积运算单元自驱动完成剩余行的计算，并输出剩余行的卷积计算结果。采用本发明中的卷积计算方法，将提高图像处理的实时性，节省存储资源，且不会出现块边界效应。
权利要求书clms
1.一种卷积计算方法，其特征在于，所述卷积计算方法包括启动工作阶段、平稳工作阶段和结束工作阶段；其中，在所述启动工作阶段，输入特征图缓存单元按行缓存每个输入特征图中的数据，并判断每个输入特征图中的缓存数据行数是否均达到kernel_size行，其中，kernel_size表示卷积核的行数；当每个输入特征图中的缓存数据行数均达到kernel_size行时，行卷积运算单元开始进行卷积运算，当每个输出特征图均输出第一行卷积计算结果时，所述启动工作阶段结束；在所述平稳工作阶段，当所述输入特征图缓存单元缓存完每个输入特征图中的新一行数据后，行卷积运算单元获取卷积运算所需的输入特征图数据和对应的卷积核数据进行卷积运算，并稳定地输出每个输出特征图新一行的卷积运算结果；当所述输入特征图缓存单元缓存完每个输入特征图的最后一行数据，并完成该行数据的卷积计算时，所述平稳工作阶段结束；在所述结束工作阶段，所述行卷积运算单元自驱动完成剩余行的计算，并输出剩余行的卷积计算结果。2.根据权利要求1中所述的卷积计算方法，其特征在于，在判断每个输入特征图中的缓存数据行数是否均达到kernel_size行时，所述缓存数据行数包括每个输入特征图数据上方填充的PAD数据的行数。3.根据权利要求2中所述的卷积计算方法，其特征在于，所述PAD数据的行数为/2。4.根据权利要求1中所述的卷积计算方法，其特征在于，如果输入特征图为原始图像数据，则所述输入特征图缓存单元为每个输入特征图设置容量为*PIC_W的缓存空间，其中，PIC_W为每个输入特征图的每行的数据量；如果输入特征图为前一层卷积运算的输出特征图，则所述输入特征图缓存单元为每个输入特征图设置容量为kernel_size*PIC_W的缓存空间。5.一种用于权利要求1中卷积计算方法的卷积计算装置，其特征在于，所述卷积计算装置包括输入特征图缓存单元，卷积核系数缓存单元、卷积核系数读取单元、行卷积运算单元和行卷积结果写出单元，其中，所述输入特征图缓存单元用于缓存各个输入特征图中的行数据；所述卷积核系数缓存单元用于缓存卷积核系数；所述卷积核系数读取单元用于从所述卷积核系数缓存单元中读取参与卷积运算的卷积核系数；所述行卷积运算单元用于从所述输入特征图缓存单元和所述卷积核系数读取单元中读取参与卷积计算的数据，进行卷积计算，并将卷积结果通过所述行卷积结果写出单元输出到外部存储装置。6.一种DnCNN网络计算方法，其特征在于，所述DnCNN网络计算方法包括启动工作阶段、平稳工作阶段和结束工作阶段；其中，在所述启动工作阶段，原始图像数据输入缓存单元按行缓存输入图像中的每个输入特征图中的数据，并判断每个输入特征图中的缓存数据行数是否均达到kernel_size行，其中，kernel_size表示卷积核的行数；当每个输入特征图中的缓存数据行数均达到kernel_size行时，行卷积运算单元开始进行第一层卷积运算；其他神经网络层需要等到前一层的各个输出特征图中的缓存数据行数达到kernel_size行，才启动当前神经网络层的计算；当输出第一行残差图像的数据时，所述启动工作阶段结束；在所述平稳工作阶段，当所述原始图像数据输入缓存单元缓存每个输入特征图的新一行数据后，所述行卷积运算单元获取卷积运算所需的输入特征图数据和对应的卷积核数据对各神经网络层进行连续运算，并稳定地输出新一行的残差图像结果数据；当所述原始图像数据输入缓存单元缓存完每个输入特征图的最后一行数据，并完成各神经网络层的计算，输出残差图像与该行对应的输出数据时，平稳工作阶段结束，进入结束工作阶段；在所述结束工作阶段，所述行卷积运算单元自驱动完成剩余行的计算，并输出残差图像剩余行的输出数据。7.根据权利要求6中所述的DnCNN网络计算方法，其特征在于，所述行卷积运算单元除了完成卷积运算外，还进行BN以及ReLU的计算。8.根据权利要求6中所述的DnCNN网络计算方法，其特征在于，在判断每个输入特征图中的缓存数据行数是否均达到kernel_size行时，所述缓存数据行数包括每个输入特征图数据上方填充的PAD数据的行数；其他神经网络层等到前一层的各个输出特征图中的缓存数据行数达到kernel_size行，所述缓存数据行数包括每个输出特征图数据上方填充的PAD数据的行数。9.根据权利要求8中所述的DnCNN网络计算方法，其特征在于，所述PAD数据的行数为/2。10.根据权利要求6中所述的DnCNN网络计算方法，其特征在于，所述原始图像数据输入缓存单元为每个输入特征图设置容量为*PIC_W的缓存空间，其中，PIC_W为每个输入特征图的每行的数据量。11.根据权利要求6中所述的DnCNN网络计算方法，其特征在于，输出第一行残差图像的数据与原始图像输入数据的行延迟数为start_src_ln_num = Layer_num + kernel_size-1-pad_num；其中，start_src_ln_num表示输出第一行残差图像的数据与原始图像输入数据的行延迟数；Layer_num表示整个DnCNN网络的层数，包含所有Conv+ReLU层、Conv+BN+ReLU层和Conv层；kernel_size表示卷积核的行数；pad_num表示对输入特征图上方填充的PAD行数。12.一种用于权利要求6中DnCNN网络计算方法的DnCNN网络计算装置，其特征在于，所述DnCNN网络计算装置包括原始图像数据输入缓存单元、卷积核系数缓存单元、卷积核系数读取单元、行卷积中间结果读取单元、行卷积运算单元、行卷积中间结果缓存单元和行卷积结果写出单元；其中，所述原始图像数据输入缓存单元用于缓存原始图像中各个输入特征图的行数据；所述卷积核系数缓存单元用于缓存卷积核系数；所述卷积核系数读取单元用于从所述卷积核系数缓存单元中读取参与卷积运算的卷积核系数；所述行卷积中间结果缓存单元用于缓存DnCNN网络计算的中间结果;所述行卷积中间结果读取单元用于从所述行卷积中间结果缓存单元中读取行卷积中间结果；所述行卷积运算单元用于从所述原始图像数据输入缓存单元/所述行卷积中间结果读取单元和所述卷积核系数读取单元中读取参与卷积运算的数据，进行卷积运算，并将得到的结果输出到所述行卷积结果写出单元；以及所述行卷积写出单元将中间结果输出至所述行卷积中间结果缓存单元，并将最终的残差图像数据至外部存储器。13.根据权利要求12中所述的DnCNN网络计算装置，其特征在于，所述行卷积中间结果缓存单元为每个中间输出特征图设置容量为kernel_size*PIC_W行的缓存空间。14.根据权利要求12中所述的DnCNN网络计算装置，其特征在于，所述行卷积运算单元除了完成卷积运算外，还进行BN以及ReLU的计算。15.根据权利要求12中所述的DnCNN网络计算装置，其特征在于，所述DnCNN网络计算装置放置的位置为以下位置其中之一：图像信号处理流程的开始处、图像信号处理流程的中间位置或者图像信号处理流程的结尾处。
说明书desc
技术领域本发明涉及卷积神经网络和芯片设计技术领域，尤其涉及一种卷积计算方法、卷积计算装置及其应用。背景技术图像降噪一直是图像信号处理ISP领域一项非常重要的功能，图像降噪可以让图像在视觉上显得更为清晰、美观，提升图片主客观质量，进而便于更好地进行图像分析和理解，因此，图像降噪技术在生物、医学、军事、自动驾驶等领域都有广泛的应用。目前主流的图像降噪方法主要分为两类，一类是基于特定形式的先验的传统图像降噪方法，这些传统的图像降噪方法不仅具有复杂的模型，而且包含了很多需要手动调节的参数，使得图像降噪的过程计算复杂。尤其是在面对恶劣天气、复杂光线、剧烈运动等复杂场景时，基于传统ISP的图像降噪处理技术已经接近瓶颈，效果调优越来越难，算法性价比越来越低。另一类图像降噪方法是基于深度学习的图像降噪方法，基于CNN网络的AI降噪算法能很好地解决传统图像降噪方法遇到的问题。在面对各种复杂的应用场景时，AI降噪算法表现出了超强的适应性和稳定性，在高效去除图像噪点的同时有效保留了图像中的真实细节；同时，AI降噪算法几乎需要进行参数调节，这为其进行大规模产业应用奠定了基础；此外，AI降噪算法是可以迭代更新的，相比于传统的图像降噪处理技术，一旦在芯片中固化后将无法进行更新，AI降噪算法具有更好的灵活性。DnCNN是当前较为著名的基于CNN网络的AI降噪算法，DnCNN，用于去噪的卷积神经网络，其来源于论文《Beyond aGaussian Denoiser: Residual Learning of Deep CNN for Image Denoising》，在该论文中首次使用了端到端的残差学习神经网络模型来进行降噪，并且获得了比先前降噪算法更好的降噪效果。同时，DnCNN还可以应用于单图超分和JPEG去块等任务。如图1中所示，图1为一种常见的DnCNN的网络结构图。该网络结构的输入为带噪点的原始图像，输出为残差图像，在原始图像基础上减去残差图像即为降噪后的图像。整个网络结构可以分成三个部分：与原始图像连接的网络层为“Conv+ReLU”，用于生成N个输出特征图；与残差图像相连接的网络层为“Conv”，用于重建输出；其余M个中间网络层都采用“Conv+BN+ReLU”的形式，其中批量归一化加在卷积和ReLU之间，这些中间网络层的输入和输出特征图的个数均为N。目前，基于CNN网络的AI降噪过程一般都放在ISP图像处理之后，即将整帧图像经传统的ISP处理完之后，再用AI降噪的方法对其进行降噪。在上述处理方式中，会导致至少一帧的帧延迟，这对于像自动驾驶等对延迟容忍度比较低的应用场景就不太适用。同时，从DnCNN的网络结构可知，基于CNN网络的AI降噪过程采用原始图像分辨率进-原始图像分辨率出的模式，对于大分辨率的应用场景将造成巨大的内存资源损耗。虽然已经在一些公开的专利中使用图像分块的技术来降低对内存的需求，但是在进行CNN网络运算时，对每个分块单独进行CNN网络运算，最后再将最后计算的结果进行合并，但是这种对每个分块单独进行CNN网络运算的结果与整图CNN网络运算的结果之间会存在一定的差异，特别是像AI降噪这种应用，可能会出现明显的块边界效应，进而影响整体降噪的效果。由于上述问题的存在，无疑限制了基于CNN网络的AI降噪算法在产业界的大规模应用。因此，亟需一种基于CNN网络的AI降噪算法，其不仅可以与传统的ISP处理相结合，不增加帧级延迟，而且能够有效降低对内存的要求，节省存储资源，且不会造成AI降噪效果的弱化。发明内容为了解决上述技术问题，本发明提供一种卷积计算方法，其特征在于：所述卷积计算方法包括启动工作阶段、平稳工作阶段和结束工作阶段；其中，在所述启动工作阶段，输入特征图缓存单元按行缓存每个输入特征图中的数据，并判断每个输入特征图中的缓存数据行数是否均达到kernel_size行，其中，kernel_size表示卷积核的行数；当每个输入特征图中的缓存数据行数均达到kernel_size行时，行卷积运算单元开始进行卷积运算，当每个输出特征图均输出第一行卷积计算结果时，所述启动工作阶段结束；在所述平稳工作阶段，当所述输入特征图缓存单元缓存完每个输入特征图中的新一行数据后，行卷积运算单元获取卷积运算所需的输入特征图数据和对应的卷积核数据进行卷积运算，并稳定地输出每个输出特征图新一行的卷积运算结果；当所述输入特征图缓存单元缓存完每个输入特征图的最后一行数据，并完成该行数据的卷积计算时，所述平稳工作阶段结束；在所述结束工作阶段，所述行卷积运算单元自驱动完成剩余行的计算，并输出剩余行的卷积计算结果。采用本发明中提供的卷积计算方法，具有如下优势：在每个输入特征图中的缓存数据量达到kernel_size时，即可以开始进行卷积计算，而不需要缓存整个输入特征图的数据，因此，在计算过程中，增强了图像处理的实时性；输入特征图缓存单元只需要为每个输入特征图设置容量为*PIC_W的缓存，而不需要缓存整个输入特征图的数据；在进行临时数据缓存时，只需设置1行数据容量用于临时数据缓存，按行输出卷积计算结果；因此，采用该卷积计算方法将大大地降低了计算所需要的内存，节省存储资源；该方法在计算过程中，其参与运算的数据与传统的整帧图片卷积运算的数据完全相同，因此，不会出现明显的块边界效应。优选地，在判断每个输入特征图中的缓存数据行数是否均达到kernel_size行时，所述缓存数据行数包括每个输入特征图数据上方填充的PAD数据的行数。优选地，所述PAD数据的行数为/2。优选地，如果输入特征图为原始图像数据，则所述输入特征图缓存单元为每个输入特征图设置容量为*PIC_W的缓存空间，其中，PIC_W为每个输入特征图的每行的数据量；如果输入特征图为前一层卷积运算的输出特征图，则所述输入特征图缓存单元为每个输入特征图设置容量为kernel_size*PIC_W的缓存空间。当每个输入特征图的缓存达到kernel_size行数据时，行卷积运算单元开始进行按行的卷积运算，同时剩余的一行缓存空间，可以继续接受外部输入特征图的数据输入。本发明还提供采用本发明中卷积计算方法的卷积计算装置，其特征在于，所述卷积计算装置包括输入特征图缓存单元、卷积核系数缓存单元、卷积核系数读取单元、行卷积运算单元和行卷积结果写出单元，其中，所述输入特征图缓存单元用于缓存各个输入特征图中的行数据；所述卷积核系数缓存单元用于缓存卷积核系数；所述卷积核系数读取单元用于从所述卷积核系数缓存单元中读取参与卷积运算的卷积核系数；所述行卷积运算单元用于从所述输入特征图缓存单元和所述卷积核系数读取单元中读取参与卷积计算的数据，进行卷积计算，并将卷积结果通过所述行卷积结果写出单元输出到外部存储装置。本发明中的卷积计算方法可以应用于DnCNN网络，本发明提供一种DnCNN网络计算方法，其特征在于，所述DnCNN网络计算方法包括启动工作阶段、平稳工作阶段和结束工作阶段；其中，在所述启动工作阶段，原始图像数据输入缓存单元按行缓存输入图像中的每个输入特征图中的数据，并判断每个输入特征图中的缓存数据行数是否均达到kernel_size行，其中，kernel_size表示卷积核的行数；当每个输入特征图中的缓存数据行数均达到kernel_size行时，行卷积运算单元开始进行第一层卷积运算；其他神经网络层需要等到前一层的各个输出特征图中的缓存数据行数达到kernel_size行，才启动当前神经网络层的计算；当输出第一行残差图像的数据时，所述启动工作阶段结束；在所述平稳工作阶段，当所述原始图像数据输入缓存单元缓存每个输入特征图的新一行数据后，所述行卷积运算单元获取卷积运算所需的输入特征图数据和对应的卷积核数据对各神经网络层进行连续运算，并稳定地输出新一行的残差图像结果数据；当所述原始图像数据输入缓存单元缓存完每个输入特征图的最后一行数据，并完成各神经网络层的计算，输出残差图像与该行对应的输出数据时，平稳工作阶段结束，进入结束工作阶段；在所述结束工作阶段，所述行卷积运算单元自驱动完成剩余行的计算，并输出残差图像剩余行的输出数据。采用本发明中提供的DnCNN网络计算方法，具有如下优势：在每个输入特征图中的缓存数据量达到kernel_size时，即可以开始进行卷积计算，而不需要缓存整个输入特征图的数据，因此，在计算过程中，增强了图像处理的实时性；原始图像数据输入缓存单元只需要为每个输入特征图设置容量为*PIC_W的缓存，而不需要缓存整个输入特征图的数据；在进行中间结果缓存时，每个输出特征图也仅需要kernel_size*PIC_W数据容量用于中间结果缓存并作为下一层神经网络的输入，因此，采用该卷积计算方法将大大地降低了计算所需要的内存，节省存储资源；该方法在计算过程中，其参与运算的数据与传统的整帧图片卷积运算的数据完全相同，因此，不会出现明显的块边界效应；传统的图像信号处理相关算法功能模块都是按行进行处理的，本发明中的按行处理的CNN网络计算方法也是按行进行输入和输出计算结果，输出结果与原始图像的延迟行数仅为Layer_num + kernel_size-1-pad_num，因此，区别于传统AI算法的按帧处理，本发明中的方法可以与传统的图像信号处理算法进行兼容并行计算，延迟较小，且不存在帧级的延迟。优选地，所述行卷积运算单元除了完成卷积运算外，还进行BN以及ReLU的计算。优选地，在判断每个输入特征图中的缓存数据行数是否均达到kernel_size行时，所述缓存数据行数包括每个输入特征图数据上方填充的PAD数据的行数；其他神经网络层等到前一层的各个输出特征图中的缓存数据行数达到kernel_size行，所述缓存数据行数包括每个输出特征图数据上方填充的PAD数据的行数。优选地，所述PAD数据的行数为/2。优选地，所述原始图像数据输入缓存单元为每个输入特征图设置容量为*PIC_W的缓存空间，其中，PIC_W为每个输入特征图的每行的数据量。优选地，输出第一行残差图像的数据与原始图像输入数据的行延迟数为start_src_ln_num = Layer_num + kernel_size-1-pad_num；其中，start_src_ln_num表示输出第一行残差图像的数据与原始图像输入数据的行延迟数；Layer_num表示整个DnCNN网络的层数，包含所有Conv+ReLU层、Conv+BN+ReLU层和Conv层；kernel_size表示卷积核的行数；pad_num表示对输入特征图上方填充的PAD行数。因此，采用本发明中的DnCNN计算方法，只产生较小的延迟。对应地，本发明还提供一种采用上述DnCNN网络计算方法的DnCNN网络计算装置，其特征在于，所述DnCNN网络计算装置包括原始图像数据输入缓存单元、卷积核系数缓存单元、卷积核系数读取单元、行卷积中间结果读取单元、行卷积运算单元、行卷积中间结果缓存单元和行卷积结果写出单元；其中，所述原始图像数据输入缓存单元用于缓存原始图像中各个输入特征图的行数据；所述卷积核系数缓存单元用于缓存卷积核系数；所述卷积核系数读取单元用于从所述卷积核系数缓存单元中读取参与卷积运算的卷积核系数；所述行卷积中间结果缓存单元用于缓存DnCNN网络计算的中间结果;所述行卷积中间结果读取单元用于从所述行卷积中间结果缓存单元中读取行卷积中间结果；所述行卷积运算单元用于从所述原始图像数据输入缓存单元/所述行卷积中间结果读取单元和所述卷积核系数读取单元中读取参与卷积运算的数据，进行卷积运算，并将得到的结果输出到所述行卷积结果写出单元；以及所述行卷积写出单元将中间结果输出至所述行卷积中间结果缓存单元，并将最终的残差图像数据至外部存储器。本发明中提供的按行处理的DnCNN网络计算装置，具有如下优势：原始图像数据输入缓存单元只需要为每个输入特征图设置容量为*PIC_W的缓存，而不需要缓存整个输入特征图的数据；在进行中间结果缓存时，行卷积中间结果缓存单元也仅需要给每个输出特征图配置kernel_size*PIC_W数据容量用于中间结果缓存并作为下一层神经网络的输入，因此，采用该装置将大大地减小了存储空间，实现了小型化、集成化，更有利于在产业上的应用；该装置在计算过程中，其参与运算的数据与传统的整帧图片卷积运算的数据完全相同，因此，不会出现明显的块边界效应。传统的图像信号处理相关算法功能模块都是按行进行处理的，本发明中的按行处理的CNN网络计算装置也是按行进行输入和输出计算结果，输出结果与原始输入图像的延迟行数仅为Layer_num + kernel_size-1-pad_num，因此，本发明中的装置可以与传统的图像信号处理装置进行兼容并行计算，延迟较小，且不存在帧级的延迟。优选地，所述行卷积中间结果缓存单元为每个中间输出特征图设置容量为kernel_size*PIC_W行的缓存空间。优选地，所述行卷积运算单元除了完成卷积运算外，还进行BN以及ReLU的计算。优选地，所述DnCNN网络计算装置放置的位置为以下位置其中之一：图像信号处理流程的开始处、图像信号处理流程的中间位置或者图像信号处理流程的结尾处。与传统的图像信号处理装置相同，本发明中的按行处理的CNN网络计算装置也是按行进行输入和输出计算结果，因此，本发明中的装置可以放置在图像信号处理装置中的任意位置，与传统的图像信号处理算法进行兼容并行计算，延迟较小，且不存在帧级的延迟。附图说明图1为常见的DnCNN的网络结构图。图2为卷积层运算的示意图。图3为本发明中按行处理的卷积计算方法的示意图。图4为本发明中按行处理的卷积计算方法对应的卷积计算装置结构图。图5为本发明中按行处理的DnCNN网络运算的一个实施例。图6为DnCNN网络中各神经网络层中行数据流示意图。图7为本发明提供一种按行处理的CNN网络计算装置。具体实施方式图2为卷积层运算的示意图。数字图像的色彩编码方法包括了RGB、YUV、YCbCr等。以RGB色彩编码为例，数字图像中的每一个像素可以由红色子像素、绿色子像素和蓝色子像素所组成；也就是说，若一张数字图像的分辨率或解析度是W*H平方像素，那么所述数字图像可以用N个二维矩阵来表示。举例来说，一张数字图像可以由多张特征图Tin_1、Tin_2、……、Tin_N所组成，所述数字图像的总数据量是W*H*N，于此W是特征图宽度，H是特征图高度，N是维度。假设一张数字图像需要和M组卷积核进行卷积运算，即通过卷积计算生成M个输出特征图像，类似地，一组卷积核中的每一者可以由N个二维矩阵来表示，一组卷积核系数的数据量为w*h*N，即计算一个输出特征图所需要的卷积核系数；那么计算M个输出特征图像时，卷积核系数的总数据量是w*h*N*M，于此w是卷积核宽度，h是卷积核高度，N是维度，M是卷积核组数。在进行一步卷积运算时，卷积核中的元素和特征图中当前对应的元素进行矩阵的乘积运算，接着卷积核依序移动一次步长来和特征图中每一步对应的元素进行矩阵的乘积运算，以此类推，直到卷积核移动到特征图的最后一个元素。值得注意的是，当卷积核移动到特征图的外部时，此时卷积核中的某些元素不能对应到特征图中的元素，所以需要扩充特征图的范围，一般是对特征图进行填充，也就是在特征图矩阵的边界上填充一些值，以增加特征图矩阵的大小，例如填充数值0，以确保卷积运算是有效的。一般而言，卷积核的大小w*h为奇数*奇数，且w和h为相等的值，假设其大小为k，即卷积核的大小为k*k，在进行填充时，填充的幅度设为/2，即在特征图矩阵的上下分别填充/2行填充数值，在特征图矩阵的左右分别填充/2列填充数值。进行填充之后，输出的特征图将与输入的特征图大小相同。举例来说，假设一组输入特征图Tin_1、Tin_2、……、Tin_N，一组卷积核Wx,y，Wx,y表示第x个输入特征图与第y个输出特征图之间的卷积核，且卷积运算的步长是1，那么可以产生一组输出特征图Tout_1、Tout_2、……、Tout_M。简言之，通过图2的卷积运算架构，可以实现卷积神经网络计算。卷积层的计算过程如图2中所示，图2中包括N个输入特征图Tin_1、Tin_2、……、Tin_N，M个输出特征图Tout_1、Tout_2、……、Tout_M，Wx,y表示第x个输入特征图与第y个输出特征图之间的卷积核，如果是3×3的卷积核，则包含9个系数。在计算过程中，每个输出特征图都需要所有输入特征图参与计算，以Tout_1的计算为例，传统的计算过程如下：将Tin_1与卷积核W1,1进行滤波运算，获取临时特征图数据Tout_1_tmp，并进行缓存；将Tin_2与卷积核W2,1进行滤波运算，将计算所得结果以点对点方式累加上之前缓存的临时特征图数据Tout_1_tmp，并将上述计算所得结果作为新的临时特征图数据Tout_1_tmp进行缓存；以类似步骤中的计算方式完成所有输入特征图数据的计算，最终获取的Tout_1_tmp即为最终的Tout_1。根据上述的计算过程可知，传统的计算方法，需要在整个输入特征图的数据均输入之后开始进行卷积计算，且在计算过程中，所有的临时特征图数据也与整张输入特征图的数据量相同，这样的计算方法将会需要巨大的内存资源，尤其是针对大分辨率的应用场景，其将占用更多的内存空间，进而限制了基于CNN的AI降噪方法在产业界的大规模应用。为了解决上述传统卷积计算方法存在的问题，本发明中提供一种按行处理的卷积计算方法，如图3中所示，以卷积核为3×3、跨度为1的卷积计算为例，如果Tin_1、Tin_2、……、Tin_N都已经有了三行数据，则根据3×3的滤波计算方式，可以将Tout_1、Tout_2、……、Tout_M中对应的一行数据计算出来。后续只要再输入一行数据，则Tout_1、Tout_2、……、Tout_M的下一行数据也都能被计算出来。该卷积计算过程可以分为三个阶段：启动工作阶段、平稳工作阶段和结束工作阶段。在启动工作阶段，输入特征图缓存单元按行缓存每个输入特征图中的数据，并判断每个输入特征图中的缓存数据量行数是否均达到kernel_size行，当每个输入特征图中的缓存数据量均达到kernel_size行数据时，行卷积运算单元开始进行卷积运算，当每个输出特征图均输出第一行卷积计算结果时，启动工作阶段结束。其中，缓存数据量包括每个输出特征图数据上方填充的PAD数据，即如果在卷积计算过程中对输入特征图进行了填充，则判断每个输入特征图中的缓存数据量行数与pad行数之和是否均达到kernel_size行，当每个输入特征图中的缓存数据量行数与pad行数之和均达到kernel_size行数据时，行卷积运算单元开始进行卷积运算。输入特征图缓存单元在进行数据缓存时，如果该输入特征图为原始图像数据，可以为每个输入特征图设置一个容量为 * PIC_W的缓存BUF，其中，PIC_W为每个输入特征图的每行的数据量。当每个输入特征图的缓存达到kernel_size行数据时，行卷积运算单元开始进行按行的卷积运算，同时剩余的一行缓存空间，可以继续接收外部输入特征图的数据输入。输入特征图缓存单元在进行数据缓存时，如果该输入特征图为前一层卷积运算的输出特征图，可以为每个输入特征图设置一个容量为kernel_size*PIC_W的缓存BUF，用于接收前一层卷积运算的卷积输出结果。后续在平稳工作阶段循环使用上述缓存BUF，直至输入特征图中的所有行数据输入完成。在平稳工作阶段，当输入特征图缓存单元缓存完每个输入特征图中的新一行数据后，行卷积运算单元获取卷积运算所需的输入特征图数据和对应的卷积核数据进行卷积运算，并稳定地输出每个输出特征图新一行的卷积运算结果。当输入特征图缓存单元缓存完每个输入特征图的最后一行数据，并完成该行数据的卷积计算时，平稳工作阶段结束，进入结束工作阶段。以图3中的输出特征图Tout_1为例，在启动工作阶段，行卷积运算单元运算过程如下：获取第一个输入特征图Tin_1中参与运算的数据PAD、PIC_1和PIC_2，并获取其对应的卷积核W1,1中的数据，进行卷积运算，得到输出特征图Tout_1中第一行PIC_1的临时数据PIC_1_tmp；获取第二个输入特征图Tin_2中参与运算的数据PAD、PIC_1和PIC_2，并获取其对应的卷积核W2,1中的数据，进行卷积运算，并将计算所得结果以点对点方式累加到之前的输出特征图Tout_1中第一行PIC_1的临时数据PIC_1_tmp；以此方法类推，直至完成所有的输入特征图数据的计算，最终获取的输出特征图Tout_1中第一行PIC_1的临时数据PIC_1_tmp即为最终的第一行输出Tout_1。将该结果通过行卷积结果输出单元输出。在平稳工作阶段，其他输出特征图中各行的结果也是通过这样的方法得出。由上述运算过程可以看出，行卷积运算单元仅需要1行数据容量用于临时数据PIC_1_tmp缓存，而不像传统卷积计算方法中需要与输入特征图同样的内存大小进行中间结果缓存，这样将进一步减小了本发明中提供的卷积计算方法所需要的存储空间。在结束工作阶段，行卷积运算单元自驱动完成剩余行的计算，并输出剩余行的卷积计算结果。以图3中的3×3的卷积核为例，利用每个输入特征图的第PIC_H-1、PIC_H行并结合PAD行，计算生成每个输出特征图的最后一行数据，并将每个输出特征图的最后一行数据输出。采用本发明中提供的卷积计算方法，具有以下优势：在每个输入特征图中的缓存数据量达到kernel_size时，即可以开始进行卷积计算，而不需要缓存整个输入特征图的数据，因此，在计算过程中，增强了图像处理的实时性；输入特征图缓存单元只需要为每个输入特征图设置容量为*PIC_W或kernel_size*PIC_W的缓存，而不需要缓存整个输入特征图的数据；在进行临时数据缓存时，只需设置1行数据容量用于临时数据缓存，按行输出卷积计算结果；因此，采用该卷积计算方法将大大地降低了计算所需要的内存，节省存储资源；该方法在计算过程中，其参与运算的数据与传统的整帧图片卷积运算的数据完全相同，因此，不会出现明显的块边界效应。图4为本发明中卷积计算方法对应的卷积计算装置结构图100。该卷积计算装置包括输入特征图缓存单元101、卷积核系数读取单元102、卷积核系数缓存单元103、行卷积运算单元104和行卷积结果写出单元105。其中，输入特征图缓存单元101用于缓存各个输入特征图中的行数据；卷积核系数缓存单元103用于缓存卷积核系数；卷积核系数读取单元102用于从卷积核系数缓存单元103中读取参与卷积运算的卷积核系数；行卷积运算单元104用于从输入特征图缓存单元101和卷积核系数读取单元102中读取参与卷积计算的数据，进行卷积计算，并将得到的卷积结果通过行卷积结果写出单元105将行卷积运算结果输出到外部存储装置。在进行卷积计算的过程中，在启动工作阶段，输入特征图缓存单元101接收每个输入特征图中按行输入的数据，并判断缓存的输入特征图行数是否达到kernel_size行；卷积核系数读取单元102从卷积核系数缓存单元103中读取参与计算所需的卷积核系数；当每个输入特征图中的缓存数据量均达到kernel_size行数据时，行卷积运算单元104开始进行卷积运算，当每个输出特征图均输出第一行卷积计算结果时，启动工作阶段结束。输入特征图缓存单元101的最小容量为*PIC_W*N，其中，kernel_size为卷积核的行数，PIC_W为输入特征图每行的数据量，N为输入特征图的数量。如果输入特征图为原始图像数据，则输入特征图缓存单元101为每个输入特征图设置容量为*PIC_W的缓存，用于缓存输入特征图的数据，当缓存的数据量达到kernel_size行时，即可进行卷积计算，同时剩余的一行缓存空间可以继续接受外部输入特征图的数据输入。如果输入特征图为前一层卷积运算的输出特征图，则输入特征图缓存单元101为每个输入特征图设置容量为kernel_size*PIC_W的缓存，用于接收前一层卷积运算的卷积输出结果。在后续平稳工作阶段，循环使用上述缓存BUF，直至输入特征图中的所有行数据输入完成。在平稳工作阶段，当输入特征图缓存单元101缓存每个输入特征图中的新一行数据后，行卷积运算单元104获取卷积运算所需的输入特征图数据和对应的卷积核数据进行卷积运算，并将卷积运算的结果输出至行卷积结果写出单元105。在结束工作阶段，行卷积运算单元104自驱动完成剩余行的计算，在计算完成之后，行卷积运算单元将每个输出特征图的最后一行输出结果输出至行卷积结果写出单元105。行卷积结果写出单元105可以在平稳工作阶段将输出特征图中的数据按行输出到外部存储器。本发明中提供的按行处理的卷积计算方法，可以应用于DnCNN运算，可以按行计算的方式将整个DnCNN网络都计算处理。因为在图1中所示的DnCNN网络结构中，BN可以与卷积计算进行合并，而ReLU只是简单的判断及赋值运算，因此整个DnCNN网络计算的本质是多个卷积层的连续计算。如图5中所示，图5为本发明中按行处理的DnCNN网络运算的一个实施例。为了更好地描述本专利所提出的DnCNN网络计算方法，该实施例对DnCNN网络进行了简化。在该DnCNN网络中，输入图像为单灰度图像，图像大小为PIC_W*PIC_H；输入图像后面接入一个“Conv+ReLU”层，其输出特征图的个数为2，卷积核的大小为3×3；“Conv+ReLU”层后面连续接入2个“Conv+BN+ReLU”层，其输入/输出特征图个数均为2，卷积核大小为3×3；第二个“Conv+BN+ReLU”层后面接入一个“Conv”层，其输出特征图为1，卷积核的大小为3×3。在图5中，为了保持连续卷积运算过程中的图像大小不变，对计算过程中的图像进行了填充，增加了PAD行。图中的PAD行并非真实特征数据，按照3×3的滤波计算要求，需要在特征图的上下各加一行数据值为0的PAD行，以确保3×3滤波计算之后，图像高度维持不变；每个特征图中的最左边和最右边也各需要增加一列数据值为0的PAD列，以确保3×3的滤波计算之后，图像的宽度维持不变。由图5中可知，当输入图像输入两行数据SRC_LN1和SRC_LN2之后，加上填充的第一行PAD行，即可以进行“Conv+ReLU”层的卷积运算，并计算出“Conv+ReLU”层的输出特征图的第一行数据LAYER1_OFMAP1_LN1和LAYER1_OFMAP2_LN1。当“Conv+ReLU”层的两个输出特征图均具有两行数据LAYER1_OFMAP1_LN1、LAYER1_OFMAP1_LN2和LAYER1_OFMAP2_LN1、LAYER1_OFMAP2_LN2，结合该层中每个输出特征图中第一行的PAD行，可以进行“第一Conv+BN+ReLU”层的卷积计算，并计算出“第一Conv+BN+ReLU”层中两个输出特征图中的第一行数据LAYER2_OFMAP1_LN1和LAYER2_OFMAP2_LN1。此时，输入图像已经输入并参与计算的数据为：SRC_LN1、SRC_LN2和SRC_LN3。当“第一Conv+BN+ReLU”层的两个输出特征图均具有两行数据LAYER2_OFMAP1_LN1、LAYER2_OFMAP1_LN2和LAYER2_OFMAP2_LN1、LAYER2_OFMAP2_LN2，结合该层中每个输出特征图中的第一行的PAD行，可以进行“第二Conv+BN+ReLU”层的卷积计算，并计算出“第二Conv+BN+ReLU”层中两个输出特征图中的第一行数据LAYER3_OFMAP1_LN1和LAYER3_OFMAP2_LN1。此时，输入图像已经输入并参与计算的数据为：SRC_LN1、SRC_LN2、SRC_LN3和SRC_LN4。当“第二Conv+BN+ReLU”层的两个输出特征图均具有两行数据LAYER3_OFMAP1_LN1、LAYER3_OFMAP1_LN2和LAYER3_OFMAP2_LN1、LAYER3_OFMAP2_LN2，结合该层中每个输出特征图中的第一行的PAD行，可以进行“Conv”层的卷积计算，并计算出“Conv”层中的第一行数据LAYER4_OFMAP1_LN1，该数据即为最终残差图像中的第一行数据。此时，输入图像已经输入并参与计算的数据为：SRC_LN1、SRC_LN2、SRC_LN3、SRC_LN4和SRC_LN5。由上述计算过程可知，只要输入5行原始图像数据，就可以进行整个简化DnCNN网络的运算，并得到第一行残差图像的数据；并且后续每输入一行原始图像数据，就能输出一行残差图像数据。请参照图6中所示，图6为DnCNN网络中各神经网络层中行数据流示意图。与图5中的计算原理类似，当一层神经网络中的输入数据加上PAD行的数据达到kernel_size的3行时，即可以开始该层神经网络的卷积计算。根据图6中所示，对于该简化的DnCNN网络，当输入图像的输入数据达到5行时，就能输出第一行残差图像的数据，并且后续每输入一行原始图像数据，就能输出一行残差图像数据。按此方法循环调用按行处理的同一卷积运算单元，即可实现完整的DnCNN 的运算。由此引起的原始图像输入数据行延迟数，可以用下面公式进行计算：start_src_ln_num = Layer_num + kernel_size-1-pad_num；其中，start_src_ln_num表示输出第一行残差图像数据时，输入图像的行数，即输出第一行残差图像的数据与原始图像输入数据的行延迟数；Layer_num表示整个DnCNN网络的层数，包含所有Conv+ReLU层、Conv+BN+ReLU层和Conv层；kernel_size表示卷积核的行数，如3x3卷积核，则kernel_size为3；pad_num表示对输入特征图上方填充的PAD行数，如前所述，一般在输入特征图的上下分别填充/2行填充数值，因此，pad_num即为/2，当kernel_size为3时，pad_num即为1。按行处理的CNN网络计算方法，与上述卷积计算方法类似，其计算过程也可以分为三个阶段：启动工作阶段、平稳工作阶段和结束工作阶段。在启动工作阶段，原始图像数据输入缓存单元按行缓存输入图像中的每个输入特征图中的数据，并判断每个输入特征图中的缓存数据量行数是否均达到kernel_size行，当每个输入特征图中的缓存数据量均达到kernel_size行数据时，行卷积运算单元开始进行第一层卷积运算，即图5中“Conv+ReLU”层的卷积计算。其中，缓存数据量包括PAD数据，即如果在卷积计算过程中对输入特征图进行了填充，则判断每个输入特征图中的缓存数据量行数与pad行数之和是否均达到kernel_size行，当每个输入特征图中的缓存数据量行数与pad行数之和均达到kernel_size行数据时，行卷积运算单元开始进行卷积运算。此时，只能进行第一层卷积，即“Conv+ReLU”层的卷积运算。要想继续启动下一层“Conv+BL+ReLU”的计算，则需要等到原始图像数据输入缓存单元缓存完新的一行数据，且“Conv+ReLU”层计算出的各个输出特征图中的数据行数加上PAD行数达到kernel_size。在后续的其他“Conv+BL+ReLU”层和“Conv”层的计算也存在类似的情况，必须等到前一层的各个输出特征图中的数据行数加上PAD行数达到kernel_size之后，才能启动当前神经网络层的计算。启动工作阶段以“Conv”层输出完成第一行残差图片的数据为止。当“Conv”层输出完成第一行残差图像的数据时，开始进入平稳工作阶段。在平稳工作阶段，当原始图像数据输入缓存单元缓存每个输入特征图的新一行数据后，行卷积运算单元获取卷积运算所需的输入特征图数据和对应的卷积核数据对各神经网络层进行连续运算，并稳定地输出新一行的残差图像结果数据。当原始图像数据输入缓存单元缓存完每个输入特征图的最后一行数据，并完成各神经网络层的计算，输出残差图像与该行对应的输出数据时，平稳工作阶段结束，进入结束工作阶段。在结束工作阶段，行卷积运算单元自驱动完成剩余行的计算，并输出残差图像剩余行的输出数据。在结束工作阶段，将不再会有原始图像输入，下面以图5中简化的DnCNN网络为例说明在结束工作阶段，行卷积运算单元的计算过程。步骤：行卷积运算单元首先利用原始图像的第PIC_H-1行、第PIC_H行并结合PAD行进行卷积运算，生成“Conv+ReLU”层中各个输出特征图中的最后一行，然后依次完成“第一Conv+BL+ReLU”层各输出特征图的第PIC_H-1行、“第二Conv+BL+ReLU”层各输出特征图的第PIC_H-2行以及“Conv”层中第PIC_H-3行的残差图像数据的计算。步骤：行卷积运算单元利用“Conv+ReLU”层中各输出特征图的第PIC_H-1行、第PIC_H行并结合PAD行进行卷积运算，生成“第一Conv+BL+ReLU”层中各个输出特征图中的最后一行，然后依次完成“第二Conv+BL+ReLU”层各输出特征图的第PIC_H-1行以及“Conv”层中第PIC_H-2行的残差图像数据的计算。步骤：行卷积运算单元利用“第一Conv+BL+ReLU”层中各输出特征图的第PIC_H-1行、第PIC_H行并结合PAD行进行卷积运算，生成“第二Conv+BL+ReLU”层中各个输出特征图中的最后一行，然后完成“Conv”层中第PIC_H-1行的残差图像数据的计算。步骤：行卷积运算单元利用“第二Conv+BL+ReLU”层中各输出特征图的第PIC_H-1行、第PIC_H行并结合PAD行进行卷积运算，完成“Conv”层中最后一行的残差图像数据的计算。采用本发明中提供的按行处理的CNN网络计算方法，具有以下优势：在每个输入特征图中的缓存数据量达到kernel_size时，即可以开始进行卷积计算，而不需要缓存整个输入特征图的数据，因此，在计算过程中，增强了图像处理的实时性；原始图像数据输入缓存单元只需要为每个输入特征图设置容量为*PIC_W的缓存，而不需要缓存整个输入特征图的数据；在进行中间结果缓存时，每个输出特征图也仅需要kernel_size*PIC_W数据容量用于中间结果缓存并作为下一层神经网络的输入，因此，采用该卷积计算方法将大大地降低了计算所需要的内存，节省存储资源；该方法在计算过程中，其参与运算的数据与传统的整帧图片卷积运算的数据完全相同，因此，不会出现明显的块边界效应；传统的图像信号处理相关算法功能模块都是按行进行处理的，本发明中的按行处理的CNN网络计算方法也是按行进行输入和输出计算结果，输出结果与原始图像的延迟行数仅为Layer_num + kernel_size-1-pad_num，因此，区别于传统AI算法的按帧处理，本发明中的方法可以与传统的图像信号处理算法进行兼容并行计算，延迟较小，且不存在帧级的延迟。如图7中所示，本发明提供一种按行处理的CNN网络计算装置200，该计算装置包括原始图像数据输入缓存单元201、卷积核系数缓存单元203、卷积核系数读取单元202、行卷积中间结果读取单元207、行卷积运算单元204、行卷积中间结果缓存单元206以及行卷积结果写出单元205。其中，原始图像数据输入缓存单元201用于缓存原始图像中各个输入特征图的行数据；卷积核系数缓存单元203用于缓存各个卷积核系数；卷积核系数读取单元202用于从卷积核系数缓存单元203中读取参与卷积运算的卷积核系数；行卷积中间结果缓存单元206用于缓存CNN网络计算的中间结果；行卷积中间结果读取单元207用于从行卷积中间结果缓存单元206中读取行卷积中间结果；行卷积运算单元204用于从原始图像数据输入缓存单元201/行卷积中间结果读取单元207和卷积核系数读取单元202中读取参与卷积运算的数据，进行卷积运算，并将得到的结果输出到行卷积结果写出单元205；行卷积写出单元205将中间结果输出至行卷积中间结果缓存单元206，将最终的残差图像数据至外部存储器。原始图像数据输入缓存单元201接收每个输入特征图中按行输入的数据，并判断缓存的输入特征图行数是否达到kernel_size行；当每个输入特征图中的缓存数据量均达到kernel_size行数据时，原始图像数据输入缓存单元会告知行卷积运算单元开始进行按行卷积运算。原始图像数据输入缓存单元201内部为原始图像的每个输入特征图设置有容量为*PIC_W的缓存空间，用于缓存输入特征图的数据，其中，kernel_size为卷积核的行数，PIC_W为输入特征图每行的数据量。当每个输入特征图缓存的数据量达到kernel_size行时，即可进行卷积计算，同时剩余的一行缓存空间可以继续接受外部输入特征图的数据输入。后续循环使用上述缓存BUF，直至原始图像输入特征图的所有行数据输入完成。卷积核系数缓存单元203用于缓存整个DnCNN网络的所有卷积核系数，这些系数在该装置启动前即被导入，且中间并不会发生改变。卷积核系数读取单元202用于读取卷积核系数缓存单元203中缓存的卷积核系数，根据行卷积运算单元204循环调用计算过程，完成相应神经网络层卷积核系数的读取。行卷积运算单元204通过循环调用的方式按行完成整个DnCNN网络计算。行卷积运算单元204除了完成卷积运算外，还会进行BN以及ReLU的计算，但是由于BN和ReLU的计算不会影响本装置的运算过程，因此本专利中只描述卷积运算。在启动工作阶段，当原始图像的每个输入特征图中的缓存数据量均达到kernel_size行数据时，行卷积运算单元204开始进行计算。此时，只能进行第一层卷积，即“Conv+ReLU”层的卷积运算。要想继续启动下一层“Conv+BL+ReLU”的计算，则需要等到原始图像数据输入缓存单元201缓存完新的一行数据，且“Conv+ReLU”层计算出的各个输出特征图中的数据行数加上PAD行数达到kernel_size。在后续的其他“Conv+BL+ReLU”层和“Conv”层的计算也存在类似的情况，必须等到前一层的各个输出特征图中的数据行数加上PAD行数达到kernel_size之后，才能启动当前神经网络层的运算。启动工作阶段以“Conv”层输出完成第一行残差图片的数据为止。当“Conv”层输出完成第一行残差图像的数据时，开始进入平稳工作阶段。在平稳工作阶段，当原始图像数据输入缓存单元201缓存每个输入特征图的新一行数据后，行卷积运算单元204获取卷积运算所需的输入特征图数据和对应的卷积核数据对各神经网络层进行连续运算，并稳定地输出新一行的残差图像结果数据。当原始图像数据输入缓存单元缓存完每个输入特征图的最后一行数据，并完成各神经网络层的计算，输出残差图像与该行对应的输出数据时，平稳工作阶段结束，进入结束工作阶段。在结束工作阶段，行卷积运算单元204自驱动完成剩余行的计算，并输出残差图像剩余行的输出数据。行卷积中间结果缓存单元206用于缓存DnCNN网络中间各层的输出特征图的行数据。以图5中简化的DnCNN网络为例，行卷积中间结果缓存单元206主要缓存“Conv+ReLU”层、“第一Conv+BL+ReLU”层和“第二Conv+BL+ReLU”层的各个输出特征图的行数据。为了节省缓存空间，中间输出特征图行数据存储空间也采用复用的方式，每个输出特征图也仅需要kernel_size*PIC_W数据容量用于中间结果缓存并作为下一层神经网络的输入。相比于传统的按帧运算的方式，每层的输出特征图均需要设置与输入特征图大小相同的缓存空间，尤其在大分辨率的情况下，本发明中采用的按行处理的方法将大大地节省了存储空间容量。行卷积中间结果读取单元207用于读取行卷积中间结果缓存单元206中的数据，根据行卷积运算单元204循环调用过程，完成相应神经网络层特征行数据的读取。本发明中提供的按行处理的CNN网络计算装置，在整个图像信号处理过程中的位置可以任意放置，可以放在整个图像信号处理流程的开始处、图像信号处理流程的中间位置或者图像信号处理流程的结尾处，在此不进行限制。因为传统的ISP模块中，其图像处理算法均是按行进行的，而现有的AI算法一般都是按帧进行处理的，所以需要ISP模块按行处理完成一帧数据处理之后，才能启动AI降噪算法；也即背景技术中介绍的目前基于CNN网络的AI降噪过程一般都放在ISP图像处理之后，因此，在该连接方式中，AI降噪算法的输出结果至少存在一帧的帧延迟，对于自动驾驶这样对延迟容忍度比较小的应用场景就不大适用。而本发明中提供的按行处理的CNN网络计算装置，因为其按行输入输出计算结果，因此，该装置可以放置在整个图像信号处理装置的任何位置，且其输出结果不存在帧级的延迟。因此，相比于传统的AI降噪装置，本发明中提供的降噪装置适应性更强，并具有更好的应用前景。本发明中提供的按行处理的CNN网络计算装置，具有如下优势：原始图像数据输入缓存单元只需要为每个输入特征图设置容量为*PIC_W的缓存，而不需要缓存整个输入特征图的数据；在进行中间结果缓存时，行卷积中间结果缓存单元也仅需要给每个输出特征图配置kernel_size*PIC_W数据容量用于中间结果缓存并作为下一层神经网络的输入，因此，采用该装置将大大地减小了存储空间，实现了小型化、集成化，更有利于在产业上的应用；该装置在计算过程中，其参与运算的数据与传统的整帧图片卷积运算的数据完全相同，因此，不会出现明显的块边界效应。传统的图像信号处理相关算法功能模块都是按行进行处理的，本发明中的按行处理的CNN网络计算装置也是按行进行输入和输出计算结果，输出结果与原始输入图像的延迟行数仅为Layer_num + kernel_size-1-pad_num，因此，本发明中的装置可以与传统的图像信号处理装置进行兼容并行计算，延迟较小，且不存在帧级的延迟。以上所述仅是本发明的优选实施例而已，并非对本发明做任何形式上的限制，虽然本发明已以优选实施例揭露如上，然而并非用以限定本发明，任何熟悉本专业的技术人员，在不脱离本发明技术方案的范围内，当可利用上述揭示的技术内容作出些许更动或修饰为等同变化的等效实施例，但凡是未脱离本发明技术方案的内容，依据本实用发明的技术实质对以上实施例所作的任何简单修改、等同变化与修饰，均仍属于本发明技术方案的范围内。
