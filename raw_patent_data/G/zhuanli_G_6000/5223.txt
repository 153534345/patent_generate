标题title
面向海量数据实时处理的云边协同自适应深度推理方法
摘要abst
本发明提供了一种面向海量数据实时处理的云边协同自适应深度推理方法。该方法包括：将DNN模型进行模型量化，根据得到的量化模型对DNN模型进行DAG构建；对DAG网络进行可行分割点的搜索，得到优化后的潜在分割点集；基于优化后的潜在分割点集对DNN模型各层在终端设备上运行的累积推理延迟、数据传输延迟和累积量化损失进行数据拟合，利用以带宽为变量的权重函数对DNN模型各层的累积推理延迟、数据传输延迟和累积量化损失的目标函数进行加权优化，得到最优的分割点；根据所述最优分割点将DNN模型进行分割。本发明考虑到模型量化带来的精度损失，将精度损失和时延根据网络质量的变化进行加权优化，以满足用户在不同的网络质量下对服务质量的不同需求。
权利要求书clms
1.一种面向海量数据实时处理的云边协同自适应深度推理方法，其特征在于，包括：将需要部署的DNN模型进行模型量化，根据得到的量化模型对DNN模型进行有向无环图DAG构建；对所述DAG网络进行可行分割点的搜索，找到DAG中的所有割点，将符合约束的割点加入到潜在分割点集，对所述潜在分割点集进行优化处理，得到优化后的潜在分割点集；基于优化后的潜在分割点集对DNN模型各层在终端设备上运行的累积推理延迟、数据传输延迟和累积量化损失进行数据拟合，将离散的数据拓展到连续域上，分别得到DNN模型各层的累积推理延迟、数据传输延迟和累积量化损失；利用以带宽为变量的权重函数对所述DNN模型各层的累积推理延迟、数据传输延迟和累积量化损失的目标函数进行加权优化，得到最优的分割点；根据所述最优分割点将所述DNN模型进行分割后，分别在终端设备和云上执行任务推理，并得到推理结果。2.根据权利要求1所述的方法，其特征在于，所述的将需要部署的DNN模型进行模型量化，根据得到的量化模型对DNN模型进行有向无环图DAG构建，包括：对需要部署的DNN模型进行预训练，通过量化器将预训练后的DNN模型的权重和激活量化为8比特，得到量化模型，只在终端设备上部署量化模型，在云上部署原始DNN模型；根据得到的量化模型对DNN模型进行DAG构建，给定一个DNN模型，构造一个DAG，通过G＝＜V,E＞来表示它，V表示DAG中顶点的集合，E表示DAG中边的集合，每个顶点vi∈V对应DNN模型的某一层，有向边ei＝＜vi,vj＞∈E表示vj把vi的输出作为它自己的输入，使用di来表示每条边ei的值，其中di表示vi的输出数据大小，将输入层作为v0，将e0＝＜v0,v1＞的值d0作为原始输入数据大小。3.根据权利要求2所述的方法，其特征在于，所述的对所述DAG网络进行可行分割点的搜索，找到DAG中的所有割点，将符合约束的割点加入到潜在分割点集，对所述潜在分割点集进行优化处理，得到优化后的潜在分割点集，包括：对于所述DAG网络首先搜索DAG网络中的所有割点，该割点为DAG中的顶点，被移除后将使得DAG不再连接，所述DAG网络中包括多个逻辑块，使用最小割方法在由一个或几个顶点组成的逻辑块中找到具有最小输出数据大小的分割点，在一个逻辑块中找到一个潜在的分割点，所有割点和逻辑块内的所有最小割点分别构成割点集和最小割集；如果输出数据大小满足di＜d0，则将割点集中的潜在分割点添加到潜在分割点集中，在最小割集中，当时，潜在分割点也被添加到潜在分割点集其中是通过最小割方法获得的逻辑块内的输出数据大小的最小和；对于链式拓扑DNN和DAG网络，移除中连续并具有相同输出数据大小的分割点；对潜在分割点集进行优化处理，从潜在分割点集中删除神经网络BN层，去除连续且数据输出量相等的点，得到优化后的潜在分割点集4.根据权利要求3所述的方法，其特征在于，所述的基于优化后的潜在分割点集对DNN模型各层在终端设备上运行的累积推理延迟、数据传输延迟和累积量化损失进行数据拟合，将离散的数据拓展到连续域上，分别得到DNN模型各层的累积推理延迟、数据传输延迟和累积量化损失，包括：设置DNN模型具有N层，其中为非负整数集，设B为网络带宽，用di表示第i层的输出数据大小，设代表第i层的数据传输延迟，用表示在终端设备上执行DNN模型的第i层的推理延迟；将wi和ai表示为第i层给定位宽的权重和激活，通过使用均方误差函数MSE，分别用和来表示第i层的权重和激活的量化误差；设代表第i层的量化权重损失和激活的总和，即假设DNN模型在x层分割，将DNN模型第x层的目标函数定义如下：其中表示从输入层到第x层的累积推理延迟，是第x层的数据传输延迟，是从输入层到第x层的累积量化损失，自变量x是DNN模型的分割层，将定义为：通过最小-最大方法归一化延迟和损失，使式中各值具有相同的数值维度，定义为：其中X分别代表标准化前tedge、ttrans和lquant的值，Xmin和Xmax分别表示tedge、ttrans和lquant中的最小和最大值，Xnormal表示归一化值，介于0和1之间；在潜在分割点的集合中，潜在分割点对应DNN模型中的层，层的输出数据大小g随层x值的递增呈指数递减，累积推理时间f和累积量化损失h随层x值的递增呈线性递增，用凸函数f、g和h分别表示累积推理时延、数据传输延迟和累积量化损失，f和h是递增的线性函数，g是递减的凸函数，目标函数重写为：的优化是一个凸优化问题。5.根据权利要求4所述的方法，其特征在于，所述的利用以带宽为变量的权重函数对所述DNN模型各层的累积推理延迟、数据传输延迟和累积量化损失的目标函数进行加权优化，得到最优的分割点，包括：利用以带宽为变量的权重函数对所述DNN模型各层的累积推理延迟、数据传输延迟和累积量化损失的目标函数进行加权优化，将改写为：其中，ω以带宽B为变量，表示为ω与带宽成比例，ω的值介于0和1之间，k控制ω的平滑度，当带宽较小时，延迟在目标函数中的权重较大，而当带宽较大时，量化损失的权重较大；加权优化后的目标函数为：在连续区域上找到所述目标函数的松弛问题的最优解x，把最优解x推广到离散域，设最优解x的下取整为上取整为如果则潜在最优解为否则为潜在最优解X为连续域上的最优解取整得到，对取整后的最优解X进行判断，将X层的累积推理延迟和数据传输延迟，即tedge+ttrans，与仅边缘或仅云推理时延进行比较，即min,ttrans)，当tedge+ttrans＜min,ttrans)时，X被确定为最佳分割点；否则，该算法从X开始搜索分割点的集合以找到tedge+ttrans＜min,ttrans)最接近X的最佳分割点X*。6.根据权利要求5所述的方法，其特征在于，所述的根据所述最优分割点将所述DNN模型进行分割后，分别在终端设备和云上执行任务推理，并得到推理结果，包括：在从调度器获得最优分割点之后，执行器组件基于所述最优分割点对所述DNN模型进行分割，分割后得到的部分量化模型在终端设备执行，在终端设备执行模型推理任务，终端设备输出模型推理结果到云，剩余的模型在云上执行，在云上继续执行模型推理任务后得到模型推理结果。
说明书desc
技术领域本发明涉及数据处理技术领域，尤其涉及一种面向海量数据实时处理的云边协同自适应深度推理方法。背景技术深度学习的快速发展使得复杂的推理任务，如计算机视觉和自然语言处理得以解决。并且还刺激了智能应用的发展，如自动驾驶、物体探测和增强现实。这些智能应用都需要终端设备收集大规模数据，并对低延迟和低能耗有很高的处理要求。通常，终端设备收集的数据由云处理后返回结果。然而，对于某些场景和任务，这种以云为中心的方法可能会面临隐私和延迟问题。例如高速铁路和高速列车为综合交通运输体系带来便利的同时，产生了多数据源与超大容量的车载数据。动车组各类系统每小时累计产生至少10GB数据；检测列车平均每月产生达170GB的列车、接触网、工务、电务各专业基础设施检测数据。随着铁路智能化、数字化运维的发展，车载各类数据仍在不断增加。传统的车载数据处理的方案是待车辆回库后，由工作人员上车将数据转储到便携式存储介质中，这种方法不仅速度慢、时间长，还存在着人力浪费甚至下载过程中断等问题，难以满足数据高速、高效下载的需求；另一种方式是使用2.4GHz和5.8GHz频段WLAN进行无线下载，但在库的短时间内只能满足500MB以内数据下载和存储需求，无法满足以千兆字节为单位的大容量数据超高速、全自动、断点续传等功能需求。因此，如何进一步提升对列车在高速运行中产生海量数据的处理效率，是对高铁列车全生命周期数据管理方式的有益补充，也是我国高铁实现及时有效的预测和检测病害，降低运营成本亟需解决的核心问题。作为一种解决方案，将云计算能力从核心网络下沉到边缘网络正成为一种新兴的计算范式。然而，在资源受限的终端设备上部署DNN可能具有挑战性。现有的研究已经探索了许多技术来在资源受限的终端设备上实现有效的DNN推断，例如模型压缩，紧凑的网络设计和提前退出。这些方法通过改变模型结构、减少参数数量或提前退出推理来减少资源需求。但是这些方法经常导致准确性的损失，并且仍然难以在一些终端设备上部署。为了充分利用终端设备的本地处理能力和云设备的高计算能力来实现低延迟，近年来提出了协同深度推理。协同深度推理将DNN视为计算图，并在终端设备和云之间进行分割。在运行时，终端设备执行DNN模型的前一部分，在本地处理输入数据，并通过网络将中间结果发送到云。云执行DNN模型的剩余部分，并将结果返回给终端设备。模型分割旨在寻找具有最小延迟或能量的最优分割点。DNN在分割点进行分割，并部署在不同的设备上。例如，有方案提出在移动设备和云之间划分DNNs，云动态地选择最佳划分解决方案以满足推断延迟或能量消耗的要求。然而，还有方案提出只处理链拓扑DNN模型。还有方案提出将具有DAG拓扑的DNNs的模型划分转化为最小割问题，可以快速求解该问题。还有方案提出将寻找最优分割解的问题建模为最短路径问题。还有方案提出通过联合优化终端设备上各层的拆分点和量化位宽，在给定边缘设备内存限制和错误限制下，最大限度地减少了的整体延迟。还有方案提出将模型划分和提前退出相结合，以在静态和动态网络环境中实现自适应模型最优划分。还有方案提出利用重要的上下文资源构造划分状态图，并提出“邻居效应”来加速推理。上述现有技术中的对列车在高速运行中产生的海量数据的处理方法的缺点为：现有对深度神经网络轻量化的方法，如模型剪枝、模型量化等，虽然减少了模型的参数和计算量，但是通常会带来模型推理精度的下降，并且对于一些资源受限的终端设备来说，轻量化后的模型可能仍难以满足设备的计算和存储限制。现有模型分割方法大多只考虑到最优化分割后模型的推理时延，但分割后的模型的协同计算还涉及传输时延和最优分割点的选取，以满足场景对时延的要求。现有技术中虽然有考虑到网络质量实时变化的情形下最优点的选择，但是大多数分割点选择算法复杂，进行决策的时延太长，导致当决策完成时网络质量又已经发生了改变，已经做出的决策结果对于当前的网络质量已经不再是最优的结果，继而再次进行分割点的重新选择。这样会造成算法不收敛，一直无法得到最优的结果，使得推理的总时延增加，推理性能下降。发明内容本发明的实施例提供了一种面向海量数据实时处理的云边协同自适应深度推理方法，以实现对列车在高速运行中产生的海量数据进行有效处理。为了实现上述目的，本发明采取了如下技术方案。一种面向海量数据实时处理的云边协同自适应深度推理方法，包括：将需要部署的DNN模型进行模型量化，根据得到的量化模型对DNN模型进行有向无环图DAG构建；对所述DAG网络进行可行分割点的搜索，找到DAG中的所有割点，将符合约束的割点加入到潜在分割点集，对所述潜在分割点集进行优化处理，得到优化后的潜在分割点集；基于优化后的潜在分割点集对DNN模型各层在终端设备上运行的累积推理延迟、数据传输延迟和累积量化损失进行数据拟合，将离散的数据拓展到连续域上，分别得到DNN模型各层的累积推理延迟、数据传输延迟和累积量化损失；利用以带宽为变量的权重函数对所述DNN模型各层的累积推理延迟、数据传输延迟和累积量化损失的目标函数进行加权优化，得到最优的分割点；根据所述最优分割点将所述DNN模型进行分割后，分别在终端设备和云上执行任务推理，并得到推理结果。优选地，所述的将需要部署的DNN模型进行模型量化，根据得到的量化模型对DNN模型进行有向无环图DAG构建，包括：对需要部署的DNN模型进行预训练，通过量化器将预训练后的DNN模型的权重和激活量化为8比特，得到量化模型，只在终端设备上部署量化模型，在云上部署原始DNN模型；根据得到的量化模型对DNN模型进行DAG构建，给定一个DNN模型，构造一个DAG，通过G＝＜V,E＞来表示它，V表示DAG中顶点的集合，E表示DAG中边的集合，每个顶点vi∈V对应DNN模型的某一层，有向边ei＝＜vi,vj＞∈E表示vj把vi的输出作为它自己的输入，使用di来表示每条边ei的值，其中di表示vi的输出数据大小，将输入层作为v0，将e0＝＜v0,v1＞的值d0作为原始输入数据大小。优选地，所述的对所述DAG网络进行可行分割点的搜索，找到DAG中的所有割点，将符合约束的割点加入到潜在分割点集，对所述潜在分割点集进行优化处理，得到优化后的潜在分割点集，包括：对于所述DAG网络首先搜索DAG网络中的所有割点，该割点为DAG中的顶点，被移除后将使得DAG不再连接，所述DAG网络中包括多个逻辑块，使用最小割方法在由一个或几个顶点组成的逻辑块中找到具有最小输出数据大小的分割点，在一个逻辑块中找到一个潜在的分割点，所有割点和逻辑块内的所有最小割点分别构成割点集和最小割集；如果输出数据大小满足di＜d0，则将割点集中的潜在分割点添加到潜在分割点集中，在最小割集中，当时，潜在分割点也被添加到潜在分割点集其中是通过最小割方法获得的逻辑块内的输出数据大小的最小和；对于链式拓扑DNN和DAG网络，移除中连续并具有相同输出数据大小的分割点；对潜在分割点集进行优化处理，从潜在分割点集中删除神经网络BN层，去除连续且数据输出量相等的点，得到优化后的潜在分割点集优选地，所述的基于优化后的潜在分割点集对DNN模型各层在终端设备上运行的累积推理延迟、数据传输延迟和累积量化损失进行数据拟合，将离散的数据拓展到连续域上，分别得到DNN模型各层的累积推理延迟、数据传输延迟和累积量化损失，包括：设置DNN模型具有N层，其中Z为非负整数集，设B为网络带宽，用di表示第i层的输出数据大小，设代表第i层的数据传输延迟，用表示在终端设备上执行DNN模型的第i层的推理延迟；将wi和ai表示为第i层给定位宽的权重和激活，通过使用均方误差函数MSE，分别用和来表示第i层的权重和激活的量化误差；设代表第i层的量化权重损失和激活的总和，即假设DNN模型在x层分割，将DNN模型第x层的目标函数定义如下：其中表示从输入层到第x层的累积推理延迟，是第x层的数据传输延迟，是从输入层到第x层的累积量化损失，自变量x是DNN模型的分割层，将定义为：通过最小-最大方法归一化延迟和损失，使式中各值具有相同的数值维度，定义为：其中X分别代表标准化前tedge、ttrans和lquant的值，Xmin和Xmax分别表示tedge、ttrans和lquant中的最小和最大值，Xnormal表示归一化值，介于0和1之间；在潜在分割点的集合中，潜在分割点对应DNN模型中的层，层的输出数据大小g随层x值的递增呈指数递减，累积推理时间f和累积量化损失h随层x值的递增呈线性递增，用凸函数f、g和h分别表示累积推理时延、数据传输延迟和累积量化损失，f和h是递增的线性函数，g是递减的凸函数，目标函数重写为：的优化是一个凸优化问题。优选地，所述的利用以带宽为变量的权重函数对所述DNN模型各层的累积推理延迟、数据传输延迟和累积量化损失的目标函数进行加权优化，得到最优的分割点，包括：利用以带宽为变量的权重函数对所述DNN模型各层的累积推理延迟、数据传输延迟和累积量化损失的目标函数进行加权优化，将改写为：其中，ω以带宽B为变量，表示为ω与带宽成比例，ω的值介于0和1之间，k控制ω的平滑度，当带宽较小时，延迟在目标函数中的权重较大，而当带宽较大时，量化损失的权重较大；加权优化后的目标函数为：在连续区域上找到所述目标函数的松弛问题的最优解x，把最优解x推广到离散域，设最优解x的下取整为上取整为如果则潜在最优解为否则为潜在最优解X为连续域上的最优解取整得到，对取整后的最优解X进行判断，将X层的累积推理延迟和数据传输延迟，即tedge+ttrans，与仅边缘或仅云推理时延进行比较，即min,ttrans)，当tedge+ttrans＜min,ttrans)时，X被确定为最佳分割点；否则，该算法从X开始搜索分割点的集合以找到tedge+ttrans＜min,ttrans)最接近X的最佳分割点X*。优选地，所述的根据所述最优分割点将所述DNN模型进行分割后，分别在终端设备和云上执行任务推理，并得到推理结果，包括：在从调度器获得最优分割点之后，执行器组件基于所述最优分割点对所述DNN模型进行分割，分割后得到的部分量化模型在终端设备执行，在终端设备执行模型推理任务，终端设备输出模型推理结果到云，剩余的模型在云上执行，在云上继续执行模型推理任务后得到模型推理结果。由上述本发明的实施例提供的技术方案可以看出，本发明方法将分割后的模型进一步轻量化，进一步减少部署所需计算和存储资源，并进一步加快推理速度。本发明还考虑到模型轻量化带来的精度损失，将精度损失和时延根据网络质量的变化进行加权优化以满足用户在不同的网络质量下对服务质量的不同需求。本发明附加的方面和优点将在下面的描述中部分给出，这些将从下面的描述中变得明显，或通过本发明的实践了解到。附图说明为了更清楚地说明本发明实施例的技术方案，下面将对实施例描述中所需要使用的附图作简单地介绍，显而易见地，下面描述中的附图仅仅是本发明的一些实施例，对于本领域普通技术人员来讲，在不付出创造性劳动的前提下，还可以根据这些附图获得其他的附图。图1为本发明实施例提供的一种实时自适应云边协同深度推理框架示意图；图2为本发明实施例提供的一种构建表示DNN模型的有向无环图示意图；图3为本发明实施例提供的一种最小割搜索方法搜索所有割点的示意图；图4为本发明实施例提供的一种用凸函数f、g和h分别表示累积推理时延、数据传输延迟和累积量化损失的示意图；图5为本发明实施例提出了一种分割算法的处理步骤示意图。具体实施方式下面详细描述本发明的实施方式，所述实施方式的示例在附图中示出，其中自始至终相同或类似的标号表示相同或类似的元件或具有相同或类似功能的元件。下面通过参考附图描述的实施方式是示例性的，仅用于解释本发明，而不能解释为对本发明的限制。本技术领域技术人员可以理解，除非特意声明，这里使用的单数形式“一”、“一个”、“所述”和“该”也可包括复数形式。应该进一步理解的是，本发明的说明书中使用的措辞“包括”是指存在所述特征、整数、步骤、操作、元件和/或组件，但是并不排除存在或添加一个或多个其他特征、整数、步骤、操作、元件、组件和/或它们的组。应该理解，当本发明实施例称元件被“连接”或“耦接”到另一元件时，它可以直接连接或耦接到其他元件，或者也可以存在中间元件。此外，这里使用的“连接”或“耦接”可以包括无线连接或耦接。这里使用的措辞“和/或”包括一个或更多个相关联的列出项的任一单元和全部组合。本技术领域技术人员可以理解，除非另外定义，这里使用的所有术语具有与本发明所属领域中的普通技术人员的一般理解相同的意义。还应该理解的是，诸如通用字典中定义的那些术语应该被理解为具有与现有技术的上下文中的意义一致的意义，并且除非像这里一样定义，不会用理想化或过于正式的含义来解释。为便于对本发明实施例的理解，下面将结合附图以几个具体实施例为例做进一步的解释说明，且各个实施例并不构成对本发明实施例的限定。模型分割：模型分割技术旨在根据不同粒度对DNN进行分割，根据性能需求和模型资源消耗自动寻找最佳分割点，将DNN的不同网络层部署至云和多台边缘设备上运行，实现云和边缘设备的协同计算。云边协同推理：云边协同推理旨在通过最小化云-边之间的网络时延或能耗来寻找到DNN模型分割的最优分割点，以网络层为粒度自动对深度学习模型进行分割并分别部署到边缘设备和云端，通过设备间的协作实现高效的DNN模型推理。本发明实施例提供的一种面向海量数据实时处理的云边协同自适应深度推理方法的基本设置和问题定义如下：考虑具有N层的DNN，其中Z为非负整数集。设B为网络带宽。用di表示第i层的输出数据大小。定义1：设代表第i层的数据传输延迟。定义2：让表示在终端设备上执行DNN的第i层的推理延迟。因为终端设备和云的计算能力差距很大，所以本发明实施例忽略了云上的推理延迟。为了测量量化误差，本发明实施例首先将wi和ai表示为第i层给定位宽的权重和激活。然后通过使用均方误差函数MSE，分别用和来表示第i层的权重和激活的量化误差。定义3：设代表第i层的量化权重损失和激活的总和，即本发明实施例提出的一种面向海量数据实时处理的云边协同自适应深度推理方法的处理流程如图1所示，包括如下的处理步骤：步骤S10、首先将需要部署的DNN模型进行模型量化，减少模型在资源受限的终端设备上部署所需的计算和存储资源。步骤S20、根据得到的量化模型对该DNN模型进行有向无环图DAG构建，将DNN模型变为可以用图论进行处理的有向无环图，以便对多分支网络进行分析处理。步骤S30、根据步骤S20得到的DAG，我们对该DAG网络进行可行分割点的搜索。该步骤中我们独创了可行分割点的搜索方法，首先找到DAG中的所有割点，将符合约束的割点加入到潜在分割点集，并将割点之间的部分模型用最小割方法找到输出数据量最小的割点集加入到潜在分割点集。然后对潜在分割点集进行优化处理，去除连续且数据输出量相等的点。步骤S40、根据步骤S30得到的优化后的潜在分割点集和DNN模型各层在终端设备运行的时延、输出数据量以及量化精度损失进行数据拟合，将离散的数据拓展到连续域上，分别得到DNN模型各层的累计时延、数据输出量和累计精度损失函数以便后续的优化。步骤S50、对步骤S40中得到的目标函数进行加权优化。我们提出了以带宽为变量的权重函数，该函数可以根据带宽的变化实时的改变权重的大小，对时延和精度损失进行加权联合优化。求解该优化问题得到最优的分割点，并将最优分割点拓展到离散域并利用提出的优化算法进行微调得到网络模型的最优分割点。步骤S60、根据步骤S50得到的最优分割点，将DNN模型进行分割，分别部署到终端设备和云上进行任务推理，并得到推理结果。基于上述定义，本发明实施例将该问题公式化为一个非线性整数优化问题。本发明实施例的目标是随着网络质量的变化，通过自适应联合优化来最小化加权延迟和损失。目标函数：假设DNN在x层分割，那么本发明实施例可以将目标函数定义如下：其中表示从输入层到第x层的累积推理延迟，是第x层的数据传输延迟，是从输入层到第x层的累积量化损失。当DNN的部分在云上执行时，使用原始位宽，以避免量化误差。如果所有层都在云上执行，即x＝0，则本发明实施例将延迟和丢失的和函数公式化为其中自变量x是DNN的分割层。本发明实施例将定义为：为了简化计算，本发明实施例通过最小-最大方法归一化延迟和损失，使式中各值具有相同的数值维度，定义为其中X分别代表标准化前tedge、ttrans和lquant的值。Xmin和Xmax分别表示tedge、ttrans和lquant中的最小和最大值。Xnormal表示归一化值，介于0和1之间。本发明实施例提出了一种如图1所示的实时自适应云边协同深度推理框架来进一步提高推理性能。RAP优化模型划分并加速决策制定，以满足动态带宽环境中的延迟要求，同时考虑推理的准确性。如图1所示，RAP分为两个阶段：线下阶段和线上阶段。在离线阶段的开始，RAP量化一个预先训练好的DNN。接下来，基于量化的DNN构建DAG。随后，分割点生成器组件在模型中找到一组潜在的分割点。最后，评估每层的延迟、输出数据大小和量化损失，并将其拟合到潜在分割点集合上的连续域，用于后续优化。在在线阶段，调度器获得在离线阶段生成的数据，用于在线最佳分割点选择。然后，执行器在分割点分割DNN，进行云边协同推理。预定训练的DNN，量化器将原始DNN的权重和激活量化为8比特。为了减少量化带来的损失，本发明实施例只在终端设备上部署量化模型，在云上部署原始网络。量化模型可以减少存储空间，加快推理速度。但这里只考虑量化造成的各层误差。在终端设备上执行的层数越多，由量化引起的累积误差就越大。因此，误差取决于终端设备上运行的DNN层的数量，并会对最终分割点选择产生影响。DAG构造器和分割点生成器：在从原始DNN导出量化模型之后，RAP旨在通过分析每层的输出数据大小来收集一组潜在分割点DNN模型通常包含多个层，一层的输出被输入到下一层。对于链式拓扑DNN，所有层都是一对一的结构，因此不需要构建DAG。链式拓扑DNN的每一层都可能成为潜在的分割点，所以只需要分析每一层的输出数据大小。对于DAG DNN，由于DAG DNN中有多个分支，拆分DAG DNN可能涉及多个层，因此需要构建DAG进行分析。为了在DAG DNN中找到潜在分割点集合RAP首先将DNN构建为DAG，图2为本发明实施例提供的一种构建表示DNN模型的DAG示意图，如图2所示。通常，给定一个DNN模型，本发明实施例构造一个DAGG＝＜V,E＞来表示它。每个顶点vi∈V对应DNN的某一层。有向边ei＝＜vi,vj＞∈E表示vj把vi的输出作为它自己的输入。本发明实施例使用di来表示每条边ei的值，其中di表示vi的输出数据大小。注意，本发明实施例将输入层作为v0，将e0＝＜v0,v1＞的值d0作为原始输入数据大小。图3为本发明实施例提供的一种最小割搜索方法搜索所有割点的示意图。最小割搜索方法首先搜索所有割点，即黑框内的顶点。然后，在逻辑块内，找到最小数据输出大小。满足约束的割点和逻辑块内最小割点被添加到分割点集合中。分割点生成器。如在现有的研究中，潜在分割点集的冗余将导致过大的搜索空间。因此，本发明实施例利用分割点生成器提出了潜在分割点寻找方法，以有效地找到潜在分割点集。对于DAG DNN，本发明实施例首先搜索DAG中的所有割点。割点被定义为DAG中的顶点，移除割点将使得DAG不再连接。如图3示，虚线框中的顶点是割点。如果删除其中一个割点，DAG将被分成两部分，并且没有连接输入顶点s和输出顶点t的路径。此外，DAG DNN中通常有多个多分支结构，例如ResNet中的残差块，这些块被称为逻辑块，如图3中的实线框所示。如果在一个逻辑块内分割模型，则需要分割多个层。因此，在第二阶段，本发明实施例考虑逻辑块内的潜在分割点。本发明实施例使用最小割方法在由一个或几个顶点组成的逻辑块中找到具有最小输出数据大小的分割点，如图3中的竖实线所示。在这种方法中，在一个逻辑块中只找到一个潜在的分割点。所有割点和逻辑块内的所有最小割点分别构成割点集和最小割集。如果输出数据大小满足di＜d0，则将割点集中的潜在分割点添加到中。在最小割集中，当时，潜在分割点也被添加到其中是通过最小割方法获得的逻辑块内的输出数据大小的最小和。这确保了分割点处的输出数据大小小于原始输入数据大小。否则，传输原始输入数据到云并在云上执行DNN会更好。对于链拓扑DNN，处理方法与DAG DNN类似，本发明实施例选择其输出数据大小小于原始输入大小的所有层，以将它们添加到分割点集中。此外，对于链式拓扑DNN和DAGDNN，本发明实施例移除中连续并具有相同输出数据大小的分割点。例如，相邻的CONV层和BN层具有相同的输出数据大小，并且都小于原始输入数据大小。本发明实施例从潜在分割点集中删除BN层。因为当输出数据大小相同时，选择更靠近输入层的分割点，这样的分割点在边缘设备上具有较少的累积推断延迟和累积损失并且对搜索空间进行了优化。在根据RAP框架在边-云上部署DNN之前，将在终端设备上获得推理延迟、输出数据大小和由每层量化引起的损失。Profiler将离散数据拟合到连续域，并为在线阶段的快速决策做准备。在连续域中，本发明实施例提供的一种用凸函数f、g和h分别表示累积推理时延、数据传输延迟和累积量化损失的示意图如图4所示，图4为中间数据输出量在连续域的拟合曲线示意图，图4为累积推理时延在连续域的拟合曲线示意图，图4为累积量化损失在连续域的拟合曲线示意图。在潜在分割点的集合中，输出数据大小g通常随x呈指数递减，累积计算时间f和累积损失h通常呈线性递增。基于上述观察，本发明实施例假设f和h是递增的线性函数，g是递减的凸函数。目标函数可以重写为：当f，g，h都是凸函数时，和函数仍然是凸的。因此，的优化是一个凸优化问题。自适应优化：本发明实施例对影响用户体验的因素进行联合分析，考虑到用户对服务质量的要求可能会随着网络环境的变化而变化。当网络质量较差时，用户对低时延要求较高，适当的精度损失是可以接受的。但是当网络质量好的时候，传输延迟不是主要因素，那么更高的推断准确率就成为用户更好的选择。因此，本发明实施例在目标函数中对时间延迟和损失进行加权，以实现自适应优化。可以改写为：其中，ω以带宽B为变量，可表示为ω与带宽成比例，ω的值介于0和1之间，k控制ω的平滑度。当带宽较小时，延迟在目标函数中的权重较大，优化更倾向于减少延迟以加快推理速度。而当带宽较大时，量化损失的权重较大，优化倾向于减少损失以提高推理精度。这样，本发明实施例改变延迟和损失的权重，以实现适应网络质量变化的不同优化。此外，为防止损失过大，本发明实施例对量化损失也进行了约束。公式化：概括地说，问题可以基于目标函数以及约束公式化为了在网络质量变化时快速确定最佳分割点，本发明实施例提出了一种分割算法来有效地寻找最佳分割点，该分割算法的处理步骤如图5所示，包括如下的处理过程：首先在连续区域上找到目标函数的松弛问题的最优解x。然后把结果推广到离散域。设最优解x的下取整为上取整为如果则潜在最优解为否则为因为通过舍入将结果从连续域扩展到离散域，所以舍入的结果可能不再是最优的。更重要的是，本发明实施例考虑了丢失的影响，它可能导致推理时延和传输时延之和大于仅边缘或仅云推理的方法。作为解决方案，本发明实施例施加了进一步的约束，以确保低延迟并微调舍入结果。因为微调不会使损失发生太大的变化，所以本发明实施例只用延时作为微调的依据。本发明实施例将X层的累积推理延迟和数据传输延迟，即tedge+ttrans，与仅边缘或仅云推理时延进行比较，即min,ttrans)。当tedge+ttrans＜min,ttrans)时，X被确定为最佳分割点。否则，该算法从X开始搜索分割点的集合以找到tedge+ttrans＜min,ttrans)最接近X的最佳分割点X*。这样，本发明实施例可以确保所选择的分割点优于仅边缘或仅云推断，并避免由函数拟合引起的误差。由于误差的影响，本发明实施例选择的拆分点可能不是最优的延迟解决方案，但它仍然可以保证拆分点的延迟优于仅边缘解决方案或仅云解决方案，并且本发明实施例还可以快速决定最佳分割点。在从调度器获得最优分割点之后，执行器组件基于最优分割点对DNN模型进行分割，分割后得到的部分量化模型在终端设备执行，在终端设备执行模型推理任务，终端设备输出模型推理结果到云，剩余的模型在云上执行，在云上继续执行模型推理任务后得到模型推理结果。综上所述，本发明使用模型分割的方法，对DNN模型进行分割，将分割的不同部分分别在终端和云端执行，这样即可以充分利用终端设备和云的计算存储能力，提高推理性能，减少推理时延并且可以避免模型轻量化方法带来的推理精度损失。本发明设计的方法将分割后的模型进一步轻量化，进一步减少部署所需计算和存储资源，并进一步加快推理速度。本发明还考虑到模型轻量化带来的精度损失，将精度损失和时延根据网络质量的变化进行加权优化以满足用户在不同的网络质量下对服务质量的不同需求。本发明通过简化分割点的搜索空间和采用复杂度低的决策算法来加快决策速度，减少决策时延，始终保持当前网络质量下的分割点最优，在最优分割点下推理性能最优。本领域普通技术人员可以理解：附图只是一个实施例的示意图，附图中的模块或流程并不一定是实施本发明所必须的。通过以上的实施方式的描述可知，本领域的技术人员可以清楚地了解到本发明可借助软件加必需的通用硬件平台的方式来实现。基于这样的理解，本发明的技术方案本质上或者说对现有技术做出贡献的部分可以以软件产品的形式体现出来，该计算机软件产品可以存储在存储介质中，如ROM/RAM、磁碟、光盘等，包括若干指令用以使得一台计算机设备执行本发明各个实施例或者实施例的某些部分所述的方法。本说明书中的各个实施例均采用递进的方式描述，各个实施例之间相同相似的部分互相参见即可，每个实施例重点说明的都是与其他实施例的不同之处。尤其，对于装置或系统实施例而言，由于其基本相似于方法实施例，所以描述得比较简单，相关之处参见方法实施例的部分说明即可。以上所描述的装置及系统实施例仅仅是示意性的，其中所述作为分离部件说明的单元可以是或者也可以不是物理上分开的，作为单元显示的部件可以是或者也可以不是物理单元，即可以位于一个地方，或者也可以分布到多个网络单元上。可以根据实际的需要选择其中的部分或者全部模块来实现本实施例方案的目的。本领域普通技术人员在不付出创造性劳动的情况下，即可以理解并实施。以上所述，仅为本发明较佳的具体实施方式，但本发明的保护范围并不局限于此，任何熟悉本技术领域的技术人员在本发明揭露的技术范围内，可轻易想到的变化或替换，都应涵盖在本发明的保护范围之内。因此，本发明的保护范围应该以权利要求的保护范围为准。
