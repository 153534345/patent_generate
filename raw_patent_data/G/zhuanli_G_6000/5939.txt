标题title
基于二分类张量增强的多分类语义分割方法
摘要abst
本发明提供一种基于二分类张量增强的多分类语义分割方法，包括步骤：将需要将分类的图片输入至原始分割网络中；由原始分割网络的特征提取部分进行特征提取，将提取的特征并行输入至N个二分类头以及中转部分；N个二分类头对输入的特征分别进行二分类处理输出N个二分类张量，中转部分输出待分类特征；将N个二分类前景分数图与待分类特征进行级联，级联张量最后送入多分类头，多分类头对输入的级联张量进行N分类处理并输出N分类张量作为最终的多分类结果。本发明可以简单地加入到多数分割网络结构中，仅带来少量的网络参数量增加。相较于直接用CE损失优化多分类头结果的方法，本发明方法能在增加少量参数消耗的情况下提升分割网络的分类性能。
权利要求书clms
1.基于二分类张量增强的多分类语义分割方法，其特征在于，包括步骤：1)将需要将分类的图片输入至原始分割网络中；原始分割网络包括特征提取部分与一个多分类头；2)由原始分割网络的特征提取部分进行特征提取，将提取的特征并行输入至N个二分类头以及中转部分；3)N个二分类头对输入的特征分别进行二分类处理输出N个二分类张量，中转部分保持输入特征的通道数，输出待分类特征；4)将N个二分类前景分数图与待分类特征进行级联，级联张量最后送入多分类头，多分类头对输入的级联张量进行N分类处理并输出N分类张量作为最终的多分类结果。2.如权利要求1所述方法，其特征在于，训练过程实现多分类方法的整个网络采用的损失函数L为：L＝LCE+α·LBCE+β·LB2M；其中，LCE与LBCE分别是多分类头和二分类头的交叉熵损失，α和β是超参数；LB2M为强化二分类张量支援属性的损失，LB2M＝Loverlap+Lmissing；Loverlap为反映二分类中不合理交叠的损失项，Lmissing为反映二分类中缺失预测的损失项。3.如权利要求2所述方法，其特征在于，反映二分类中不合理交叠的损失项Loverlap的具体计算方法为：其中，C表示当前输入图片中所含真值类别的数目；对于所含的第i个真值类别，li对应表示该类别标签的序号，f表示对输入x的非线性映射，f＝δ-δ，δ表示Sigmoid函数，k和b为超参数；Overlap为其他类别在第li个类别对应的真值区域的交叠程度。4.如权利要求2所述方法，其特征在于，反映二分类中缺失预测的损失项Lmissing的具体计算方法为：其中，sum表示对所有元素求和，*表示对应位置元素相乘，表示第li个类别对应的二分类预测分数，表示二分类真实标签。5.如权利要求1所述方法，其特征在于，原始分割网络为HRNetV2。
说明书desc
技术领域本发明涉及多分类技术，特别涉及一种基于二分类张量增强支援多分类分割的技术。背景技术随着硬件算力与深度学习的不断发展，对图像的高精度像素级处理的需求愈加普遍。图像分割作为计算机视觉中最为常见的视觉任务，依托深度神经网络可以实现对图像的像素级分类。在许多应用场景中，图像分割是处理流程中不可或缺的一环，如自动驾驶、增强现实等，分割的结果直接影响了下游处理的效果。本发明主要致力于增强分割网络的分类环节，从而提升分割效果。多数实现语义分割的网络最终仅通过交叉熵损失优化最终输出的多分类张量，在多数任务中取得了相对较好的分割结果。然而由于CE损失仅激励正确类别上的预测分数，容易忽略对相似类别分数的抑制，进而容易导致网络在分辨相似类别时产生混淆。尤其是在人体解析等具体下属任务中，混淆类别带来的误分类对网络的影响显得不可忽视。使用二分类头支援多分类头可以增加分割网络的分类能力，但各个类别的二分类预测之间的关系难以通过BCE损失得到反映，故二分类头的输出张量可以再进一步通过新的损失约束，实现对最终结果更好的支援。发明内容本发明所要解决的技术问题是，提供一种新型损失对二分类张量进行优化，使得二分类张量可以更好支援语义分割网络的最终结果，实现到多分类结果更好的支援的方法。本方法旨在减少二分类张量中不正确类别的预测在各个真值区域的二分类分数，以及进一步加强各个真值区域内正确预测的分数。另外，本发明旨在进一步提高分割网络对相似类别的分类能力。通过对已有网络结构增加简单的二分类头，对损失进行优化，从而提升二分类张量对最终结果的支持效果，进一步提升最终分割结果的平均交并比。本发明为解决上述技术问题所采用的技术方案是，基于二分类张量增强的多分类语义分割方法，包括步骤：1)将需要将分类的图片输入至原始分割网络中；原始分割网络包括特征提取部分与一个多分类头；2)由原始分割网络的特征提取部分进行特征提取，将提取的特征并行输入至N个二分类头以及中转部分；3)N个二分类头对输入的特征分别进行二分类处理输出N个二分类张量，中转部分保持输入特征的维度并进行简单的特征转换，输出待分类特征；4)将N个二分类前景分数图与待分类特征进行级联，级联张量最后送入多分类头，多分类头对输入的级联张量进行N分类处理并输出N分类张量作为最终的多分类结果。进一步的，训练过程实现多分类方法的整个网络采用的损失函数L为：L＝LCE+α·LBCE+β·LB2M；其中，LCE与LBCE分别是多分类头和二分类头的交叉熵损失，α和β是超参数；LB2M为强化二分类张量支援属性的损失，LB2M＝Loverlap+Lmissing；Loverlap为反映二分类中不合理交叠的损失项，Lmissing为反映二分类中缺失预测的损失项。本发明的有益效果是，可以简单地加入到多数分割网络结构中，仅带来少量的网络参数量增加，改进策略可以提高分割网络结果的平均交并比，通过设计的B2M损失对简易二分类头的输出张量进一步约束。相较于直接用CE损失优化多分类头结果的方法，本发明方法能在增加少量参数消耗的情况下提升分割网络的分类性能。附图说明图1：本发明多分类示意图；图2：发明中使用的网络示意图；图3：二分类头的结构图。具体实施方式由于语义分割任务可视为逐个像素的分类任务。设标签种类有N类，常规的语义分割网络最终通过多分类头对每个像素进行N分类。考虑到二分类头能够协助N分类头进行分类，申请人提出了一种通过强化二分类张量的特性进而提升分割效果的改进策略。结构上通过设计一个简单的二分类头与一个中转部分；损失上设计了一种强化二分类张量支援属性的损失，名为B2M损失。如图1所示，我们选择HRNetV2作为实施改进策略的baseline网络。首先，我们将原分割网络中要通过多分类头的张量同时送进多个并行二分类头和一个中转部分，多个并行二分类头用于N分类问题转化为N个二分类问题并输出N个二分类结果，中转部分用于保持待分类张量的通道数，输出待分类的特征，再将N个二分类结果与待分类的特征级联，级联张量最后送入多分类头，多分类头用于输出最终的N分类结果。多分类头结构在原网络设计的基础上增加N个输入通道以配合级联中加入的二分类张量。对于网络的训练，网络的最终结果仍然使用CE损失优化；二分类张量的优化除了采用BCE损失外，还需要使用提出的B2M损失。我们通过将N分类问题转化为N个二分类问题，进而从多分类真值标签得到二分类头的真值标签g1,g2...gN。输入一张图片，二分类头会输出N张二分类前景分数图，每张前景分数图对应一个类别，其中第k张记为pk，pk∈H×W,k＝1,2...N,H和W分别是分数图的高和宽，其对应真值gk∈{0,1}H×W。pk中前景分数大于0.5的区域为前景区域，记输入图片中实际存在的标签类别的序号为l1,l2...lC，C为一张图片中所含真值类别的数目。由于仅靠BCE损失优化，二分类张量中各个类别的分数图相互独立，这使得该张量在不同类别上预测的前景区域可能存在交叠或缺失，即二进制张量上的某些像素在一类以上的预测分数高于0.5或所有类别上都小于0.5。这种各类前景区域的交叠与缺失会弱化对相应位置多分类结果的支援。对于第li类的预测，我们通过如下公式计算出其他类别在其对应的真值区域的交叠程度Overlap，其中“sum”表示对所有元素求和，“*”表示对应位置元素相乘：得到交叠程度Overlap后，将其通过如下的非线性映射，其中“σ”表示Sigmoid函数，k和b为超参数：f＝σ-σ 依次对C个类别的交叠程度映射后，在类别上取平均，我们得到了B2M损失的第一项，记为Loverlap，该损失项主要针对二分类预测中不合理交叠的抑制：对于缺失预测的区域，我们采用类似计算交并比的方法进一步增强真值区域的正确分数。记该项损失为Lmissing，计算方式如下：由此可计算所提出的B2M损失，即LB2M：LB2M＝Loverlap+Lmissing 整个网络的损失函数如下，LCE与LBCE分别是多分类头和二分类头的交叉熵损失，α和β是超参数：L＝LCE+α·LBCE+β·LB2M 本发明在含有8个TITAN X PASCAL的服务器上进行实现，网络采用HRNetV2作为baseline，如图2所示。网络整体主要包含了主干网络backbone，二分类环节binaryclassitication head和多分类环节multi-classitication head。主干网络为HRNetV2-W48，用于提取特征；二分类头结构如图3所示，中转部分transformation part与二分类头的结构相似，都是由2个1×1卷积层、一个批标准化Batch Normalization层和一个激活函数Relu层构成，二者仅在末尾卷积层的输出通道数上有区别；多分类头结构与baseline类似。设计策略的主要步骤体现在：利用轻量二分类头获得二分类张量，计算各真值类别对应的交叠程度并在类别上取均值，计算各真值类别在真值区域的平均分数并在类别上取均值，利用这两个均值对二分类张量进行优化。下面结合实验结果说明本发明的效果，语义分割中人体解析任务的数据集有较多的相似类别，故选择如下三个数据集用于实验。baseline和采用策略改进后的网络在训练和测试都使用了相同的实验条件：表1在三个数据集上的mIoU对比实验本方法在三个数据集上较原分割网络都对mIoU有较为明显的提升，由此可见该策略对网络性能提高的有效性。
