标题title
一种基于分布式联邦学习的云边网络通信优化方法及系统
摘要abst
本发明公开了一种基于分布式联邦学习的云边网络通信优化方法及系统，方法包括以下步骤：步骤A、构建分布式联邦学习框架下的云边网络框架，包括了主从结构模式下运行的分布式联邦学习和完全去中心化的分布式联邦学习两种模式；步骤B、建立主从结构分布式联邦学习模式的模型；步骤C、建立去中心化联邦学习模式的模型，并在该模式下实现异步训练算法；步骤D、建立去中心化异步模型训练场景下的边缘节点选择算法。本发明提高了大数据场景下云边网络结构的模型训练速度，降低了通信成本。
权利要求书clms
1.一种基于分布式联邦学习的云边网络通信优化方法，其特征在于：包括以下步骤：步骤A、构建分布式联邦学习框架下的云边网络框架，在基于传统中心服务器联邦学习的训练过程和框架模型的基础上，提出去中心化异步联邦学习架构；步骤B、建立主从结构分布式联邦学习模式的模型，包括最小化模型聚合的损失函数、分布式联邦学习的全局联合优化目标、分布式模型参数的梯度下降函数和参数更新过程；步骤C、建立去中心化联邦学习模式的模型，并在该模式下实现异步训练算法，包括在边缘节点异质化问题突出的情况下，如何从以主从结构的分布式联邦学习转化为去中心化的分布式联邦学习，并提出模式更新后的参数更新过程和联合优化目标；步骤D、建立去中心化异步模型训练场景下的边缘节点选择算法，用来优化分布式联邦学习目标函数的收敛速度，降低算法复杂度，避免陷入局部最优解。2.根据权利要求1所述的基于分布式联邦学习的云边网络通信优化方法，其特征在于：步骤A中所述的分布式联邦学习框架下的云边网络框架，包含了主从结构模式下运行的分布式联邦学习和完全去中心化的分布式联邦学习两种模式。3.根据权利要求1所述的基于分布式联邦学习的云边网络通信优化方法，其特征在于：步骤B中，边缘节点及其集合的表示为d∈D，云端服务器表示为ε，模型的损失函数表示为f，损失函数的梯度表示为Δf，模型训练的步长表示为η，节点d上的本地训练数据表示为Xd，节点d上的每轮训练时间的间隔为τd，模型聚合的权重表示为μ；在主从结构下分布式联邦学习的训练过程中，假设训练的模型包含一组参数用ω表示，这些参数通过本地训练数据并在云端聚合来学习，令ω*为模型训练的最优参数，则模型的学习过程就是最小化模型聚合的损失函数，表示为:ω*＝arg min f其中f为模型的损失函数，在深度学习模型中一般为交叉熵损失函数；假设Xd表示边缘节点d上的本地训练数据，ωd表示边缘节点的本地模型参数，可得主从结构下分布式联邦学习的全局联合优化目标为：其中ρ为二次惩罚项，接下来对单个节点的训练过程进行独立分析，在每轮训练中，模型采用梯度下降法从训练数据中学习更新的梯度，假设设备节点d的损失函数为fd，在时刻t的本地模型参数的梯度下降更新可以表示为：其中η表示训练步长，表示损失函数fd的梯度，当所有节点完成这一轮的本地模型训练后，节点将模型参数发送到云端进行参数聚合，可表示为：其中μ为模型聚合的权重，云端聚合的模型参数就是所有边缘节点的模型参数加权平均，并且对于全局模型的参数聚合，都是在每轮迭代的最后才进行的，再下发给每个训练节点执行下一轮的训练。4.根据权利要求1所述的基于分布式联邦学习的云边网络通信优化方法，其特征在于：步骤C中，假设在第t轮迭代中，节点d收到其他节点推送的模型更新用集合表示为则可以用数学公式表示参数更新过程为：其中η表示本地训练步长，μ表示模型聚合权重，由此可得，去中心化异步联邦学习的联合优化目标为：5.根据权利要求1所述的基于分布式联邦学习的云边网络通信优化方法，其特征在于：步骤C中，分布式异步联邦学习算法的流程如下：C1：初始并更新节点d的参数，ω0，d←ω0，t＝1，2，...，T；；C2：判断t≡0 modτd，若是，进入步骤C3；若否，进入步骤C1；C3：更新节点d的梯度，C4：基于反熵算法自适应选择新的节点集合j∈Jt；C5：推送模型参数C6：获取上一个时间τd内，其他节点推送的模型p∈Pt；C7：聚合6.根据权利要求1所述的基于分布式联邦学习的云边网络通信优化方法，其特征在于：步骤D中，边缘节点选择算法采用反熵算法。7.根据权利要求6所述的基于分布式联邦学习的云边网络通信优化方法，其特征在于：步骤D中，基于反熵算法的自适应节点选择算法流程如下：D1：设置模型损失函数；D2：计算损失函数训练前后误差；D3：计算模型推送概率并推送模型；D4：根据收到的模型进行聚合；D5：判断是否满足迭代次数？若是，结束；若否，跳到步骤D2。8.一种基于分布式联邦学习的云边网络通信优化系统，其特征在于，所述系统采用分布式联邦学习框架下的云边网络框架，所述云边网络框架包括多个边缘结点和云中心服务器，所述云中心服务器和边缘节点均有运算和训练机器学习模型的能力；所述云边网络框架包括主从结构模式下运行的分布式联邦学习和完全去中心化的分布式联邦学习两种模式；在主从结构的云边网络框架中，当分布式联邦学习在这种模式下运行时，联邦学习不集中收集用户数据，而是进行一系列步骤的迭代训练，首先每个设备节点在本地训练自己的参数模型并进行梯度更新，然后所有节点将训练过的模型参数发送到云端来聚合更新，最后云端下发更新后的参数到所有设备进行下一轮训练，重复迭代直到模型收敛；在完全去中心化的分布式联邦学习云边网络框架中，当分布式联邦学习在这种模式下运行时，可以避免中央服务器的同步参数聚合限制，在本地训练之后通过异步更新与其他设备进行信息交换，实现模型更新；同时在该模式下，采用反熵通信算法，来代替联邦学习中的中央服务器同步算法；节点可以自适应调整在时钟间隔下推送的节点数，在保证所有节点的最终一致性下，提高训练模型的收敛速度。
说明书desc
技术领域本发明涉及联邦机器学习技术领域，特别地涉及针对在省级智慧能源服务平台云边协同网络边缘节点上进行分布式人工智能模型训练场景的通信优化方法和系统，具体涉及一种基于分布式联邦学习的云边网络通信优化方法及系统。背景技术近年来，以深度学习为代表的机器学习技术的发展为人工智能技术的进步创造了动力。而随着物联网技术的发展，更多微型设备甚至移动设备都具备强大的芯片、传感器以及计算能力，能够在处理高级任务的同时，收集和产生更丰富的数据。以这些数据作为驱动，为机器学习创造了十分有利的基础条件。而在万物互联的时代，这些处于边缘的设备每分每秒都产生着数以亿计的数据，这些数据全部上传到云服务器会占用大量的网络带宽。同时，以云为中心的学习方式传输延迟高，不能及时进行数据交互，给网络带来不必要的负担。同时，数据所有者对隐私越来越注重，用户往往不愿共享自己的个人数据。许多国家和组织也制定了相关隐私政策，例如欧盟制定的《通用数据保护条例》。因此，利用一些边缘设备的计算和存储能力，把计算推向边缘被提出作为一种解决方案。因此，在应对需要并且可以并行处理大量数据的机器学习领域，联邦学习应运而生。其目的在于保护大数据环境下模型学习中涉及的用户数据隐私。在联邦学习训练过程中，只需要将所有边缘节点在其私有数据上训练的本地模型上传到云服务器中进行聚合，不涉及数据本身，很大程度上提高了用户数据的隐私性。同时，边缘计算的提出是为了缓解云中心的计算压力，目的是把云服务中心的计算任务卸载到边缘，这恰好与联邦学习的计算模式相适应，为联邦学习创造了有利条件。在边缘设备上训练模型，除了保证数据不离开本地，还能让计算更加靠近数据源以节省通信成本。省级智慧能源服务平台中边缘设备利用本地数据训练得到本地模型，再通过广域网传送到系统中的云端服务器。然而参与分布式学习的设备成千上万，边缘设备和云端服务器之间的大量通信必然会占用过多的带宽。同时，边缘设备的信号和能量状态也会影响与服务器的通信，导致产生网络延迟，消耗更多的通信成本。同时，升级智慧能源服务平台面向的用户对自身数据对于隐私有着高需求，因此也需要一种无需使自身数据离开本地的训练模式。因此为了提高训练过程中通信的实时性，满足用户的隐私需求，可以应用联邦学习来解决上述的问题。发明内容本发明的目的是提供一种基于分布式联邦学习的云边网络通信优化方法及系统，以解决省级智慧能源服务平台中应用机器学习模型的数据并行训练需求爆发式增长，带来的以云为中心网络通信负担，以及考虑大数据应用中的用户隐私要求的技术问题。为实现本发明的目的，本发明提供的技术方案如下：第一方面本发明实施例提供了一种基于分布式联邦学习的云边网络通信优化方法，包括以下步骤：步骤A、构建分布式联邦学习框架下的云边网络框架，在基于传统中心服务器联邦学习的训练过程和框架模型的基础上，提出去中心化异步联邦学习架构；步骤B、建立主从结构分布式联邦学习模式的模型，包括最小化模型聚合的损失函数、分布式联邦学习的全局联合优化目标、分布式模型参数的梯度下降函数和参数更新过程；步骤C、建立去中心化联邦学习模式的模型，并在该模式下实现异步训练算法，包括在边缘节点异质化问题突出的情况下，如何从以主从结构的分布式联邦学习转化为去中心化的分布式联邦学习，并提出模式更新后的参数更新过程和联合优化目标；步骤D、建立去中心化异步模型训练场景下的边缘节点选择算法，用来优化分布式联邦学习目标函数的收敛速度，降低算法复杂度，避免陷入局部最优解。其中，步骤A中所述的分布式联邦学习框架下的云边网络框架，包含了主从结构模式下运行的分布式联邦学习和完全去中心化的分布式联邦学习两种模式。其中，步骤B中，边缘节点及其集合的表示为d∈D，云端服务器表示为ε，模型的损失函数表示为f，损失函数的梯度表示为Δf，模型训练的步长表示为η，节点d上的本地训练数据表示为Xd，节点d上的每轮训练时间的间隔为τd，模型聚合的权重表示为μ；在主从结构下分布式联邦学习的训练过程中，假设训练的模型包含一组参数用ω表示，这些参数通过本地训练数据并在云端聚合来学习，令ω*为模型训练的最优参数，则模型的学习过程就是最小化模型聚合的损失函数，表示为:ω*＝arg min f其中f为模型的损失函数，在深度学习模型中一般为交叉熵损失函数；假设Xd表示边缘节点d上的本地训练数据，ωd表示边缘节点的本地模型参数，可得主从结构下分布式联邦学习的全局联合优化目标为：其中ρ为二次惩罚项，接下来对单个节点的训练过程进行独立分析，在每轮训练中，模型采用梯度下降法从训练数据中学习更新的梯度，假设设备节点d的损失函数为fd，在时刻t的本地模型参数的梯度下降更新可以表示为：其中η表示训练步长，表示损失函数fd的梯度，当所有节点完成这一轮的本地模型训练后，节点将模型参数发送到云端进行参数聚合，可表示为：其中μ为模型聚合的权重，云端聚合的模型参数就是所有边缘节点的模型参数加权平均，并且对于全局模型的参数聚合，都是在每轮迭代的最后才进行的，再下发给每个训练节点执行下一轮的训练。其中，步骤C中，假设在第t轮迭代中，节点d收到其他节点推送的模型更新用集合表示为则可以用数学公式表示参数更新过程为：其中η表示本地训练步长，μ表示模型聚合权重，由此可得，去中心化异步联邦学习的联合优化目标为：其中，步骤C中，分布式异步联邦学习算法的流程如下：C1：初始并更新节点d的参数，ω0，d←ω0，t＝1，2，...，T；C2：判断t≡0 mod τd，若是，进入步骤C3；若否，进入步骤C1；C3：更新节点d的梯度，C4：基于反熵算法自适应选择新的节点集合j∈Jt；C5：推送模型参数→节点j；C6：获取上一个时间τd内，其他节点推送的模型p∈Pt；C7：聚合其中，步骤D中，边缘节点选择算法采用反熵算法。其中，步骤D中，基于反熵算法的自适应节点选择算法流程如下：D1：设置模型损失函数；D2：计算损失函数训练前后误差；D3：计算模型推送概率并推送模型；D4：根据收到的模型进行聚合；D5：判断是否满足迭代次数？若是，结束；若否，跳到步骤D2。第二方面本申请实施例提供了一种基于分布式联邦学习的云边网络通信优化系统，所述系统采用分布式联邦学习框架下的云边网络框架，所述云边网络框架包括多个边缘结点和云中心服务器，所述云中心服务器和边缘节点均有运算和训练机器学习模型的能力；所述云边网络框架包括主从结构模式下运行的分布式联邦学习和完全去中心化的分布式联邦学习两种模式；在主从结构的云边网络框架中，当分布式联邦学习在这种模式下运行时，联邦学习不集中收集用户数据，而是进行一系列步骤的迭代训练，首先每个设备节点在本地训练自己的参数模型并进行梯度更新，然后所有节点将训练过的模型参数发送到云端来聚合更新，最后云端下发更新后的参数到所有设备进行下一轮训练，重复迭代直到模型收敛；在完全去中心化的分布式联邦学习云边网络框架中，当分布式联邦学习在这种模式下运行时，可以避免中央服务器的同步参数聚合限制，在本地训练之后通过异步更新与其他设备进行信息交换，实现模型更新；同时在该模式下，采用反熵通信算法，来代替联邦学习中的中央服务器同步算法；节点可以自适应调整在时钟间隔下推送的节点数，在保证所有节点的最终一致性下，提高训练模型的收敛速度。与现有技术相比，本发明的有益效果如下：针对机器学习中大数据处理的问题，充分利用了云边网络的通信结构，利用云边网络架构的边缘节点力资源，通过联邦学习分配机器学习数据训练任务，减轻云中心服务器运算负担，同时缓解数据上传时带来的通信压力，解决传输延迟带来的数据交互效率低的问题。针对传统联邦学习的云中心服务器架构中容易出现的网络阻塞、数据隐私泄露等问题，提出了基于反熵算法的去中心化异步模型训练方案，通过节点间彼此分散的并行任务执行及节点模型推送聚合实现协作训练，进一步提高了云边网络训练和通信效率的平衡，同时加强了对用户隐私的保护。针对经典反熵算法下模型训练收敛慢的问题，提出了基于自适应反熵算法的去中心化异步边缘联邦学习算法，借鉴了模拟退火算法对训练模型推送节点的选择概率进行自适应调整，实现分布式边缘节点间的完全去云化模型训练，加快训练模型收敛性。附图说明图1是本发明基于分布式联邦学习的云边网络架构图；图2是本发明分布式异步联邦学习算法的流程图；图3是本发明基于反熵算法的自适应节点选择算法流程图。具体实施方式下面结合本发明实施例中的附图，对本发明实施例中的技术方案进行清楚、完整地地描述，显然，所描述的实施例仅仅是本发明一部分实施例，而不是全部的实施例。基于本发明中的实施例，本领域普通技术人员在没有做出创造性劳动前提下所获得的所有其他实施例，都属于本发明保护的范围。参照图1，本发明实施案例提供一种基于分布式联邦学习的云边网络通信优化方法，包括如下步骤：步骤A、构建分布式联邦学习框架下的云边网络框架，在基于传统中心服务器联邦学习的训练过程和框架模型的基础上，提出去中心化异步联邦学习架构。传统中心服务器联邦学习的训练过程，包括本地模型的梯度下降更新以及全局模型的聚合更新过程的数学表示，这也代表了分布式中心同步训练算法的基本流程。如附图1所示是基于分布式联邦学习的云边网络架构的示意图，左边五个节点代表边缘结点的计算集群，右边代表云中心服务器。云中心和边缘节点均有运算和训练机器学习模型的能力。虚线部分代表主从结构的云边网络通信架构，当分布式联邦学习在这种模式下运行时，联邦学习不集中收集用户数据，而是进行一系列步骤的迭代训练。首先每个设备节点在本地训练自己的参数模型并进行梯度更新，然后所有节点将训练过的模型参数发送到云端来聚合更新，最后云端下发更新后的参数到所有设备进行下一轮训练，重复迭代直到模型收敛。实现部分代表完全去中心化的分布式联邦学习云边网络通信架构，当分布式联邦学习在这种模式下运行时，可以避免中央服务器的同步参数聚合限制，在本地训练之后通过异步更新与其他设备进行信息交换，实现模型更新。同时在该模式下，本发明采用分布式领域中广泛使用的反熵通信算法，来代替联邦学习中的中央服务器同步算法。这是一种不需要云端聚合模型的完全分布式算法，通过两两节点对之间的信息交换来传播信息。本发明在每个节点在每个时钟间隔用推送的方式将自身信息传递给其他节点，并采用了异步时钟模型。本发明对反熵信息交换的推送过程进行了改进，使节点可以自适应调整在时钟间隔下推送的节点数，在保证所有节点的最终一致性下，提高训练模型的收敛速度。步骤B、建立主从结构分布式联邦学习模式的模型，包括最小化模型聚合的损失函数，分布式联邦学习的全局联合优化目标，分布式模型参数的梯度下降函数和参数更新过程。然后将在下一个步骤建立去中心化联邦学习模式下异步训练算法的基本流程。在说明模型数学含义之前，首先说明几组通用的符号表示：边缘节点及其集合的表示为d∈D,云端服务器表示为ε，模型的损失函数表示为f，损失函数的梯度表示为Δf，模型训练的步长表示为η，节点d上的本地训练数据表示为Xd，节点d上的每轮训练时间的间隔为τd，模型聚合的权重表示为μ。在主从结构下分布式联邦学习的训练过程中，假设训练的模型包含一组参数用ω表示，这些参数通过本地训练数据并在云端聚合来学习。令ω*为模型训练的最优参数，则模型的学习过程就是最小化模型聚合的损失函数，表示为:ω*＝arg min f其中f为模型的损失函数，在深度学习模型中一般为交叉熵损失函数。假设Xd表示边缘节点d上的本地训练数据，ωd表示边缘节点的本地模型参数，可得主从结构下分布式联邦学习的全局联合优化目标为：其中ρ为二次惩罚项。接下来对单个节点的训练过程进行独立分析，在每轮训练中，模型采用梯度下降法从训练数据中学习更新的梯度，假设设备节点d的损失函数为fd，在时刻t的本地模型参数的梯度下降更新可以表示为：其中η表示训练步长，表示损失函数fd的梯度。当所有节点完成这一轮的本地模型训练后，节点将模型参数发送到云端进行参数聚合，可表示为：其中μ为模型聚合的权重，可以注意到，云端聚合的模型参数就是所有边缘节点的模型参数加权平均，并且对于全局模型的参数聚合，都是在每轮迭代的最后才进行的，再下发给每个训练节点执行下一轮的训练。由于不同节点的性能差异，执行训练速度快的节点需要等待云端获取到所有节点的模型参数，之后云端聚合参数并下发给每个节点，才能开始下一轮迭代。步骤C、建立去中心化联邦学习模式的模型，并在该模式下实现异步训练算法，包括在边缘节点异质化问题突出的情况下，如何从以主从结构的分布式联邦学习转化为去中心化的分布式联邦学习，并提出模式更新后的参数更新过程和联合优化目标。为了加快模型训练的速度，采用反熵算法来实现去中心化分布式联邦学习的转换，本发明实现了该算法在异步通信条件下的实现。在说明算法前，先解剖本发明异步通信实现原理：对于反熵算法的异步时钟模型，假设每个边缘节点维系一个本地时钟，每隔固定时间发起信息交换。在去中心化分布式联邦学习模型训练场景下，信息交换的时间间隔就是节点的一轮迭代训练间隔，信息交换的内容就是节点本轮训练后的模型参数。由于每个节点的可用计算资源不同，训练的时间间隔也不相同，并且节点之间交换信息的过程是独立的。具体来说，去中心结构下的分布式联邦学习中，在节点每轮迭代的开始阶段，首先执行节点模型基于本地数据集的训练，这与主从结构下的联邦学习的过程基本相同。不同之处在于，当节点的本轮训练结束后，不是发送模型参数给服务器节点进行同步等待更新，而是主动将自己训练后的模型参数，按照某些算法推送给其他邻居训练节点，之后更新本地模型，并开始下一轮次的训练，而不需要等待同步响应。将在下一个步骤中详细介绍提出的模型推送的自适应节点选择算法。对于收到模型推送的节点，在自己当前轮次训练结束后，先根据收到的模型进行聚合，再使用新的模型开始下一轮次训练。由于每个节点在每个轮次的训练过程中，都有一定概率收到其他节点推送的模型，因此在每轮训练迭代的间隙，节点不断进行模型更新。假设在第t轮迭代中，节点d收到其他节点推送的模型更新用集合表示为则可以用数学公式表示参数更新过程为：其中η表示本地训练步长，μ表示模型聚合权重，由此可得，去中心化异步联邦学习的联合优化目标为：基于上面对于分布式异步联邦学习算法的描述，其算法流程图可见附图2。步骤C中，分布式异步联邦学习算法的流程如下：C1：初始并更新节点d的参数，ω0，d←ω0，t＝1，2，...，T；C2：判断t≡0 mod τd，若是，进入步骤C3；若否，进入步骤C1；C3：更新节点d的梯度，C4：基于反熵算法自适应选择新的节点集合j∈Jt；C5：推送模型参数→节点j；C6：获取上一个时间τd内，其他节点推送的模型p∈Pt；C7：聚合步骤D、建立去中心化异步模型训练场景下的边缘节点选择算法，用来优化分布式联邦学习目标函数的收敛速度，降低算法复杂度，避免陷入局部最优解。本发明采用反熵算法作为自适应节点选择算法，在经典反熵算法中，每个节点以固定的通信周期，采用推或拉的形式进行信息交换，在本发明中采用推的形式进行信息传递。在去中心化异步模型训练的场景下，实质上相当于多个模型在节点间的网络拓扑上进行随机漫步，并从每个节点的本地数据学习训练模型。为了加快训练过程，不同模型之间在漫步的过程中还会相互融合。上一个步骤中分布式异步联邦学习算法流程展示了单个节点的循环迭代训练，具体的实现来说就是在节点的每个本地训练周期τ，随机从网络上其他节点中选择p个对等节点，并推送本地信息到这些节点中，这些节点的本地训练周期结束后再进行模型融合，其中为了减少通信代价，p通常取很小的数目。固定的通信周期τ以及节点数p的选取很好的控制了模型交换的通信量，保证了模型的收敛速度。但在去中心化异步模型训练的场景下，节点的本地模型训练过程中使用的是随机梯度下降算法，模型训练的效果不是线性增长的，损失函数值的下降是随着模型接近最优解而逐渐趋于平缓的过程。如果采用固定的通信周期以及固定的推送节点数，节点间无差别的随机进行等量的模型交换，并不能达到最优的模型收敛效果。因此设计的算法决定不以固定的节点数进行模型交换，而是根据本地模型的训练损失来决定与其他节点进行模型交换的概率。借鉴了模拟退火算法的思想，对反熵算法中推送模型的节点数进行自适应选择，这是一种基于蒙特卡洛迭代求解的随机寻优算法。算法的原理是模拟物理中固体物质的退火过程，从较高的温度出发进行函数的随机寻优，并随着温度参数的下降减少随机性，逐步得到求解函数的近似最优解。这种算法在迭代过程中引入了随时间变化的概率函数，可以最终收敛于全局最优的结果，避免求解陷入局部极小区域。对于节点的梯度下降模型训练过程，在训练的前期迭代过程，节点的每轮训练都会导致损失函数值的迅速减小，从几何角度来说就是损失函数曲线的梯度下降幅度很大。因此在训练的前期迭代过程中，需要比较频繁的进行模型交换，使得每个节点都能从其他节点的训练结果中收益，从而保证全局模型的快速收敛。而在训练的后期阶段，由于模型参数基本达到最优解的邻域范围内，每轮训练模型的损失函数值在极小值点附近徘徊，模型参数的变化差异很小，因此不需要频繁的进行模型交换，也能保证模型趋于收敛，这与模拟退火算法寻解过程的思路是基本一致的。因此，在设计的算法中，对于每个节点的每轮训练，不是将其模型推送到固定数目的p个邻居节点，而是通过模拟退火算法设计接受概率函数，自适应的选择推送模型的节点，这里的接受概率就是选择节点作为推送模型节点的概率。假定每个训练节点为模拟退火算法中的一个固体物质，由于模拟退火算法中是根据固体的内能的变化幅度来决定接受新状态的概率，因此使用模型训练的损失函数值的倒数表示其内能E，每轮训练中损失函数值的倒数的差值为内能的改变量ΔE，损失函数值减小的越多，接受概率值越大，即为:ΔE＝Et+1-Et模拟退火算法中还定义了温度参数来控制算法的收敛，如果温度大会导致退火太快，温度小则迭代次数增多，所以采用冷却因子来控制温度参数变化，通常控制退火温度以指数形式下降。在这里定义初始温度为T0，冷却因子为ρ，则退火温度值T随时间的变化为:Tt＝ρtT0最后是模拟退火算法中接受概率函数的设计，由于接受概率函数实质上是当前训练节点推送模型到其他每个节点的概率，因此损失函数减小的幅度越大，推送模型概率也要越大，并且即使在损失函数值上升时，也能有一定概率推送模型。选择了Sigmoid类函数作为模拟退火的概率函数，因为其函数值有界，曲线平滑连续呈S型单调递增，符合算法中推送模型的概率变化,sigmoid函数如下所示；由以上可以得出，在训练时间节点t，任意节点收到当前训练节点d推送本地模型的概率为根据推送概率方程可以发现，任意节点收到当前训练节点d推送本地模型的概率符合伯努利分布并且随着时间间隔推移，温度Tt由冷却因子ρ呈指数下降，节点推送模型的分布概率趋近于固定值即退化为经典的反熵算法，此时节点d推送本地模型到所有其他节点的均值为1。附图3详细表示了基于反熵算法的自适应节点选择算法流程。基于反熵算法的自适应节点选择算法流程如下：D1：设置模型损失函数；D2：计算损失函数训练前后误差；D3：计算模型推送概率并推送模型；D4：根据收到的模型进行聚合；D5：判断是否满足迭代次数？若是，结束；若否，跳到步骤D2。与上述方法相对应地，本发明实施例还提供了一种基于分布式联邦学习的云边网络通信优化系统，所述系统采用分布式联邦学习框架下的云边网络框架，所述云边网络框架包括多个边缘结点和云中心服务器，所述云中心服务器和边缘节点均有运算和训练机器学习模型的能力；所述云边网络框架包括主从结构模式下运行的分布式联邦学习和完全去中心化的分布式联邦学习两种模式；在主从结构的云边网络框架中，当分布式联邦学习在这种模式下运行时，联邦学习不集中收集用户数据，而是进行一系列步骤的迭代训练，首先每个设备节点在本地训练自己的参数模型并进行梯度更新，然后所有节点将训练过的模型参数发送到云端来聚合更新，最后云端下发更新后的参数到所有设备进行下一轮训练，重复迭代直到模型收敛；在完全去中心化的分布式联邦学习云边网络框架中，当分布式联邦学习在这种模式下运行时，可以避免中央服务器的同步参数聚合限制，在本地训练之后通过异步更新与其他设备进行信息交换，实现模型更新；同时在该模式下，采用反熵通信算法，来代替联邦学习中的中央服务器同步算法；节点可以自适应调整在时钟间隔下推送的节点数，在保证所有节点的最终一致性下，提高训练模型的收敛速度。最后应当说明的是：上述实施例只是用于对本发明的举例和说明，而非意在将本发明限制于所描述的实施例范围内。此外本领域技术人员可以理解的是，本发明不局限于上述实施例，根据本发明教导还可以做出更多种的变型和修改，这些变型和修改均落在本发明所要求保护的范围内。
