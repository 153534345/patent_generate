标题title
一种基于深度集成学习的AD预测方法、系统及装置
摘要abst
本发明公开了一种基于深度集成学习的AD预测方法、系统及装置，属于医学影像处理领域。针对现有技术中存在的通过计算机辅助标记软件来肉眼观察患者脑PET图像中的大脑代谢活性来诊断AD诊断效率低且误诊率高等问题，本发明通过从ADNI数据库中获取PET图像，并对获取的PET图像进行切片，对切片后的PET图像中进行数据扩增，将扩增后的PET切片图像分别输入到ResNet‑34网络和EfficientNet‑b1网络进行特征学习，将学习到的特征通过MLP进行分类，对分类结果进行融合，再将融合后的结果进行预测输出，从而实现强化预测模型对PET的表征学习能力，提高预测早期阿尔茨海默症的准确性。
权利要求书clms
1.一种基于深度集成学习的AD预测方法，其步骤包括，从ADNI数据库中获取PET图像，并对获取的PET图像进行切片；对切片后的PET图像中进行数据扩增；将扩增后的PET切片图像分别输入到ResNet-34网络和EfficientNet-b1网络中进行特征学习；将ResNet-34网络和EfficientNet-b1网络中学习到的特征通过MLP进行分类；对分类结果进行融合，再将融合后的结果进行预测输出。2.根据权利要求1所述的一种基于深度集成学习的AD预测方法，其特征在于，所述ResNet-34网络是一个残差结构比例为的网络，所述ResNet-34网络结构中的Highway Network网络与扩增后的PET切片图像中的低阶特征信息融合。3.根据权利要求2所述的一种基于深度集成学习的AD预测方法，其特征在于，获取所述EfficientNet-b1网络的缩放权重，通过扩增后的PET切片图像进行迁移学习，得到所述EfficientNet-b1网络新的权重值；所述Efficientnet-b1网络自动搜索复合系数，通过网络的深度、宽度和分辨率三个维度优化预测网络。4.根据权利要求3所述的一种基于深度集成学习的AD预测方法，其特征在于，所述EfficientNet-b1网络结构包括主干网络、全局平均池化、全局最大池化、特征拼接和分类器。5.根据权利要求4所述的一种基于深度集成学习的AD预测方法，其特征在于，当扩增后的PET切片图像输入到主干网络之后，所述EfficientNet-b1网络学习到扩增后的PET切片图像的特征信息，生成对应的特征矩阵再经过全局平均池化和全局最大池化后，获得两组一维特征信息进行信息特征拼接，拼接后的特征信息经分类器分类后，再进行反向传播，进行多次迭代形成最优权重。6.根据权利要求5所述的一种基于深度集成学习的AD预测方法，其特征在于，采用10k-fold交叉验证对多张处理后的PET切片图像进行模型训练，训练时以其中一组为验证集，剩余图像为训练集，优化器使用SGD，学习率衰减策略为StepLR，损失函数采用交叉熵损失函数。7.根据权利要求6所述的一种基于深度集成学习的AD预测方法，其特征在于，所述交叉熵损失函数LCE的计算公式为：其中，N为样本数，M为类别数，yi为样本i的类别，正类为1，负类为0，Li为每个训练样本与对应的类别在交叉熵运算中的损失值，pi为样本i预测为正类的概率，yic为符号函数，pic为样本i预测概率。8.根据权利要求7所述的一种基于深度集成学习的AD预测方法，其特征在于，在预测训练过程中选取10k-fold交叉验证模型；使用随机尺度变换、随机小角度旋转、随机水平镜像和随机垂直镜像四种扩增方式。9.一种基于深度集成学习的AD预测系统，其特征在于，其采用如权利要求1-8中任意一项所述的基于深度集成学习的AD预测方法对PET图像进行特征学习；所述AD预测系统包括：输入模块，输入PET图像进行切片处理后，进行扩增，用于增加训练集的样本；训练模块，将扩增后的PET切片图像分别输入到ResNet-34网络和EfficientNet-b1网络中进行特征学习，学习到的特征再经过MLP进行分类；输出模块，对分类结果进行融合，再将融合后的结果进行预测输出。10.一种基于深度集成学习的AD预测装置，包括存储器、处理器以及存储在所述存储器上并可在所述处理器上运行的计算机程序，其特征在于，所述处理器执行所述程序时实现如权利要求1-8中任意一项所述的基于深度集成学习的AD预测方法的步骤。
说明书desc
技术领域本发明涉及医学影像处理领域，更具体地说，涉及一种基于深度集成学习的AD预测方法、系统及装置。背景技术阿尔兹海默症是一种进行性的神经系统退化疾病，临床表现为记忆障碍、失语、失认等。AD已成为一种全球流行病，全世界有超过5000万人患有痴呆症，每年给全球带来的社会经济负担保守估计超过1万亿美元。AD发病的病因迄今未明，尚无特效药能治愈或者有效逆转疾病进程，只能使用药物等减缓病情的发展，并且尽早采取相应措施有针对性地改善护理条件有助于老年患者的康复或者延后临床发病时间。目前临床医生诊断阿尔茨海默症的常用办法是利用计算机辅助标记软件来肉眼观察患者脑PET图像中的大脑代谢活性来判断。但这种方法存在诊断效率低、误诊率高且诊断过程复杂的特点，不利于疾病及早发现和后期治疗。随着神经成像技术的快速发展，神经影像诊断成为诊断阿尔茨海默病直观且可靠的方法。在神经影像诊断中，脑正电子发射型计算机断层显像是检测阿尔茨海默症的重要神经成像技术，是反映脑部病变基因、分子、代谢及功能状态的显像。它能体现与大脑谷氨酸能突触和星形胶质细胞活性区域的葡萄糖消耗，是脑活动代谢和神经元功能强弱的“晴雨表”。研究表明PET比MRI更早地在患有轻度认知障碍的个体中显示AD神经病变的特征。因此，基于PET的神经影像诊断是AD早期筛查的重要手段。近年来随着计算机辅助技术的发展，越来越多基于深度学习和数字图像处理技术在医学领域尤其是阿尔茨海默症预测方面的应用取得了巨大的成果。脑PET神经影像能够有效地预测早期阿尔茨海默症，但受试者早期的PET中存在病灶特征不明显的特点，且PET存在信噪比低、数据量少等问题，使得前期病变样本和正常样本的区分难度较大。因此，为强化预测模型对PET的表征学习能力，提高预测早期阿尔茨海默症的准确性，研究一种能在AD临床症状出现之前就可精确地诊断AD的预测方法变得十分必要。发明内容1.要解决的技术问题针对现有技术中存在的通过计算机辅助标记软件来肉眼观察患者脑PET图像中的大脑代谢活性来诊断AD，诊断效率低、误诊率高且诊断过程复杂，不利于疾病及早发现和后期治疗等问题，本发明提供了一种基于深度集成学习的AD预测方法、系统及装置，它可以实现强化预测模型对PET的表征学习能力，提高预测早期阿尔茨海默症的准确性。2.技术方案本发明的目的通过以下技术方案实现。一种基于深度集成学习的AD预测方法，其步骤包括，从ADNI数据库中获取PET图像，并对获取的PET图像进行切片；对切片后的PET图像中进行数据扩增；将扩增后的PET切片图像分别输入到ResNet-34网络和EfficientNet-b1网络中进行特征学习；将ResNet-34网络和EfficientNet-b1网络中学习到的特征通过MLP进行分类；对分类结果进行融合，再将融合后的结果进行预测输出。进一步地，所述ResNet-34网络是一个残差结构比例为的网络，所述ResNet-34网络结构中的Highway Network网络与扩增后的PET切片图像中的低阶特征信息融合。进一步地，获取所述EfficientNet-b1网络的缩放权重，通过扩增后的PET切片图像进行迁移学习，得到所述EfficientNet-b1网络新的权重值；所述Efficientnet-b1网络自动搜索复合系数，通过网络的深度、宽度和分辨率三个维度优化预测网络。进一步地，所述EfficientNet-b1网络结构包括主干网络、全局平均池化、全局最大池化、特征拼接和分类器。进一步地，当扩增后的PET切片图像输入到主干网络之后，所述EfficientNet-b1网络学习到扩增后的PET切片图像的特征信息，生成对应的特征矩阵再经过全局平均池化和全局最大池化后，获得两组一维特征信息进行信息特征拼接，拼接后的特征信息经分类器分类后，再进行反向传播，进行多次迭代形成最优权重。进一步地，采用10k-fold交叉验证对多张处理后的PET切片图像进行模型训练，训练时以其中一组为验证集，剩余图像为训练集，优化器使用SGD，学习率衰减策略为StepLR，损失函数采用交叉熵损失函数。进一步地，所述交叉熵损失函数LCE的计算公式为：其中，N为样本数，M为类别数，yi为样本i的类别，正类为1，负类为0，Li为每个训练样本与对应的类别在交叉熵运算中的损失值，pi为样本i预测为正类的概率，yic为符号函数，pic为样本i预测概率。进一步地，在预测训练过程中选取10k-fold交叉验证模型；使用随机尺度变换、随机小角度旋转、随机水平镜像和随机垂直镜像四种扩增方式。一种基于深度集成学习的AD预测系统，其采用基于深度集成学习的AD预测方法对PET图像进行特征学习；所述AD预测系统包括：输入模块，输入PET图像进行切片处理后，进行扩增，用于增加训练集的样本；训练模块，将扩增后的PET切片图像分别输入到ResNet-34网络和EfficientNet-b1网络中进行特征学习，学习到的特征再经过MLP进行分类；输出模块，对分类结果进行融合，再将融合后的结果进行预测输出。一种基于深度集成学习的AD预测装置，包括存储器、处理器以及存储在所述存储器上并可在所述处理器上运行的计算机程序，所述处理器执行所述程序时实现基于深度集成学习的AD预测方法的步骤。3.有益效果相比于现有技术，本发明的优点在于：本发明的一种基于深度集成学习的AD预测方法、系统及装置，ResNet-34网络可以让更深的网络训练出好的效果，其结构中的Highway Network能够保障高阶特征信息不丢失，EfficientNet-b1网络可以扩大网络感受野范围，强化模型学习PET图像特征间的细微特征，再将学习到的特征信息通过MLP进行分类，对分类结果进行融合，再将融合后的结果进行预测输出。通过利用ResNet-34网络以及EfficientNet-b1网络共同运行可以很好的学习PET图像的特征，形成信息互补，能够在AD临床症状出现之前就可以精确地诊断AD，强化预测模型对PET的表征学习能力，提高预测早期阿尔茨海默症的准确性。附图说明图1为本发明的一种基于深度集成学习的AD预测方法网络框架图；图2为本发明的一种基于深度集成学习的AD预测方法网络训练和测试流程图；图3为本发明的一种基于深度集成学习的AD预测方法中ResNet-34网络结构示意图；图4为本发明的一种基于深度集成学习的AD预测方法中EfficientNet-b1网络结构示意图。图中标号说明：1、随机尺度变换；2、随机小角度旋转；3、随机水平镜像；4、随机垂直镜像。具体实施方式下面结合说明书附图和具体的实施例，对本发明作详细描述。实施例如图1所示，本实施例提供的一种基于深度集成学习的AD预测方法、系统及装置，从ADNI数据库中获取PET图像，并对获取的PET图像进行切片，对切片后的PET图像中进行数据扩增，将扩增后的PET切片图像分别输入到ResNet-34网络和EfficientNet-b1网络中进行特征学习，将ResNet-34网络和EfficientNet-b1网络中学习到的特征通过MLP进行分类，对分类结果进行融合，再将融合后的结果进行预测输出。具体到本实施例中，如图1和图2所示，为本实施例提供的一种基于深度集成学习的AD预测方法的网络架构图及AD预测方法的网络训练和测试流程图。其测试流程为：数据预处理。由于AD疾病研究的特殊性，本实施例研究以数据集阿尔茨海默病神经为基础，该数据库可在网站上公开获取。ADNI于2003年由美国国家老龄问题研究所、美国国家生物医学成像和生物工程研究所等非营利组织发起，致力于全世界的医学专家共同解决日益严重的人口老龄化带来的AD疾病。从ADNI数据库里获取的神经影像脑PET图像的尺寸有128*128、168*168、256*256、336*336和少量400*400共5种尺寸图像，分别于飞利浦医疗系统和西门子等多家医疗公司生产的设备拍摄。可以看出256*256和336*336分别是128*128和168*168放大两倍得到的，168*168是128*128边缘扩充黑边得到的。因此，在选择训练数据尺寸大小时，折中选取224*224尺度，作为标准输入图像尺寸。这种选取尺寸的好处在于，不会将PET图像信息缩放过度而导致图像的形态变化过大，最大限度的保留PET切片图像的原始特征信息。数据扩增和增强。对获取的切片后的PET图像通过随机尺度变换1、随机小角度旋转2、随机水平镜像3和随机垂直镜像4四种方式进行扩增和增强。训练数据扩增可以增加训练集的样本，可以有效缓解模型过度拟合的情况，也可以给模型带来更强的泛化能力。其中，随机尺度变换1通过调用随机尺度变换函数方式得到，主要用于多尺度PET图像的深度学习，以强化网络学习到不同尺度的PET特征信息；随机小角度旋转2通过调用随机小角度旋转函数方式得到，主要用于多角度PET图像的深度学习，以强化网络学习到不同角度的PET特征信息；随机水平镜像3通过调用随机水平垂直平移函数方式得到，主要用于不同水平和垂直方向的PET图像的深度学习，以强化网络学习到不同水平和垂直方向的PET特征信息；随机垂直镜像4通过调用随机水平垂直镜像函数方式得到，主要用于批量复制不同水平和垂直PET图像的深度学习，以强化网络学习到更多的不同水平和垂直方向的PET特征信息。网络训练。在考虑内存、运行时间以及鲁棒性角度之后，通过选择残差网络34型和缩放网络b1型作为本实施例中基于深度集成学习的预测网络结构。如图3所示，ResNet-34网络是一个残差结构比例为的网络。具体地，ResNet-34网络中有4个layer层结构，其个数依次是3个、4个、6个和3个，并且在本实施例中仅使用该残差结构比例的网络，网络越深，获取的信息越多，特征也越丰富。但是随着网络的加深，优化效果反而越差，测试数据和训练数据的准确率反而降低了。这是由于网络的加深会造成梯度爆炸和梯度消失的问题，而ResNet-34网络却可以让更深的网络也能训练出好的效果，其结构中的跳跃连接网络，可以保障高阶特征信息不丢失，并且能很好的与低阶特征信息有效融合，提升网络的特征学习能力。本实施例中，所述的高阶特征信息是指在ResNet-34网络训练中，经过多次训练获得的高度抽象的特征，而低阶特征信息是指在开始训练中获得的特征信息，如图像的颜色变化、形状大小等表征信息。缩放网络是通过将网络的深度、宽度和分辨率组合起来按照一定规则缩放，从而提高网络的效果，EfficientNet在网络变大时效果提升明显，精度上限也进一步提升。值得说明的是，现有技术中，Efficientnet网络的分类性能较好，但是EfficientNet网络依赖预训练权重，而在没有预训练权重的前提下，造成其优秀的缩放性能无法得到展现。具体到本实施例中，通过获取公开版EfficientNet网络的缩放权重，利用现有的脑PET切片图像进行迁移学习获得新的权重值，最终EfficientNet网络的优秀分类性能得以展现。本实施例中，Efficientnet-b1网络的缩放比例是width_coefficient=1.0，depth_coefficient=1.1，resolution=240，dropout_rate=0.2，通过自动搜索复合系数从网络的深度、宽度和分辨率三个维度优化预测网络。其中，基于神经结构搜索技术可以获得最优的一组参数或复合系数，来达到精度和运算复杂度的权衡。EfficientNet-b1网络结构包括主干网络、全局平均池化、全局最大池化、特征拼接和分类器。如图4所示，在网络训练过程中，当切片后的PET图像输入到主干网络之后，网络学习到了切片后的PET图像的特征信息，生成对应的特征矩阵再经过全局平均池化和全局最大池化后，获得两组一维特征信息进行特征拼接，特征拼接完成后的特征信息经过多层感知机分类，再进行反向传播，进行多次迭代形成最优权重，预测网络完成训练。由此可知，ResNet-34网络可以让更深的网络也能训练出好的效果，在该网络中，其结构Highway Network能够保障高阶特征信息不丢失，EfficientNet-b1网络可以扩大网络感受视野范围，强化模型学习PET图像特征间的细微特征，这两种网络结构结合工作，可以很好的学习PET图像的特征，形成信息互补，提升预测精度。MLP感知分类。MLP有三层神经网络，分别为输入层、隐藏层和输出层，可以有效解决单层感知机无法解决的非线性问题，提升预测网络的分类性能和预测精度。本实施例中，将切片后的PET图像输入到ResNet-34网络中，网络经过卷积、池化和残差之后获得特征矩阵y；将切片后的PET图像输入到EfficientNet-b1网络中，网络经过卷积、池化之后获得特征矩阵y*，最后，将特征矩阵y输入MLP获得一个低维表征向量，将特征矩阵y*输入MLP获得一个低维表征向量，将两个低维表征向量进行逐元素相加，获得新的低维表征向量即新的特征矩阵，再将新的特征矩阵进行MLP训练，通过不断训练迭代得到更加合适的参数和阈值，最后输出层输出相应的低维度表征向量，即代表网络学习到了训练集的表征信息。训练策略。使用10k-fold交叉验证进行模型训练，在本实施例中，将获取的8000张PET图像分为10组，每组800张图像，训练时以其中一组为验证集，剩余图像为训练集。优化器使用SGD，学习率衰减策略为StepLR，损失函数采用交叉熵损失。使用10k-fold交叉验证，目的是为了在有限的数据集内，使预测网络充分利用数据资源以训练成最优权重。十折可以整除数据集，使得每折数据量相同。在网络训练阶段，交叉熵损失不断迭代优化预测权重，是预测网络学习到病灶信息的重要环节。交叉熵损失函数LCE的计算公式如下：其中，N为样本数，M为类别数，yi为样本i的类别，正类为1，负类为0，Li为每个训练样本与对应的类别在交叉熵运算中的损失值，pi为样本i预测为正类的概率，yic为符号函数，pic为样本i预测概率。测试增强。在测试过程中，本实施例同样使用随机尺度变换1、随机小角度旋转2、随机水平镜像3和随机垂直镜像4四种增强方式，获得大量有效数据样本，为预测网络精度提供多样数据信息以提升预测模型的鲁棒性和预测精度。同时，测试中选取10k-fold交叉验证训练的效果最好的模型进行测试，选择置信度最高的预测类别作为该图像最终预测结果。测试结果。在训练过程中，模型训练及测试运行环境为：Windows系统，6GB显存，Python3.8，使用Pytorch深度学习框架，优化器为Adam，训练学习率为0.0005，最大轮次epoch为100，batchsize为64，采用十折交叉训练，并使用混合精度训练加速库训练，加速库参数设置accumulation_steps=4，opt_level="O1"。在训练过程中，当损失值小于最优值时保存模型，直到轮次结束。如表1所示，为本实施例提供的一种基于深度集成学习的AD预测方法与进几年先进的AD预测方法对比表。其中，NC表示认知正常，SEN表示敏感性，SPE表示特异性，ACC表示准确性。对于敏感性SEN，也就是真阳性率，表示的是真正有病的样本在所有预测有病的样本中所占的比例。而对于特异性SPE，是真阴性率，表示的是真正没病的样本在所有预测没病的样本中所占的比例。由于在敏感性SEN中，如果预测有病但没病，则不如尽量减少预测没病但是实际有病的样本比率。这说明，在实际诊断专家系统中，两个指标中更为重要的是特异性SPE。ROC曲线又称受试者工作特征曲线，是反映敏感性SEN和特异性SPE连续变量的综合指标，ROC曲线一定程度上可以反映分类器的分类效果，在本实施例中定义一个AUC，AUC是ROC曲线下的面积，可以通过AUC值反映ROC曲线表达的分类能力。训练过程验证集Loss=0.043，AUC=98.125%，测试集F1=92.7%。其中，Loss=0.043是网络在训练集中迭代200次后在0.043上下趋于稳定，说明网络已经拟合了训练集数据。测试集FI表示的是在网络测试集中测试指标F1的值，是模型精准率和召回率的一种加权平均，是综合评价分类召回率与精确率，是评价模型分类性能的重要指标。表1 本实施例提供的AD预测方法与近几年先进的AD预测方法对比表由表1可知，本实施例提供的AD预测方法与近几年先进的AD预测方法相比，准确性ACC比最新文献高9.24%，比文献中实验效果最好的结果高1.57%，其他参数均高于当前文献实验结果。此外，本实施例提供的一种基于深度集成学习的AD预测系统，采用基于深度集成学习的AD预测方法进行PET图像的特征学习；所述AD预测系统包括：输入模块，输入PET图像进行切片处理后，通过随机尺度变换1、随机小角度旋转2、随机水平镜像3和随机垂直镜像4四种方式扩增，用于增加训练集的样本；训练模块，将扩增后的PET切片图像分别输入到ResNet-34网络和EfficientNet-b1网络进行特征学习，学习到的特征再经过MLP进行分类；输出模块，对分类结果进行融合，再将融合后的结果进行预测输出。本实施例还提供一种基于深度集成学习的AD预测装置，AD预测装置为一种计算机设备，包括存储器、处理器以及存储在存储器上并可在处理器上运行的计算机程序。处理器执行程序时实现如本实施例中基于深度集成学习的AD预测方法的步骤。该计算机设备可以是可以执行程序的智能手机、平板电脑、笔记本电脑、台式计算机、机架式服务器、刀片式服务器、塔式服务器或机柜式服务器等。本实施例的计算机设备至少包括但不限于：可通过系统总线相互通信连接的存储器、处理器。存储器包括闪存、硬盘、多媒体卡、卡型存储器、随机访问存储器、静态随机访问存储器、只读存储器、电可擦除可编程只读存储器、可编程只读存储器、磁性存储器、磁盘、光盘等。存储器可以是计算机设备的内部存储单元，例如该计算机设备的硬盘或内存，也可以是计算机设备的外部存储设备，例如该计算机设备上配备的插接式硬盘，智能存储卡，安全数字卡，闪存卡等。当然，存储器还可以既包括计算机设备的内部存储单元也包括其外部存储设备。本实施例中，存储器通常用于存储安装于计算机设备的操作系统和各类应用软件等。此外，存储器还可以用于暂时地存储已经输出或者将要输出的各类数据。处理器在一些实施例中可以是中央处理器、控制器、微控制器、微处理器、或其他数据处理芯片。该处理器通常用于控制计算机设备的总体操作，在本实施例中，处理器用于运行存储器中存储的程序代码或者处理数据。以上示意性地对本发明创造及其实施方式进行了描述，该描述没有限制性，在不背离本发明的精神或者基本特征的情况下，能够以其他的具体形式实现本发明。附图中所示的也只是本发明创造的实施方式之一，实际的结构并不局限于此，权利要求中的任何附图标记不应限制所涉及的权利要求。所以，如果本领域的普通技术人员受其启示，在不脱离本创造宗旨的情况下，不经创造性的设计出与该技术方案相似的结构方式及实施例，均应属于本专利的保护范围。此外，“包括”一词不排除其他元件或步骤，在元件前的“一个”一词不排除包括“多个”该元件。产品权利要求中陈述的多个元件也可以由一个元件通过软件或者硬件来实现。第一，第二等词语用来表示名称，而并不表示任何特定的顺序。
