标题title
无人机角度下的人群聚集识别方法、系统及其应用
摘要abst
本申请提出了无人机角度下的人群聚集识别方法、系统及其应用，包括以下步骤：S00、采集多帧目标图像作为训练图像数据，并标注训练图像中每个人头的位置得到人群头部位置标签；S10、将人群头部位置标签聚类生成每帧训练图像中的聚类中心点作为标签数据；S20、使用标签数据和训练图像数据训练得到人群中心点算法网络；S30、通过人群中心点算法网络估算待测视频图像帧的人群的聚类中心点；S40、计算不同待测视频图像帧中的聚类中心点的坐标差异，并进行归类匹配得到人群的轨迹和运动方向。本申请更加具备实用性，因为它可以为防止灾难事件提供了更好的人群行为分析。
权利要求书clms
1.无人机角度下的人群聚集识别方法，其特征在于，包括以下步骤：S00、采集多帧目标图像作为训练图像数据，并标注训练图像中每个人头的位置得到人群头部位置标签；S10、将所述人群头部位置标签聚类生成每帧训练图像中的聚类中心点作为标签数据；S20、使用所述标签数据和所述训练图像数据训练得到人群中心点算法网络；S30、通过所述人群中心点算法网络估算待测视频图像帧的人群的聚类中心点；S40、计算不同待测视频图像帧中的聚类中心点的坐标差异，并进行归类匹配得到人群的轨迹和运动方向。2.如权利要求1所述的无人机角度下的人群聚集识别方法，其特征在于，S10步骤中，通过Mean Shift聚类算法获取所述人群头部位置标签的聚类中心点。3.如权利要求1所述的无人机角度下的人群聚集识别方法，其特征在于，S20步骤中，所述人群中心点算法网络采用全卷积神经网络，通过卷积层代替全连接层。4.如权利要求3所述的无人机角度下的人群聚集识别方法，其特征在于，S20步骤中，所述全卷积神经网络包括将输入图像降为低维的隐含表示层的编码器和将所述隐含表示层上采样到所需的输出分辨率的解码器，且每个所述编码器包括卷积层、批归一化层及最大池化层，每个所述解码器包括转置卷积层和批归一化层。5.如权利要求1所述的无人机角度下的人群聚集识别方法，其特征在于，S40步骤中，在计算不同待测视频图像帧中的聚类中心点的坐标差异之前，将每帧待测视频图像降噪处理过滤掉背景。6.如权利要求5所述的无人机角度下的人群聚集识别方法，其特征在于，S40步骤中，通过计算每帧待测视频图像的每一对聚类中心点之间的欧几里得距离，并通过中心点对之间的最小距离进行匹配得到坐标差异。7.如权利要求1-6任意一项所述的无人机角度下的人群聚集识别方法，其特征在于，S40步骤中，归类至少分为东、西、南、北、东北、西北、东南及西南。8.一种无人机角度下的人群聚集识别系统，其特征在于，包括：采集模块，用于采集多帧目标图像作为训练图像数据，并标注训练图像中每个人头的位置得到人群头部位置标签；输入待测视频图像；聚类模块，用于将人群头部位置标签聚类生成每帧训练图像中的聚类中心点作为标签数据；训练模块，用于使用标签数据和训练图像数据训练得到人群中心点算法网络；计算模块，用于通过人群中心点算法网络估算待测视频图像帧的人群的聚类中心点；输出模块，用于计算不同待测视频图像帧中的聚类中心点的坐标差异，并进行归类匹配得到人群的轨迹和运动方向。9.一种电子装置，包括存储器和处理器，其特征在于，所述存储器中存储有计算机程序，所述处理器被设置为运行所述计算机程序以执行权利要求1至7任一项所述的无人机角度下的人群聚集识别方法。10.一种可读存储介质，其特征在于，所述可读存储介质中存储有计算机程序，所述计算机程序包括用于控制过程以执行过程的程序代码，所述过程包括根据权利要求1至7任一项所述的无人机角度下的人群聚集识别方法。
说明书desc
技术领域本申请涉及图像识别技术领域，特别是涉及无人机角度下的人群聚集识别方法、系统及其应用。背景技术集会游行、节日庆祝、音乐会等人群聚集形式对城市安全管理带来了挑战，缺乏管控的人群聚集可能造成严重恶劣影响的后果。目前所谓的自动人群聚集分析方法，通常包括人群计数和相关的人群密度估计，包括对聚集引起的灾难的预防，如踩踏事件。而监控人群的一种成本低廉的方法是使用无人驾驶飞行器，比如现在常用的无人机。通过配置相机和GPU设备，无人机就可以成为飞行的计算机视觉设备，可以迅速被部署到现场，实施人群聚集分析。但是无人机监控人群聚集也有一些缺点。一方面，计算机视觉算法在高空视角会面临更多的挑战，因为高空视角和地面固定监控完全不同，此外聚集人员数量规模可能会非常大，对运算分析有很大影响。另一方面，在计算机视觉领域普遍应用的图像算法方法并不能满足无人机所提出的严格的实时要求。换句话说，需要选择一个在可用性和效率之间达到良好平衡的轻量级模型是至关重要的。目前在计算机视觉领域，有许多的关于人群计数和人群密度估计的实现方法，用得比较多的是使用密度估计。也有采用得比较多的方案是通过图像上的滑动窗口来检测人体或人体头部的目标检测算法：但是即使采用最先进的物体检测器，如YOLO系列，运用到非常密集的小物体时，检测效果还是很差的。为了解决这个问题，科学家引入了基于回归的算法，直接学习从图像到人数的映射，比如学习密度图，虽然这个此算法比较有效，但其对计算设备的要求很高，并不符合无人机通常提出的严格要求。如何微调深度神经架构以实现精度和性能之间的最佳平衡是一个核心问题。比如在VisDrone2022比赛上，TransCrowd算法准确率是最高的，但这个算法基于VisionTransformer ，基于Transformer造成了该算法对计算资源的要求很高，想运用到无人机上面基本不可能，而且该算法只是对人的数量进行回归，而不提供对检测人流有用的密度图。综上，尽管用无人机进行人群分析已经取得了一些成果，但目前所提出的方法仍有较大改进的余地。为此，亟待一种能够解决上述问题的无人机角度下的人群聚集识别方法、系统及其应用。发明内容本申请实施例提供了无人机角度下的人群聚集识别方法、系统及其应用，针对目前技术对无人机性能要求高和缺陷较多的问题。本发明核心技术主要是基于FCN模型，模型对无人机拍摄的同一视频序列的连续帧估计“中心点密度图”，然后计算帧之间检测到的中心点的位移，可以确定人群运动的方向。将密度估计方法与聚类相结合，并不跟踪人群中某个人的运动。第一方面，本申请提供了无人机角度下的人群聚集识别方法，所述方法包括以下步骤：S00、采集多帧目标图像作为训练图像数据，并标注训练图像中每个人头的位置得到人群头部位置标签；S10、将人群头部位置标签聚类生成每帧训练图像中的聚类中心点作为标签数据；S20、使用标签数据和训练图像数据训练得到人群中心点算法网络；S30、通过人群中心点算法网络估算待测视频图像帧的人群的聚类中心点；S40、计算不同待测视频图像帧中的聚类中心点的坐标差异，并进行归类匹配得到人群的轨迹和运动方向。进一步地，S10步骤中，通过Mean Shift聚类算法获取人群头部位置标签的聚类中心点。进一步地，S20步骤中，人群中心点算法网络采用全卷积神经网络，通过卷积层代替全连接层。进一步地，S20步骤中，全卷积神经网络包括将输入图像降为低维的隐含表示层的编码器和将隐含表示层上采样到所需的输出分辨率的解码器，且每个编码器包括卷积层、批归一化层及最大池化层，每个解码器包括转置卷积层和批归一化层。进一步地，S40步骤中，在计算不同待测视频图像帧中的聚类中心点的坐标差异之前，将每帧待测视频图像降噪处理过滤掉背景。进一步地，S40步骤中，通过计算每帧待测视频图像的每一对聚类中心点之间的欧几里得距离，并通过中心点对之间的最小距离进行匹配得到坐标差异。进一步地，S40步骤中，归类至少分为东、西、南、北、东北、西北、东南及西南。第二方面，本申请提供了一种无人机角度下的人群聚集识别系统，包括：采集模块，用于采集多帧目标图像作为训练图像数据，并标注训练图像中每个人头的位置得到人群头部位置标签；输入待测视频图像；聚类模块，用于将人群头部位置标签聚类生成每帧训练图像中的聚类中心点作为标签数据；训练模块，用于使用标签数据和训练图像数据训练得到人群中心点算法网络；计算模块，用于通过人群中心点算法网络估算待测视频图像帧的人群的聚类中心点；输出模块，用于计算不同待测视频图像帧中的聚类中心点的坐标差异，并进行归类匹配得到人群的轨迹和运动方向。第三方面，本申请提供了一种电子装置，包括存储器和处理器，存储器中存储有计算机程序，处理器被设置为运行计算机程序以执行上述的无人机角度下的人群聚集识别方法。第四方面，本申请提供了一种可读存储介质，可读存储介质中存储有计算机程序，计算机程序包括用于控制过程以执行过程的程序代码，过程包括根据上述的无人机角度下的人群聚集识别方法。本发明的主要贡献和创新点如下：1、与现有技术相比，本申请不是简单考虑静态图像帧中的人群计数和密度估计，而是通过分析视频检测人群流动。因为我们的目标不仅是在单一的高空场景中识别人的存在，而且要确定人群是如何流动的。这与人的跟踪算法不同，因此本申请更加具备实用性，可以为防止灾难事件提供了更好的人群行为分析以及帮助在智能城市的场景中各种安全管理的应用；2、与现有技术相比，本申请在无人机拍摄的视频中对人群密度估计和聚类实现了较好的效果，特别从计算成本的角度看，效率很高；3、与现有技术相比，本申请通过整合可用的场景和协同数据来增加数据集的规模，可以帮助进一步提高深度学习模型的稳健性。本申请的一个或多个实施例的细节在以下附图和描述中提出，以使本申请的其他特征、目的和优点更加简明易懂。附图说明此处所说明的附图用来提供对本申请的进一步理解，构成本申请的一部分，本申请的示意性实施例及其说明用于解释本申请，并不构成对本申请的不当限定。在附图中：图1是根据本申请实施例的无人机角度下的人群聚集识别方法的流程；图2是根据本申请实施例的人群中心点算法网络示意图；图3-图5是根据本申请实施例的多种聚类生成中心点的实例图；图6是根据本申请实施例的电子装置的硬件结构示意图。具体实施方式这里将详细的对示例性实施例进行说明，其示例表示在附图中。下面的描述涉及附图时，除非另有表示，不同附图中的相同数字表示相同或相似的要素。以下示例性实施例中所描述的实施方式并不代表与本说明书一个或多个实施例相一致的所有实施方式。相反，它们仅是与如所附权利要求书中所详述的、本说明书一个或多个实施例的一些方面相一致的装置和方法的例子。需要说明的是：在其他实施例中并不一定按照本说明书示出和描述的顺序来执行相应方法的步骤。在一些其他实施例中，其方法所包括的步骤可以比本说明书所描述的更多或更少。此外，本说明书中所描述的单个步骤，在其他实施例中可能被分解为多个步骤进行描述；而本说明书中所描述的多个步骤，在其他实施例中也可能被合并为单个步骤进行描述。尽管用无人机进行人群分析已经取得了一些成果，但目前所提出的方法仍有较大改进的余地。基于此，本发明基于全卷积网络来解决现有技术存在的问题。该网络识别每一帧中的图像信息，并同时学习进行人群密度估计和人群聚类。这样一来，人群就可以通过他们的中心点来识别，通过追踪中心点来识别人群的轨迹，跟踪他们的运动。实施例一本申请旨在提出一种无人机角度下的人群聚集识别方法，可以，具体地，参考图1，所述方法包括以下步骤：S00、采集多帧目标图像作为训练图像数据，并标注训练图像中每个人头的位置得到人群头部位置标签；S10、将人群头部位置标签聚类生成每帧训练图像中的聚类中心点作为标签数据；其中，通常提供的数据集是不会存在关于视频的中心点密度图的标签数据，一般数据集都是标记人体或者头部的位置，下面描述从这些标记生成CGT标签数据。由于假设在原始的无人机拍摄的视频中没有关于人群中心点位置的标签，因此首先将Mean Shift聚类算法应用于上述的人群头部位置标签以获得中心点。Mean Shift是一种基于中心点的算法，它在某个区域将中心点的候选点更新为给定的点的平均值。然后在后处理步骤中对这些候选者进行过滤，以消除近似重复的内容。具体来说。如果在像素xi有一个中心点，将其表示为一个delta函数δ，使用高斯内核对delta函数进行卷积，便得到一个“中心点密度图”C，即真实的中心点密度图CGT：其中，K是中心点的数量；δ在x = xi时等于1，否则等于0；Gσ是高斯核。由于每个视频序列中人群头部的大小相似，根据经验设定σ=10，因为这个值会导致更好的性能，这要归功于足够大的“信心”激活区域生成的密度图中心点的例子。而使用Mean Shift求中心点是因为不可能事先知道人群中的聚类数量，所以需要一种不需要预先指定聚类数量的算法。通过上述的方式，遵循无监督的学习方法来寻找人群中心点，但当找到它们的位置后，可以作为生成的标签来指导有监督的学习方法。尽管这种策略在很大程度上取决于所选择的特定聚类算法，但它能够自动生成标签数据，并定量评估神经网络所执行的聚类任务。S20、使用标签数据和训练图像数据训练得到人群中心点算法网络；以往，热力图中心点的识别是在生成人群密度图后，通过经典的聚类算法来完成的，这样分步骤的做法影响了整体算法的推理速度。而在本实施例中，寻找人群中心点的任务被直接整合到网络训练中。如图2所示，本申请采用全卷积神经网络，只进行卷积和池化操作，不包含全连接层。全连接通常是典型的CNN网络的组成部分。本申请采用了有一个1×1卷积核，步长为1的卷积层来代替全连接层，一方面的好处是模型的参数更少，另一方面，网络能接收任意大小的图像作为输入。尽管如此，为了更好地评估，将每一帧的输入分辨率固定为640×512×3。其中，FCN的结构由两大部分组成：一个编码器Encoder模块将输入降为低维的隐含表示层；一个解码器Decoder模块将隐含表示层上采样到所需的输出分辨率。本申请设计了一个尽可能简单的FCN网络：如图2所示，在此实现中，一个缩放层对范围内的每个像素值进行标准化。然后，模型的编码器部分重复应用四个模块，包括一个具有内核的卷积层3×3，批归一化，以及核2×2的最大池化，直到达到潜伏空间Z∈R40×32×128。解码器通过转置卷积和批量归一化对特征图进行上采样。最后，1×1 卷积层产生大小为640×512×1的输出密度图。激活函数选择常用的ReLU。其中，每个编码器块都包括了卷积层+批归一化层+最大池化层，每个解码器层都包括了转置卷积层+批归一化层。在本实施例中，本申请的网络通过训练学习直接估计中心点密度图，并使用了下面的损失函数来训练为最小化预测和地面实况中心点密度图之间的平均平方误差：其中，N为样本数，CP和CGT分别为预测的中心点密度图和真实的中心点密度图，运算符代表计算欧氏距离。S30、通过人群中心点算法网络估算待测视频图像帧的人群的聚类中心点；在本实施例中，如图3-5所示，展示了几种情况的聚类生成中心点示意图，其中图5只有两个点是因为把该图左侧作为一个簇，右侧作为另外一个簇；左上角的人比较多，会偏向左上方，右侧的簇偏中心。S40、计算不同待测视频图像帧中的聚类中心点的坐标差异，并进行归类匹配得到人群的轨迹和运动方向。在本实施例中，由于FCN预测的密度图的特点是非标准化的值，可能包含噪音。比如Ground Truth中，背景像素构建值为0，但不能保证其值在预测的热图中保持为0。为了研究这对性能的影响，首先应用最小-最大归一化，将其范围限制在；然后，对像素值进行阈值，这样，任何低于阈值的值都被认为是背景。一个较高的阈值过滤了背景，基本上仅保留了模型对这些地区的人的存在更有信心的区域。而在识别中心点并通过经验阈值τ过滤图像后，为了计算被识别的人群的实际位移，并确定其运动方向，计算不同帧中预测的中心点的坐标差异。在时间tk的结束帧中，中心点的位移是相对于在时间t0的开始帧中检测到的中心点计算的。由于是在二维平面上计算，这个位移可以用坐标之间的欧几里得距离来简单计算。首先假设，给定的一群人，有可能在连续的帧之间移动，但新中心点与前一帧中的原中心点的距离小于与当前帧中所有其他中心点的距离。因此，为了确定能否将新预测的中心点与现有的中心点联系起来，从而确定它们移动的方向，通过计算每一帧中每一对中心点之间的欧几里得距离，并用中心点对之间的最小距离来匹配它们。如此就可以把每一次人群的移动归类为面向几个典型方向，即东/西/南/北，加上东北、西北、东南、西南等几个中间方向。例如Pi是在时间i预测的中心点的集合，可以分三个场景：• |P0| = |Pk|：在这种情况下，P0中的每个中心点关联到了Pk最近的中心点。• |P0|＞|Pk|：在这种情况下，在结束帧中的中心点较少。用d= ||P0| - |Pk||表示t0和tk中的中心点数量的绝对值之差，这可能表明网络预测错误，也可能在t0的两个中心点融合为tk的一个中心点，或者中心点在tk的时间离开视野。• |P0|＜|Pk|：在这种情况下，在起始帧中的中心点较少。然后，在时间tk，有更多的中心点，这些中心点将保持未匹配的状态。可能表明网络预测错误，也可能在tk形成新的集群，或者最后进入视野中的新中心点。其中，P0表示最开始待测图像帧的中心点集合，Pk表示在tk时刻预测的中心点的集合。本步骤主要用于跟踪人群；0时刻到tk时刻，两个能关联上的中心点，代表了这个人群聚集的行进方向。综上，本申请所提出的方法是基于FCN模型，模型对无人机拍摄的同一视频序列的连续帧估计“中心点密度图”。由于人群可以被看作是不一定遵循同一方向的多组人群，预测的中心点代表了这些人群。然后计算帧之间检测到的中心点的位移，可以确定人群运动的方向。该方法将密度估计方法与聚类相结合，并不跟踪人群中某个人的运动，这个方法出发点是方法的复杂性和计算成本。虽然基于个体位置的人群密度图可以保留更多的信息，但事实上追踪场景中每个个体运动轨迹的成本巨大。此外，个体追踪不仅不实用，而且也不重要，因为在人群管理场景中，重要的是识别整体的人流，而不是场景中每个人的精确位置。因此，本申请的方法将只关注高密度区域，即那些对应于人流集中的区域，同时方法对遮挡具有内在的稳健性，这会提升人流检测器的效果，特别是从高空看的时候。实施例二基于相同的构思，本申请还提出了一种无人机角度下的人群聚集识别系统，包括：采集模块，用于采集多帧目标图像作为训练图像数据，并标注训练图像中每个人头的位置得到人群头部位置标签；输入待测视频图像；聚类模块，用于将人群头部位置标签聚类生成每帧训练图像中的聚类中心点作为标签数据；训练模块，用于使用标签数据和训练图像数据训练得到人群中心点算法网络；计算模块，用于通过人群中心点算法网络估算待测视频图像帧的人群的聚类中心点；输出模块，用于计算不同待测视频图像帧中的聚类中心点的坐标差异，并进行归类匹配得到人群的轨迹和运动方向。实施例三本实施例还提供了一种电子装置，参考图6，包括存储器404和处理器402，该存储器404中存储有计算机程序，该处理器402被设置为运行计算机程序以执行上述任一项方法实施例中的步骤。具体地，上述处理器402可以包括中央处理器，或者特定集成电路，或者可以被配置成实施本申请实施例的一个或多个集成电路。其中，存储器404可以包括用于数据或指令的大容量存储器404。举例来说而非限制，存储器404可包括硬盘驱动器、软盘驱动器、固态驱动器、闪存、光盘、磁光盘、磁带或通用串行总线驱动器或者两个或更多个以上这些的组合。在合适的情况下，存储器404可包括可移除或不可移除的介质。在合适的情况下，存储器404可在数据处理装置的内部或外部。在特定实施例中，存储器404是非易失性存储器。在特定实施例中，存储器404包括只读存储器和随机存取存储器。在合适的情况下，该ROM可以是掩模编程的ROM、可编程ROM、可擦除PROM、电可擦除PROM、电可改写ROM或闪存或者两个或更多个以上这些的组合。在合适的情况下，该RAM可以是静态随机存取存储器或动态随机存取存储器，其中，DRAM可以是快速页模式动态随机存取存储器404、扩展数据输出动态随机存取存储器、同步动态随机存取内存等。存储器404可以用来存储或者缓存需要处理和/或通信使用的各种数据文件，以及处理器402所执行的可能的计算机程序指令。处理器402通过读取并执行存储器404中存储的计算机程序指令，以实现上述实施例中的任意无人机角度下的人群聚集识别方法。可选地，上述电子装置还可以包括传输设备406以及输入输出设备408，其中，该传输设备406和上述处理器402连接，该输入输出设备408和上述处理器402连接。传输设备406可以用来经由一个网络接收或者发送数据。上述的网络具体实例可包括电子装置的通信供应商提供的有线或无线网络。在一个实例中，传输设备包括一个网络适配器，其可通过基站与其他网络设备相连从而可与互联网进行通讯。在一个实例中，传输设备406可以为射频模块，其用于通过无线方式与互联网进行通讯。输入输出设备408用于输入或输出信息。在本实施例中，输入的信息可以是待测视频等，输出的信息可以是人群轨迹和移动方向等。实施例四本实施例还提供了一种可读存储介质，可读存储介质中存储有计算机程序，计算机程序包括用于控制过程以执行过程的程序代码，过程包括根据实施例一的无人机角度下的人群聚集识别方法。需要说明的是，本实施例中的具体示例可以参考上述实施例及可选实施方式中所描述的示例，本实施例在此不再赘述。通常，各种实施例可以以硬件或专用电路、软件、逻辑或其任何组合来实现。本发明的一些方面可以以硬件来实现，而其他方面可以以可以由控制器、微处理器或其他计算设备执行的固件或软件来实现，但是本发明不限于此。尽管本发明的各个方面可以被示出和描述为框图、流程图或使用一些其他图形表示，但是应当理解，作为非限制性示例，本文中描述的这些框、装置、系统、技术或方法可以以硬件、软件、固件、专用电路或逻辑、通用硬件或控制器或其他计算设备或其某种组合来实现。本发明的实施例可以由计算机软件来实现，该计算机软件由移动设备的数据处理器诸如在处理器实体中可执行，或者由硬件来实现，或者由软件和硬件的组合来实现。包括软件例程、小程序和/或宏的计算机软件或程序可以存储在任何装置可读数据存储介质中，并且它们包括用于执行特定任务的程序指令。计算机程序产品可以包括当程序运行时被配置为执行实施例的一个或多个计算机可执行组件。一个或多个计算机可执行组件可以是至少一个软件代码或其一部分。另外，在这一点上，应当注意，如图中的逻辑流程的任何框可以表示程序步骤、或者互连的逻辑电路、框和功能、或者程序步骤和逻辑电路、框和功能的组合。软件可以存储在诸如存储器芯片或在处理器内实现的存储块等物理介质、诸如硬盘或软盘等磁性介质、以及诸如例如DVD及其数据变体、CD等光学介质上。物理介质是非瞬态介质。本领域的技术人员应该明白，以上实施例的各技术特征可以进行任意的组合，为使描述简洁，未对上述实施例中的各个技术特征所有可能的组合都进行描述，然而，只要这些技术特征的组合不存在矛盾，都应当认为是本说明书记载的范围。以上实施例仅表达了本申请的几种实施方式，其描述较为具体和详细，但并不能因此而理解为对本申请范围的限制。应当指出的是，对于本领域的普通技术人员来说，在不脱离本申请构思的前提下，还可以作出若干变形和改进，这些都属于本申请的保护范围。因此，本申请的保护范围应以所附权利要求为准。
