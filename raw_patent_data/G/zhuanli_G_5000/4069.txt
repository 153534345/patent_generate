标题title
一种结合毫米波雷达信息的车端摄像头标定方法
摘要abst
本发明公开了一种结合毫米波雷达信息的车端摄像头标定方法。本发明将毫米波雷达与相机相结合，使用毫米波雷达对周围环境的感知数据与相机的检测结果相互关联并配准，弥补相机缺乏的三维信息的缺点，进而实现相机的在线外参校正，在满足实时性的同时还可以保证标定精度。本发明兼顾了实时性与精度，结合现有的人工测量和纯相机自标定方法的优势，实现了较为精确的相机自标定；本发明可以实现自适应外参调整，当相机外参的变化在一定范围内时，本发明都可以自适应地对其进行校正修改。当相机外参出现较大变动时，例如偏航角、滚动角发生较大变化时，本发明可以检测到大角度变化，可以提示用户尽快维修调整。
权利要求书clms
1.一种结合毫米波雷达信息的车端摄像头标定方法，其特征在于，包括以下步骤：步骤1、标定得到相机内参，计为内参K和畸变系数D，并测量出相机相对于车辆后轴中心的初始外部参数矩阵，计为初始旋转矩阵R0和初始位移向量t0；步骤2、利用毫米波雷达采集目标点云数据；步骤3、在毫米波雷达目标点云数据中提取目标点云，并记录下每个目标点云相对于车辆的深度信息，同时标注出目标点云的类别；步骤4、检测相机采集到的图像数据中的相机目标，得到相机二维目标检测结果，该二维目标检测结果至少包括相机目标的位置及类别；步骤5、将相机可视范围内的通过步骤3提取的雷达目标点云的类别与通过步骤4获得的相机目标检测结果进行对应关联：当相机可视范围内的雷达目标点云与步骤4获得的相机目标检测结果无法关联时，输出大误差告警信号，提示用户急需回厂调整相机和雷达安装结构；当相机可视范围内的雷达目标点云与步骤4获得的相机目标检测结果能够关联时，进入步骤6；步骤6、获得相机检测到的相机目标所对应的雷达目标点云，根据雷达目标点云的位置估算出在相机坐标系中相应的目标深度；步骤7、结合相机内参、相机目标检测结果和步骤6估计出的深度，基于雷达目标点云在相机坐标系下投影出虚拟目标点云；步骤8、基于初始旋转矩阵R0和初始位移向量t0，将虚拟目标点云投影回车辆坐标系中；步骤9、估算虚拟目标点云相对于雷达目标点云的旋转矩阵R1和位移向量t1，校正相机外参R′、t′，计算公式如下：＝|t0]步骤10、重复步骤6到步骤9，直到虚拟目标点云与雷达目标点云之间的误差小于一个阈值δ；设共迭代了x次，则确定最终的相机外参R、t如下式所示：＝|...t1]|t0]式中，Rx、tx为第x次迭代时估算的虚拟目标点云相对于雷达目标点云的旋转矩阵和位移向量。2.如权利要求1所述的一种结合毫米波雷达信息的车端摄像头标定方法，其特征在于，步骤2中，将毫米波雷达采集到的目标点云数据对齐到以车辆后轴中心建立的世界坐标系。3.如权利要求1所述的一种结合毫米波雷达信息的车端摄像头标定方法，其特征在于，步骤3中，使用聚类方法提取目标点云，或者使用神经网络模型推理得到目标点云。4.如权利要求1所述的一种结合毫米波雷达信息的车端摄像头标定方法，其特征在于，步骤6中，采用如下公式估算深度：Pc＝R*Pw+t式中，Pc表示点云在相机坐标系下的坐标，其z分量就是目标在相机坐标系下相应的深度；R为当前相机外参；t为当前相机位移矩阵；Pw为毫米波雷达点云目标在车辆坐标系下的位置。5.如权利要求1所述的一种结合毫米波雷达信息的车端摄像头标定方法，其特征在于，步骤7包括以下步骤：步骤701、确定点云中心Dc，计算公式如下：式中：为Pc的z分量；D为畸变系数；K-1为相机内参逆矩阵；p为二维检测框中心点像素坐标，将步骤4中目标在图像数据中的位置记录为二维检测框；步骤702、确定好点云中心后，将对应的雷达目标点云放置到相机坐标系中作为虚拟目标点云。6.如权利要求1所述的一种结合毫米波雷达信息的车端摄像头标定方法，其特征在于，步骤8中，采用如下公式将虚拟目标点云投影回车辆坐标系中：式中：Dw为虚拟目标点云在车辆坐标系中的点坐标；为初始旋转逆矩阵；Dc为虚拟目标点云在相机坐标系中的点坐标。7.一种结合毫米波雷达信息的车端摄像头标定方法，其特征在于，包括以下步骤：步骤1、标定得到相机内参，计为内参K和畸变系数D，并测量出相机相对于车辆后轴中心的初始外部参数矩阵，计为初始旋转矩阵R0和初始位移向量t0；步骤2、利用毫米波雷达采集建筑物墙面点云数据；步骤3、在毫米波雷达建筑物墙面点云数据中提取雷达墙面点云，并记录下每个雷达墙面点云相对于车辆的深度信息，同时标注出雷达墙面点云的法向量；步骤4、检测相机采集到的图像数据中的相机墙面，得到相机墙面检测结果，该相机墙面检测结果至少包括相机墙面的位置及法向量；步骤5、将相机可视范围内的通过步骤3提取的雷达墙面点云的法向量与通过步骤4获得的相机墙面检测结果进行对应关联：当相机可视范围内的雷达墙面点云与步骤4获得的相机墙面检测结果无法关联时，输出大误差告警信号，提示用户急需回厂调整相机和雷达安装结构；当相机可视范围内的雷达墙面点云与步骤4获得的相机墙面检测结果能够关联时，进入步骤6；步骤6、获得相机检测到的相机墙面所对应的雷达墙面点云，根据雷达墙面点云的位置估算出在相机坐标系中相应的目标深度；步骤7、结合相机内参、相机目标检测结果和步骤6估计出的深度，基于雷达墙面点云在相机坐标系下投影出虚拟墙面点云；步骤8、基于初始旋转矩阵R0和初始位移向量t0，将虚拟墙面点云投影回车辆坐标系中；步骤9、估算虚拟墙面点云相对于雷达墙面点云的旋转矩阵R1和位移向量t1，校正相机外参R′、t′，计算公式如下：＝|t0]步骤10、重复步骤6到步骤9，直到虚拟墙面点云与雷达墙面点云之间的误差小于一个阈值δ；设共迭代了x次，则确定最终的相机外参R、t如下式所示：＝|...t1]|t0]式中，Rx、tx为第x次迭代时估算的虚拟目标点云相对于雷达目标点云的旋转矩阵和位移向量。
说明书desc
技术领域本发明涉及一种车端摄像头标定方法。背景技术在智能交通系统中，车辆需要安装大量传感器收集场景数据，用于感知环境，加以处理后用于规划决策。在主流解决方案中，相机与毫米波雷达的组合凭借其较为成熟的技术和较低的成本在车辆感知系统中得到了广泛的应用。将相机采集到的图像与毫米波雷达采集到的雷达点云融合到一起可以生成一个兼容视觉特征和空间特征的场景。对相机数据进行目标识别跟踪等处理，得到的结果都是位于图像的像素坐标系的二维局部信息；对毫米波雷达点云数据进行聚类处理，可以得到目标在三维空间坐标系中的位置。融合两部分信息，可以对车辆周围的静、动态目标实现目标类别、目标位置、目标状态等全方位感知。为了有效准确地融合毫米波雷达点云数据与相机图像数据，需要对两种传感器做标定，建立像素坐标系与空间坐标系之间的联系。相机参数包括相机内参以及相机外参。相机内参：用来描述相机自身属性的参数矩阵，一般包括相机的焦距、主点位置和畸变参数，焦距和主点位置可以表示成一个3*3的矩阵，畸变参数可以表示成一个5*1的向量。相机外参：用来描述相机在世界中的朝向角度和位置，一般包括相机的旋转矩阵和位移向量，旋转矩阵可以表示成一个3*3的矩阵，位移向量可以表示成一个3*1的向量。一种传统的标定方法是手动测量相机在车辆上相对于毫米波雷达的旋转角和位移量，作为固定参数，在车辆出厂后就不再改变。这种标定方法的精度受限于测量工具和测量方法，由于相机感光成像平面无法直接接触，所以测量得到的旋转角和位移量并不精确。同时由于参数在出厂之后不再改变，一旦相机出现位姿变换，使用原有外参做数据融合会出现数据位置偏差，融合后感知精度大幅下降。另一种比较常见的外参标定方法是使用相机观测场景中的几何信息，根据一些几何特性估计出相机自身外参。这种标定方法需要将毫米波雷达和相机转换到同一个以地面为基准建立的世界坐标系中。在确定好相机外参的初始值后，可以实现在线外参标定与外参校正。但是这种方法对场景的要求较高，只有场景比较空旷且富含几何信息时，这种方法的精度才能得到保障。发明内容本发明要解决的技术问题是：现有的相机标定方法无法确保精度。为了解决上述技术问题，本发明的技术方案是提供了一种结合毫米波雷达信息的车端摄像头标定方法，其特征在于，包括以下步骤：步骤1、标定得到相机内参，计为内参K和畸变系数D，并测量出相机相对于车辆后轴中心的初始外部参数矩阵，计为初始旋转矩阵R0和初始位移向量t0；步骤2、利用毫米波雷达采集目标点云数据；步骤3、在毫米波雷达目标点云数据中提取目标点云，并记录下每个目标点云相对于车辆的深度信息，同时标注出目标点云的类别；步骤4、检测相机采集到的图像数据中的相机目标，得到相机二维目标检测结果，该二维目标检测结果至少包括相机目标的位置及类别，其中目标在图像数据中的位置记录为二维检测框；步骤5、将相机可视范围内的通过步骤3提取的雷达目标点云的类别与通过步骤4获得的相机目标检测结果进行对应关联：当相机可视范围内的雷达目标点云与步骤4获得的相机目标检测结果无法关联时，输出大误差告警信号，提示用户急需回厂调整相机和雷达安装结构；当相机可视范围内的雷达目标点云与步骤4获得的相机目标检测结果能够关联时，进入步骤6；步骤6、获得相机检测到的相机目标所对应的雷达目标点云，根据雷达目标点云的位置估算出在相机坐标系中相应的目标深度；步骤7、结合相机内参、相机目标检测结果和步骤6估计出的深度，基于雷达目标点云在相机坐标系下投影出虚拟目标点云；步骤8、基于初始旋转矩阵R0和初始位移向量t0，将虚拟目标点云投影回车辆坐标系中；步骤9、估算虚拟目标点云相对于雷达目标点云的旋转矩阵R1和位移向量t1，校正相机外参R′、t′，计算公式如下：＝|t0]步骤10、重复步骤6到步骤9，直到虚拟目标点云与雷达目标点云之间的误差小于一个阈值δ；设共迭代了x次，则确定最终的相机外参R、t如下式所示：＝|...t1]|t0]式中，Rx、tx为第x次迭代时估算的虚拟目标点云相对于雷达目标点云的旋转矩阵和位移向量。优选地，步骤2中，将毫米波雷达采集到的目标点云数据对齐到以车辆后轴中心建立的世界坐标系。优选地，步骤3中，使用聚类方法提取目标点云，或者使用神经网络模型推理得到目标点云。优选地，步骤6中，采用如下公式估算深度：Pc＝R*Pw+t式中，Pc表示点云在相机坐标系下的坐标，其z分量就是目标在相机坐标系下对应的深度；R为当前相机外参；t为当前相机位移矩阵；Pw为毫米波雷达点云目标在车辆坐标系下的位置。优选地，步骤7包括以下步骤：步骤701、确定点云中心Dc，计算公式如下：式中：为Pc的z分量；D为畸变系数；K-1为相机内参逆矩阵；p为二维检测框中心点像素坐标，将步骤4中目标在图像数据中的位置记录为二维检测框；步骤702、确定好点云中心后，将对应的雷达目标点云放置到相机坐标系中作为虚拟目标点云。优选地，步骤8中，采用如下公式将虚拟目标点云投影回车辆坐标系中：式中：Dw为虚拟目标点云在车辆坐标系中的点坐标；为初始旋转逆矩阵；Dc为虚拟目标点云在相机坐标系中的点坐标。本发明的另一个技术方案是提供了一种结合毫米波雷达信息的车端摄像头标定方法，其特征在于，包括以下步骤：步骤1、标定得到相机内参，计为内参K和畸变系数D，并测量出相机相对于车辆后轴中心的初始外部参数矩阵，计为初始旋转矩阵R0和初始位移向量t0；步骤2、利用毫米波雷达采集建筑物墙面点云数据；步骤3、在毫米波雷达建筑物墙面点云数据中提取雷达墙面点云，并记录下每个雷达墙面点云相对于车辆的深度信息，同时标注出雷达墙面点云的法向量；步骤4、检测相机采集到的图像数据中的相机墙面，得到相机墙面检测结果，该相机墙面检测结果至少包括相机墙面的位置及法向量；步骤5、将相机可视范围内的通过步骤3提取的雷达墙面点云的法向量与通过步骤4获得的相机墙面检测结果进行对应关联：当相机可视范围内的雷达墙面点云与步骤4获得的相机墙面检测结果无法关联时，输出大误差告警信号，提示用户急需回厂调整相机和雷达安装结构；当相机可视范围内的雷达墙面点云与步骤4获得的相机墙面检测结果能够关联时，进入步骤6；步骤6、获得相机检测到的相机墙面所对应的雷达墙面点云，根据雷达墙面点云的位置估算出在相机坐标系中相应的目标深度；步骤7、结合相机内参、相机目标检测结果和步骤6估计出的深度，基于雷达墙面点云在相机坐标系下投影出虚拟墙面点云；步骤8、基于初始旋转矩阵R0和初始位移向量t0，将虚拟墙面点云投影回车辆坐标系中；步骤9、估算虚拟墙面点云相对于雷达墙面点云的旋转矩阵R1和位移向量t1，校正相机外参R′、t′，计算公式如下：＝|t0]步骤10、重复步骤6到步骤9，直到虚拟墙面点云与雷达墙面点云之间的误差小于一个阈值δ；设共迭代了x次，则确定最终的相机外参R、t如下式所示：＝|...t1]|t0]式中，Rx、tx为第x次迭代时估算的虚拟目标点云相对于雷达目标点云的旋转矩阵和位移向量。本发明将毫米波雷达与相机相结合，使用毫米波雷达对周围环境的感知数据与相机的检测结果相互关联并配准，弥补相机缺乏的三维信息的缺点，进而实现相机的在线外参校正，在满足实时性的同时还可以保证标定精度。相比于现有技术方案，本发明具体具有如下有益效果：本发明兼顾了实时性与精度，结合现有的人工测量和纯相机自标定方法的优势，实现了较为精确的相机自标定。本发明可以实现自适应外参调整，当相机外参的变化在一定范围内时，本发明都可以自适应地对其进行校正修改。当相机外参出现较大变动时，例如偏航角、滚动角发生较大变化时，本发明可以检测到大角度变化，可以提示用户尽快维修调整。附图说明图1为本发明的流程图；图2示意了车辆坐标系。具体实施方式下面结合具体实施例，进一步阐述本发明。应理解，这些实施例仅用于说明本发明而不用于限制本发明的范围。此外应理解，在阅读了本发明讲授的内容之后，本领域技术人员可以对本发明作各种改动或修改，这些等价形式同样落于本申请所附权利要求书所限定的范围。结合图1，本实施例公开的一种结合毫米波雷达信息的车端摄像头标定方法包括以下步骤：步骤1、标定得到相机内参，计为内参K和畸变系数D，相机作为可选项可以选择小孔相机或是鱼眼相机。测量毫米波雷达和相机的安装位姿，包括雷达天线阵面朝向、雷达距离车辆后轴中心位置、相机镜头朝向和相机距离车辆后轴中心位置等，测量出相机相对于车辆后轴中心的初始外部参数矩阵，计为初始旋转矩阵R0和初始位移向量t0，后续标定结果都在这个测量结果的基础上进行调整。步骤2、利用毫米波雷达采集目标点云数据，将毫米波雷达采集到的目标点云数据对齐到以车辆后轴中心建立的世界坐标系，坐标系的建立如图2所示。步骤3、在毫米波雷达目标点云数据中聚类提取雷达目标点云，并记录下每个雷达目标点云相对于车辆的深度信息，同时标注出雷达目标的类别，这些类别用于与相机的检测结果进行关联。本实施例中，作为可选项，可以使用传统聚类方法提取雷达目标，也可以使用神经网络模型推理得到雷达目标。若采用聚类方法提取雷达目标，可以采用如下方法：步骤3A01、设定聚类的区域与聚类中心的数量；步骤3A02、随机选择初始聚类中心；步骤3A03、根据点到聚类中心的距离不同将其归属到不同类中；步骤3A04、根据不同类的点云估计出新的聚类中心；步骤3A05、按照新的聚类中心重复步骤3A03及步骤3A04再次对点云进行聚类；步骤3A06、重复步骤3A03至步骤3A05，直到新的聚类中心相对于上一次聚类估计出的聚类中心产生的变化小于一个阈值τ，就停止迭代估计；步骤3A07、将聚类得到的每个类别对应的点云作为一个雷达目标点云，根据目标的点云特征确定目标类别，记录下目标在车辆坐标系下的目标位置。若使用神经网络模型推理得到雷达目标点云，可以采用如下方法：步骤3B01、使用神经网络提取雷达点云特征；步骤3B02、分析雷达点云特征，以此回归点云目标边界框和目标类别；步骤3B03、将每个边界框内部的所有点作为这个边界框的目标点云并根据目标框的类别属性确定目标类别，记录下目标在车辆坐标系下的目标位置，其中，雷达目标位置计为Pw。步骤4、检测相机采集到的图像数据中的相机目标。本实施例中，使用深度神经网络对相机采集到的图像数据进行推理，得到当前图像数据中的相机目标检测结果，获得相机目标的位置及类别，其中目标在图像中的位置记录为二维检测框。步骤5、将相机可视范围内的通过步骤3提取的雷达目标点云的类别与通过步骤4获得的相机目标检测结果进行对应关联：当相机可视范围内的雷达目标点云与步骤4获得的相机目标检测结果无法关联时，输出大误差告警信号，提示用户急需回厂调整相机和雷达安装结构；当相机可视范围内的雷达目标点云与步骤4获得的相机目标检测结果能够关联时，进入步骤6。步骤6、获得相机检测到的相机目标所对应的雷达目标点云，根据雷达目标点云的位置估算出在相机坐标系中相应的目标深度，计算公式如下：Pc＝R*Pw+t式中，Pc表示雷达目标点云位置在相机坐标系下的坐标，其z分量就是目标在相机坐标系下相应的深度；R为当前相机外参；t为当前相机位移矩阵；Pw为毫米波雷达点云目标在车辆坐标系下的位置。步骤7、结合相机内参、相机目标检测结果和步骤6估计出的深度，在相机坐标系下投影出虚拟目标点云，包括以下步骤：步骤701、确定点云中心Dc，计算公式如下：式中：为Pc的z分量；D为畸变系数；K-1为相机内参逆矩阵；p为二维检测框中心点像素坐标。步骤702、确定好点云中心后，将对应的雷达目标点云放置到相机坐标系中作为虚拟目标点云。步骤8、将虚拟目标点云投影回车辆坐标系中，计算公式如下：式中：Dw为虚拟目标点云在车辆坐标系中的点坐标；为初始旋转逆矩阵；Dc为虚拟目标点云在相机坐标系中的点坐标。步骤9、估算虚拟目标点云相对于雷达目标点云的旋转矩阵R1和位移向量t1，校正相机外参R′、t′，计算公式如下：＝|t0]步骤10、重复步骤6到步骤9，直到虚拟目标点云与雷达目标点云之间的误差小于一个阈值δ。设共迭代了x次，则确定最终的相机外参R、t如下式所示：＝|...t1]|t0]式中，Rx、tx为第x次迭代时估算的虚拟目标点云相对于雷达目标点云的旋转矩阵和位移向量。在上述步骤中，雷达点云和相机中的目标作为可选项可以替换成建筑物的墙面，目标中心位置可以替换成墙面的中心位置，目标类别可替换成墙面的法向量。经过替换后，依旧使用步骤6到步骤10迭代算法进行在线外参校正，其中在步骤5中建立关联时，将根据类别建立关联替换成根据法向量相似性建立关联，最终实现的相机外参标定。本实施例公开的一种结合毫米波雷达信息的车端摄像头标定方法对相机外参在线校正方法进行了较大改进，相比于根据相机拍摄场景中的几何信息进行在线外参校正，本发明结合毫米波雷达点云，得到的场景几何信息更加准确，因此得到的外参估计结果更加精确。同事，由于本发明使用增量式更新校准相机外参，导致每一次对相机外参的调整都是微调修正，这种调整可以满足对相机外参的实时调整，无需车辆回厂进行重新标定。本发明公开的方法也考虑了大视角变化情况，并能及时检测发现，提示用户有必要回厂调整标定。
