标题title
车联网中基于MePC-F模型的实时强化联邦学习数据隐私安全方法
摘要abst
本发明公开了一种车联网中基于MePC‑F模型的实时强化联邦学习数据隐私安全方法，包括：构建多个边缘服务器Ei和一个云服务器CS；边缘服务器Ei从云服务器CS中下载初始A型梯度并解密为随机初始化B型梯度进行局部模型训练；边缘服务器Ei通过解码函数从中获取需要保留的部分梯度信息并将剩余的梯度信息经同态加密为再通过MePC算法广播发送给其它所有的边缘服务器Ej；所有边缘服务器更新共享后的A类梯度信息分别为所有边缘服务器将上传到云服务器CS，云服务器CS通过PreFLa算法聚合全局参数；重复以上步骤直到达到终止条件。本发明防止了端与端之间的数据泄露，实现了数据隐私安全保护，在防止原始数据泄露的同时减小通信开销。
权利要求书clms
1.一种车联网中基于MePC-F模型的实时强化联邦学习数据隐私安全方法，其特征在于，该方法包括以下步骤：S1、构建多个边缘服务器Ei和一个云服务器CS；获取车辆数据D＝{D1，D2，…，Di}，边缘服务器Ei获取对应车辆数据Di；S2、在第k轮联邦任务中，边缘服务器Ei从云服务器CS中下载初始A型梯度并解密为随机初始化B型梯度边缘服务器Ei根据其车辆数据Di的最小化损失函数来计算本地网络模型训练中的梯度，边缘服务器Ei完成T轮本地训练完后的梯度信息记为S3、边缘服务器Ei通过解码函数从中获取需要保留的部分梯度信息并将剩余的梯度信息经同态加密为再通过MePC算法广播发送给其它所有的边缘服务器Ej；边缘服务器Ei根据解码函数获取来自其它边缘服务器Ej的对应部分梯度信息所有边缘服务器更新共享后的A类梯度信息分别为i∈，n为边缘服务器的总数；S4、所有边缘服务器将上传到云服务器CS，云服务器CS通过PreFLa算法聚合全局参数，PreFLa算法通过强化学习获得最大化回报来选择边缘服务器Ei的最优参数权重比ai，k，全局梯度参数根据ai，k进行聚合；参数的上传和下载过程是并行的，所有参数都经过HE加密；S5、重复步骤S2-S4，直到达到终止条件，云服务器CS计算最终的全局梯度参数，下发给各边缘服务器，边缘服务器根据多个车辆数据的特征提取，计算MePC-F模型的精确度和最优损失函数，得到训练好的MePC-F模型，完成整个训练过程，实时输出给车联网对应的服务。2.根据权利要求1所述的车联网中基于MePC-F模型的实时强化联邦学习数据隐私安全方法，其特征在于，所述步骤S2中，本地网络模型训练的具体方法为：采用深度神经网络DNN模型，DNN通过将不同车辆数据作为原始输入来执行端到端的特征学习和分类器训练，使用随机梯度下降作为子程序来最小化每个本地训练中损失值；Ei在第k轮通信中从云服务器CS下载基础层参数，即解密前的初始A型梯度并解密为A型梯度随机初始化B型梯度其中，k∈，K表示联邦任务的总轮数；若为第一轮联邦任务，CS随机初始化在本地训练之前，Ei通过使用同态加密对解密为并记为局部模型的损失函数设置如下：L＝l+λ2其中，l表示网络的损失，第二项是L2正则化项，λ是正则化系数；wi表示局部模型中的总权重信息，wi，t是局部模型在t时刻的权重信息，wi，t+1是局部模型在t+1时刻的权重信息；Ei更新Gk并替换模型的权重参数wi，通过最小化损失函数继续进行局部模型训练如下：wi＝wi-ηGk其中，η是学习率，Gk是和的总表示，这里的随机初始化；边缘服务器Ei在达到T轮本地训练后，此时会得到每个局部模型的准确率aCCi，k和3.根据权利要求1所述的车联网中基于MePC-F模型的实时强化联邦学习数据隐私安全方法，其特征在于，所述步骤S3中，MePC算法的具体方法为：第k轮联邦任务中，所有的边缘服务器使用MePC来交换基础层梯度其中，表示第k轮联邦任务中第n个边缘服务器的A类加密数据，表示第k轮联邦任务中第i个边缘服务器的A类加密数据，表示第k轮联邦任务中第i个边缘服务器广播发给其他边缘服务器的A类加密数据，即为去除了自己保留的那一份后的加密数据；为了避免数据被破解的风险，在每个网络中取随机比例χ的梯度即为并保持同一轮联邦的随机比例χ相同，再将加密为在不同轮的联邦任务中，随机比例χ是变化的，χ∈；剩下的梯度通过同态加密为被均分为n-1份的值划分为：只有被保留在Ei中，其它部分和随机参数χ将会以密文的形式广播发送给其它Ej；通过这种方式，即使部分传输内容被攻击，最初的数据也不会泄露；共享给其它Ej的梯度信息是当Ei接收到由其它服务器发送的数据包它在本地执行数据验证。4.根据权利要求3所述的车联网中基于MePC-F模型的实时强化联邦学习数据隐私安全方法，其特征在于，所述步骤S3中，在本地执行数据验证的具体方法为：在第k轮联邦任务中，使用相应的“乘法”方法进行验证，每个边缘服务器自己设计两个解码函数，如下：其中，L0是的长度，L’是的长度；解码函数的下标k，表示第k轮联邦任务中的解码函数；L0＝χ·L其中，L是的长度，与的长度相等；要求满足所有边缘服务器的解码函数对同一个数据包执行“并”操作得到全0，并执行“交”操作得到全1，即：首先，初始化解码函数如下：将数据包与其它服务器中相应的解码函数相乘；由于中0的二进制位被乘得0，所以Ei保证只得到它自己的部分数据包；当中的二进制位为1时，得到对应位置的梯度信息的密文，如下：Ei将从其它边缘服务器Ej获取的所有数据包数组添加到对应位置，得到所有密文数据，并更新为最后即：每次进行安全多方计算时，随着k的增加，将每个Ei中的解码函数的二进制向左循环移动m个单位，以保证共享的动态性，并将它们平均划分到E1，E2，…，En中，且每个部分的数据信息不重复。5.根据权利要求1所述的车联网中基于MePC-F模型的实时强化联邦学习数据隐私安全方法，其特征在于，所述步骤S4中，PreFla算法的具体方法为：PreFLa采用强化学习RL进行适配来选择最优参数权重比ai，k聚合全局参数在上行通信阶段，每个边缘服务器不仅训练局部模型，还将本地参数上传到云服务器CS进行联合聚合；在第k轮联邦中执行MePC算法后，Ei通过TLS/SSL安全通道将参数和上传到CS；在聚合阶段，由于每个ES的分布不平衡和数据异构性，其模型参数用于聚合对该阶段的收敛速度具有至关重要的影响；因此，有必要考虑k轮联邦聚合中参与者Ei的参数权重比ai，k；使用基于DQN的强化学习去预测参数权重比，通过Q函数来存储信息，以防止空间多维灾难；为了更好地实现模型个性化，减少MePC-F中上传权重的等待时间，用DQN来选择最优参数权重比ai，k，聚合更新CS中的全局参数强化学习包括：状态、动作、奖励函数以及反馈。6.根据权利要求5所述的车联网中基于MePC-F模型的实时强化联邦学习数据隐私安全方法，其特征在于，所述步骤S4中，状态、动作、奖励函数以及反馈的具体方法为：状态：第k轮的状态其中，是精度差，表示为：动作：参数权重占比ai，k表示为第k轮联邦任务的动作；为避免陷入局部最优解，采用ε-贪心算法优化动作选择过程，得到ai，k：其中P是权重排列的集合，rand是一个随机数，rand∈，Q指代理在状态si，k下采取行动ai，k时的累积折现收益；一旦DQN在测试期间被训练为近似Q，DQN代理将为第k轮中的所有动作计算{Q|ai，k∈}；每个动作值表示代理通过在状态si，k选择特定动作ai，k获得的最大预期回报；奖励：将第k轮联邦结束时观察到的奖励设置为：其中，是一个正数，确保rk随着训练准确度Δacci，k呈指数增长；第一项激励代理选择能够实现更高测试精度的设备；用来控制随着Δacci，k增长rk的变化；当Δacci，k小于0时，有rk∈；训练DQN代理以最大化累积折扣奖励的期望，如下式所示：其中，γ∈；最优动作值函数Q是RL代理寻求的备忘单，定义为从si，k开始的累积折现收益的最大期望：Q＝E|si，k，ai，k)应用函数逼近技术学习一个参数化的值函数Q逼近最优值函数Q；rk+γmax Q是Q学习的目标；DNN用于表示函数逼近器；RL学习问题变成最小化目标和逼近器之间的MSE损失，定义为：l＝-Q)2CS更新全局参数wk为：其中，η≥0是步长；云服务器CS得到最佳学习模型后，得到第k轮权重比序列的ai，k，将全局参数更新为：所有边缘服务器更新全局参数并开始接下来的T轮本地训练。7.根据权利要求1所述的车联网中基于MePC-F模型的实时强化联邦学习数据隐私安全方法，其特征在于，该方法中HE加密的方法具体为：权重矩阵和偏置向量的加密方案遵循相同的思想，实数a的加法同态加密表示为aE，在加法同态加密中，对于任意两个数a和b，有aE+bE＝E；将任何实数r转换为编码的有理数不动点v的方法是：认为梯度中的每个编码实数r可以表示为有理定理的H位数，由一个符号位、z位整数位和d位小数位组成；因此，每个可以编码的有理数都由其H＝1+z+d位定义；执行编码以允许乘法运算，这需要运算模数为H+2d以避免比较；解码定义为：这些编码数字的乘法需要去除因子1/2d；使用Paillier加法加密时，可以准确计算编码乘法的情况，但只能保证一次同态乘法；为简单起见，在解码时处理它；最大的可加密整数是V-1，所以最大的可加密实数必须考虑到这一点，因此，整数z和小数d的选择条件如下：V≥2H+2d≥21+z+3d。8.根据权利要求1所述的车联网中基于MePC-F模型的实时强化联邦学习数据隐私安全方法，其特征在于，所述步骤S5中最优的损失函数为其中，L表示Ei网络的损失。
说明书desc
技术领域本发明涉及联网车辆用户协同处理实时安全行为分析技术领域，尤其涉及一种车联网中基于MePC-F模型的实时强化联邦学习数据隐私安全方法。背景技术随着车联网支持各种实时通信和服务的发展，通过车载单元等互联设备生成的数据量空前巨大，面向车辆用户的大量异构性数据和设备计算能力的差异性，联邦学习为满足网络模型实时训练过程中数据安全保护要求提供了一种有效的解决方案，它可以让不同的边缘设备在不暴露原始数据的情况下协同训练机器学习模型。边缘计算海量数据与用户个人隐私联合紧密，例如，用户的轨迹、信用卡、账单等数据，切实关系到用户隐私安全，如发生数据泄露，将给用户带来重大安全隐患。联邦学习可以在一定程度上保护数据，但依旧存在信息泄露的风险，主要有四种类型:1)成员泄露，2)非预期特征泄露，3)代表原始数据泄露的类，4)原始数据泄露。最后一种类型的数据泄漏对于隐私敏感的参与者来说是最不可接受的。为了保护移动用户的数据隐私性，解决上述原始数据泄露问题，研究者们在基于密码学的数据安全保护进行了大量的研究：差分隐私、同态加密、多方安全计算。差分隐私通常使用三种噪声添加机制：分别为拉普拉斯机制、高斯机制和指数机制。通过添加噪声来干扰上下文信息，以保护数据的隐私，但如果噪声增加过多则会影响模型训练的性能。同态加密中常用的是加法和乘法同态加密：研究表明，使用Paillier加法同态加密计算时，噪声会增加一倍，而使用El Gamal乘法同态加密计算时，噪声呈二次增长。为了增加数据的可用性并克服噪声问题，研究者引入bootstrapping，通过设定阈值进行加密解密降低噪声，从而允许该方案计算无限次的操作。还可以进行批处理，或者进行并行同态计算或删除对的压缩来解决噪声问题。安全多方计算是指在无可信第三方的条件下多方参与者安全地计算一个约定函数的问题，主要目的是在计算过程中必须保证各方私密输入独立，计算时不泄露任何本地数据。有研究证明使用安全多方计算可以解决联邦学习中的梯度泄露问题，并证明只需对第一隐藏层进行信息交换就可在保证精确度的同时进行数据安全保护。但它的信息交互的过程是P2P的，所以会出现通信开销大的问题。大部分基于密码学的数据安全保护研究都是集中式解决方法，为了在数据安全保护的同时解决时间开销问题：联邦学习可以让边缘设备在不暴露原始数据的情况下协同训练机器学习模型。联邦学习通常采用参数服务器架构，其中客户端由参数服务器同步局部模型训练。通常使用同步方法实现，即中央服务器将全局模型同步发送给多个客户机，多个客户机基于本地数据训练模型后同步将更新后的模型返回中央服务器。这可能会因为掉队而变得缓慢。由于计算能力和电池时间有限，可用性和完成时间因设备而异，因此全局同步非常困难，尤其是在联合学习场景中。有人提出了一种新的联合优化异步算法来解决正则化局部问题以保证收敛，使得多个设备和服务器能够在不泄露隐私的情况下协同高效地训练模型。尽管在数据安全方面有很多的研究。但大多数都限制于解决原始数据安全问题，如何在复杂车联网空间中，同时满足移动用户大数据隐私性和可用性为目标，设计一个有效的联邦学习算法来减少通信开销的同时防止梯度泄露后导致数据被恢复的问题依旧是开放的。首先，联邦学习中数据都存储在本地节点中，可以减少数据传输中原始数据泄露的风险问题。但仅仅只传输梯度信息，依旧会出现原始数据被恢复的可能性。安全多方计算中数据交互可以使得多方拥有数据，降低梯度信息被泄露后样本被信息恢复的可能性。但现有的安全多方计算中用户交互信息的方式是所有用户都发送给其他用户，简单讲就是使用单播的方式，这样就会带来较高的时间开销。所以在应对车辆用户的数据安全和实时性需求时，找到一个合适的解决方案降低数据被攻击和被恢复的风险，并降低传输时延就很重要。其次，由于不同边缘服务器的数据和设备差异性，在训练过程中有针对性的提高整个模型训练精度也是很有必要的。采用典型的联邦平均同步方式进行全局参数聚合会出现掉队现象而变得缓慢。在平衡计算通信时间开销的同时，多个模型个性化训练来保障全局精度也是很重要。然而，大多数基于数据安全的联邦学习算法依赖于同步聚合算法会带来高时延对满足车联网的实时性需求具有挑战性。因此一个基于强化学习的联邦学习算法来降低时延提高精确度并保障数据安全是有必要的。发明内容本发明要解决的技术问题在于针对现有技术中的缺陷，提供一种车联网中基于MePC-F模型的实时强化联邦学习数据隐私安全方法。本发明解决其技术问题所采用的技术方案是：本发明提供一种车联网中基于MePC-F模型的实时强化联邦学习数据隐私安全方法，该方法包括以下步骤：S1、构建多个边缘服务器Ei和一个云服务器CS；获取车辆数据D＝{D1，D2，…，Di}，边缘服务器Ei获取对应车辆数据Di；S2、在第k轮联邦任务中，边缘服务器Ei从云服务器CS中下载初始A型梯度并解密为随机初始化B型梯度边缘服务器Ei根据其车辆数据Di的最小化损失函数来计算本地网络模型训练中的梯度，边缘服务器Ei完成T轮本地训练完后的梯度信息记为S3、边缘服务器Ei通过解码函数从中获取需要保留的部分梯度信息并将剩余的梯度信息经同态加密为再通过MePC算法广播发送给其它所有的边缘服务器Ej；边缘服务器Ei根据解码函数获取来自其它边缘服务器Ej的对应部分梯度信息所有边缘服务器更新共享后的A类梯度信息分别为i∈，n为边缘服务器的总数；S4、所有边缘服务器将上传到云服务器CS，云服务器CS通过PreFLa算法聚合全局参数，PreFLa算法通过强化学习获得最大化回报来选择边缘服务器Ei的最优参数权重比ai，k，全局梯度参数根据ai，k进行聚合；参数的上传和下载过程是并行的，所有参数都经过HE加密；S5、重复步骤S2-S4，直到达到终止条件，云服务器CS计算最终的全局梯度参数，下发给各边缘服务器，边缘服务器根据多个车辆数据的特征提取，计算MePC-F模型的精确度和最优损失函数，得到训练好的MePC-F模型，完成整个训练过程，实时输出给车联网对应的服务。。进一步地，本发明的所述步骤S2中，本地网络模型训练的具体方法为：采用深度神经网络DNN模型，DNN通过将不同车辆数据作为原始输入来执行端到端的特征学习和分类器训练，使用随机梯度下降作为子程序来最小化每个本地训练中损失值；Ei在第k轮通信中从云服务器CS下载基础层参数，即解密前的初始A型梯度并解密为A型梯度随机初始化B型梯度其中，k∈，K表示联邦任务的总轮数；若为第一轮联邦任务，CS随机初始化在本地训练之前，Ei通过使用同态加密对解密为并记为局部模型的损失函数设置如下：L＝l+λ2其中，l表示网络的损失，第二项是L2正则化项，λ是正则化系数；wi表示局部模型中的总权重信息，wi，t是局部模型在t时刻的权重信息，wi，t+1是局部模型在t+1时刻的权重信息；Ei初始化Gk并替换模型的权重参数wi，通过最小化损失函数继续进行局部模型训练如下：wi＝wi-ηGk其中，η是学习率，Gk是和的总表示，这里的随机初始化；边缘服务器Ei在达到T轮本地训练后，此时会得到每个局部模型的准确率acci，k和进一步地，本发明的所述步骤S3中，MePC算法的具体方法为：第k轮联邦任务中，所有的边缘服务器使用MePC来交换基础层梯度其中，表示第k轮联邦任务中第n个边缘服务器的A类加密数据，表示第k轮联邦任务中第i个边缘服务器的A类加密数据，表示第k轮联邦任务中第i个边缘服务器广播发给其他边缘服务器的A类加密数据，即为去除了自己保留的那一份后的加密数据；为了避免数据被破解的风险，在每个网络中取随机比例χ的梯度即为并保持同一轮联邦的随机比例χ相同，再将加密为在不同轮的联邦任务中，随机比例χ是变化的，χ∈；剩下的梯度通过同态加密为被均分为n-1份的值划分为：只有被保留在Ei中，其它部分和随机参数χ将会以密文的形式广播发送给其它Ej；通过这种方式，即使部分传输内容被攻击，最初的数据也不会泄露；共享给其它Ej的梯度信息是当Ei接收到由其它服务器发送的数据包它在本地执行数据验证。进一步地，本发明的所述步骤S3中，在本地执行数据验证的具体方法为：在第k轮联邦任务中，使用相应的“乘法”方法进行验证，每个边缘服务器自己设计两个解码函数，如下：其中，L0是的长度，L’是的长度；解码函数的下标k，表示第k轮联邦任务中的解码函数；L0＝χ·L其中，L是的长度，与的长度相等；要求满足所有边缘服务器的解码函数对同一个数据包执行“并”操作得到全0，并执行“交”操作得到全1，即：首先，初始化解码函数如下：将数据包与其它服务器中相应的解码函数相乘；由于中0的二进制位被乘得0，所以Ei保证只得到它自己的部分数据包；当中的二进制位为1时，得到对应位置的梯度信息的密文，如下：Ei将从其它边缘服务器Ej获取的所有数据包数组添加到对应位置，得到所有密文数据，并更新为最后即：每次进行安全多方计算时，随着k的增加，将每个Ei中的解码函数的二进制向左循环移动m个单位，以保证共享的动态性，并将它们平均划分到E1，E2，…，En中，且每个部分的数据信息不重复。进一步地，本发明的所述步骤S4中，PreFla算法的具体方法为：PreFLa采用强化学习RL进行适配来选择最优参数权重比ai，k聚合全局参数在上行通信阶段，每个边缘服务器不仅训练局部模型，还将本地参数上传到云服务器CS进行联合聚合；在第k轮联邦中执行MePC算法后，Ei通过TLS/SSL安全通道将参数和上传到CS；在聚合阶段，由于每个ES的分布不平衡和数据异构性，其模型参数用于聚合对该阶段的收敛速度具有至关重要的影响；因此，有必要考虑k轮联邦聚合中参与者Ei的参数权重比ai，k；使用基于DQN的强化学习去预测参数权重比，通过Q函数来存储信息，以防止空间多维灾难；为了更好地实现模型个性化，减少MePC-F中上传权重的等待时间，用DQN来选择最优参数权重比ai，k，聚合更新CS中的全局参数强化学习包括：状态、动作、奖励函数以及反馈。进一步地，本发明的所述步骤S4中，状态、动作、奖励函数以及反馈的具体方法为：状态：第k轮的状态其中，是精度差，表示为：动作：参数权重占比ai，k表示为第k轮联邦任务的动作；为避免陷入局部最优解，采用ε-贪心算法优化动作选择过程，得到ai，k：其中P是权重排列的集合，rand是一个随机数，rand∈，Q指代理在状态si，k下采取行动ai，k时的累积折现收益；一旦DQN在测试期间被训练为近似Q，DQN代理将为第k轮中的所有动作计算{Q|ai，k∈}；每个动作值表示代理通过在状态si，k选择特定动作ai，k可以获得的最大预期回报；奖励：将第k轮联邦结束时观察到的奖励设置为：其中，是一个正数，确保rk随着测试准确度Δacci，k呈指数增长；第一项激励代理选择能够实现更高测试精度的设备；用来控制随着Δacci，k增长rk的变化；当Δacci，k小于0时，有rk∈；训练DQN代理以最大化累积折扣奖励的期望，如下式所示：其中，γ∈；最优动作值函数Q是RL代理寻求的备忘单，定义为从si，k开始的累积折现收益的最大期望：Q＝E|si，k，ai，k)应用函数逼近技术学习一个参数化的值函数Q逼近最优值函数Q；rk+γmax Q是Q学习的目标；DNN用于表示函数逼近器；RL学习问题变成最小化目标和逼近器之间的MSE损失，定义为：l＝-Q)2CS更新全局参数wk为：其中，η≥0是步长；云服务器CS得到最佳学习模型后，得到第k轮权重比序列的ai，k，将全局参数更新为：所有边缘服务器更新全局参数并开始接下来的T轮本地训练。进一步地，本发明的该方法中HE加密的方法具体为：权重矩阵和偏置向量的加密方案遵循相同的思想，实数a的加法同态加密表示为aE，在加法同态加密中，对于任意两个数a和b，有aE+bE＝E；将任何实数r转换为编码的有理数不动点v的方法是：认为梯度中的每个编码实数r可以表示为有理定理的H位数，由一个符号位、z位整数位和d位小数位组成；因此，每个可以编码的有理数都由其H＝1+z+d位定义；执行编码以允许乘法运算，这需要运算模数为H+2d以避免比较；解码定义为：这些编码数字的乘法需要去除因子1/2d；使用Paillier加法加密时，可以准确计算编码乘法的情况，但只能保证一次同态乘法；为简单起见，在解码时处理它；最大的可加密整数是V-1，所以最大的可加密实数必须考虑到这一点，因此，整数z和小数d的选择条件如下：V≥2H+2d≥21+z+3d。进一步地，本发明的所述步骤S5中最优的损失函数为其中，L表示Ei网络的损失。本发明产生的有益效果是：提出一种多方广播安全计算的联邦学习模型。该模型将MePC算法和PreFla算法相结合解决车联网中联邦学习训练数据安全和通信开销问题。并考虑同态加密以及安全多方计算的混合优势来防止端与端之间的数据泄露，在数据被攻击后降低原始数据的还原度，以最大限度实现数据的隐私安全保护。提出一种安全广播多方计算MePC。针对安全多方计算，只共享第一层的梯度信息就可以大大降低数据被恢复的风险并减少通信量。在共享过程中采用广播的方式，边缘服务器模型经过解码函数取各自的部分，可以将时间复杂度从O降低到O，在防止原始数据泄露的同时减小通信开销。提出了基于权重占比的联邦学习算法PreFla。利用PreFla找到最优的梯度权重占比去聚合全局参数，使用每个边缘服务器的精确度差值来设计奖励函数，使得整体回报最大的动作选择即为每轮联邦的权重占比。并在损失函数中添加L2正则化项来促进边缘服务器协作并降低数据异构性带来的时延和性能问题。从而更好的泛化全局模型、加速收敛。附图说明下面将结合附图及实施例对本发明作进一步说明，附图中：图1是本发明实施例的MePC-F模型；图2是本发明实施例的MePC-F模型的流程图；图3是本发明实施例的MePC算法；图4是本发明实施例的MNIST上四种方法隐藏第一个隐藏层不隐藏时的DLG结果；FL；MePC-F；PeMPC；Gaussian；Laplacian；图5是本发明实施例的DLG在MNIST上的性能，当第一个隐藏层的梯度被四种方法替换时；图6是本发明实施例的No-IID MNIST数据的平均准确率和损失；图7是本发明实施例的No-IID CAFIR-10数据的平均准确率和损失。具体实施方式为了使本发明的目的、技术方案及优点更加清楚明白，以下结合附图及实施例，对本发明进行进一步详细说明。应当理解，此处所描述的具体实施例仅用以解释本发明，并不用于限定本发明。本发明实施例中涉及的参数说明如下：表1参数说明其中，Ei表示当前的边缘服务器，Ej表示除当前边缘服务器之外的边缘服务器，Es表示所有边缘服务器。本发明实施例的车联网中基于MePC-F模型的实时强化联邦学习数据隐私安全方法，包括以下步骤：S1、构建多个边缘服务器Ei和一个云服务器CS；获取车辆数据D＝{D1，D2，…，Di}，边缘服务器Ei获取对应车辆数据Di；S2、在第k轮联邦任务中，边缘服务器Ei从云服务器CS中下载初始A型梯度并解密为随机初始化B型梯度边缘服务器Ei根据其车辆数据Di的最小化损失函数来计算本地网络模型训练中的梯度，边缘服务器Ei完成T轮本地训练完后的梯度信息记为S3、边缘服务器Ei通过解码函数从中获取需要保留的部分梯度信息并将剩余的梯度信息经同态加密为再通过MePC算法广播发送给其它所有的边缘服务器Ej；边缘服务器Ei根据解码函数获取来自其它边缘服务器Ej的对应部分梯度信息所有边缘服务器更新共享后的A类梯度信息分别为i∈，n为边缘服务器的总数；S4、所有边缘服务器将上传到云服务器CS，云服务器CS通过PreFLa算法聚合全局参数，PreFLa算法通过强化学习获得最大化回报来选择边缘服务器Ei的最优参数权重比ai，k，全局参数根据ai，k进行聚合；参数的上传和下载过程是并行的，所有参数都经过HE加密；S5、重复步骤S2-S4，直到达到终止条件，完成整个训练过程。终止条件可以是最大训练周期数、损失函数的收敛性或其他用户定义的条件。最后，可以根据以下公式得到最优的损失函数。其中，L表示Ei网络的损失。本地训练的具体方法为：在局部模型阶段，采用深度神经网络来学习云模型和ES模型。DNN通过将不同用户数据作为原始输入来执行端到端的特征学习和分类器训练。将在提出的算法中使用随机梯度下降作为子程序来最小化每个本地训练中损失值。在下行通信阶段Ei在第k轮通信中从CS下载基础层参数并随机初始化其中，K表示联邦任务的总轮数。若为第一轮联邦任务，CS随机初始化在本地训练之前，Ei需要通过使用同态加密)对解密为并记为为了更好的体现模型个性化，局部模型的损失函数设置如下：L＝l+λ2其中l表示网络的损失，例如分类任务的交叉熵损失。第二项是L2正则化项，既可以保留自己的个性化能力，又可以提高与其他参与者的协作效率。λ是正则化系数。Ei初始化Gk并替换模型的权重参数wi，继续进行局部模型训练如下wi＝wi-ηGk其中，η是学习率，Gk是和的总表示。这里的随机初始化。Ei在达到T轮本地训练后，此时会得到每个局部模型的准确率acci，k、和端与端之间直接共享用户信息是禁止的，边缘服务器中的数据在通信前需要进行加密，防止数据在通信前被攻击。这个过程使用HE来避免信息泄露。以下将展示使用实数进行加法HE的过程。权重矩阵和偏置向量的加密方案遵循相同的思想，实数a的加法同态加密表示为aE。在加法同态加密中，对于任意两个数a和b，有aE+bE＝E。将任何实数r转换为编码的有理数不动点v的方法是：认为梯度中的每个编码实数r可以表示为有理定理的H位数，由一个符号位、z位整数位和d位小数位组成。因此，每个可以编码的有理数都由其H＝1+z+d位定义。执行编码以允许乘法运算，这需要运算模数为H+2d以避免比较。解码定义为：这些编码数字的乘法需要去除因子1/2d。使用Paillier加法加密时，可以准确计算编码乘法的情况，但只能保证一次同态乘法。为简单起见，在解码时处理它。如果只发生了一次代码乘法，则它是正确的。因为最大的可加密整数是V-1，所以最大的可加密实数必须考虑到这一点。因此，整数z和小数d的选择必须如下：V≥2H+2d≥21+z+3d加密过后的和aCCi，k分别表示为和MePC算法的具体方法如图3所示。第k轮联邦任务中，使用MePC来交换基础层梯度为了避免数据被破解的风险，在每个网络中取随机比例χ的梯度即为并保持同一轮联邦的随机比例χ相同。在不同轮的联邦任务中，随机比例χ是变化的，剩下的梯度被均分为n-1份如图3所示，的值划分为：只有被保留在Ei中，其他部分和随机参数χ将会以密文的形式广播发送给其他ESs。通过这种方式，即使部分传输内容被攻击，最初的数据也不会泄露。具体来说，如果攻击者想要获取数据就必须获取的所有部分。但是，和χ在参与者Ei和接收者Ej之间通信时都是通过同态加密保持密文形式。共享给其他ESs的梯度信息是当Ei接收到由其他服务器发送的数据包它在本地执行数据验证。具体来说，它使用相应的“乘法”方法进行验证。每个边缘服务器自己设计两个解码功能，如下：其中，L0是的长度，L’是的长度。L0＝χ·L其中，L是的长度，与的长度相等。要求满足所有ES的解码函数对同一个数据包执行“并”操作得到全0，并执行“交”操作得到全1，即首先，初始化解码函数如下，需要说明的是，在初始化的时候，不同Ei发送的数据包在同一个联邦任务中的数据解码也是同一个函数。将数据包与其他服务器中相应的解码函数相乘。由于中0的二进制位被乘得0，所以Ei可以保证只得到它自己的部分数据包。当中的二进制位为1时，可以得到对应位置的梯度信息的密文，如下：Ei将从其他ES获取的所有数据包数组添加到对应位置，得到所有密文数据，并更新为最后即每次进行安全多方计算时，随着k的增加将每个Ei中的解码函数的二进制向左循环移动m个单位，以保证共享的动态性，并可以将它们平均划分到E1，E2，…，En中，且每个部分的数据信息不重复。PreFla算法的具体方法为：车联网中的数据分布较为分散且数据的不平衡和异构化问题，在满足实时性要求的同时提高个性化服务需求就很困难。为了防止不同边缘服务器通信过程中的用户隐私泄露，在通信过程中使用HE对参数进行加密。为了更好的实现针对不同的用户数据进行个性化训练，将第一层设置为基础层，使用现有的联邦学习方法以协作方式进行训练，而其他层作为个性化层在本地训练，从而能够捕获不同ES设备的个人信息。这样，在联合训练过程之后，全局共享的基础层可以转移到ES中，以构建自己的个性化深度学习模型，并使用其独特的个性化层。仅从CS下载基础层参数个性化层的参数随机生成并使用本地数据进行微调。为了满足实时性要求，实现ES的个性化需求，PreFLa采用强化学习进行适配来选择最优参数权重比ai，k聚合全局参数在上行通信阶段，每个ES不仅训练局部模型，还将本地参数上传到CS进行联合聚合。在第k轮联邦中执行MePC算法后，Ei通过TLS/SSL安全通道将参数和上传到BS。在聚合阶段，由于每个ES的分布不平衡和数据异构性，其模型参数用于聚合对该阶段的收敛速度具有至关重要的影响。因此，有必要考虑k轮联邦聚合中参与者Ei的参数权重比ai，k。本发明中使用基于DQN的强化学习去预测参数权重比，通过Q函数而不是Q-Learning中的表存储来存储信息，以防止空间多维灾难。为了更好地实现模型个性化，减少MePC-F中上传权重的等待时间，用DQN来选择最优参数权重比ai，k来，聚合更新CS中的全局参数强化学习中核心内容有：状态、动作、奖励函数以及反馈，定义如下：状态：第k轮的状态其中，是精度差，表示为：动作：参数权重占比ai，k表示为第k轮联邦任务的动作。为避免陷入局部最优解，采用ε-贪心算法优化动作选择过程，可以得到ai，k：其中P是权重排列的集合，rand是一个随机数，Q指代理在状态si，k下采取行动ai，k时的累积折现收益。一旦DQN在测试期间被训练为近似Q，DQN代理将为第k轮中的所有动作计算{Q|ai，k∈}。每个动作值表示代理通过在状态si，k选择特定动作ai，k可以获得的最大预期回报。奖励：将第k轮联邦结束时观察到的奖励设置为其中，是一个正数，确保rk随着测试准确度Δacci，k呈指数增长。第一项激励代理选择能够实现更高测试精度的设备。用来控制随着Δacci，k增长rk的变化。一般来说，随着机器学习训练的进行，模型准确率会以较慢的速度增加。但在联邦合作任务中，由于数据分布不平衡和异质性，模型精度可能会降低。因此，随着FL进入后期阶段，使用指数项来放大边界准确度的增加。第二项-1用来鼓励智能体提高模型准确性，因为当Δacci，k小于0时，有rk∈。训练DQN代理以最大化累积折扣奖励的期望，如下式所示其中，γ∈。最优动作值函数Q是RL代理寻求的备忘单，定义为从si，k开始的累积折现收益的最大期望：Q＝E|si，k，ai，k)然后，可以应用函数逼近技术学习一个参数化的值函数Q逼近最优值函数Q。第一步的rk+γmax Q是Q学习的目标。通常，DNN用于表示函数逼近器。RL学习问题变成最小化目标和逼近器之间的MSE损失，定义为：l＝-Q)2CS更新全局参数wk为：其中，η≥0是步长。CS重复上述步骤以获得最佳学习模型。CS可以得到第k轮权重比序列的ai，k，将全局参数更新为：所有ES更新全局参数并开始接下来的T轮本地训练。实验测试实施例：为了验证所提出的机制的有效性，给出了实验结果和分析。分别考虑具有1个云服务器、10个边缘服务器的系统。实验学习率α为0.01，折扣因子γ为0.9。正整数取3。各参数取值见表2。表2参数设置在两个数据集上验证了提出的模型的有效性：MNIST和CIFAR-10。所提出的联邦学习模型MePC-F的性能是根据DLG的重建图像、平均精度和平均损失来评估的。首先，防御DLG攻击的五种方案的性能，然后将所提出的联邦学习模型MePC-F的性能与集中式和PeMPC进行比较。以下场景中的所有结果都是1000次独立实验的平均值。1)防御DLG攻击的性能这一节评估MePC-F的有效性并与FL、PeMPC和DP算法在DLG重建图像方面进行比较。为MNIST数据集上的单个图像计算网络的公共梯度，不同方案的结果如图4所示。由于研究表明隐藏第一层的梯度可以减少数据的重建，用四种方法替换第一层的梯度：提出的MePC-F、PeMPC、高斯分布噪声和拉普拉斯分布噪声以查看DLG的行为。在完成隐藏第一层的梯度后，DLG使用这些梯度来恢复创建公共共享梯度的图像。从图4可以看出，在没有任何方法隐藏第一层的梯度中的FL)时，DLG过程可以准确地重建训练数据。当第一层的梯度用本发明提出的方法MePC-F进行保护时，图4中可以有效地防止信息泄漏。当迭代步数达到500时，DLG仍然无法构建图像。从图4中可以看到与图4类似的结果，PeMPC也可以防御图4中的DLG攻击。从图4可以看出，通过在第一层加入高斯噪声，重建图像从第15轮开始有部分显示，到第20轮已经构建了原图的基本轮廓。随着迭代轮数增加到500轮，可以清晰地恢复图像。图4中的拉普拉斯噪声与驾驭高斯噪声也有类似的现象。从图5可以看出，如果恶意服务器将所有隐藏层的梯度作为纯文本接收，则重建过程能够获得最低梯度损失和图像的MSE。随着轮数的增加，PeMPC和MePC-F不会收敛到零，图像的MSE达到107。在原始梯度上添加拉普拉斯和高斯噪声会收敛到10-5，图4也证明了当达到20轮时数据可以被重构。图像的MSE越大，表明图像被重建的可能性就越小。基于以上实验结果验证了在原始梯度上加入拉普拉斯和高斯噪声可以防止早期的部分梯度泄漏，但是随着轮数的增加，由于深度泄漏仍然会恢复原始数据。然而，PeMPC和MePC-F无论训练轮数多久都是可以防止DLG攻击重建原始数据的有效方法。2)平均准确率和平均损失的性能比较在本节中，评估MePC-F的有效性，并与集中式和PeMPC在平均准确度、MNIST和CIFAR-10数据集上的平均损失方面进行比较。从图6中可以看出模型在MNIST数据集上达到98％的准确度所需的轮数。三个方法的平均准确率都随着训练轮次的增加而增加。在MNIST数据上实现目标准确度集中式方法需要25轮，PeMPC需要140轮和MePC-F需要40轮，MePC-F需要的训练轮数比PeMPC低71.2％。原因是所提出的强化联邦学习算法PreFLa可以通过与环境的交互找到更好的聚合参数权重ai,k，可以更好地应对No-IID数据，加速模型收敛，达到目标精度。集中式是在在所有数据的组合上训练，所以它的准确性将高于联邦学习算法的准确性。但是从图中可以看出PeMPC的收敛几乎可以达到集中式的精度。从图6中，可以看到三个方案的平均损失随着训练轮数的增加而减少。对于集中式，平均损失从0.233减少到0.052。PeMPC的平均损失从0.35减少到0.084。同时，本发明提出的MePC-F的平均损失降低到0.06，低于PeMPC的28.6％。当训练轮数达到100轮时，提出的MePC-F几乎可以达到集中式的损失值。从图7中可以看出，模型在CAFIR-10上达到50％的目标准确度所需的轮数。可以看到与图6类似的结果。三个模型的平均准确率都在增加，直到达到目标值。对于集中式，平均准确度从0.42增加到0.5，共23轮。PeMPC的平均准确率从0.372上升到0.5，共89轮。同时，所提出的MePC-F的平均精度在41轮时达到目标精度，比PeMPC低53.9％。图7表明，MePC-F使用比PeMPC更优的权重ai,k来更新全局模型，这导致更快的收敛速度。从图7可以看出，三种方案的平均损失正在减少，直到达到稳定值。集中式、MePC-F、PeMPC依次达到损失最小值，提出的MePC-F的时间效率在PeMPC下更好。表3 100轮内三种方案的最高精度MNISTCIFAR-10centralized98.4％51.4％MePC-F98.2％51.1％PeMPC97.6％49.2％表3给出三种方案在100轮内的精度。对于MNIST数据，所提出的MePC-F的平均准确率为98.2％，比PeMPC高0.6％。PeMPC的准确率几乎可以达到集中训练的准确率。对于CAFIR-10数据，MePC-F在100轮时的平均准确度高达0.511，比PeMPC高1.9％。它表明，MePC-F可以通过最优权重更新ai,k,比PeMPC更好地聚合全局参数，从而获得更高的准确度，更接近集中准确度。应当理解的是，对本领域普通技术人员来说，可以根据上述说明加以改进或变换，而所有这些改进和变换都应属于本发明所附权利要求的保护范围。
