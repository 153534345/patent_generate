标题title
一种小样本图像分类方法
摘要abst
本发明公开一种小样本图像分类方法，包括，基于储备池构建小样本学习模型，其中所述小样本学习模型包括特征提取模块、基于储备池的特征增强模块及分类器；获取自动驾驶过程中的小样本数据集，通过小样本数据对小样本学习模型进行训练、测试及验证，生成优化模型，获取自动驾驶过程中的实测小样本图像，通过优化模型对实测小样本图像进行分类，得到分类结果以实现自动驾驶过程中的小样本图像分类。
权利要求书clms
1.一种小样本图像分类方法，其特征在于，包括：基于储备池构建小样本学习模型，其中所述小样本学习模型包括特征提取模块、基于储备池的特征增强模块及分类器；获取自动驾驶过程中的小样本数据集，通过小样本数据对小样本学习模型进行训练、测试及验证，生成优化模型，获取自动驾驶过程中的实测小样本图像，通过优化模型对实测小样本图像进行分类，得到分类结果以实现自动驾驶过程中的小样本图像分类。2.根据权利要求1所述的分类方法，其特征在于：所述特征提取模块为卷积网络以对小样本图像进行特征提取。3.根据权利要求1所述的分类方法，其特征在于：所述基于储备池的特征增强模块包括通道级特征增强模块及像素级特征增强模块，其中所述通道级特征增强模块及像素级特征增强模块均包括储备池，所述储备池内部拓扑采用半全连接结构。4.根据权利要求3所述的分类方法，其特征在于：所述通道级特征增强模块由依次连接的线性层、储备池及残差块组成，其中所述残差块内包含一种批归一化层及前馈层。5.根据权利要求3所述的分类方法，其特征在于：所述像素级特征增强模块采用基于三个储备池的注意力机制，通过三个储备池生成新的特征图参数，根据新的特征图参数生成输出特征。6.根据权利要求1所述的分类方法，其特征在于：所述分类器采用线性分类器，后续将线性分类器替换为余弦分类器。7.根据权利要求1所述的分类方法，其特征在于：所述小样本数据集包括目标域数据及辅助数据集。8.根据权利要求1所述的分类方法，其特征在于：对小样本学习模型进行训练、测试及验证的过程包括：对所述小样本数据集进行划分，划分为训练集、验证集及测试集，通过训练集采用交叉验证法对样本学习模型进行训练，将训练好的模型中的线性分类器替换为余弦分类器，并对替换后的模型中的参数进行微调，通过小样本数据集采用元学习方法对微调后的模型进行训练验证及测试，生成优化模型。
说明书desc
技术领域本发明涉及图像分类技术领域，特别涉及一种小样本图像分类方法。背景技术近年来，深度学习方法凭借大规模数据大幅度提高了图像分类、人脸识别、目标检测以及语义分割等任务的分类精度，在计算机视觉领域取得了巨大的成功。然而，现实场景往往是数据稀缺的，即并不具备获得大规模可训练数据的条件，使得深度学习方法容易产生过拟合、低泛化能力等问题。为了能够在数据稀缺的场景下进行学习，小样本学习成为深度学习的一个重要研究方向。目前小样本学习大体上可以被分为两类，基于数据增强的方法和基于学习策略的方法。基于数据增强的方法旨在生成新样本来扩充原始样本空间或者特征空间；基于学习策略的方法可以细分为基于模型微调的方法、基于元学习的方法等。模型微调的方法指对传统的神经网络进行预训练并精细的调参，此类方法操作简单，已经取得了很好的效果，但仍然存在过拟合问题。元学习方法在解决小样本问题时显示出了巨大的潜力。基于元学习的方法将训练集划分为大量的元任务，通过元任务训练模型从而使其具有解决元任务的能力，而不是训练网络识别所有类别的图像，这样网络具有足够的泛化能力取解决来自测试集的元任务。元学习方法常常与其他方法结合，具体包括基于度量学习的元学习方法、基于外部记忆的元学习方法以及基于学习优化器的元学习方法等。针对现有技术中小样本图像分类过程中的特征提取网络提取的特征判别性不充分、容易过拟合、跨域场景下泛化能力不足的问题。基于上面的分析，在解决小样本问题时需要关注两个方面的问题：1）更好的提取特征来指导分类；2）增强学习到的特征以缓解过拟合，提高模型泛化能力。受启发与人脑是一种天然的小样本学习范式，引入类脑知识解决小样本问题或许具有应用前景。再结合过拟合问题，本发明考虑一种类脑模型—储备池计算，其依靠内部复杂动力学特性而天然具有一定抗过拟合能力，能够有效表达复杂输入信息，但在计算机视觉任务上如小样本图像分类上几乎没有应用，进而无法有效对自动驾驶过程中小样本图像如低频率或危险场景下的物体图像进行有效分类。发明内容为解决上述现有技术中所存在的自动驾驶过程中的小样本图像的分类过程中特征提取网络提取的特征判别性不充分、容易过拟合、跨域场景下泛化能力不足导致小样本图像分类不准确的问题，本发明提供一种小样本图像分类方法，能够对小样本图像进行有效分类。为了实现上述技术目的，本发明提供了如下技术方案：一种小样本图像分类方法，包括：基于储备池构建小样本学习模型，其中所述小样本学习模型包括特征提取模块、基于储备池的特征增强模块及分类器；获取自动驾驶过程中的小样本数据集，通过小样本数据对小样本学习模型进行训练、测试及验证，生成优化模型，获取自动驾驶过程中的实测小样本图像，通过优化模型对实测小样本图像进行分类，得到分类结果以实现自动驾驶过程中的小样本图像分类。可选的，所述特征提取模块为卷积网络以对小样本图像进行特征提取。可选的，所述基于储备池的特征增强模块包括通道级特征增强模块及像素级特征增强模块，其中所述通道级特征增强模块及像素级特征增强模块均包括储备池，所述储备池内部拓扑采用半全连接结构。可选的，所述通道级特征增强模块由依次连接的线性层、储备池及残差块组成，其中所述残差块内包含一种批归一化层及前馈层。可选的，所述像素级特征增强模块采用基于三个储备池的注意力机制，通过三个储备池生成新的特征图参数，根据新的特征图参数生成输出特征。可选的，所述分类器采用线性分类器，后续将线性分类器替换为余弦分类器。可选的，所述小样本数据集包括目标域数据及辅助数据集。可选的，对小样本学习模型进行训练、测试及验证的过程包括：对所述小样本数据集进行划分，划分为训练集、验证集及测试集，通过训练集采用交叉验证法对样本学习模型进行训练，将训练好的模型中的线性分类器替换为余弦分类器，并对替换后的模型中的参数进行微调，通过小样本数据集对微调后的模型进行训练验证及测试，生成优化模型。本发明具有如下技术效果：1）本发明能够对自动驾驶过程中的小样本图像进行有效分类，针对过拟合问题，本发明提出了一种新的训练策略：第一训练阶段先在小样本数据的训练集上使用线性分类器预训练模型；第二训练阶段使用余弦相似度分类器代替原线性分类器并微调模型，以元学习方式在整个小样本数据集上完成图像分类任务。其中，将特征提取网络提取的特征分别送入储备池通道级特征增强模块和基于储备池的注意力机制的像素级特征增强模块，最后进行特征融合得到增强后的特征。特征增强模块学习更具判别性的特征，增强模型的泛化能力提升小样本图像自动驾驶过程中的不同场景下的分类有效性。2）针对特征提取增强问题，本发明在元学习阶段使用余弦相似度分类器，与基于储备池网络的像素级和通道级特征增强结合诱导网络提取具有低类间方差、高类内方差分布的特征，从而更好地指导分类提升自动驾驶过程中的小样本图像特征层面的分类有效性。3）本发明在几个常见公开小样本图像分类数据集上做了广泛的实验，所提模型和方法达到了具有竞争力的准确率，在面对跨域问题时表现较好。附图说明为了更清楚地说明本发明实施例或现有技术中的技术方案，下面将对实施例中所需要使用的附图作简单地介绍，显而易见地，下面描述中的附图仅仅是本发明的一些实施例，对于本领域普通技术人员来讲，在不付出创造性劳动性的前提下，还可以根据这些附图获得其他的附图。图1为本发明实施例提供的基于储备池计算的小样本学习模型算法整体框架示意图；图2为本发明实施例提供的基于储备池计算的两阶段训练方法示意图。具体实施方式下面将结合本发明实施例中的附图，对本发明实施例中的技术方案进行清楚、完整地描述，显然，所描述的实施例仅仅是本发明一部分实施例，而不是全部的实施例。基于本发明中的实施例，本领域普通技术人员在没有做出创造性劳动前提下所获得的所有其他实施例，都属于本发明保护的范围。传统的深度学习方法面对自动驾驶过程中的数据稀缺的现实场景时，模型易过拟合且泛化能力不佳。近年来，多种多样的小样本学习方法被提出来解决这个问题。然而，目前的小样本学习存在算法和模型复杂、跨域问题泛化能力不足等问题。针对以上问题，受启发于储备池计算不依赖于训练而缓解过拟合的特性，我们提出了一种基于储备池计算的小样本学习方法。在训练策略方面，我们先在自动驾驶过程中的小样本数据集的训练集上预训练模型，然后再微调模型完成小样本学习任务；在模型设计方面，通过储备池模块和基于储备池计算的注意力机制对嵌入网络提取的特征分别进行通道级增强和像素级增强，同时联合余弦分类器使得特征分布具有高类间方差低类内方差的特性。实验表明，该算法在FC100、CIFAR-FS、Mini-ImageNet和CUB-200数据集以及跨域场景设置下的准确率均优于现有的方法。因此，所提方法能够有效缓解过自动驾驶过程中的小样本图像分类中的过拟合问题，且泛化能力强，一定程度解决了跨域问题，以提升小样本图像分类的准确性。针对上述方案，本发明提供如下技术方案：1基于储备池计算的小样本图像分类1.1 问题定义与传统的机器学习和深度学习方法不同，小样本学习有其特殊的学习方法和训练策略。由于小样本学习的后续任务都基于少量有标签数据，而少量数据难以学习到数据模式，容易过拟合。因此，一般会引入一个含有丰富标注样本和类别的辅助数据集以帮助模型学习先验知识，然后再利用这些先验知识在目标数据域上获得更好的任务表现。小样本学习通常以元任务的方式进行训练和评估，每个元任务都以N-way K-shot方法获得，即每个元任务都包括种类别的数据,每类数据只包含个有标签的样本，同时从每类数据中抽取个样本作为预测样本。有标签样本构成的数据集一般称为支持集，预测样本构成的数据集称为查询集。即：其中， 和分别表示有标签样本中第i个样本及其对应的标签类别；表示类别数量，为支持集中每类样本的数量；表示查询集中每类预测样本的数量。模型在支持集上学习后在测试集上评估其泛化能力。通过从新类中抽取大量的元任务来获得这些任务的平均准确率，以评估模型在小样本学习任务上的分类性能。1.2 算法框架基于储备池计算的小样本学习模型框架如图1所示，该模型主要由以下三个模块组成：特征提取模块、基于储备池的特征增强模块和分类器模块。首先，通过特征提取模块对输入图像进行特征提取。然后，将提取的特征进行维度变换后输入储备池特征增强模块，储备池通道级特征增强模块对输入特征进行高维表示以提取重要的通道信息；基于储备池的注意力像素级特征增强模块对输入特征的重要像素信息进行提取。然后，随后将两部分增强特征进行融合输出到分类器模块。1.3 两阶段训练策略小样本学习的数据集通常划分为训练集、验证集和测试集，其中训练集为基类数据，验证集和测试集为新类数据。如图2所示，本发明提出了一种基于模型微调的两阶段训练策略。第一阶段为模型预训练。将自动驾驶过程中的小样本数据集的训练集按照合适的比例划分为新的训练集和验证集，模型在新划分的数据集上以传统图像分类的方式进行训练，分类器使用线性分类器，最后得到预训练模型。该阶段使得模型能够充分学习基类的特征，为将学习到的知识迁移到小样本学习任务时做准备，一定程度上缓解过拟合问题。第二阶段为模型微调的小样本学习阶段。将第一阶段的预训练模型的分类器部分换为余弦分类器，然后对学习率等参数进行微调。再在原始的小样本数据集上以N-way K-shot的元学习方式进行模型训练和评估。针对微调阶段的模型，训练集用于训练模型以及确定参数；验证集用于确定网络结构以及调整模型的超参数；测试集用于测试模型的泛化能力。1.4 特征提取模块随着卷积网络宽度和深度的增加，网络对图像信息的提取能更加充分，但由于数据样本较少带来的过拟合问题，使得在小样本学习任务中网络不能一味的加深加宽。文发明使用了小样本学习任务中不同的主流主干网络作为特征提取模块。通过特征提取模块提取输入图像的特征向量过程如下式所示：其中，为特征图的通道数，和分别为特征图的高和宽。1.5 特征增强模块1.5.1半全连接的储备池内部拓扑结构储备池的强大性能来源于其内部复杂的动力学特性，表现为储备池内部神经元之间的连接方式，称其为储备池内部拓扑结构。因此，用储备池来处理复杂的视觉信息时，需要设一个相匹配的拓扑结构来提升储备池的性能。本发明的不使用传统的随机方法生成，也不同于经典的延迟线结构、循环结构以及对称结构等拓扑结构，本发明提出了一种半全连接的拓扑结构，生成方式如下所述。首先，生成一个的矩阵，使其元素全为；然后，将第一行最后一个元素和从第二行第一个元素开始的对角线元素设为，即： 公式中的下标代表元素在中的位置，为第k+1行第k列的元素。随后，从矩阵第一个元素开始，按从左到右从上往下的顺序，每隔p个元素将其值设为，当要设置的元素超出矩阵范围时停止。对于网络的随机性，本发明最后随机选择四分之一的元素及其对称位置的元素设置为0。那么整个连接矩阵中大部分元素为0和，小部分元素为和。为了储备池能够稳定运行，的谱半径应该被约束到1，即对进行如下变换：其中，为缩放尺度因子，为变换前的的特征值绝对值中的最大值。根据实验结果显示，相较于其他几种经典拓扑结构，本发明的拓扑结构具有较好的信息流动能力和更丰富的动力学特征，更适合处复杂的视觉数据。1.5.2 储备池通道级特征增强模块储备池计算模块主要由半全连接拓扑结构的储备池和残差模块组成。在特征输入储备池之前，需要通过一个线性层对提取的特征进行维度变换，使其变为适应储备池输入的维度，即，其中，表示线性层的输出维度，也是储备池输入的维度。由于储备池计算的传统优势在于处理时序数据，而在自动驾驶场景中小样本图像数据不具有此类关系。因此，本发明将按照通道维度进行划分得到了个维的数据，将其视为个时刻的输入。那么储备池内部神经元状态更新方程如下式所示：其中，是输入特征到储备池的连接矩阵，其元素按高斯分布生成；按照本发明所提出的半全连接拓扑结构的生成。这两个矩阵按照各自的规律生成后固定不变，不需要学习。表示第t+1个输入，表示第t+1个输入时储备池内部神经元的状态。表示激活函数。储备池每个时刻的输出和整个储备池的输出根据下式计算： 其中，代表矩阵拼接操作；代表储备池输出连接矩阵，不同于传统的岭回归方法来求解该矩阵，本发明使用一个可学习的线性层来逼近该矩阵。储备池后接一个残差模块，残差模块内含一个批归一化层和前馈层以增加网络信息流通能力，防止网络退化。整个储备池通道级特征增强模块RCM的运算对应输出如下式所示：其中 ，为整个特征增强模块的参数，为储备池的输出先经过BN层处理再经过FF层处理的结果。1.5.3 基于储备池的注意力机制像素级特征增强模块在小样本学习领域，注意力机制常被用来整合特征信息。本发明提出了一种新颖的注意力机制生成方式，相较于传统的基于线性变换或卷积的生成方式，本方法使得特征分布具有高类间方差、低类内方差的特点。模块通过储备池生成新的特征图Q、K和V,然后根据下式计算输出：其中，为可学习参数，RCi为第i个储备池计算结果。最后进行特征融合：1.6 分类器模块被增强的输出特征随后送入分类器得到最后的分类结果： 第一阶段使用的是线性分类器，则：其中，为分类权重矩阵的转置，是偏置项。第二阶段使用余弦分类器，则：其中，是一个可学习的尺度因子。尽管最近余弦相似性已成为分类任务和FSL的有效相似函数，但是在本发明的工作中以不同的方式使用它，即对余弦分类器优点的一种可能解释是，余弦分类器中的归一化操作迫使特征提取模块提取输入图像最具代表性的特征。同时，余弦分类器结合储备池模块使得增强的特征分布具有低类内方差和高类间方差的特征。储备池与余弦分类器相结合，通过N-way K-shot采样训练测试，提高了小样本任务分类精度和小样本模型ModelFSL的泛化能力。通过上述的训练测试对构建的模型进行优化，生成优化模型即小样本模型ModelFSL，并获取在自动驾驶场景中需要分类的实测小样本图像，通过优化模型对实测小样本图像进行识别，生成最终的分类结果Ypredict。2实验结果及分析2.1 数据集和实验环境本发明对所提方法和模型在Cifar-fs、FC100和Mini-Imagenet这三个标准公开的数据集上进行了常规小样本图像分类实验。随后，为了验证模型的泛化性能，我们设置了跨域场景，在Mini-Imagenet上训练模型后，在CUB数据集上验证模型性能。Cifar-fs数据集源自Cifar 100数据集，共包含100个类，每类包含600张尺寸大小为的图像，使用时将其划分为训练集、验证集和测试集。FC100数据集也源自Cifar 100数据集，共包含100个类，每类包含600张图像。但与Cifar-fs不同的是，FC100在使用时不是按照类别划分的，而是按照超类进行划分的。FC100共包含20个超类，其中训练集有12个超类，验证集有4个超类，测试集有4个超类。Mini-Imagenet数据集由ImageNet数据集中选取的100个类构成，每个类别有600张图像，每幅图像的尺寸为。使用时将其分为训练集、验证集和测试集。CUB数据集共包含200种鸟类的11788张图像。使用中将其划分为训练集、验证集和测试集。实验平台的配置GTX2080Ti显卡，使用Linux操作系统、Python3.8和PyTorch1.9.0+cu102深度学习框架。2.2实验设置对于特征提取器，以小样本图像分类常用ResNet12和ResNet18为骨干网络，按照两阶段训练方式进行训练。第一阶段训练100个epoch,采用SGD优化器，初始学习率为0.001并动态调整；第二阶段训练300个epoch，每个epoch包含50个元任务，最后给出的结果是1500个元任务的平均分类精度。实验在mini-Imagenet、Cifar-FS、FC100等数据集上采用5-way 1-shot和5-way 5-shot方式采样任务来测试模型的准确性。所提方法在Cifar-FS、FC100、Mini-ImageNet等小样本数据集上的图像分类精度至少比现有方法高1.07%，在从Mini-ImageNet到CUB-200的自动驾驶过程中的不同场景即跨域场景设置下的分类精度至少优于现有方法1.77%，所提方法具有较强的泛化性。以上显示和描述了本发明的基本原理、主要特征和优点。本行业的技术人员应该了解，本发明不受上述实施例的限制，上述实施例和说明书中描述的只是说明本发明的原理，在不脱离本发明精神和范围的前提下，本发明还会有各种变化和改进，这些变化和改进都落入要求保护的本发明范围内。本发明要求保护范围由所附的权利要求书及其等效物界定。
