标题title
基于LG-CenterNet模型的复杂道路场景目标检测方法及装置
摘要abst
本发明公开了一种基于LG‑CenterNet模型的复杂道路场景目标检测方法及装置，采集原始的道路图像数据集制作数据集，通过构建LG‑CenterNet网络模型，使用ResNet50作为模型的Backbone提取特征对，采用层级引导注意力机制对主干网络的不同尺度的特征图来提高其感受野的同时对不同层级的特征进行引导；再将层级引导机制处理过的特征图输入到ScalesEncoder模块处理；采用反卷积模块进行特征像素还原；对还原的特征采用新的特征增强模块解决像素还原过程中出现的特征信息丢失的问题；最终将增强后的特征图输入到Center points预测模块进行道路目标类别识别和位置定位。本发明在自建的复杂道路场景数据集的识别平均精度为86.93％，道路场景目标图像检测速度达到50帧/s，能够满足对道路场景的准确检测和实时检测的要求。
权利要求书clms
1.一种基于LG-CenterNet模型的复杂道路场景目标检测方法，其特征在于，包括以下步骤：对复杂道路场景的图像进行处理，获取到含有多种类别的道路目标图像，对图像中的道路目标进行类别和位置标记，构建出复杂的道路场景数据集并进行预处理；构建目标检测LG-CenterNet模型，并将上述的道路目标数据集通过LG-CenterNet模型进行训练得到模型S；所述LG-CenterNet模型包括Backbone模块、层级引导注意力模块、Scales Encoder模块、反卷积模块、特征增强模块和Centerpoints预测模块；使用训练好的模型S对复杂道路目标通过Center points预测模块以热力图的形式进行目标定位、边框大小划分和类别预测，并将得到的结果在视频或者图像上进行显示输入相应的效果。2.根据权利要求1所述的一种基于LG-CenterNet模型的复杂道路场景目标检测方法，其特征在于，步骤所述的对道路场景数据集预处理是通过将像素不一和复杂道路场景的图像进行归一化处理，将图像的大小归一化为512×512像素大小，再通过批标准化、ReLU激活函数和最大池化操作得到分布均匀的特征目标样本。3.根据权利要求1所述的一种基于LG-CenterNet模型的复杂道路场景目标检测方法，其特征在于，所述步骤实现过程如下：LG-CenterNet模型中提出新的MresneIt50作为Backbone模块，MresneIt50由多个残差块组成，其中将4个残差模块提取到的特征图记为E1，通道数为512；将6个残差块提取到的特征图记为E2，通道数为1024；将3个通道数提取到的特征图记为E3，通道数为2048；将Backbone提取到的特征图E1、E2、E3输入到层级引导注意力模块中，其主要的结构包括两个分支：全局池化分支和层级引导分支，将通道数为512的特征图E1输入到全局池化分支，通过全局最大池化层和上采样层操作获得EC1；将通道数为512、1024、2048的特征图E1、E2、E3输入到层级引导分支中，通过一系列的平均池化和卷积操作并配合上采样得到EC2；将EC1和EC2使用add进行特征联合获得EC3，从而减少计算参数；将提取到的EC3输入到Scales Encoder模块，进行一系列的卷积和残差模块运算后得到EC4；将提取到的EC4输入到反卷积模块，反卷积模块由3个deconv组组成，通过每次deconv组的卷积运算将特征图尺寸不断放大，同时通道数不断降低，得到尺度为128×128×64的特征图记为EC5；将特征图EC5输入到特征增强模块进行卷积运算得到尺度大小为128×128×64特征图EC6，P-FEM由3×3的Poly-Scale Convolution、批标准化、ReLU激活函数和Sigmoid激活函数构成，主要是为了提高特征图中的局部信息的相关性，增强其对特征的表达能力。4.根据权利要求1所述的一种基于LG-CenterNet模型的复杂道路场景目标检测方法，其特征在于，所述步骤实现过程如下：Centerpoints预测模块通过对训练好的模型S对输入的图片进行分类预测，将原始图像生成尺度与EC6大小一致的heatmap图，随后通过分别计算热力图的损失值记为Lh，目标长宽的损失值记为Ls和中心点偏移量的损失值记为Lf来确定目标的位置和大小并生成最后的分类定位的heatmap；其中总体的网络损失为：Ld＝Lk+λsLs+λfLf其中λs＝0.1，λf＝1；对于输入图片大小为512×215的图像来说其通过该网络生成的特征图为H×W×C，则Lk、Ls和Lf计算公式分别为：其中，AHWC为图像中目标标注的真实值，A'HWC为图像的预测值，α和β分别为2和4，N为图像中关键点的个数，s'pk为预测尺寸，sk为真实尺寸，p为图像中目标的中心点位置。5.一种基于LG-CenterNet模型的复杂道路场景目标检测装置，包括存储器、处理器及存储在存储器上并可在处理器上运行的计算机程序，其特征在于，所述计算机程序被加载至处理器时实现根据权利要求1-4任一项所述的基于LG-CenterNet模型的复杂道路场景目标检测方法。
说明书desc
技术领域本发明属于语义分割、图像处理及智能驾驶领域，具体涉及一种基于LG-CenterNet模型的复杂道路场景目标检测方法及装置。背景技术近些年汽车数目稳健上升导致交通事故频发，这严重威胁到了人民的生命安全。如今，随着自动驾驶技术的发展，研究人员也从汽车被动安全技术研究转向了汽车主动安全技术研究。实现汽车的自动化必须使用一些先进的技术手段才能完成部分的汽车驾驶任务。采用深度学习方法对道路场景目标进行智能检测是解决汽车主动安全技术的关键。现阶段的目标检测网络主要是通过主干网络进行特征提取，但是在对底层的多尺度问题没有进行过多的考虑，可能会导致多尺度目标检测能力不足的情况。发明内容发明目的：针对现阶段复杂道路场景目标检测应用效果不佳，常规的检测方法不能满足实际道路环境的检测要求，提供一种基于LG-CenterNet模型的复杂道路场景目标检测方法及装置。技术方案：本发明提出一种基于LG-CenterNet模型的复杂道路场景目标检测方法，具体包括以下步骤：对复杂道路场景的图像进行处理，获取到含有多种类别的道路目标图像，对图像中的道路目标进行类别和位置标记，构建出复杂的道路场景数据集并进行预处理；构建目标检测LG-CenterNet模型，并将上述的道路目标数据集通过LG-CenterNet模型进行训练得到模型S；所述LG-CenterNet模型包括Backbone模块、层级引导注意力模块、Scales Encoder模块、反卷积模块、特征增强模块和Centerpoints预测模块；使用训练好的模型S对复杂道路目标通过Center points预测模块以热力图的形式进行目标定位、边框大小划分和类别预测，并将得到的结果在视频或者图像上进行显示输入相应的效果。进一步地，步骤所述的对道路场景数据集预处理是通过将像素不一和复杂道路场景的图像进行归一化处理，将图像的大小归一化为512×512像素大小，再通过批标准化、ReLU激活函数和最大池化操作得到分布均匀的特征目标样本。进一步地，所述步骤实现过程如下：LG-CenterNet模型中提出新的MresneIt50作为Backbone模块，MresneIt50由多个残差块组成，其中将4个残差模块提取到的特征图记为E1，通道数为512；将6个残差块提取到的特征图记为E2，通道数为1024；将3个通道数提取到的特征图记为E3，通道数为2048；将Backbone提取到的特征图E1、E2、E3输入到层级引导注意力模块中，其主要的结构包括两个分支：全局池化分支和层级引导分支，将通道数为512的特征图E1输入到全局池化分支，通过全局最大池化层和上采样层操作获得EC1；将通道数为512、1024、2048的特征图E1、E2、E3输入到层级引导分支中，通过一系列的平均池化和卷积操作并配合上采样得到EC2；将EC1和EC2使用add进行特征联合获得EC3，从而减少计算参数；将提取到的EC3输入到Scales Encoder模块，进行一系列的卷积和残差模块运算后得到EC4；将提取到的EC4输入到反卷积模块，反卷积模块由3个deconv组组成，通过每次deconv组的卷积运算将特征图尺寸不断放大，同时通道数不断降低，得到尺度为128×128×64的特征图记为EC5；将特征图EC5输入到特征增强模块进行卷积运算得到尺度大小为128×128×64特征图EC6，P-FEM由3×3的Poly-Scale Convolution、批标准化、ReLU激活函数和Sigmoid激活函数构成，主要是为了提高特征图中的局部信息的相关性，增强其对特征的表达能力。进一步地，所述步骤实现过程如下：Centerpoints预测模块通过对训练好的模型S对输入的图片进行分类预测，将原始图像生成尺度与EC6大小一致的heatmap图，随后通过分别计算热力图的损失值记为Lh，目标长宽的损失值记为Ls和中心点偏移量的损失值记为Lf来确定目标的位置和大小并生成最后的分类定位的heatmap；其中总体的网络损失为：Ld＝Lk+λsLs+λfLf其中λs＝0.1，λf＝1；对于输入图片大小为512×215的图像来说其通过该网络生成的特征图为H×W×C，则Lk、Ls和Lf计算公式分别为：其中，AHWC为图像中目标标注的真实值，A'HWC为图像的预测值，α和β分别为2和4，N为图像中关键点的个数，s'pk为预测尺寸，sk为真实尺寸，p为图像中目标的中心点位置。基于相同的发明构思，本发明还提供一种基于LG-CenterNet模型的复杂道路场景目标检测装置，包括存储器、处理器及存储在存储器上并可在处理器上运行的计算机程序，所述计算机程序被加载至处理器时实现上述的基于LG-CenterNet模型的复杂道路场景目标检测方法。有益效果：与现有技术相比，本发明的有益效果：1、通过改进LG-CenterNet模型的主干网络，提出MresneIt50加强特征提取效果；2、提出一种层级引导注意力模块对主干网络提取到的特征图的进行特征融合；3、提出新的Scales Encoder模块和特征增强模块注重对局部特征的提取，避免在反卷积模块中出现的特征丢失问题；4、改进后的LG-CenterNet目标检测模型对比原来的CenterNet框架的平均精度mAP提升了5个百分点；5、本发明在应对复杂道路场景也有较高的检测精度。附图说明图1是基于LG-CenterNet模型的复杂道路场景目标检测方法的流程图；图2是本发明提出的基于LG-CenterNet目标检测模型示意图；图3是本发明提出的残差块结构Mblock结构示意图；图4是层级引导注意力模型结构示意图；图5是Scales Encoder模块结构示意图；图6是特征增强模块结构示意图；图7是采用LG-CenterNet目标检测模型后得到的检测效果图。具体实施方式下面结合附图对本发明作进一步详细说明。本实施方式中涉及大量变量，现将各变量作如下说明。如表1所示。表1变量说明表变量变量说明S3×3，通道数为1024的卷积核E1Backbone模块中4个残差块提取到的特征图E2Backbone模块中6个残差块提取到的特征图E3Backbone模块中3个残差块提取到的特征图EC1E1经过全局池化分支得到的特征图EC2E1、E2、E3经由层级引导分支得到的特征图EC3特征图EC2经由ScalesEncoder模块处理后的特征图EC4特征图EC3经由ScalesEncoder模块处理后的特征图EC5特征图EC4经由反卷积模块处理后的特征图EC6特征图EC5经由特征增强模块处理后的特征图本发明提供一种基于LG-CenterNet模型的复杂道路场景目标检测方法，通过采集道路场景不同目标图像并进行标记制作成复杂道路场景数据集，利用提出的MresneIt50作为主干网络进行特征提取，对于主干网络中提取到的不同尺度的特征图输入到层级引导注意力模块当中，随后通过Scales Encoder模块得到多个感受野特征，之后利用反卷积模块进行特征像素还原，利用Poly-Scale Convolution构建特征增强模块提高局部特征的信息相关性。最终利用Center points预测模块对目标的中心点位置、预测框的尺度大小和中心点的偏移进行预测，同时识别出目标类别。如图1所示，具体包括以下步骤：步骤1：对复杂道路场景的图像进行处理，获取到含有多种类别的道路目标图像进行预处理，并对图像中的道路目标进行类别和位置标记，构建出复杂的道路场景数据集。对道路场景数据集预处理主要是通过将像素不一和复杂道路场景的图像进行归一化处理，将图像的大小归一化为512×512像素大小，再通过批标准化、ReLU激活函数和最大池化操作得到目标样本处于在图像分布较为均匀。步骤2、构建目标检测LG-CenterNet模型，LG-CenterNet模型结构如图2所示，并将上述的道路目标数据集通过LG-CenterNet模型进行训练得到模型S，其中LG-CenterNet网络主要包括Backbone模块、层级引导注意力模块、Scales Encoder模块、反卷积模块、特征增强模块和Centerpoints预测模块。LG-CenterNet模型中提出新的MresneIt50作为Backbone模块，MresneIt50由多个残差块Mblock组成，残差块结构Mblock如图3所示，其中将4个残差块提取到的特征图记为E1，通道数为512；将6个残差块提取到的特征图记为E2，通道数为1024；将3个通道数提取到的特征图记为E3，通道数为2048。将Backbone提取到的特征图E1、E2、E3输入到层级引导注意力模块中，LGA模块结构如图4所示，其主要的结构包括两个分支：全局池化分支和层级引导分支，将通道数为512的特征图E1输入到全局池化分支，通过全局最大池化层和上采样层操作获得EC1；将通道数为512、1024、2048的特征图E1、E2、E3输入到层级引导分支中，通过一系列的平均池化和卷积操作并配合上采样得到EC2。将EC1和EC2使用add进行特征联合获得EC3，从而减少计算参数。将提取到的EC3输入到Scales Encoder模块，Scales Encoder模块结构如图5所示，进行一系列的卷积和残差模块运算后得到EC4。将提取到的EC4输入到反卷积模块，反卷积模块由3个deconv组组成，通过每次deconv组的卷积运算将特征图尺寸不断放大，同时通道数不断降低，得到尺度为128×128×64的特征图记为EC5。将特征图EC5输入到P-FEM进行卷积运算得到尺度大小为128×128×64特征图EC6，P-FEM由3×3的Poly-Scale Convolution、批标准化、ReLU激活函数和Sigmoid激活函数构成，主要是为了提高特征图中的局部信息的相关性，增强其对特征的表达能力。P-FEM结构如图6所示。步骤3：使用训练好的模型S对道路场景目标通过Centerpoints预测模块以热力图的形式进行目标定位、边框大小划分和类别预测，并将得到的结果在视频或者图像上进行显示输入相应的效果。Centerpoints预测模块通过对训练好的模型S对输入的图片进行分类预测，将原始图像生成尺度与EC6大小一致的heatmap图，随后通过分别计算热力图的损失值记为Lh，目标长宽的损失值记为Ls和中心点偏移量的损失值记为Lf来确定目标的位置和大小并生成最后的分类定位的heatmap。其中总体的网络损失为Ld。Ld＝Lk+λsLs+λfLf其中λs＝0.1，λf＝1。对于输入图片大小为512×215的图像来说其通过该网络生成的特征图为H×W×C，则Lk、Ls和Lf计算公式分别为：其中，AHWC为图像中目标标注的真实值，A'HWC为图像的预测值，α和β分别为2和4，N为图像中关键点的个数，s'pk为预测尺寸，sk为真实尺寸，p为图像中目标的中心点位置。基于相同的发明构思，本发明还提供一种基于LG-CenterNet模型的复杂道路场景目标检测装置，包括存储器、处理器及存储在存储器上并可在处理器上运行的计算机程序，所述计算机程序被加载至处理器时实现上述的基于LG-CenterNet模型的复杂道路场景目标检测方法。如图7所示。将自建的复杂场景数据集通过LG-CenterNet网络进行训练，得到可以识别复杂场景目标的模型，通过数据集中的验证集进行模型性能验证，如图7所示。本发明在自建的复杂道路场景数据集的识别平均精度为86.93％，道路场景目标图像检测速度达到50帧/s，能够满足对道路场景的准确检测和实时检测的要求。其中，Precision为精确度，Recall为召回率，AP为精度，mAP为平均精度，FPS为帧数，t为检测单张图片的时间。数据集中有较多样本类别，n表示样本个数，TP为正样本并被认定为正样本的数量；TN为负样本模型识别也为负样本的总数；FP为负样本模型认定为正样本的总数；FN为负样本模型认定为正样本的总数。上面结合附图对本发明的实施方式作了详细说明，但是本发明并不限于上述实施方式，在本领域普通技术人员所具备的知识范围内，还可以在不脱离本发明宗旨的前提下做出各种变化。
