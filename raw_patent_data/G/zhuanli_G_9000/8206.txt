标题title
一种基于视觉的轮速里程计校正方法
摘要abst
本发明涉及一种基于视觉的轮速里程计校正方法，该方法包括以下步骤：步骤1：获取系统的内参数和外参数；步骤2：获取并同步视觉信息和轮速里程计信息；步骤3：基于MSCKF算法对视觉信息和轮速里程计信息进行融合，即根据轮速里程计信息进行状态的预测并根据视觉信息进行状态的更新，以校正轮速里程计；步骤4：判断是否执行完所有的特征点更新；步骤5：若是，则得到当前局部地图位姿，进而得到系统全局定位，若否，则返回步骤2，与现有技术相比，本发明具有校正轮速里程计的时间累积误差、提高定位精度和计算效率高等优点。
权利要求书clms
1.一种基于视觉的轮速里程计校正方法，其特征在于，该方法包括以下步骤：步骤1：获取系统的内参数和外参数；步骤2：获取并同步视觉信息和轮速里程计信息；步骤3：基于MSCKF算法对视觉信息和轮速里程计信息进行融合，即根据轮速里程计信息进行状态的预测并根据视觉信息进行状态的更新，以校正轮速里程计；步骤4：判断是否执行完所有的特征点更新；步骤5：若是，则得到当前局部地图位姿，进而得到系统全局定位，若否，则返回步骤2。2.根据权利要求1所述的一种基于视觉的轮速里程计校正方法，其特征在于，所述的步骤1中，系统的内参数包括相机内参、左右轮轴距b、左轮速系数kl和右轮速系数kr，系统的外参数包括轮速坐标系到相机坐标系的旋转矩阵和轮速坐标系到相机坐标系的平移矩阵CpO。3.根据权利要求1所述的一种基于视觉的轮速里程计校正方法，其特征在于，所述的步骤3中，具体包括以下步骤：步骤31：轮速里程计预测；步骤32：状态增广；步骤33：轮速里程计更新。4.根据权利要求3所述的一种基于视觉的轮速里程计校正方法，其特征在于，所述的步骤31中，轮速里程计预测的过程具体包括以下步骤：步骤311：初始化状态向量和协方差，将滑动窗口的状态分为里程计位姿和相机位姿，总状态为当前里程计位姿增广上N帧的相机位姿，里程计位姿和相机位姿的表达式分别为：其中，R为旋转矩阵，G为全局坐标系，O为轮速坐标系，C为相机坐标系，为轮速坐标系到全局坐标系的里程计位姿，为相机坐标系到全局坐标系的相机位姿，为轮速坐标系到地面坐标系的旋转矩阵，GpO为轮速坐标系到全局坐标系的平移矩阵，GpC为相机坐标系到地面坐标系的平移矩阵，SE3为欧式群；步骤312：根据轮速里程计信息进行状态的预测，基于IMU处理方法对轮速里程计信息进行处理并建立常微分方程：其中，OωO为相对轮速坐标系的瞬时角速度，OvO为相对轮速坐标系的瞬时速度，×为瞬时角速度的反对称矩阵，为轮速坐标系到地面坐标系的旋转矩阵，GvO为轮速坐标系到全局坐标系下的瞬时速度，为旋转矩阵的微分，为平移矩阵的微分，kl和kr分别为左轮速系数和右轮速系数，b为左右轮轴距，vl和vr分别为左轮的速度和右轮的速度；步骤313：采用欧拉积分对步骤312得到的常微分方程进行积分，以进行均值的预测：其中，为k+1时刻轮速坐标系到地面坐标系的旋转矩阵，GPOk+1为k+1时刻轮速坐标系到全局坐标系的平移矩阵，为k时刻轮速坐标系到地面坐标系的旋转矩阵，GPOk为k时刻轮速坐标系到全局坐标系的平移矩阵，Δt为k时刻与k+1时刻之间的时间差，{ΔR，Δp}为位姿增量；步骤314：对于协方差进行预测，定义旋转的误差为：其中，δθ为旋转误差量，为轮速坐标系到地面坐标系的旋转矩阵的估计值；步骤315：得到相对于里程计位姿的雅克比和相对于位姿增量{ΔR，Δp}的雅克比分别为：其中，Φ为相对于里程计位姿的雅克比，F为相对于位姿增量的雅克比；步骤316：根据雅克比对协方差进行预测，协方差矩阵的预测公式为：其中，Q为位姿增量{ΔR，Δp}的噪声，根据位姿增量的大小进行设置，为里程计位姿对应的协方差，维度为6×6，为N帧相机位姿对应的协方差矩阵，维度为6N×6N，为里程计位姿与N帧相机位姿之间的关联协方差。5.根据权利要求4所述的一种基于视觉的轮速里程计校正方法，其特征在于，所述的步骤311中，总状态的状态向量为：其中，χ为状态向量，N为相机的帧数，为相机坐标系到全局坐标系的第N帧相机位姿；协方差的分块矩阵为：其中，为里程计位姿对应的协方差，维度为6×6，为N帧相机位姿对应的协方差，维度为6N×6N，为里程计位姿与N帧相机位姿之间的关联协方差。6.根据权利要求3所述的一种基于视觉的轮速里程计校正方法，其特征在于，所述的步骤32中，状态增广的过程具体包括以下步骤：步骤321：当新产生一帧图像时，通过里程计位姿计算得到相机位姿：其中，为相机坐标系到全局坐标系的旋转矩阵，为轮速坐标系到全局坐标系的旋转矩阵，为相机坐标系到轮速坐标系的旋转矩阵，GpC为相机坐标系到全局坐标系的平移矩阵，GpO为轮速坐标系到全局坐标系的平移矩阵，OpC为相机坐标系到轮速坐标系的平移矩阵；步骤322：将相机位姿放到原状态向量χ里得到增广状态向量，并对协方差矩阵进行扩展：其中，J为协方差矩阵相对于原状态向量χ的雅克比，J的第一列和第二列为相对于里程计位姿的雅克比，为轮速坐标系到相机坐标系的旋转矩阵，×为轮速坐标系到相机坐标系的平移矩阵的反对称矩阵。7.根据权利要求3所述的一种基于视觉的轮速里程计校正方法，其特征在于，所述的步骤33中，轮速里程计更新的过程包括对一个特征点的处理、对多个特征点的处理以及边缘化处理。8.根据权利要求7所述的一种基于视觉的轮速里程计校正方法，其特征在于，所述的对一个特征点的处理过程具体包括以下步骤：步骤331：根据特征点对多个历史相机状态的约束更新状态向量，每个用以进行更新的特征点Gpf均被滑窗内的M帧相机观测到，特征点Gpf在其中一帧图像上的投影方程为：其中，π为相机的投影函数，为相机坐标系到全局坐标系的旋转矩阵的转置，Zi为特征点Gpf在相机第i帧图像上的投影，为第i帧图像的特征点，i为相机图像的帧数，为通过里程计位姿计算得到相机位姿；步骤332：将特征点在其中一帧图像上的投影方程线性化：其中，ri为残差，表示特征点在相机第i帧图像上的投影误差，为残差ri对于第i帧状态向量χi的雅克比，为残差ri对第i帧图像的特征点的雅克比，δχi为第i帧状态向量χi的差值，为第i帧图像的特征点的差值；步骤333：将特征点的3D位置恢复，一个特征点具有M帧相机的观测，将M帧相机的观测堆叠在一起得到一个线性化方程：r＝Hχδχ+HfδGpf其中，Hχ为M帧相机的观测堆叠后的残差r对整个状态向量χ的雅克比，Hf为M帧相机的观测堆叠后的残差r对特征点Gpf的雅克比；步骤334：在线性化方程左右两边同时乘以一个满足条件ATHf＝0的矩阵AT，以消除线性化方程中关于特征点的部分：ATr＝ATHχδχ+ATHfδGpfATHf＝0ATr＝ATHχδχ其中，AT为Hf的左零空间，δχ为状态向量χ的差值，用以消除线性化方程中关于特征点的部分；步骤335：求解矩阵A，即对Hf进行QR分解，再对Hf左乘得到一个不含特征点的线性方程A＝Q2其中，Q2与Q1为对Hf进行QR分解后的标准正交矩阵，Q2与Q1正交，R1为对Hf进行QR分解后的上三角矩阵，为Hf左乘AT后的矩阵，为不含特征点的线性方程，和分别表示残差r和雅克比Hf在左零空间上的投影。9.根据权利要求8所述的一种基于视觉的轮速里程计校正方法，其特征在于，所述的对多个特征点的处理过程具体包括以下步骤：步骤336：一个特征点对应一个线性方程，将所有特征点对应的线性方程堆叠起来得到一个总线性方程：r*＝H*δχ其中，r*为所有特征点堆叠后的残差，H*为残差r*对所有特征点的雅克比；步骤337：对总线性方程进行QR分解，进行一次压缩，具体是对H*进行QR分解，并将分解后的H*代入到总线性方程中：R2＝TH其中，Q3与Q4为对H*进行QR分解后的标准正交矩阵，Q3与Q4正交，R1为对H*进行QR分解后的上三角矩阵，TH表示行数为H的上三角矩阵；步骤339：总线性方程的左右两边同时乘以T，最后得到一个压缩后的总线性方程，压缩后的总线性方程的行数最大值与状态的维度相同，用以进行EKF更新：其中，rn为压缩后的总线性方程。10.根据权利要求9所述的一种基于视觉的轮速里程计校正方法，其特征在于，所述的边缘化处理具体为：将滑动窗口的状态中最旧的一帧状态及其对应的协方差去掉，去掉的这帧里的所有特征点均用以进行更新。
说明书desc
技术领域本发明涉及多传感器融合技术，尤其是涉及一种基于视觉的轮速里程计校正方法。背景技术随着扫地机器人、自动餐车等移动机器人的兴起，人们对移动机器人的运用越来越广。而对移动机器人运动过程中的定位和导航是其完成各种任务的基础。移动机器人的定位主要依赖于各种传感器感知周围环境信息，从而分析获得其与周围环境中各物体的位置关系，进而实现实时的自我定位。但单一传感器物理条件上存在局限性，在实际应用中倘若某一传感器发生错误或误差，SLAM系统则可能出现定位偏差等现象，多传感器信息融合技术可以有效地解决以上问题。多传感器融合技术可以将多个传感器的定位信息进行有效的数据融合，综合优化，处理得到所需的估计与决策的数据，以增强数据的可靠性和利用性。随着近年来无人驾驶，无人机和移动机器人领域的不断发展，多传感器融合技术也得到迅速的发展。目前得到广泛应用的多传感器信息融合算法有，卡尔曼滤波算法，扩展卡尔曼滤波算法，经典推理法，神经网络算法等。基于单一传感器如轮速里程计的SLAM技术已经能够有效地提取周围环境信息，完成机器人的定位需求。因此该技术在Turtle Bot等机器人中取得了令人满意的实验结果。尽管如此，该技术目前还存在以下缺陷：第一，由于差速轮速里程计与真实位姿存在差距，定位误差随时间累积，在大场景长时间的环境中机器人不能获得可靠定位，需要进行人工校正。第二，基于图像的视觉里程计同样能满足简单的定位需求，但相较于轮速里程计实时性差、高动态环境下同样易出现误差。发明内容本发明的目的就是为了克服上述现有技术存在的缺陷而提供一种基于视觉的轮速里程计校正方法。本发明的目的可以通过以下技术方案来实现：一种基于视觉的轮速里程计校正方法，该方法包括以下步骤：步骤1：获取系统的内参数和外参数；步骤2：获取并同步视觉信息和轮速里程计信息；步骤3：基于MSCKF算法对视觉信息和轮速里程计信息进行融合，即根据轮速里程计信息进行状态的预测并根据视觉信息进行状态的更新，以校正轮速里程计；步骤4：判断是否执行完所有的特征点更新；步骤5：若是，则得到当前局部地图位姿，进而得到系统全局定位，若否，则返回步骤2。所述的步骤1中，系统的内参数包括相机内参、左右轮轴距b、左轮速系数kl和右轮速系数kr，系统的外参数包括轮速坐标系到相机坐标系的旋转矩阵和轮速坐标系到相机坐标系的平移矩阵CpO。所述的步骤3中，具体包括以下步骤：步骤31：轮速里程计预测；步骤32：状态增广；步骤33：轮速里程计更新。所述的步骤31中，轮速里程计预测的过程具体包括以下步骤：步骤311：初始化状态向量和协方差，将滑动窗口的状态分为里程计位姿和相机位姿，总状态为当前里程计位姿增广上N帧的相机位姿，里程计位姿和相机位姿的表达式分别为：其中，R为旋转矩阵，G为全局坐标系，O为轮速坐标系，C为相机坐标系，为轮速坐标系到全局坐标系的里程计位姿，为相机坐标系到全局坐标系的相机位姿，为轮速坐标系到地面坐标系的旋转矩阵，GpO为轮速坐标系到全局坐标系的平移矩阵，GpC为相机坐标系到地面坐标系的平移矩阵，SE3为欧式群；步骤312：根据轮速里程计信息进行状态的预测，基于IMU处理方法对轮速里程计信息进行处理并建立常微分方程：其中，OωO为相对轮速坐标系的瞬时角速度，OvO为相对轮速坐标系的瞬时速度，×为瞬时角速度的反对称矩阵，为轮速坐标系到地面坐标系的旋转矩阵，GvO为轮速坐标系到全局坐标系下的瞬时速度，为旋转矩阵的微分，为平移矩阵的微分，kl和kr分别为左轮速系数和右轮速系数，b为左右轮轴距，vl和vr分别为左轮的速度和右轮的速度；步骤313：采用欧拉积分对步骤312得到的常微分方程进行积分，以进行均值的预测：其中，为k+1时刻轮速坐标系到地面坐标系的旋转矩阵，GPOk+1为k+1时刻轮速坐标系到全局坐标系的平移矩阵，为k时刻轮速坐标系到地面坐标系的旋转矩阵，GPOk为k时刻轮速坐标系到全局坐标系的平移矩阵，Δt为k时刻与k+1时刻之间的时间差，{ΔR，Δp}为位姿增量；步骤314：对于协方差进行预测，定义旋转的误差为：其中，δθ为旋转误差量，为轮速坐标系到地面坐标系的旋转矩阵的估计值；步骤315：得到相对于里程计位姿的雅克比和相对于位姿增量{ΔR，Δp}的雅克比分别为：其中，Φ为相对于里程计位姿的雅克比，F为相对于位姿增量的雅克比；步骤316：根据雅克比对协方差进行预测，协方差矩阵的预测公式为：其中，Q为位姿增量{ΔR，Δp}的噪声，根据位姿增量的大小进行设置，为里程计位姿对应的协方差，维度为6×6，为N帧相机位姿对应的协方差矩阵，维度为6N×6N，为里程计位姿与N帧相机位姿之间的关联协方差。所述的步骤311中，总状态的状态向量为：其中，χ为状态向量，N为相机的帧数，为相机坐标系到全局坐标系的第N帧相机位姿；协方差的分块矩阵为：其中，为里程计位姿对应的协方差，维度为6×6，为N帧相机位姿对应的协方差，维度为6N×6N，为里程计位姿与N帧相机位姿之间的关联协方差。所述的步骤32中，状态增广的过程具体包括以下步骤：步骤321：当新产生一帧图像时，通过里程计位姿计算得到相机位姿：其中，为相机坐标系到全局坐标系的旋转矩阵，为轮速坐标系到全局坐标系的旋转矩阵，为相机坐标系到轮速坐标系的旋转矩阵，GpC为相机坐标系到全局坐标系的平移矩阵，GpO为轮速坐标系到全局坐标系的平移矩阵，OpC为相机坐标系到轮速坐标系的平移矩阵；步骤322：将相机位姿放到原状态向量χ里得到增广状态向量，并对协方差矩阵进行扩展：其中，J为协方差矩阵相对于原状态向量χ的雅克比，J的第一列和第二列为相对于里程计位姿的雅克比，为轮速坐标系到相机坐标系的旋转矩阵，×为轮速坐标系到相机坐标系的平移矩阵的反对称矩阵。所述的步骤33中，轮速里程计更新的过程包括对一个特征点的处理、对多个特征点的处理以及边缘化处理。所述的对一个特征点的处理过程具体包括以下步骤：步骤331：根据特征点对多个历史相机状态的约束更新状态向量，每个用以进行更新的特征点Gpf均被滑窗内的M帧相机观测到，特征点Gpf在其中一帧图像上的投影方程为：其中，π为相机的投影函数，为相机坐标系到全局坐标系的旋转矩阵的转置，Zi为特征点Gpf在相机第i帧图像上的投影，为第i帧图像的特征点，i为相机图像的帧数，为通过里程计位姿计算得到相机位姿；步骤332：将特征点在其中一帧图像上的投影方程线性化：其中，ri为残差，表示特征点在相机第i帧图像上的投影误差，为残差ri对于第i帧状态向量χi的雅克比，为残差ri对第i帧图像的特征点的雅克比，δχi为第i帧状态向量χi的差值，为第i帧图像的特征点的差值；步骤333：将特征点的3D位置恢复，一个特征点具有M帧相机的观测，将M帧相机的观测堆叠在一起得到一个线性化方程：r＝Hχδχ+HfδGpf其中，Hχ为M帧相机的观测堆叠后的残差r对整个状态向量χ的雅克比，Hf为M帧相机的观测堆叠后的残差r对特征点Gpf的雅克比；步骤334：在线性化方程左右两边同时乘以一个满足条件ATHf＝0的矩阵AT，以消除线性化方程中关于特征点的部分：ATr＝ATHχδχ+ATHfδGpfATHf＝0ATr＝ATHχδχ其中，AT为Hf的左零空间，δχ为状态向量χ的差值，用以消除线性化方程中关于特征点的部分；步骤335：求解矩阵A，即对Hf进行QR分解，再对Hf左乘得到一个不含特征点的线性方程A＝Q2其中，Q2与Q1为对Hf进行QR分解后的标准正交矩阵，Q2与Q1正交，R1为对Hf进行QR分解后的上三角矩阵，为Hf左乘AT后的矩阵，为不含特征点的线性方程，和分别表示残差r和雅克比Hf在左零空间上的投影。所述的对多个特征点的处理过程具体包括以下步骤：步骤336：一个特征点对应一个线性方程，将所有特征点对应的线性方程堆叠起来得到一个总线性方程：r*＝H*δχ其中，r*为所有特征点堆叠后的残差，H*为残差r*对所有特征点的雅克比；步骤337：对总线性方程进行QR分解，进行一次压缩，具体是对H*进行QR分解，并将分解后的H*代入到总线性方程中：R2＝TH其中，Q3与Q4为对H*进行QR分解后的标准正交矩阵，Q3与Q4正交，R1为对H*进行QR分解后的上三角矩阵，TH表示行数为H的上三角矩阵；步骤339：总线性方程的左右两边同时乘以T，最后得到一个压缩后的总线性方程，压缩后的总线性方程的行数最大值与状态的维度相同，用以进行EKF更新：其中，rn为压缩后的总线性方程。所述的边缘化处理具体为：将滑动窗口的状态中最旧的一帧状态及其对应的协方差去掉，去掉的这帧里的所有特征点均用以进行更新。与现有技术相比，本发明具有以下优点：第一，本方法使用MSCKF算法，在特征层将视觉信息与轮速信息进行融合，能够有效校正轮速里程计的时间累积误差，最终达到提高定位精度的效果，并且具有鲁棒性好的特点。第二，本方法的定位准确率优于在KAIST URBAN DATA SET数据集上的主流算法，并且使用Givens Rotation方法求解，具有较高的计算效率，以达到较高的实时性。附图说明图1为本发明的流程示意图。图2为MSCKF信息融合过程的示意图。具体实施方式下面结合附图和具体实施例对本发明进行详细说明。实施例如图2所示，本发明提供了一种基于视觉的轮速里程计校正方法，该方法包括以下步骤：步骤1：获取系统的内参数和外参数；步骤2：获取并同步视觉信息和轮速里程计信息；步骤3：基于MSCKF算法对视觉信息和轮速里程计信息进行融合，即根据轮速里程计信息进行状态的预测并根据视觉信息进行状态的更新，以校正轮速里程计；步骤4：判断是否执行完所有的特征点更新；步骤5：若是，则得到当前局部地图位姿，进而得到系统全局定位，若否，则返回步骤2。在步骤3中，对视觉信息和轮速里程计信息进行融合的过程具体包括以下步骤：步骤301：轮速里程计预测：将滑动窗口的状态分为里程计位姿和相机位姿，里程计位姿的表达式为：其中，R为旋转矩阵，G为全局坐标系，O为轮速坐标系，C为相机坐标系，为轮速坐标系到全局坐标系的里程计位姿，为轮速坐标系到地面坐标系的旋转矩阵，GpO为轮速坐标系到全局坐标系的平移矩阵，SE3为特殊欧式群。相机位姿的表达式为：其中，为相机坐标系到全局坐标系的相机位姿，GpC为相机坐标系到地面坐标系的平移矩阵；总状态为当前里程计位姿增广上N帧的相机位姿，状态向量为：其中，χ为状态向量，N为状态向量里增广相机位姿的帧数，为相机坐标系到全局坐标系的第N帧相机位姿；协方差的分块矩阵为：其中，为里程计位姿的协方差，维度为6×6，为对应N帧相机位姿的协方差矩阵，维度为6N×6N，为里程计位姿与N帧相机位姿之间的关联协方差；根据轮速里程计信息进行状态的预测并根据视觉信息进行状态的更新，首先根据轮速里程计信息进行状态的预测，基于IMU处理方法对轮速里程计信息进行处理并建立常微分方程：其中，OωO为相对轮速坐标系的顺时角速度，类似于IMU gyrosope的测量，是个3D量，但实际上轮速计只能测到2D的旋转，只有能测到绕z轴的角速度，OvO为瞬时速度，同样是个3D量，但轮速也只能测到沿x轴方向的速度，kl和kr分别为左轮的速度和右轮的速度，×为瞬时角速度的反对称矩阵，为轮速坐标系到全局坐标系下的瞬时速度，vl和vr分别为左轮的速度和右轮的速度；采用欧拉积分对常微分方程进行积分，以进行均值的预测：其中，为k+1时刻轮速坐标系到地面坐标系的旋转矩阵，GPOk+1为k+1时刻轮速坐标系到全局坐标系的平移矩阵，为k时刻轮速坐标系到地面坐标系的旋转矩阵，GPOk为k时刻轮速坐标系到全局坐标系的平移矩阵，Δt为k时刻与k+1时刻之间的时间差，{ΔR，Δp}为位姿增量；对于协方差的预测，先求雅克比，首先定义旋转矩阵的误差为：其中，δθ为旋转误差量，为轮速坐标系到地面坐标系的旋转矩阵的估计值；那么可以求得，相对于里程计位姿的雅克比为：其中，Φ为相对于里程计位姿的雅克比，OωO为相对轮速坐标系的顺时角速度，OvO为瞬时速度；相对于位姿增量{ΔR，Δp}的雅克比为：其中，F为相对于位姿增量的雅克比；得到协方差矩阵的预测公式：其中，Q为位姿增量{ΔR，Δp}的噪声，根据位姿增量的大小进行设置，为里程计位姿的协方差，维度为6×6，为对应N帧相机位姿的协方差矩阵，维度为6N×6N，为里程计位姿与N帧相机位姿之间的关联协方差。步骤302：进行状态增广：当新来一帧图像时，通过里程计位姿计算得到相机位姿：其中，为相机坐标系到全局坐标系的旋转矩阵，为轮速坐标系到全局坐标系的旋转矩阵，为相机坐标系到轮速坐标系的旋转矩阵，GpC为相机坐标系到全局坐标系的平移矩阵，GpO为轮速坐标系到全局坐标系的平移矩阵，OpC为相机坐标系到轮速坐标系的平移矩阵；将相机位姿放到原状态向量里得到增广之后的状态向量，并对协方差矩阵进行扩展：其中，J为协方差矩阵相对于原状态向量χ的雅克比，χ为原状态向量，J的第一列和第二列为相对于里程计位姿的雅克比，为轮速坐标系到相机坐标系的旋转矩阵，×为轮速坐标系到相机坐标系的平移矩阵的反对称矩阵。步骤303：对轮速里程计进行更新：步骤A：一个特征点的处理：每个用以做更新的特征点Gpf会被滑窗内的M帧相机观测到，特征点Gpf在其中一帧图像上的投影方程为：其中，π为相机的投影函数，为相机坐标系到全局坐标系的旋转矩阵的转置，Zi为特征点在相机第i帧图像上的投影，为第i帧图像的特征点，i为相机图像的帧数，为通过里程计位姿计算得到相机位姿；将投影方程线性化：其中，ri为残差，表示特征点在相机第i帧图像上的投影误差，为残差ri对于第i帧状态向量χi的雅克比，为残差ri对第i帧图像的特征点的雅克比，δχi为第i帧状态向量χi的差值，为第i帧图像的特征点的差值；计算对整个状态向量χ的雅克比需要获得特征点所以需要将特征点的3D位置恢复，因为一个特征点具有M帧相机的观测，所以将M帧相机的观测堆叠在一起得到一个线性化方程：r＝Hχδχ+HfδGpf但是线性化方程里有特征点Gpf，而状态里面没有特征点Gpf，不能直接用以进行EKF更新，通过在线性化方程左右两边同时乘以一个满足ATHf＝0的矩阵AT将HfδGpf消掉：ATr＝ATHχδχ+ATHfδGpfATHf＝0ATr＝ATHχδχ其中，AT为Hf的左零空间，用以消除线性化方程中关于特征点的部分。进而求解矩阵A，即对Hf进行QR分解，对Hf左乘Q2与Q1正交，得到一个不含特征点的线性方程A＝Q2其中，Q2与Q1为对Hf进行QR分解后的标准正交矩阵，Q2与Q1正交，R1为对Hf进行QR分解后的上三角矩阵，为Hf左乘AT后的矩阵，为不含特征点的线性方程，和分别表示残差r和雅克比Hf在左零空间上的投影。总线性方程的行数很大，直接用来做EKF更新效率很低，因此对总线性方程进行QR分解，进行一次压缩，具体是对H*做QR分解：带入到总线性方程中得到：R2＝TH总线性方程的左右两边同时乘以T得到：最后得到一个压缩后的总线性方程：其中，Q3与Q4为对H*进行QR分解后的标准正交矩阵，Q3与Q4正交，R1为对H*进行QR分解后的上三角矩阵，TH表示行数为H的上三角矩阵。压缩后的总线性方程的行数最大值能够与状态向量的维度相同，最终压缩后的总线性方程用以进行EKF更新。步骤C：边缘化处理进行边缘化操作，即如何删除滑窗里的状态，将最旧的一帧状态及其对应的协方差去掉，去掉的这一帧里的所有特征点都被用以进行更新操作。为了验证本发明的性能，本实施例使用FLIR公司的FL3-U3-20E4C-C款全局快门彩色双目相机，相机频率为10Hz，相机分辨率为1289x 560，双目相机图像以10Hz的频率采集，并以无损PNG格式存储在未校正的8位拜耳阵列图像中，图像的拜耳阵列为RGGB，轮速编码器为RLS公司的LM13款磁性旋转编码器，编码器频率为100Hz，编码器精度为4096PPR，基于上述传感器数据，本发明比纯轮速里程计精度更好。以上所述，仅为本发明的具体实施方式，但本发明的保护范围并不局限于此，任何熟悉本技术领域的工作人员在本发明揭露的技术范围内，可轻易想到各种等效的修改或替换，这些修改或替换都应涵盖在本发明的保护范围之内。因此，本发明的保护范围应以权利要求的保护范围为准。
