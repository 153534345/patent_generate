标题title
基于Transformer网络和超球空间学习的多模态图像处理方法及系统
摘要abst
本发明公开了一种基于Transformer网络和超球空间学习的多模态图像处理方法及系统，包括获取预训练的Transformer网络模型，得到教师模型；构建由教师模型和多模态融合模型组成的多分支模型；提取教师蒸馏向量和学生蒸馏向量，以及各模态图像在单位超球空间的特征及其分类概率；计算各模态的蒸馏损失、模态间中心对齐损失、模态内均匀性损失和分类损失，并由此更新多模态融合模型；采用更新后的多模态融合模型基于待检测模态的图像和待查询模态的图像生成零样本跨模态检索结果。本发明能够有效提升多模态融合模型的建模和对齐多模态分布的能力，消除不同模态之间的模态差异问题，从而实现零样本跨模态检索。
权利要求书clms
1.一种基于Transformer网络和超球空间学习的多模态图像处理方法，其特征在于，该方法具体包括如下步骤：步骤S1：获取预训练的Transformer网络模型，并基于各个模态的图像数据以自监督方式微调该预训练的Transformer网络模型，得到各个模态对应的教师模型；步骤S2：构建能够基于多模态图像进行超球空间学习的多分支模型，其由各个模态对应的教师模型和一个多模态融合模型构成；步骤S3：基于各个模态对应的教师模型分别提取各个模态图像的教师蒸馏向量，基于所述多模态融合模型提取各个模态图像的学生蒸馏向量，并基于所述多模态融合模型提取各个模态图像在单位超球空间的特征及其分类概率；步骤S4：基于所述各个模态图像的教师蒸馏向量、所述各个模态图像的学生蒸馏向量、所述各个模态图像在单位超球空间的特征以及所述各个模态图像在单位超球空间的分类概率计算各个模态的蒸馏损失、模态间中心对齐损失、模态内均匀性损失和分类损失，并基于所述蒸馏损失、所述模态间中心对齐损失、所述模态内均匀性损失和所述分类损失更新所述多模态融合模型；步骤S5：采用更新后的所述多模态融合模型基于待检测模态的图像和待查询模态的图像生成零样本跨模态检索结果。2.根据权利要求1所述的基于Transformer网络和超球空间学习的多模态图像处理方法，其特征在于，所述步骤S1中各个模态的图像数据包括照片和素描图，此时基于各个模态的图像数据以自监督方式微调该预训练的Transformer网络模型具体包括：分别采用照片和素描图数据以自监督方式微调该预训练Transformer网络模型，获得照片模态和素描图模态的教师模型，所述自监督方式，即把标签信息排除在外，以避免在微调过程中模型泛化性的退化，即用“多裁剪”策略为每个照片图像或素描图图像生成一组不同的视图V，其中包括两个分辨率为224×224的全局视图xg,1和xg,2，以及10个分辨率为96×96的局部视图；然后，从预训练的Transformer网络模型初始化出两个待微调模型，记为模型P和模型T；微调过程遵循从局部到整体的策略，把V中的所有视图输入模型P，而只把全局视图输入模型T，则优化公式定义如下：其中，Zt，τt，θt和Zp，τp，θp分别表示模型T和P的输出、温度超参和参数，ψ表示Softmax归一化操作，KL表示Kullback-Leibler散度；x可以是任意全局视图，但不可以是局部视图；x′可以是任意视图，但不可以和x相同；表示最小化Kullback-Leibler散度，因此，上述公式用于对齐局部视图和全局视图的输出，以及对齐不同的全局视图；最后，模型T的参数以指数移动平均方式更新：θt＝ζθt+θp，其中，ζ是预设的处于之间的参数；分别取得图像模态和素描图模态的训练完成后的模型T，作为对应模态的教师模型。3.根据权利要求2所述的基于Transformer网络和超球空间学习的多模态图像处理方法，其特征在于，所述步骤S2的具体实现方式为：将步骤S1获取到的照片模态的教师模型和素描图模态的教师模型分别记为gI和gS，其中，I和S分别表示照片模态和素描图模态，照片模态的教师模型的结构是由骨架网络fI和投影网络hI构成，素描图模态的教师模型的结构是由骨架网络fS和投影网络hS构成；进一步构建能够基于多模态图像进行超球学习的多分支模型，其由上述两个模态的教师模型和一个多模态融合模型构成，多模态融合模型的基础网络结构也是Transformer网络，并基于知识蒸馏适应性地增加蒸馏标记，同时基于超球空间学习适应性地增加融合标记，多模态融合模型的结构是由一个骨架网络fF和两个投影网络hD和hF构成，用gD表示fF和hD构成的模型，gF表示fF和hF构成的模型，教师模型的蒸馏标记用于计算教师蒸馏向量，多模态融合模型的蒸馏标记用于计算所述各个模态的学生蒸馏向量，多模态融合模型的融合标记的输出用于计算单位超球空间上的特征和分类概率。4.根据权利要求3所述的基于Transformer网络和超球空间学习的多模态图像处理方法，其特征在于，所述步骤S3的具体实现方式为：不论是教师模型或多模态融合模型，蒸馏标记由骨架网络fI，fS或fF学习得到，并由投影网络hI，hS或hD投影到一个K维的空间中，得到蒸馏向量；以任意第i张照片或任意第i张素描图为例，和分别表示照片和素描图的教师蒸馏向量，而和分别表示照片和素描图的学生蒸馏向量；另外，融合标记由fF学习得到，并由hF投影到单位超球空间，得到图像在这个单位超球空间中的特征，和分别表示照片和素描图的特征，这些特征通过一个所有模态共享的线性分类器进行分类，得到分类概率。5.根据权利要求4所述的基于Transformer网络和超球空间学习的多模态图像处理方法，其特征在于，所述步骤S4的具体实现方式为：多模态融合模型的训练过程是在各个模态对应的教师模型的监督下进行的，因为各个模态对应的教师模型是以自监督方式预训练的，它们被优化为发现每张图像所特有的全局结构信息；然而，多模态融合模型的目的是消除同个类别但不同模态的分布之间的模态差异，这将不可避免地要求多模态融合模型更多地关注整个类别共享的更具辨别性的局部结构，逐渐忘却每张图像所特有的结构信息，因此，通过知识蒸馏来避免这种名叫“灾难性遗忘”的现象；基于照片的教师蒸馏向量及其学生蒸馏向量计算照片的蒸馏损失基于素描图的教师蒸馏向量及其学生蒸馏向量计算素描图的蒸馏损失以照片为例，给定N张图像构成的一批数据，知识蒸馏匹配教师蒸馏向量和学生蒸馏向量的概率分布，计算照片的蒸馏损失如下：其中，τI和τD分别表示照片模态教师模型和多模态融合模型的温度超参，其余符号与前述内容定义一致；同理，也能够由一批素描图图像计算得到；因此，多模态融合模型的总体蒸馏损失定义为：照片和素描图都被投影到单位超球空间，并期望照片和素描图能够按照类别聚集起来，当所有类别的图像都各自聚集起来，那它们的分布在超球空间中是线性可分的，因此，使用一个线性分类器对特征进行分类，计算分类损失如下：其中，表示数学期望，xi表示任意第i张照片或者素描图，yi表示xi的类别标签，θc表示所述线性分类器的参数，P；θc)表示参数为θc的线性分类器将xi分类为yi的概率；此外，基于各个模态图像在单位超球空间的特征计算模态间中心对齐损失明确要求各个模态图像在单位超球空间的特征分布在超球上是重叠的：其中，为了简化表示，*表示照片模态I或者素描图模态S，λ是指数移动平均的权值，表示一批图像数据中类别标签为yj的样本的数量，表示类中心，Y表示由各个类别yi组成的类集合，上述第二行公式表示L2范数归一化类中心，即将类中心映射回单位超球空间；另外，基于各个模态图像在单位超球空间的特征和径向基函数，为每个模态的特征计算模态内均匀性损失，其中模态内均匀性损失定义为成对特征的高斯势的期望的对数；最后，总的模态内均匀性损失是各个模态的模态内均匀性损失与的和：其中，和表示同模态的任意两张图像，t是固定为2的参数，为任意成对图像和计算高斯势；最后，多模态融合模型的总体目标函数是上述四种损失的线性加权，定义如下：其中，λ1和λ2分别是模态间中心对齐损失和模态内均匀性损失的超参数，计算出多模态融合模型的总体目标函数的值后，根据随机梯度下降算法更新多模态融合模型的参数，得到更新后的所述多模态融合模型。6.根据权利要求5所述的基于Transformer网络和超球空间学习的多模态图像处理方法，其特征在于，所述步骤S5的具体实现方式为：当多模态融合模型更新完成后，使用所述更新后的所述多模态融合模型的骨架网络fF提取各个模态图像的融合标记向量，基于待检测模态的图像提取待检测图像的融合标记向量，基于待查询模态的图像提取待查询图像的融合标记向量；最后，根据上述两种融合标记向量计算所述待检测图像与待查询图像的余弦相似度，按从大到小顺序排序后生成所述零样本跨模态检索结果。7.根据权利要求6所述的基于Transformer网络和超球空间学习的多模态图像处理方法，其特征在于，所述K固定设为65536。8.一种基于Transformer网络和超球空间学习的多模态图像处理系统，用于实现如权利要求1-7中任意一项所述的基于Transformer网络和超球空间学习的多模态图像处理方法，其特征在于，该系统包括：成像单元，用于采集多模态的图像样本；数据存储单元，用于存储所述多模态的图像样本；神经网络单元，包括预训练的Transformer网络模型、以自监督方式微调的各个模态对应的教师模型和多模态融合模型；数据处理单元，基于所述各个模态对应的教师模型提取各个模态图像的教师蒸馏向量，基于所述多模态融合模型提取各个模态图像的学生蒸馏向量，并基于所述多模态融合模型提取各个模态图像在单位超球空间的特征及其分类概率；同时，基于各个模态图像的教师蒸馏向量、学生蒸馏向量、各个模态图像在单位超球空间的特征及其分类概率计算蒸馏损失、模态间中心对齐损失、模态内均匀性损失和分类损失，并基于所述蒸馏损失、所述模态间中心对齐损失、所述模态内均匀性损失和所述分类损失更新多模态融合模型。9.根据权利要求8所述的基于Transformer网络和超球空间学习的多模态图像处理系统，其特征在于，所述数据处理单元基于各个模态图像的教师蒸馏向量及其学生蒸馏向量计算蒸馏损失，基于各个模态图像在单位超球空间的特征计算模态间中心对齐损失和模态内均匀性损失，基于各个模态图像在单位超球空间的分类概率计算分类损失，并基于线性加权的方式加权蒸馏损失、模态间中心对齐损失、模态内均匀性损失和分类损失，计算得到最终的损失值，用于更新多模态融合模型。
说明书desc
技术领域本发明涉及深度学习领域，具体涉及一种基于Transformer网络和超球空间学习的多模态图像处理方法及系统。背景技术随着科学技术的快速发展，图像数据变得越来越容易获取。这些图像数据具有多样的来源、视角、风格等等，形成多模态图像数据集。例如，素描图和照片是具有不同风格的两种模态图像，素描图具有高度的抽象性和描绘对象的结构细节，照片具有描绘对象的丰富视觉特征和复杂的背景信息。对于多模态图像的数据处理以及检索成为了深度学习技术领域的研究热点。但是，现有的多模态图像处理方法，绝大多数假定实际应用时待查询模态的图像和被查询模态的图像所包含的类别与训练模型时所用数据类别完全一致，未考虑实际应用时遇到训练数据所不包含的类别的情况，造成检索结果较差。此外，现有的多模态图像处理方法，均采用深度卷积神经网络作为基础网络架构，提取特征以供下游任务。然而，深度卷积网络的性能受限于卷积操作的局部性，无法建模对象的全局结构信息。最近提出的Transformer网络具有多头自注意力机制，能够有效建模对象的全局结构信息，在图像识别任务表现良好。综上所述，现有的多模态图像处理方法具有应用设置不合理以及基础网络结构限制性能的问题。发明内容有鉴于此，本发明提供了一种基于Transformer网络和超球空间学习的多模态图像处理方法及其处理系统，解决了现有的多模态图像处理方法存在的应用设置不合理以及基础网络结构限制性能的问题。为解决以上问题，本发明的技术方法为采用一种基于Transformer网络和超球空间学习的多模态图像处理方法，包括：获取预训练的Transformer网络模型，并基于各个模态的图像数据以自监督方式微调该预训练的Transformer网络模型，得到教师模型；构建能够基于多模态图像进行超球空间学习的多分支模型，其由各个模态对应的教师模型和一个多模态融合模型构成；基于教师模型提取各个模态图像的教师蒸馏向量；基于多模态融合模型提取各个模态图像的学生蒸馏向量，并基于多模态融合模型提取各个模态图像在单位超球空间的特征及其分类概率；根据教师蒸馏向量、学生蒸馏向量、特征、分类概率计算各个模态的蒸馏损失、模态间中心对齐损失、模态内均匀性损失和分类损失；基于蒸馏损失、模态间中心对齐损失、模态内均匀性损失和分类损失更新所述多模态融合模型；更新后的多模态融合模型基于待检测模态的图像和待查询模态的图像生成零样本跨模态检索结果。进一步的是，构建能够基于多模态图像进行超球空间学习的多分支模型，其由各个模态对应的所述教师模型和一个多模态融合模型构成，包括：所述教师模型的网络结构是Transf ormer网络，并基于各个模态的图像数据以自监督训练方式微调预训练的Transformer网络模型，并基于知识蒸馏适应性地增加蒸馏标记；所述多模态融合模型是基于消除模态差异的目的提出的模型，其基础网络结构为Transformer网络，并基于知识蒸馏适应性地增加蒸馏标记，并基于超球学习适应性地增加融合标记。进一步的是，所述蒸馏标记和所述融合标记是Transformer网络模型的输入嵌入向量，基于Transformer网络模型的多头自注意力层和全连接层训练得到。进一步的是，教师模型的所述蒸馏标记的输出用于计算所述教师蒸馏向量，多模态融合模型的所述蒸馏标记的输出用于计算所述学生蒸馏向量，多模态模型的所述融合标记的输出用于计算单位超球空间的特征和分类概率。进一步的是，基于所述教师蒸馏向量、所述学生蒸馏向量、所述特征、所述分类概率计算蒸馏损失、模态间中心对齐损失、模态内均匀性损失和分类损失，包括：基于所述教师蒸馏向量和所述学生蒸馏向量计算各个模态的蒸馏损失；基于各个模态的特征计算模态间中心对齐损失和模态内均匀性损失；基于各个模态的分类概率计算分类损失。进一步的是，基于各个模态的特征计算模态间中心对齐损失和模态内均匀性损失，包括：所述特征是由多模态融合模型的所述融合标记的输出计算得到的，其位于单位超球空间，具有向量模为一的性质；所述模态间中心对齐损失，基于所述特征，为每个模态中的每个类别计算类中心，归一化类中心使其向量模为一，对齐不同模态的同种类别的类中心，计算模态间中心对齐损失；所述模态内均匀性损失，包括：基于所述特征和径向基函数，为每个模态的特征计算模态内均匀性损失，其中模态内均匀性损失定义为成对特征的高斯势的对数的平均。进一步的是，基于各个模态的分类概率计算分类损失，包括：所述分类概率是基于所述对应模态的特征经过一个线性分类器输出得到，其中线性分类器的权值是所有模态共享的。相应地，所述多模态图像处理方法的各个模态的图像数据的获取方式为：获取不同模态的图像样本，包括但不限于人工绘制的素描图样本和成像设备采集的照片样本，构成训练所述预训练的Transformer网络模型参数的数据集。相应地，所述多模态融合模型基于待检测模态的图像和待查询模态的图像生成零样本跨模态检索结果，包括：所述多模态融合模型基于待检测模态的图像提取待检测图像的融合标记；所述多模态融合模型基于待查询模态的图像提取待查询图像的融合标记；计算所述待检测图像与所述待查询图像的余弦相似度，按从大到小顺序排序后生成所述零样本跨模态检索结果。相应地，本发明提供了一种基于Transformer网络和超球空间学习的多模态图像处理系统，包括：成像单元，用于采集多模态的图像样本；数据存储单元，用于存储多模态的图像样本；神经网络单元，包括预训练的Transformer网络模型、以自监督方式微调的各个模态的教师模型和多模态融合模型；数据处理单元，基于所述教师模型提取各个模态图像的教师蒸馏向量，基于所述多模态融合模型提取各个模态图像的学生蒸馏向量，并基于所述多模态融合模型提取各个模态图像在单位超球空间的特征及其分类概率；同时，基于所述教师蒸馏向量、学生蒸馏向量、所述特征、所述分类概率计算各个模态的蒸馏损失、模态间中心对齐损失、模态内均匀性损失和分类损失，并基于所述蒸馏损失、所述模态间中心对齐损失、所述模态内均匀性损失和所述分类损失更新多模态融合模型。进一步的是，所述数据处理单元基于所述教师蒸馏向量和所述学生蒸馏向量计算蒸馏损失，基于所述特征计算模态间中心对齐损失和模态内均匀性损失，基于各个模态的所述分类概率计算分类损失，并基于线性加权的方式加权所述蒸馏损失、所述模态间中心对齐损失、所述模态内均匀性损失和所述分类损失，计算得到最终的损失值，更新多模态融合模型。本发明基于Transformer网络和超球空间学习的多模态图像处理方法，适应性地为Trans former网络添加蒸馏标记和融合标记，构建能够基于多模态图像进行超球空间学习的多分支模型，利用全局结构建模能力提取各个模态图像样本的教师蒸馏向量、学生蒸馏向量、单位超球空间上的特征及其分类概率，并通过计算蒸馏损失、模态间中心对齐损失、模态内均匀性损失和分类损失，有效提升多模态融合模型的建模和对齐多模态分布的能力，消除不同模态之间的模态差异问题，从而实现零样本跨模态检索。附图说明图1是本发明基于Transformer网络和超球空间学习的多模态图像处理方法的简化流程图；图2是本发明基于Transformer网络和超球空间学习的多模态图像处理系统的简化单元连接图；图3是本发明的一优选实施例的多模态融合模型的简化流程图；图4是本发明的一优选实施例的多分支模型的简化流程图。具体实施方式为了使本领域的技术人员更好地理解本发明的技术方案，下面结合附图和具体的实施例对本发明作进一步的详细说明。实施例1如图1所示，本发明是一种基于Transformer网络和超球空间学习的多模态图像处理方法，包括步骤S1至步骤S5。S1：获取预训练的Transformer网络模型，并基于各个模态的图像数据以自监督方式微调该预训练的Transformer网络模型，得到教师模型。Transformer网络首先被提出于自然语言处理领域，以序列化的文本数据作为输入。最近，Transformer网络结构已经被改进为可处理图像数据，在计算机视觉领域表现优异。如图3所示，Transformer网络结构由L层的多头自注意力模块和前馈神经网络模块交替组成，其中每个模块都包含预先层归一化和残差连接。它将每张图像按方格切割为一系列的固定分辨率的图像块，再将这些图像块线性投影，并加上可训练的位置编码，形成序列化的块标记向量。这些序列化的块标记是图像块的特征表示，可以通过取均值以聚合块标记的信息，也可以通过额外训练一个标记以聚合块标记的信息，作为整张图像的特征表示。本实施例包含两种模态的图像数据，分别是照片和素描图。如图3所示，在预训练的Transformer网络中适应性地增加蒸馏标记，以聚合其他块标记的信息。分别采用照片和素描图数据以自监督方式微调该预训练Transformer网络模型，获得照片模态和素描图模态的教师模型。所述自监督方式，即把标签信息排除在外，以避免在微调过程中模型泛化性的退化。更具体地说，用“多裁剪”策略为每个图像生成一组不同的视图，其中包括两个分辨率为224×224的全局视图xg,1和xg,2，以及10个分辨率为96×96的局部视图。然后，从预训练的Transformer网络模型初始化出两个待微调模型，记为模型P和模型T。微调过程遵循从局部到整体的策略，把V中的所有视图输入模型P，而只把全局视图输入模型T，则优化公式定义如下：其中，Zt，τt，θt和Zp，τp，θp分别表示模型T和P的输出、温度超参和参数，ψ表示Softmax归一化操作，KL表示Kullback-Leibler散度。x可以是任意全局视图，但不可以是局部视图。xS可以是任意视图，但不可以和x相同。表示最小化Kullback-Leibler散度，即使得模型P和T的输出相似，并更新模型P的参数。因此，上述公式用于对齐局部视图和全局视图的输出，以及对齐不同的全局视图。最后，模型T的参数以指数移动平均方式更新：θt＝ζθt+θp。其中，ζ是预设的处于之间的参数。分别取得照片模态和素描图模态的训练完成后的模型T，作为对应模态的教师模型。S2：构建能够基于多模态图像进行超球空间学习的多分支模型，其由各个模态对应的教师模型和一个多模态融合模型构成。由步骤S1，获取到照片和素描图模态的带有蒸馏标记的Transformer网络教师模型，分别记为gI和gS。其中，I和S分别表示照片模态和素描图模态。如图4所示，照片模态的教师模型是由骨架网络fI和投影网络hI构成，素描图模态的教师模型是由骨架网络fS和投影网络hS构成。进一步地，构建能够基于多模态图像进行超球学习的多分支模型，其由上述两个模态的教师模型和一个多模态融合模型构成。与特定模态的教师模型不同，多模态融合模型旨在消除模态间的分布差异，同时处理所有模态的图像数据，为所有模态输出具有相似分布的特征。如图3所示，它的基础网络结构也是Transformer网络，并基于知识蒸馏适应性地增加蒸馏标记，并基于超球空间学习适应性地增加融合标记。因此，如图4所示，它由一个骨架网络fF和两个投影网络hD和hF构成。为了简化公式，用gD表示fF和hD构成的模型，gF表示fF和hF构成的模型。与蒸馏标记类似，融合标记也是可训练的输入嵌入向量。但它们的作用不同，教师模型的蒸馏标记用于计算教师蒸馏向量，多模态融合模型的蒸馏标记用于计算所述各个模态的学生蒸馏向量，多模态融合模型的融合标记的输出用于计算单位超球空间上的特征和分类概率。S3：基于各教师模型分别提取各个模态图像的教师蒸馏向量，基于所述多模态融合模型提取各个模态图像的学生蒸馏向量，并基于所述多模态融合模型提取各个模态图像在单位超球空间的特征及其分类概率。如图4所示，不论是教师模型或多模态融合模型，蒸馏标记由骨架网络学习得到，并由投影网络投影到一个K维的空间中，得到蒸馏向量。以任意第i张照片或任意第i张素描图为例，和分别表示照片和素描图的教师蒸馏向量，而和分别表示照片和素描图的学生蒸馏向量。另外，融合标记由fF学习得到，并由hF投影到单位超球空间，得到图像在这个单位超球空间中的特征。同样的例子，和分别表示照片和素描图的特征。这些特征通过一个所有模态共享的线性分类器进行分类，得到分类概率。S4：基于所述教师蒸馏向量、所述学生蒸馏向量、所述特征、所述分类概率计算各个模态的蒸馏损失、模态间中心对齐损失、模态内均匀性损失和分类损失，并基于所述蒸馏损失、所述模态间中心对齐损失、所述模态内均匀性损失和所述分类损失更新多模态融合模型。多模态融合模型的训练过程是在各个模态的教师模型的监督下进行的。因为各个模态的教师模型是以自监督方式预训练的，它们被优化为发现每张图像所特有的全局结构信息。然而，多模态融合模型的目的是消除同个类别但不同模态的分布之间的模态差异，这将不可避免地要求多模态融合模型更多地关注整个类别共享的更具辨别性的局部结构，逐渐忘却每张图像所特有的结构信息。因此，我们通过知识蒸馏来避免这种名叫“灾难性遗忘”的现象。本实施例包含照片和素描图，基于照片的教师蒸馏向量及其学生蒸馏向量计算照片的蒸馏损失基于素描图的教师蒸馏向量及其学生蒸馏向量计算素描图的蒸馏损失以照片为例，给定N张图像构成的一批数据，知识蒸馏匹配教师蒸馏向量和学生蒸馏向量的概率分布，计算照片的蒸馏损失如下：其中，τI和τD分别表示照片模态教师模型和多模态融合模型的温度超参，其余符号与前述内容定义一致。类似地，也可由一批素描图计算得到。因此，多分支模型的总体蒸馏损失可以定义如下：如图4所示，照片和素描图都被投影到单位超球空间，并期望照片和素描图能够按照类别聚集起来。当所有类别的图像都各自聚集起来，那它们的分布在超球空间中是线性可分的。因此，可以使用一个线性分类器对特征进行分类，计算分类损失如下：其中，表示数学期望，xi表示任意第i张照片或者素描图，yi表示xi的类别标签，θc表示所述线性分类器的参数，P；θc)表示参数为θc的线性分类器将xi分类为yi的概率。因此，分类损失可以通过所有模态共享的线性分类器进行模态内和模态间的分布对齐。此外，基于各个模态的特征计算模态间中心对齐损失明确要求各个模态的特征分布在超球上是重叠的。其中，为了简化表示，*表示照片模态I或者素描图模态S，λ是指数移动平均的权值，Nyi表示一批图像数据中类别标签为yj的样本的数量，表示类中心，Y表示由各个类别yi组成的类集合。上述第二行公式表示L2范数归一化类中心，使类中心的模为1，即将类中心映射回单位超球空间。和结合，多模态融合模型能够从模态间和模态内两方面对齐特征分布。然而，对齐性和均匀性都是超球空间中的特征的关键性质，因为均匀性意味着超球空间的表示能力得到充分利用。具体而言，基于各个模态的特征和径向基函数，为每个模态的每一批特征计算模态内均匀性损失，其中模态内均匀性损失定义为成对特征的高斯势的期望的对数。最后，总的模态内均匀性损失是各个模态的模态内均匀性损失与的和：其中，为了简化表示，*表示照片模态I或者素描图模态S，和表示同模态的任意两张图像，t是固定为2的参数，为任意成对图像和计算高斯势。值得注意的是，总的模态内均匀性损失是各个模态的模态内均匀性损失之和，而不是不分模态地约束所有的特征。这样的损失函数设计是有理由的，因为理想情况下，所有模态在超球空间的分布是趋于均匀分布的，但不同模态的同类特征的分布具有重叠的位置。最后，多模态融合模型的总体目标函数是上述四个损失的线性加权，定义如下：其中，λ1和λ2分别是模态间中心对齐损失和模态内均匀性损失的超参数。计算出多模态融合模型的总体目标函数的值后，根据随机梯度下降算法更新多模态融合模型的参数，得到训练完成的多模态融合模型。S5：所述多模态融合模型基于待检测模态的图像和待查询模态的图像生成零样本跨模态检索结果。当多模态融合模型训练完成时，可使用所述训练完成的多模态融合模型的骨架网络fF提取各个模态的图像的融合标记向量，基于待检测模态的图像提取待检测图像的融合标记向量，基于待查询模态的图像提取待查询图像的融合标记向量。最后，根据上述两种融合标记向量计算所述待检测图像与待查询图像的余弦相似度，按从大到小顺序排序后生成所述零样本跨模态检索结果。实施例2本实施例在实施例1的基础上，进行实验验证。本实施例采用零样本跨模态检索领域的三个主流数据集作为训练和测试的数据集，分别是Sketchy，TU-Berlin，QuickDraw。它们都包含照片模态和素描图模态的数据和标签，用于零样本照片-素描图检索任务。具体地，Sketchy最初由125个类别的75471张素描图和12500张照片构成，且素描图和图像之间有配对关系。之后，Sketchy的照片集被拓展到73002张。TU-Berlin由250个类别的20000张素描图和204489张照片构成，因此素描图和照片的数量严重不平衡，素描图的抽象程度高；QuickDraw是三个数据集中最大的，由110个类别的330000张素描图和204000张照片构成，素描图的抽象程度最高。对于Sketchy来说，有两种训练类和测试类的划分方式：一种随机选择25个类作为测试类，另一种则是选择与ImageNet类别不重叠的21类作为测试类。为了简单起见，我们把前者称为Sketchy，把后者称为Sketchy-NO。TU-Berlin与Sketchy类似，随机选择20个类作为测试类。QuickDraw与Sketchy-NO类似，选择30个与ImageNet类别不重叠的类作为测试类。此外，我们通过迭代量化对实值特征进行二值化处理，以便和哈希方法比较。余弦距离和汉明距离分别用于计算实值和二进制表示的相似度。评估标准采用召全率和平均召全率的均值，Prec@K和mAP@K表示检索的前K个结果计算得到的召全率和平均召全率。进一步地，基于本发明所要求保护的系统在本实施例中被定义为TVT，其余检索方法都是使用度较高的素描图检索方法。实验结果如表1和表2所示，TVT方法相比所有现有方法都显示出持续和显著的改进。大多数零样本素描图检索方法只在Sketchy和TU-Berlin上进行了实验，这两个数据集都随机选择测试类。具体来说，在这两个数据集上，TVT始终以mAP@all分数11.1％和0.5％的改进击败现有最好方法。然而，在更现实和更具挑战性的数据集上，TVT取得了更显著的提升。在Sketchy-NO上，与DSN相比，TVT将mAP@200得分从0.501提高到0.531。此外，在大规模的QuickDraw上，TVT实现了近100％的mAP@all分数的巨大改进。考虑到这些数据集的大规模性质和固定类别分割的限制，这些结果有效地证明了TVT的巨大改进不是偶然的，也不是由分割偏差造成的。与哈希方法相比，TVT也得到了最好的结果。当使用只考虑前100或200名候选样本的指标来比较结果时，TVT所取得的改进更加明显。在Sketchy和TU-Berlin上，TVT远超DSN，Prec@100的分数分别提高了13.1％和13.0％。在QuickDraw上，TVT的mAP@200和Prec@200分数相比于Dey etal.分别增加了112.2％和330.9％。这些结果意味着正确结果有更高的概率出现在前100或200个检索结果中，这很适合于检索任务。所有这些比较可以证明，TVT可以有效地对齐模态内和模态间的分布而不损失均匀性，然后在未见类上实现令人满意的泛化。表1：TVT和其他10个现有的零样本素描图检索方法在Sketchy和TU-Berlin上的比较。下标“b”表示由二值表示得到的结果，“-”表示该方法未报告相关结果。最好和次好的结果分别被粗体和下划线表示出来。表2：TVT和其他两个方法在QuickDraw上的比较。最好的结果被粗体表示出来。相应的，如图2所示，本发明提供一种基于Transformer网络和超球空间学习的多模态图像处理系统，包括：成像单元，用于采集多模态的图像样本；数据存储单元，用于存储多模态的图像样本；神经网络单元，包括预训练的Transformer网络模型、以自监督方式微调的各个模态的教师模型和多模态融合模型；数据处理单元，基于所述教师模型提取各个模态图像的教师蒸馏向量，基于所述多模态融合模型提取各个模态图像的学生蒸馏向量，并基于所述多模态融合模型提取各个模态图像在单位超球空间的特征及其分类概率；同时，基于所述教师蒸馏向量、学生蒸馏向量、所述特征、所述分类概率计算各个模态的蒸馏损失、模态间中心对齐损失、模态内均匀性损失和分类损失，并基于所述蒸馏损失、所述模态间中心对齐损失、所述模态内均匀性损失和所述分类损失更新多模态融合模型。进一步地，所述数据处理单元基于所述教师蒸馏向量和所述学生蒸馏向量计算蒸馏损失，基于所述特征计算模态间中心对齐损失和模态内均匀性损失，基于各个模态的所述分类概率计算分类损失，并基于线性加权的方式加权所述蒸馏损失、所述模态间中心对齐损失、所述模态内均匀性损失和所述分类损失，计算得到最终的损失值，更新多模态融合模型。以上对本发明实施例所提供的一种基于Transformer网络和超球空间学习的多模态图像处理方法及其系统进行了详细介绍。说明书中各个实施例采用递进的方式描述，每个实施例重点说明的都是与其他实施例的不同之处，各个实施例之间相同相似部分互相参见即可。对于实施例公开的装置而言，由于其与实施例公开的方法相对应，所以描述的比较简单，相关之处参见方法部分说明即可。应当指出，对于本技术领域的普通技术人员来说，在不脱离本发明原理的前提下，还可以对本发明进行若干改进和修饰，这些改进和修饰也落入本发明权利要求的保护范围内。专业人员还可以进一步意识到，结合本文中所公开的实施例描述的各示例的单元及算法步骤，能够以电子硬件、计算机软件或者二者的结合来实现，为了清楚地说明硬件和软件的可互换性，在上述说明中已经按照功能一般性地描述了各示例的组成及步骤。这些功能究竟以硬件还是软件方式来执行，取决于技术方案的特定应用和设计约束条件。专业技术人员可以对每个特定的应用来使用不同方法来实现所描述的功能，但是这种实现不应认为超出本发明的范围。结合本文中所公开的实施例描述的方法或算法的步骤可以直接用硬件、处理器执行的软件模块，或者二者的结合来实施。软件模块可以置于随机存储器、内存、只读存储器、电可编程ROM、电可擦除可编程ROM、寄存器、硬盘、可移动磁盘、CD-ROM、或技术领域内所公知的任意其它形式的存储介质中。
