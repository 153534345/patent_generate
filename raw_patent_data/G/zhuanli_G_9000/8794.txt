标题title
一种纹理协同的深度特征图压缩方法
摘要abst
本发明属于图像压缩和图像质量增强领域，具体提供一种纹理协同的深度特征图压缩方法；本发明在编码端将压缩后低质量图像和压缩后深度特征图同时传输，在解码端通过构建图像重建网络，实现压缩后低质量图像和压缩后深度特征图融入，重建得到高质量的自然图像，即能够实现图像的高清可视，同时，基于重建高质量图像再次提取的深度特征与压缩后的深度特征进行再次融合后，能够大大提升后续视觉任务的性能。综上，本发明基于图像重建网络既能够在解码端提供人眼理解的视觉图像，又能够进一步提高特征的压缩效率后提升后续视觉任务性能。
权利要求书clms
1.一种纹理协同的深度特征图压缩方法，包括：编码与解码，其特征在于，所述编码包括：特征编码与图像编码；所述特征编码为：首先，将原始RGB图像输入至VGG16，将VGG16的第一个池化层的输出作为提取的原始图像的深度特征；然后，对提取到的深度特征的每一个通道进行单独量化得到其对应的特征图；最后，将所有特征图存储为YUV400的格式，利用HEVC Test Model进行压缩，得到压缩特征并传输；所述图像编码为：对原始图像进行4倍降采样，并将降采样后的RGB图像转换为YCbCr图像；再对YCbCr图像采用HM进行压缩，得到压缩图像并传输；所述解码包括：解压与图像重建；步骤1.解压：将压缩特征的每个通道进行解压和反量化，得到解压后的特征HRfeature_input；将解压得到的YCbCr图像转换为RGB图像，得到低质量图像LQinput；步骤2.图像重建：将低质量图像Lqinput与特征HRfeature_input输入图像重建网络，由图像重建网络输出高质量图像Recout；所述图像重建网络包括：特征提取模块、超分辨率模块与输出通道分支；其中，所述特征提取模块由残差单元U1至U16依次连接组成，具体为：残差单元U1的结构为：CONV 3×3×64+CONV 3×3×64，其输入为经过CONV 3×3×64卷积后的低质量图像Lqinput，输出为U1out；残差单元U2的结构为：CONV 3×3×64+CONV 3×3×64，其输入U2in为U1out+U1in，输出为U2out；残差单元U3至残差单元U16均与残差单元U2结构相同；所述超分辨率模块由连个超分模块SR1和SR2组成，具体为：超分单元SR1的结构为：CONV 3×3×256+PixelShuffer×2，其输入为U1in+U16out+U16in，输出为SR1out；超分单元SR2的结构为：CONV 3×3×256+PixelShuffer×2，其输入为SR1out+HRfeature_input，输出为SR2out；所述输出通道分支由网络单元R组成，其结构为：CONV 3×3×64+CONV 3×3×3，网络单元R的输入Rin为SR2out、输出为Rout，Rout与LQinput相加得到重建的RGB图像Recout。2.按权利要求1所述纹理协同的深度特征图压缩方法，其特征在于，所述纹理协同的深度特征图压缩方法还包括：特征融合，具体为：将高质量的重建图像输入至VGG16，将VGG16的第一个池化层的输出作为提取的重建图像的深度特征，将重建图像的深度特征与特征HRfeature_input进行融合得到融合特征，利用融合特征做后续的视觉任务；融合公式为：fifusion＝max其中，firec为重建图像的深度特征的第i个通道，为特征HRfeature_input的第i个通道，fifusion为融合特征的第i个通道。3.按权利要求1所述纹理协同的深度特征图压缩方法，其特征在于，所述量化公式为：其中，fi表示待量化特征中的第i个通道；bitdepth为比特深度，为预设值、本实施例中设置为8，用以表示将浮点数量化到0-255；fiquant为量化后特征的第i个通道；所述反量化公式为：其中，fidequant表示反量化后特征的第i个通道。4.按权利要求1所述纹理协同的深度特征图压缩方法，其特征在于，所述RGB图像转换为YCbCr图像的转换公式为：其中，R、G和B分别代表RGB图像的R通道、G通道和B通道的像素值，Y、Cb和Cr分别代表转换得到YCbCr图像的Y通道、Cb通道和Cr通道的像素值；所述YCbCr图像转换为RGB图像的转换公式为：其中，·-1表示矩阵求逆。
说明书desc
技术领域本发明属于图像压缩和图像质量增强领域，具体提供一种纹理协同的深度特征图压缩方法。背景技术近几年，深度学习在目标识别、图像分类以及语义分割等视觉任务上表现出惊人的潜力，深度学习的性能取决于对特征提取和表示；在传统应用中，通常是从压缩的图像中提取特征，这样节约了存储空间和带宽，但是压缩后的图像会出现失真，会影响深度学习做后续的视觉任务，如会使深度学习模型的准确率下降。为了避免上述问题，诸多研究者尝试直接在未压缩的图像上提取特征，接着对特征进行压缩和传输，这样能缓解压缩给识别造成的影响；但是，直接从原始图像提取特征并传输也存在局限性。由于特征只能用于模型做视觉任务，并不能直接给人观看；在一些需要提供人眼能观看的图像的场景下就显得很有局限性，如视频监控；而且，在传输特征的同时，需要考虑在低压缩率的情况下，还要达到较高后续视觉任务的性能。发明内容本发明的目的在于针对上述现有技术存在的诸多局限，提出了一种纹理协同的深度特征图压缩方法，不但能在解码端提供一张供人查看的高质量图像，同时还能保证在高压缩率的情况下所提供的特征能在视觉任务上达到较好的性能。为实现上述目的，本发明采用的技术方案如下：一种纹理协同的深度特征图压缩方法，包括：编码与解码，其特征在于，所述编码包括：特征编码与图像编码；所述特征编码为：首先，将原始RGB图像输入至VGG16，将VGG16的第一个池化层的输出作为提取的原始图像的深度特征；然后，对提取到的深度特征的每一个通道进行单独量化得到其对应的特征图；最后，将所有特征图存储为YUV400的格式，利用HEVC TestModel进行压缩，得到压缩特征并传输；所述图像编码为：对原始图像进行4倍降采样，并将降采样后的RGB图像转换为YCbCr图像；再对YCbCr图像采用HM进行压缩，得到压缩图像并传输；所述解码包括：解压与图像重建；步骤1.解压：将压缩特征的每个通道进行解压和反量化，得到解压的后特征HRfeature_input；将解压得到的YCbCr图像转换为RGB图像，得到低质量图像LQinput；步骤2.图像重建：将低质量图像Lqinput与特征HRfeature_input输入图像重建网络，由图像重建网络输出高质量图像Recout；所述图像重建网络包括：特征提取模块、超分辨率模块与输出通道分支；其中，所述特征提取模块由残差单元U1至U16依次连接组成，具体为：残差单元U1的结构为：CONV 3×3×64+CONV 3×3×64，其输入为经过CONV 3×3×64卷积后的低质量图像Lqinput，输出为U1out；残差单元U2的结构为：CONV 3×3×64+CONV 3×3×64，其输入U2in为U1out+U1in，输出为U2out；残差单元U3至残差单元U16均与残差单元U2结构相同；所述超分辨率模块由连个超分模块SR1和SR2组成，具体为：超分单元SR1的结构为：CONV 3×3×256+PixelShuffer×2，其输入为U1in+U16out+U16in，输出为SR1out；超分单元SR2的结构为：CONV 3×3×256+PixelShuffer×2，其输入为SR1out+HRfeature_input，输出为SR2out；所述输出通道分支由网络单元R组成，其结构为：CONV 3×3×64+CONV 3×3×3，网络单元R的输入Rin为SR2out、输出为Rout，Rout与LQinput相加得到重建的RGB图像Recout。进一步的，所述纹理协同的深度特征图压缩方法还包括：特征融合，具体为：将高质量的重建图像输入至VGG16，将VGG16的第一个池化层的输出作为提取的重建图像的深度特征，将重建图像的深度特征与特征HRfeature_input进行融合得到融合特征，利用新特征做后续的视觉任务；融合公式为：fifusion＝max其中，firec为重建图像的深度特征的第i个通道，为特征图HRfeature_input的第i个通道，fifusion为融合特征的第i个通道；max表示取最大值。进一步的，所述量化公式为：其中，fi表示待量化特征中的第i个通道；bitdepth为比特深度，为预设值、本实施例中设置为8，用以表示将浮点数量化到0-255；fiquant为量化后特征的第i个通道；round表示逐元素四舍五入取整，min表示取最小值；所述反量化公式为：其中，fidequant表示反量化后特征的第i个通道。进一步的，所述RGB图像转换为YCbCr图像的转换公式为：其中，R、G和B分别代表RGB图像的R通道、G通道和B通道的像素值，Y、Cb和Cr分别代表转换得到YCbCr图像的Y通道、Cb通道和Cr通道的像素值；所述YCbCr图像转换为RGB图像的转换公式为：其中，·-1表示矩阵求逆。与现有技术相比，本发明是有益效果在于：本发明提出了一种纹理协同的深度特征图压缩方法，在编码端将压缩后低质量图像和压缩后深度特征图同时传输，在解码端通过构建图像重建网络，实现压缩后低质量图像和压缩后深度特征图融合，重建得到高质量的自然图像，即能够实现图像的高清可视，同时，基于重建高质量图像再次提取的深度特征与压缩后的深度特征进行再次融合后，能够提升后续视觉任务的性能。综上，本发明基于图像重建网络既能够在解码端提供人眼理解的视觉图像，又能够进一步提高特征的压缩效率的同时还能提升后续视觉任务性能。附图说明图1为本发明实施例中的图像重建网络结构图。图2为本发明实施例中纹理协同的深度特征图压缩方法的流程图。图3为本发明实施例与对比例在各个数据集下Compression Rate-Fidelity曲线对比图。具体实施方式下面将结合附图对本发明得实施例中的技术方案进行清楚、完整的描述，显然，下面所描述的实施例仅是本发明一部分的实施例，而不是全部的实施例；基于本发明中的实施例，本领域普通技术人员在没有付出创造性劳动前提下，所获得的所有其他实施例，都属于本发明保护的范围。本实施例提供一种纹理协同的深度特征图压缩方法，其流程如图2所示，包括：编码与解码，具体步骤如下：所述编码包括：特征编码与图像编码；所述特征编码具体为：首先，将原始RGB图像输入至VGG16，将VGG16的第一个池化层的输出作为提取的原始图像的深度特征；然后，对提取到的深度特征的每一个通道进行单独量化得到其对应的特征图，量化公式如下：其中，fi表示待量化特征中的第i个通道；bitdepth为比特深度，为预设值、本实施例中设置为8，用以表示将浮点数量化到0-255；fiquant为量化后特征的第i个通道；round表示逐元素将值四舍五入到最接近的整数，min表示矩阵中最小的一个值；最后，将量化后的所有特征图存储为YUV400的格式后，利用HEVC Test Model进行压缩，得到压缩特征并传输；所述图像编码具体为：首先，对原始图像进行4倍降采样，并将降采样后的RGB图像转换为YCbCr图像，转换公式如下：其中，R、G和B分别代表RGB图像的R通道、G通道和B通道的像素值，同理，Y、Cb和Cr分别代表转换得到YCbCr图像的Y通道、Cb通道和Cr通道的像素值；然后，对YCbCr图像采用HM进行压缩，得到压缩图像并传输；所述解码包括：解压与图像重建；步骤1.解压：将压缩特征的每个通道进行解压和反量化，得到解压后的特征HRfeature_input；反量化的公式如下：其中，fidequant表示反量化后特征的第i个通道；解压得到解压后的YCbCr图像，最后再把YCbCr图像转换为RGB图像，得到低质量图像LQinput；转换公式如下：其中，·-1表示矩阵求逆；步骤2.图像重建：将低质量图像Lqinput与特征HRfeature_input输入图像重建网络，由图像重建网络输出高质量图像Recout；所述图像重建网络共由37层卷积层组成，所有卷积层对应的卷积核大小均为3×3、激活函数均为LeakyRelu函数；具体网络结构如图1所示，图中“CONV 3×3×32”表示一层卷积层、且对应的卷积核的大小为3×3、卷积的输出通道为32、padding参数为“same”，“PixelShuffer×2”表示2倍上采样；更为具体的讲：所述图像重建网络共有两个输入，分别是降采样后经HM压缩后的低质量图像LQinput和从原始图像提取的压缩后的特征HRfeature_input，网络的输出为重建后的高质量图像Recout，重建网络具体包含：特征提取模块、超分辨率模块与输出通道分支；所述特征提取模块，由残差单元U1、U2、U3…U16依次连接组成，具体为：残差单元U1的结构为：CONV 3×3×64+CONV 3×3×64，其输入为经过CONV 3×3×64卷积后的低质量图像，输出为U1out；残差单元U2的结构为：CONV 3×3×64+CONV 3×3×64，其输入U2in为U1out+U1in，输出为U2out；残差单元U3的结构为：CONV 3×3×64+CONV 3×3×64，其输入U3in为U2out+U2in、输出为U3out；依次类推，残差单元U4～U16与U2、U3的连接方式一致；所述超分辨率模块由连个超分模块SR1和SR2组成，具体为：超分单元SR1的结构为：CONV 3×3×256+PixelShuffer×2，其输入为U1in+U16out+U16in，输出为SR1out；超分单元SR2的结构为：CONV 3×3×256+PixelShuffer×2，其输入为SR1out+HRfeature_input，输出为SR2out所述输出通道分支由网络单元R组成，其结构为：CONV 3×3×64+CONV 3×3×3，网络单元R的输入Rin为SR2out、输出为Rout，Rout与LQinput相加得到重建的RGB图像Recout；所述图像重建网络的训练过程如下：构建训练集：采用ImageNet2012测试集中前20000张RGB图像切分为N×M大小的子图像作为训练图像，将训练图像依次经过特征编码与图像编码、以及解压处理后作为输入，并将训练图像作为标签，形成训练样本，进而构建得训练集；本实施例中，N＝M＝400；训练：设置训练参数与损失函数，采用Adam优化器对图像重建网络进行训练；所述学习率为2×10-4，并且在迭代次数为50000、100000、200000和300000时学习率会减半、批尺寸为8、迭代次数为300000，所述损失函数为：其中，Y1表示重建网络输出的重建图像，Y0表示标签，Y表示图像Y的第i行、第j列的像素值，N、M分别表示输入图像的高、宽。进一步的，本实施例中还包括特征融合，用于后续的视觉任务；具体为将高质量的重建图像输入至VGG16，将VGG16的第一个池化层的输出作为提取的重建图像的深度特征，将重建图像的深度特征与特征HRfeature_input进行融合得到融合特征，利用新特征做后续的视觉任务；融合公式如下：fifusion＝max其中，firec为重建图像的深度特征的第i个通道，为特征HRfeature_input的第i个通道，fifusion为融合特征的第i个通道；max表示选取两个输入矩阵对应位置的最大值。基于上述技术方案，本实施例在两个图像集进行测试，分别是ImageNet 2012图像集和Pascal Voc 2007图像集，其中，选择4个HEVC中的量化因子进行对比；利用两种方法进行了对比：1)默认的HEVC intra压缩方法，2)纹理协同的深度特征图压缩方法；两个图像集对应的测试结果依次如图3中、所示，其中，横轴为compressionrate、表示未压缩之前的大小与压缩之后大小的比值，纵轴为Fidelity、其计算公式如下：其中，C为测试集图像的数量；v为原始图像提取的特征经过VGG16池化层后面所有模块，送入分类器得到的预测向量；表示从重建后的图像提取的特征与压缩后的特征进行按融合公式进行融合后得到的新特征，将其通过VGG16池化层后面所有模块后，再送入分类器得到的分类向量；argmax表示向量中最大值所在的下标；“HEVC-intra”表示默认的HEVC压缩方法得到图像的rate-fidelity曲线，“Ours”表示我们提出的纹理协同的深度特征图压缩方法；由图3可知，本实施例中纹理协同的深度特征图压缩方法优于HEVC压缩方法，测试结果证明了本发明方法的有效性及优越性。综上所述，本发明所提出的纹理协同的深度特征图压缩方法具有出色的表现，相较于HEVC intra，在同等Compression rate下，可以获得更高的Fidelity。以上所述，仅为本发明的具体实施方式，本说明书中所公开的任一特征，除非特别叙述，均可被其他等效或具有类似目的的替代特征加以替换；所公开的所有特征、或所有方法或过程中的步骤，除了互相排斥的特征和/或步骤以外，均可以任何方式组合。
