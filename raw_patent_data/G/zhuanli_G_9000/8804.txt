标题title
基于深度学习的车道线检测方法、系统、计算机及存储介质
摘要abst
本发明公开了基于深度学习的车道线检测方法、系统、计算机及存储介质，引入图像分割网络，图像分割网络在车道线被部分遮挡或不连续时，检测模型仍然能得到车道线的区域和走势，二值图作为Mask提取特征图中表征车道线的特征图，利用权值矩阵增强车道线特征，并利用车道线特征相似的特性，使用现有的车道特征补足车道特征不明显区域。二值图Mask的引入大大增强了模型对车道线区域的捕获能力。另外，引入Transformer的注意力机制并且在embedding输入Transformer之前做车道线相似区域的特征增强，因此对于车道线有较强的捕捉能力，能很好的把车道线作为前景信息从图像中判别出，减少了无效离散点和算力消耗。
权利要求书clms
1.基于深度学习的车道线检测方法，其特征在于，包括以下步骤：S1、通过交通监控摄像枪拍摄带有车道线的视频，并从视频中截取多张带有车道线的图像，形成数据集；S2、对步骤S1形成的数据集进行预处理，并将预处理后的数据集划分为训练集和测试集；S3、构建双分支的车道线检测模型，两个分支分别设特征提取器和图像分割器；S4、通过训练集训练双分支的车道线检测模型；S5、通过训练好的双分支的车道线检测模型对测试集进行检测。2.根据权利要求1所述的基于深度学习的车道线检测方法，其特征在于，所述步骤S2中，对步骤S1形成的数据集进行预处理，具体包括：S2-1、使用图像标注工具labelme中的linestrip标注图像中的车道线并生成json文件；S2-2、利用Tusimple处理方法对json文件进行处理，生成二值图，作为标签信息；S2-3、采用仿射变换、旋转和色彩变换对生成的二值图进行数据增强，拓展数据集；S2-4、利用Python并引入第三方库OpenCV读取拓展后的数据集，对数据集进行数据清洗。3.根据权利要求1所述的基于深度学习的车道线检测方法，其特征在于，所述步骤S3中，构建的双分支的车道线检测模型中，语义分割网络ENet作为backbone，由五个stage组成，stage1-3属于encoder部分，stage4-5属于decoder部分；模型构建时，特征提取器和图像分割器共享stage1和stage2，stage3作为特征提取器，decoder作为图像分割器；经过特征提取器得出特征图-1，尺度为：W*H*C；经过图像分割器得出二值图，尺度为：W*H*2，W、H为原图像宽、高，C为特征图通道数；融合特征图-1和二值图得到特征图-2，为了避免过拟合同时避免丢失车道线信息，特征图-2再经过卷积、下采样操作得到特征图-3，把特征图-3展平，得到长度为wh*c的embedding，w、h、c分别为特征图-3的宽、高、通道数；embedding作为Transformer结构中第一个encoder的输入；Transformer结构由六个串联的encoder和六个串联的decoder构成，经过Transformer最终得出车道线坐标。4.根据权利要求3所述的基于深度学习的车道线检测方法，其特征在于，融合特征图-1和二值图得到特征图-2时，二值图作为Mask弥补缺失车道特征，利用权值矩阵增强车道线特征，采用的公式如下：Wreg＝softmaxF2＝F1·Wreg上式中，Rmask为二值图，F1为特征图-1，Wreg为权重矩阵。5.根据权利要求3所述的基于深度学习的车道线检测方法，其特征在于，所述图像分割器的损失函数为：Lp＝BCE上式中，Op，Gp分别为网络的预测坐标和真实坐标；Transformer的encoder点乘为：O＝AV上式中，Q、K、V分别表示对每个输入行进行线性转换的查询、键和值序列，A为注意力图，衡量区域间的相关性，为Transformer拥有长距离捕捉能力的关键，O为自注意力的输出；输出预测坐标的损失函数：上式中，xi为预测坐标，xGT为实际坐标；总损失函数：Ltotal＝Lp+Lpx。6.根据权利要求1所述的基于深度学习的车道线检测方法，其特征在于，所述步骤S4中，用步骤S2得到的训练集对步骤S3构建的双分支的车道检测模型进行训练，epoch为12000，学习率为：0.00025，batch为16，动态减小学习率，利用自适应矩估计Adam优化器进行参数优化，结合Adam优化损失下降。7.一种基于深度学习的车道线检测系统，所述基于深度学习的车道线检测系统用于实现权利要求1-6中任一的基于深度学习的车道线检测方法，其特征在于，包括交通监控摄像枪、图像截取模块、预处理模块、车道线检测模块；其中，所述交通监控摄像枪，用于拍摄带有车道线的视频；所述图像截取模块，用于从视频中截取多张带有车道线的图像，形成数据集；所述预处理模块，用于对形成的数据集进行预处理，并将预处理后的数据集划分为训练集和测试集；所述车道线检测模块，用于构建、训练双分支的车道线检测模型，并通过训练好的双分支的车道线检测模型对车道线进行检测。8.一种计算机，包括存储器、处理器及存储在存储器上并可在处理器上运行的计算机程序，其特征在于，所述处理器执行所述程序时实现权利要求1-6任意一项所述方法的步骤。9.一种存储介质，其存储有计算机程序，其特征在于，该程序被处理器执行时实现权利要求1-6任意一项所述方法的步骤。
说明书desc
技术领域本发明涉及机器视觉检测的技术领域，尤其涉及到基于深度学习的车道线检测方法、系统、计算机及存储介质。背景技术城市道路智慧交通系统需要对交通路口的交通环境、态势进行感知与理解，交通路口的交通环境包括路口内的等待车辆、车道线以及交通信号灯等。城市交通路口的车道线检测对于智慧交通系统中合理控制不同向车道的交通信号灯时长、缓解交通拥堵有着极其重要的作用，当交通高峰期时，利用车道线检测，区分不同驶向的车道，合理分配每条车道、不同行驶方向的交通灯等待时长和通行时长对于缓解城市交通拥堵，能极大地提高交通行驶效率，避免交通事故发生。车道线检测研究常用于自动驾驶辅助技术，几乎没有基于交通摄像枪的检测任务和数据集，本发明方法是把车道线检测技术应用于路口交通监控摄像枪，利用摄像枪获取图像数据并检测车道线。车道线的检测任务中，传统方法主要是利用图像分割和后处理方法，预测得出的车道线由离散点组成，导致车道线不连续，具体实现为采用性能较好的图像分割网络得出车道Mask，利用Mask提取车道特征，最后使用后处理方法，得出能表示车道线走势的坐标点，但这些网络模型的推理过程需占用较大的显存，并且需要算力较高的设备支持，无法实现实时检测且无法嵌入到交通摄像枪中；目前研究中有人提出直接使用深度学习的Transformer得到对应车道线的方法，该类方法能得出平滑的车道线，且拥有较快的推理速度，但其具有大量使用魔法数字、泛化性不好的特点，并且缺乏车道线的预测推理能力，针对车道线不明显的状况，这类方法无法对车道线进行准确的检测和预测推理。发明内容本发明的目的在于克服现有技术的不足，提供一种能克服图像拍摄角度、即使在车道线特征弱或是被遮挡场景下也能进行检测、检测速度快、检测准确率高的基于深度学习的车道线检测方法。为实现上述目的，本发明所提供的技术方案为：基于深度学习的车道线检测方法，包括以下步骤：S1、通过交通监控摄像枪拍摄带有车道线的视频，并从视频中截取多张带有车道线的图像，形成数据集；S2、对步骤S1形成的数据集进行预处理，并将预处理后的数据集划分为训练集和测试集；S3、构建双分支的车道线检测模型，两个分支分别设特征提取器和图像分割器；S4、通过训练集训练双分支的车道线检测模型；S5、通过训练好的双分支的车道线检测模型对测试集进行检测。进一步地，所述步骤S2中，对步骤S1形成的数据集进行预处理，具体包括：S2-1、使用图像标注工具labelme中的linestrip标注图像中的车道线并生成json文件；S2-2、利用Tusimple处理方法对json文件进行处理，生成二值图，作为标签信息；S2-3、采用仿射变换、旋转和色彩变换对生成的二值图进行数据增强，拓展数据集；S2-4、利用Python并引入第三方库OpenCV读取拓展后的数据集，对数据集进行数据清洗。进一步地，所述步骤S3中，构建的双分支的车道线检测模型中，语义分割网络ENet作为backbone，由五个stage组成，stage1-3属于encoder部分，stage4-5属于decoder部分；模型构建时，特征提取器和图像分割器共享stage1和stage2，stage3作为特征提取器，decoder作为图像分割器；经过特征提取器得出特征图-1，尺度为：W*H*C；经过图像分割器得出二值图，尺度为：W*H*2，W、H为原图像宽、高，C为特征图通道数；融合特征图-1和二值图得到特征图-2，为了避免过拟合同时避免丢失车道线信息，特征图-2再经过卷积、下采样操作得到特征图-3，把特征图-3展平，得到长度为wh*c的embedding，w、h、c分别为特征图-3的宽、高、通道数；embedding作为Transformer结构中第一个encoder的输入；Transformer结构由六个串联的encoder和六个串联的decoder构成，经过Transformer最终得出车道线坐标。进一步地，融合特征图-1和二值图得到特征图-2时，二值图作为Mask弥补缺失车道特征，利用权值矩阵增强车道线特征，采用的公式如下：Wreg＝softmaxF2＝F1·Wreg上式中，Rmask为二值图，F1为特征图-1，Wreg为权重矩阵。进一步地，所述图像分割器的损失函数为：Lp＝BCE上式中，Op，Gp分别为网络的预测坐标和真实坐标；Transformer的encoder点乘为：O＝AV上式中，Q、K、V分别表示对每个输入行进行线性转换的查询、键和值序列，A为注意力图，衡量区域间的相关性，为Transformer拥有长距离捕捉能力的关键，O为自注意力的输出；输出预测坐标的损失函数：上式中，xi为预测坐标，xGT为实际坐标；总损失函数：Ltotal＝Lp+Lpx。进一步地，所述步骤S4中，用步骤S2得到的训练集对步骤S3构建的双分支的车道检测模型进行训练，epoch为12000，学习率为：0.00025，batch为16，动态减小学习率，利用自适应矩估计Adam优化器进行参数优化，结合Adam优化损失下降。为实现上述目的，本发明另外提供一种基于深度学习的车道线检测系统，该系统用于实现上述车道线检测方法，具体包括交通监控摄像枪、图像截取模块、预处理模块、车道线检测模块；其中，所述交通监控摄像枪，用于拍摄带有车道线的视频；所述图像截取模块，用于从视频中截取多张带有车道线的图像，形成数据集；所述预处理模块，用于对形成的数据集进行预处理，并将预处理后的数据集划分为训练集和测试集；所述车道线检测模块，用于构建、训练双分支的车道线检测模型，并通过训练好的双分支的车道线检测模型对车道线进行检测。为实现上述目的，本发明另外提供一种计算机，包括存储器、处理器及存储在存储器上并可在处理器上运行的计算机程序，所述处理器执行所述程序时实现上述车道线检测方法的步骤。为实现上述目的，本发明另外提供一种存储介质，其存储有计算机程序，该程序被处理器执行时实现上述车道线检测方法的步骤。与现有技术相比，本方案原理及优点如下：1)许多现有的深度学习模型仅仅是通过图像分割或者多项式回归得到车道线，其训练的损失函数依赖于相机内参和相机高度等外参，模型泛化性差且体积较大，模型推理能力弱。相比于此，本方案引入图像分割网络，图像分割网络在车道线被部分遮挡或不连续时，检测模型仍然能得到车道线的区域和走势，二值图作为Mask提取特征图中表征车道线的特征图，利用权值矩阵增强车道线特征，并利用车道线特征相似的特性，使用现有的车道特征补足车道特征不明显区域。二值图Mask的引入大大增强了模型对车道线区域的捕获能力。2)现有的基于图像分割的车道线检测模型在得出车道线Mask之后会通过不同后处理方法得出能表示车道线的离散点，但是这类方法仍然不能准确表示车道线位置，预测点中包含了大量离散点。相比于此，本方案引入Transformer的注意力机制并且在embedding输入Transformer之前做了车道线相似区域的特征增强，因此对于车道线有较强的捕捉能力，能很好的把车道线作为前景信息从图像中判别出，减少了无效离散点和算力消耗。3)现有的准确率较高的基于图像分割的车道线检测模型体积大、实时性不高、资源占用高，而参数量少、资源占用少的Transformer车道检测模型泛化性不好且需要精炼模型参数。相比于此，本方案融合图像分割与Transformer，使用二值图做监督信息和特征增强，充分利用Transformer优秀的特征提取能力，解决了车道线被遮挡问题和把自动驾驶领域的车道线检测方法应用交通监控摄像领域时因二者视角差别较大带来的车道线无法准确拟合的问题，拥有较好的准确率和鲁棒性，且参数量比纯图像分割模型少。附图说明为了更清楚地说明本发明实施例或现有技术中的技术方案，下面将对实施例或现有技术描述中所需要使用的服务作简单地介绍，显而易见地，下面描述中的附图仅仅是本发明的一些实施例，对于本领域普通技术人员来讲，在不付出创造性劳动的前提下，还可以根据这些附图获得其他的附图。图1为本发明基于深度学习的车道线检测方法的原理流程图；图2为本发明基于深度学习的车道线检测方法中数据预处理的原理流程图；图3为Tusimple方法处理后的二值图；图4为双分支的车道线检测模型的结构示意图；图5为车道线检测的效果图。具体实施方式下面结合具体实施例对本发明作进一步说明：实施例一：本实施例所述的基于深度学习的车道线检测方法，包括以下步骤：S1、通过交通监控摄像枪拍摄带有车道线的视频，并从视频中截取多张带有车道线的图像，形成数据集；S2、对步骤S1形成的数据集进行预处理，并将预处理后的数据集划分为训练集和测试集；本步骤中，如图2所示，对步骤S1形成的数据集进行预处理，具体包括：S2-1、使用图像标注工具labelme中的linestrip标注图像中的车道线并生成json文件；S2-2、利用Tusimple处理方法对json文件进行处理，生成二值图，作为标签信息；S2-3、采用仿射变换、旋转和色彩变换对生成的二值图进行数据增强，拓展数据集；S2-4、利用Python并引入第三方库OpenCV读取拓展后的数据集，对数据集进行数据清洗。S3、构建如图4所示的双分支的车道线检测模型，两个分支分别设特征提取器和图像分割器；具体地，本步骤构建的双分支的车道线检测模型中，语义分割网络ENet作为backbone，由五个stage组成，stage1-3属于encoder部分，stage4-5属于decoder部分；模型构建时，特征提取器和图像分割器共享stage1和stage2，stage3作为特征提取器，decoder作为图像分割器；经过特征提取器得出特征图-1，尺度为：W*H*C；经过图像分割器得出二值图，尺度为：W*H*2，W、H为原图像宽、高，C为特征图通道数；融合特征图-1和二值图得到特征图-2，为了避免过拟合同时避免丢失车道线信息，特征图-2再经过卷积、下采样操作得到特征图-3，把特征图-3展平，得到长度为wh*c的embedding，w、h、c分别为特征图-3的宽、高、通道数；embedding作为Transformer结构中第一个encoder的输入；Transformer结构由六个串联的encoder和六个串联的decoder构成，经过Transformer最终得出车道线坐标。上述融合特征图-1和二值图得到特征图-2时，二值图作为Mask弥补缺失车道特征，利用权值矩阵增强车道线特征，采用的公式如下：Wreg＝softmaxF2＝F1·Wreg上式中，Rmask为二值图，F1为特征图-1，Wreg为权重矩阵。图像分割器的损失函数为：Lp＝BCE上式中，Op，Gp分别为网络的预测坐标和真实坐标；Transformer的encoder点乘为：O＝AV上式中，Q、K、V分别表示对每个输入行进行线性转换的查询、键和值序列，A为注意力图，衡量区域间的相关性，为Transformer拥有长距离捕捉能力的关键，O为自注意力的输出；输出预测坐标的损失函数：上式中，xi为预测坐标，xGT为实际坐标；总损失函数：Ltotal＝Lp+Lpx。S4、通过训练集训练双分支的车道线检测模型；本步骤中，用步骤S2得到的训练集对步骤S3构建的双分支的车道检测模型进行训练，epoch为12000，学习率为：0.00025，batch为16，动态减小学习率，利用自适应矩估计Adam优化器进行参数优化，结合Adam优化损失下降。S5、通过训练好的双分支的车道线检测模型对测试集进行检测，检测效果如图5所示。本实施例引入图像分割网络，图像分割网络在车道线被部分遮挡或不连续时，检测模型仍然能得到车道线的区域和走势，二值图作为Mask提取特征图中表征车道线的特征图，利用权值矩阵增强车道线特征，并利用车道线特征相似的特性，使用现有的车道特征补足车道特征不明显区域。二值图Mask的引入大大增强了模型对车道线区域的捕获能力。还有的是，引入Transformer的注意力机制并且在embedding输入Transformer之前做了车道线相似区域的特征增强，因此对于车道线有较强的捕捉能力，能很好的把车道线作为前景信息从图像中判别出，减少了无效离散点和算力消耗。最后，融合图像分割与Transformer，使用二值图做监督信息和特征增强，充分利用Transformer优秀的特征提取能力，解决了车道线被遮挡问题和把自动驾驶领域的车道线检测方法应用交通监控摄像领域时因二者视角差别较大带来的车道线无法准确拟合的问题，拥有较好的准确率和鲁棒性，且参数量比纯图像分割模型少。实施例二：本实施例所述的基于深度学习的车道线检测系统用于实现上述基于深度学习的车道线检测方法，具体包括交通监控摄像枪1、图像截取模块2、预处理模块3、车道线检测模块4；其中，所述交通监控摄像枪1，用于拍摄带有车道线的视频；所述图像截取模块2，用于从视频中截取多张带有车道线的图像，形成数据集；所述预处理模块3，用于对形成的数据集进行预处理，并将预处理后的数据集划分为训练集和测试集；所述车道线检测模块4，用于构建、训练双分支的车道线检测模型，并通过训练好的双分支的车道线检测模型对车道线进行检测。实施例三：本实施例所述的一种计算机，包括存储器、处理器及存储在存储器上并可在处理器上运行的计算机程序，所述处理器执行所述程序时实现上述基于深度学习的车道线检测方法的步骤。步骤具体包括：S1、通过交通监控摄像枪拍摄带有车道线的视频，并从视频中截取多张带有车道线的图像，形成数据集；S2、对步骤S1形成的数据集进行预处理，并将预处理后的数据集划分为训练集和测试集；S3、构建双分支的车道线检测模型，两个分支分别设特征提取器和图像分割器；S4、通过训练集训练双分支的车道线检测模型；S5、通过训练好的双分支的车道线检测模型对测试集进行检测。实施例四：本实施例所述的一种存储介质，其存储有计算机程序，该程序被处理器执行时实现上述基于深度学习的车道线检测方法的步骤。步骤具体包括：S1、通过交通监控摄像枪拍摄带有车道线的视频，并从视频中截取多张带有车道线的图像，形成数据集；S2、对步骤S1形成的数据集进行预处理，并将预处理后的数据集划分为训练集和测试集；S3、构建双分支的车道线检测模型，两个分支分别设特征提取器和图像分割器；S4、通过训练集训练双分支的车道线检测模型；S5、通过训练好的双分支的车道线检测模型对测试集进行检测。以上所述之实施例子只为本发明之较佳实施例，并非以此限制本发明的实施范围，故凡依本发明之形状、原理所作的变化，均应涵盖在本发明的保护范围内。
