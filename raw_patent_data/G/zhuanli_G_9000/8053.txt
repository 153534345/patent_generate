标题title
图像处理模型训练及图像处理方法、装置、设备和存储介质
摘要abst
本公开提供了一种图像处理模型训练及图像处理方法、装置、设备和存储介质，涉及人工智能技术领域，具体为深度学习、图像处理、计算机视觉技术领域。图像处理模型训练方法包括：将教师模型输出的第一图像特征转换为第一概率分布；将学生模型输出的第二图像特征转换为第二概率分布；基于所述学生模型的先验概率分布，以及所述第一概率分布和所述第二概率分布，构建损失函数；基于所述损失函数，调整所述学生模型的模型参数。本公开可以提高所训练的学生模型的精度。
权利要求书clms
1.一种图像处理模型训练方法，包括：将教师模型输出的第一图像特征转换为第一概率分布；将学生模型输出的第二图像特征转换为第二概率分布；基于所述学生模型的先验概率分布，以及所述第一概率分布和所述第二概率分布，构建损失函数；基于所述损失函数，调整所述学生模型的模型参数。2.根据权利要求1所述的方法，其中，所述损失函数为互信息损失函数，所述基于所述第一概率分布和所述第二概率分布，构建损失函数，包括：基于所述第一概率分布和所述第二概率分布，构建联合概率分布；确定所述学生模型的先验概率分布；将所述第二概率分布作为所述学生模型的后验概率分布；基于所述联合概率分布、所述先验概率分布和所述后验概率分布，构建所述互信息损失函数。3.根据权利要求2所述的方法，其中，所述确定所述学生模型的先验概率分布，包括：确定所述学生模型的初始概率分布；基于可学习的分布参数，以及所述初始概率分布，确定所述学生模型的先验概率分布。4.根据权利要求3所述的方法，还包括：基于所述损失函数，调整所述可学习的分布参数。5.根据权利要求3所述的方法，其中，所述确定所述学生模型的初始概率分布，包括：采用高斯分布对所述学生模型进行随机初始化，以获得所述学生模型的初始概率分布。6.根据权利要求1-5任一项所述的方法，还包括：采用所述教师模型，对输入的第一图像进行特征提取处理，以输出所述第一图像特征；和/或，采用所述学生模型，对输入的第二图像进行特征提取处理，以输出所述第二图像特征；其中，所述第一图像和所述第二图像来自于同一张图像。7.根据权利要求6所述的方法，还包括：对原始图像进行第一数据增强处理，以获得所述第一图像；对所述原始图像进行第二数据增强处理，以获得所述第二图像；其中，所述第一数据增强处理与所述第二数据增强处理不同。8.一种图像处理方法，包括：获取待处理图像；采用图像特征提取模型，提取所述待处理图像的图像特征；基于所述图像特征，获取所述待处理图像的图像处理结果；其中，所述图像特征提取模型是采用如权利要求1-7任一项所述的方法所训练的学生模型。9.一种图像处理模型训练装置，包括：第一转换模块，用于将教师模型输出的第一图像特征转换为第一概率分布；第二转换模块，用于将学生模型输出的第二图像特征转换为第二概率分布；构建模块，用于基于所述学生模型的先验概率分布，以及所述第一概率分布和所述第二概率分布，构建损失函数；调整模块，用于基于所述损失函数，调整所述学生模型的模型参数。10.根据权利要求9所述的装置，其中，所述损失函数为互信息损失函数，所述构建模块进一步用于：基于所述第一概率分布和所述第二概率分布，构建联合概率分布；确定所述学生模型的先验概率分布；将所述第二概率分布作为所述学生模型的后验概率分布；基于所述联合概率分布、所述先验概率分布和所述后验概率分布，构建所述互信息损失函数。11.根据权利要求10所述的装置，其中，所述构建模块进一步用于：确定所述学生模型的初始概率分布；基于可学习的分布参数，以及所述初始概率分布，确定所述学生模型的先验概率分布。12.根据权利要求11所述的装置，还包括：学习模块，用于基于所述损失函数，调整所述可学习的分布参数。13.根据权利要求11所述的装置，其中，所述构建模块进一步用于：采用高斯分布对所述学生模型进行随机初始化，以获得所述学生模型的初始概率分布。14.根据权利要求9-13任一项所述的装置，还包括：第一特征提取模块，用于采用所述教师模型，对输入的第一图像进行特征提取处理，以输出所述第一图像特征；和/或，第二特征提取模块，用于采用所述学生模型，对输入的第二图像进行特征提取处理，以输出所述第二图像特征；其中，所述第一图像和所述第二图像来自于同一张图像。15.根据权利要求14所述的装置，还包括：第一数据增强模块，用于对原始图像进行第一数据增强处理，以获得所述第一图像；第二数据增强模块，用于对所述原始图像进行第二数据增强处理，以获得所述第二图像；其中，所述第一数据增强处理与所述第二数据增强处理不同。16.一种图像处理装置，包括：获取模块，用于获取待处理图像；提取模块，用于采用图像特征提取模型，提取所述待处理图像的图像特征；确定模块，用于基于所述图像特征，获取所述待处理图像的图像处理结果；其中，所述图像特征提取模型是采用如权利要求1-7任一项所述的方法所训练的学生模型。17.一种电子设备，包括：至少一个处理器；以及与所述至少一个处理器通信连接的存储器；其中，所述存储器存储有可被所述至少一个处理器执行的指令，所述指令被所述至少一个处理器执行，以使所述至少一个处理器能够执行权利要求1-8中任一项所述的方法。18.一种存储有计算机指令的非瞬时计算机可读存储介质，其中，所述计算机指令用于使所述计算机执行根据权利要求1-8中任一项所述的方法。19.一种计算机程序产品，包括计算机程序，所述计算机程序在被处理器执行时实现根据权利要求1-8中任一项所述的方法。
说明书desc
技术领域本公开涉及人工智能技术领域，具体为深度学习、图像处理、计算机视觉技术领域，尤其涉及一种图像处理模型训练及图像处理方法、装置、设备和存储介质。背景技术知识蒸馏是模型压缩的一种常用方法，不同于模型压缩中的剪枝和量化，知识蒸馏是通过构建一个轻量化的小模型，利用性能更好的大模型的监督信息，来训练这个小模型，以期达到更好的性能和精度。这个大模型称之为教师模型，小模型称之为学生模型。来自teacher模型输出的监督信息称之为知识，而student模型学习来自teacher模型的监督信息的过程称之为蒸馏。发明内容本公开提供了一种图像处理模型训练及图像处理方法、装置、设备和存储介质。根据本公开的一方面，提供了一种图像处理模型训练方法，包括：将教师模型输出的第一图像特征转换为第一概率分布；将学生模型输出的第二图像特征转换为第二概率分布；基于所述学生模型的先验概率分布，以及所述第一概率分布和所述第二概率分布，构建损失函数；基于所述损失函数，调整所述学生模型的模型参数。根据本公开的另一方面，提供了一种图像处理方法，包括：获取模块，用于获取待处理图像；提取模块，用于采用图像特征提取模型，提取所述待处理图像的图像特征；确定模块，用于基于所述图像特征，获取所述待处理图像的图像处理结果；其中，所述图像特征提取模型是采用上述任一方面的任一项所述的方法所训练的学生模型。根据本公开的另一方面，提供了一种图像处理模型训练装置，包括：第一转换模块，用于将教师模型输出的第一图像特征转换为第一概率分布；第二转换模块，用于将学生模型输出的第二图像特征转换为第二概率分布；构建模块，用于基于所述学生模型的先验概率分布，以及所述第一概率分布和所述第二概率分布，构建损失函数；调整模块，用于基于所述损失函数，调整所述学生模型的模型参数。根据本公开的另一方面，提供了一种图像处理装置，包括：获取待处理图像；采用图像特征提取模型，提取所述待处理图像的图像特征；基于所述图像特征，获取所述待处理图像的图像处理结果；其中，所述图像特征提取模型是采用上述任一方面的任一项所述的方法所训练的学生模型。根据本公开的另一方面，提供了一种电子设备，包括：至少一个处理器；以及与所述至少一个处理器通信连接的存储器；其中，所述存储器存储有可被所述至少一个处理器执行的指令，所述指令被所述至少一个处理器执行，以使所述至少一个处理器能够执行如上述任一方面的任一项所述的方法。根据本公开的另一方面，提供了一种存储有计算机指令的非瞬时计算机可读存储介质，其中，所述计算机指令用于使所述计算机执行根据上述任一方面的任一项所述的方法。根据本公开的另一方面，提供了一种计算机程序产品，包括计算机程序，所述计算机程序在被处理器执行时实现根据上述任一方面的任一项所述的方法。根据本公开的技术方案，可以提高所训练的学生模型的精度。应当理解，本部分所描述的内容并非旨在标识本公开的实施例的关键或重要特征，也不用于限制本公开的范围。本公开的其它特征将通过以下的说明书而变得容易理解。附图说明附图用于更好地理解本方案，不构成对本公开的限定。其中：图1是本公开实施例提供的一种图像处理模型训练方法的流程图；图2是用来实现本公开实施例的图像处理模型训练方法或图像处理方法的应用场景的示意图；图3是本公开实施例提供的一种图像处理模型训练架构图；图4是本公开实施例提供的另一种图像处理模型训练方法的流程图；图5是本公开实施例提供的一种图像处理方法的流程图；图6是本公开实施例提供的一种图像处理模型训练装置的结构图；图7是本公开实施例提供的一种图像处理装置的结构图；图8是用来实现本公开实施例的图像处理模型训练方法或图像处理方法的电子设备的示意图。具体实施方式以下结合附图对本公开的示范性实施例做出说明，其中包括本公开实施例的各种细节以助于理解，应当将它们认为仅仅是示范性的。因此，本领域普通技术人员应当认识到，可以对这里描述的实施例做出各种改变和修改，而不会背离本公开的范围和精神。同样，为了清楚和简明，以下的描述中省略了对公知功能和结构的描述。相关技术中，知识蒸馏是直接监督学生模型输出的图像特征，例如，采用教师模型输出的图像特征以及学生模型输出的图像特征构建L2损失函数，基于L2损失函数调整学习模型的模型参数，使得学生模型输出的图像特征尽量接近教师模型输出的图像特征。但是，当教师模型与学生模型的结构差异较大时，直接监督学生模型输出的图像特征的方式，会导致所训练的学生模型的精度较差。为了提高模型精度，本公开提供如下实施例。图1是本公开实施例提供的一种图像处理模型训练方法的流程图，如图1所示，该方法包括：101、将教师模型输出的第一图像特征转换为第一概率分布。102、将学生模型输出的第二图像特征转换为第二概率分布。103、基于所述学生模型的先验概率分布，以及所述第一概率分布和所述第二概率分布，构建损失函数。104、基于所述损失函数，调整所述学生模型的模型参数。其中，教师模型和学生模型均是深度神经网络模型，相比较来讲，教师模型的结构比学生模型的结构复杂、性能较高，通过知识蒸馏过程，作为小模型的学生模型可以学习到作为大模型的教师模型的知识，从而提高学生模型的性能。针对图像处理领域，教师模型和学生模型可以称为图像处理模型。进一步地，可以均是用于提取图像特征的模型，还可以称为图像特征提取模型。具体地，模型结构可以为卷积神经网络模型，即，教师模型可以是规模较大的CNN模型，学生模型是规模较小的CNN模型。更为具体地，教师模型例如为ResNet模型，学生模型例如为MobileNet模型。在图像处理领域，教师模型和学生模型的输入均是图像，输出是图像特征，为了区分，教师模型输出的图像特征可以称为第一图像特征，学生模型输出的图像特征可以称为第二图像特征。与相关技术中，直接基于第一图像特征和第二图像特征构建损失函数不同的是，本实施例中，可以分别将第一图像特征转换为第一概率分布和第二概率分布，进而基于第一概率分布和第二概率分布构建损失函数。其中，可以采用归一化函数将图像特征转换为概率分布。归一化函数例如为softmax函数。其中，上述的101与102无时序限制关系。构建损失函数时，还可以确定学生模型的先验概率分布，基于先验概率分布、第一概率分布和的第二概率分布构建损失函数。先验概率分布是不依靠观测数据的概率分布，能够表达学生模型的随机性，通过考虑学生模型的先验概率分布能够提高灵活性，进而提高所训练的学生模型的精准度。获得损失函数后，可以采用通常的模型参数更新算法，例如反向传播算法，调整学生模型的模型参数。本实施例中，将图像特征转换为概率分布，基于概率分布构建损失函数，而不是直接基于图像特征构建损失函数，由于采用了概率分布，可以使得学生模型学习到更多的知识，提高学生模型的精度。另外，构建损失函数时还考虑了学生模型的先验概率分布，可以提高灵活性，进一步提高学生模型的精度。为了更好地理解本公开实施例，下面对本公开实施例适用的应用场景进行说明。本实施例以图像处理领域为例。图像处理例如包括：人脸识别、目标检测、目标分类等。以人脸识别为例，最终的学生模型可以用于人脸识别。比如，如图2所示，用户可以在移动设备上安装可以进行人脸识别的应用，APP可以通过移动设备上的人脸采集装置采集人脸图像，之后，若移动设备本身具有人脸识别能力，比如，APP在移动设备本地配置了用于人脸识别的学生模型，则可以利用该学生模型，在移动设备本地对采集的人脸图像进行人脸识别。本公开的技术方案中，所涉及的用户个人信息的收集、存储、使用、加工、传输、提供和公开等处理，均符合相关法律法规的规定，且不违背公序良俗。可以理解的是，上述以在移动设备侧的人脸识别为例，还可以是学生模型部署在服务端，此时，APP可以将采集的人脸图像发送给服务端，由服务端基于配置的用于人脸识别的学生模型，对接收的人脸图像进行人脸识别。图2的左侧示出了学生模型的应用过程，比如，采用学生模型进行人脸识别。为了应用学生模型，需要先获取学生模型，学生模型可以基于知识蒸馏训练得到。其中，如图2的右侧所示，训练过程可以由服务器202执行，即，在服务器内完成学生模型的训练，服务器可以将所训练的学生模型发送给移动设备，从而在移动设备本地采用学生模型进行人脸识别。知识蒸馏架构中，可以包括教师模型和学生模型，教师模型是已经训练好的规模较大的模型，学生模型是规模较小的待训练模型。以人脸识别为例，教师模型可以对图像样本进行特征提取处理，输出第一图像特征，学生模型也可以对图像样本进行特征提取处理，输出第二图像特征。图像特征可以具体为特征图。图像样本可以来自于已有的样本集，样本集例如为ImageNet。另外，教师模型对应的图像样本可以称为第一图像，学生模型对应的图像样本可以称为第二图像，第一图像和第二图像可以来自于同一张图像，例如，对同一张图像进行不同的数据增强处理方法获得。本实施例中，第一图像和第二图像来自于同一张图像，结合后续的互信息损失函数，可以利用同源数据的互信息最大的特性，通过最小化后续的互信息损失函数，提升学生模型的性能。由于样本集的样本数量有限，为了获得更多的样本量，本实施例中，可以针对同一张图像样本进行不同的数据增强处理，以获得第一图像和第二图像，第一图像作为教师模型的输入，第二图像作为学生模型的输入。如图3所示，同一个图像样本可以称为原始图像，可以对原始图像进行第一数据增强处理，以获得第一图像，对所述原始图像进行第二数据增强处理，以获得第二图像，第一数据增强处理与第二数据增强处理不同。数据增强处理例如包括：裁剪、旋转、遮挡、尺寸变换、修改亮度等。第一数据增强处理和第二数据增强处理可以是同类的处理方式，例如，均是旋转，或者，均是修改亮度。另外，第二数据增强处理的处理强度大于第一数据增强处理的处理强度。以旋转为例，第二数据增强处理的旋转角度大于第一数据增强处理的旋转角度。由于第一数据增强处理对应的是教师模型，第二数据增强处理对应的是学生模型，教师模型的性能较学生模型的性能强，因此，即使采用强度较低的处理方式，教师模型也可以传输较多的知识，而学生模型对应强度较高的处理方式，可以学习到更多的知识，提升学生模型的精度。第一图像输入到教师模型后，可以输出第一图像特征，第二图像输入到学生模型后，可以输出第二图像特征。之后，可以采用softmax函数对将图像特征转换为概率分布。如图3所示，教师模型对应的第一概率分布用t_logit表示，学生模型对应的第二概率分布用s_logit表示。其中，可以基于第一概率分布和第二概率分布构建联合概率分布。另外，还可以随机获得符合N的高斯分布，并基于符合N的先验高斯分布，其中的m和d是可学习的参数。之后，可以基于联合概率分布、符合N的先验高斯分布，以及后验概率分布构建基于高斯先验的互信息损失函数。获得损失函数后，可以采用BP算法更新学生模型的模型参数，以及更新可学习的参数m和d，直至达到预设的迭代次数后结束，以获得最终的学生模型。结合图3所示的架构，本公开还提供一种模型训练方法。图4是本公开实施例提供的另一种图像处理模型训练方法的流程图，本实施例提供的方法包括：401、对原始图像进行第一数据增强处理，以获得第一图像。402、采用教师模型，对输入的所述第一图像进行特征提取处理，以输出第一图像特征。403、将所述第一图像特征转换为第一概率分布。404、对所述原始图像进行第二数据增强处理，以获得第二图像。405、采用学生模型，对输入的所述第二图像进行特征提取处理，以输出第二图像特征。406、将所述第二图像特征转换为第二概率分布。其中，原始图像可以是在已有的样本集中获得的图像。第一数据增强处理与第二数据增强处理不同，从而基于相同的原始图像可以获得两个不同的第一图像和第二图像。第一数据增强处理和第二数据增强可以是同类别的数据增强处理方式，例如，均是旋转操作。另外，第二数据增强处理的处理强度可以大于第一数据增强处理的处理强度，例如，第二数据增强处理的旋转角度大于第一数据增强处理的旋转角度。由于第一数据增强处理对应的是教师模型，第二数据增强处理对应的是学生模型，教师模型的性能较学生模型的性能强，因此，即使采用强度较低的处理方式，教师模型也可以传输较多的知识，而学生模型对应强度较高的处理方式，可以学习到更多的知识，提升学生模型的精度。本实施例中，通过对原始图像进行不同的数据增强处理，获得第一图像和第二图像，可以在较少样本量的基础上获得第一图像和第二图像，提高学生模型的精度，并且可以提高学生模型的鲁棒性。教师模型和学生模型可以均是用于提取图像特征的深度神经网络模型，教师模型是已训练的模型，学生模型是待训练的模型。教师模型例如是ResNet模型，学生模型例如是MobileNet模型。教师模型和学生模型的输入是图像，输出是图像特征。可以采用softmax函数，将图像特征转换为概率分布。其中，401-403与404-406无时序限制关系。407、基于所述第一概率分布和所述第二概率分布，构建联合概率分布。本实施例中采用的损失函数是互信息损失函数，用公式表示为：Mutual_loss＝p*)+logp-log)) 其中，Mutual_loss是互信息损失函数，p是教师模型和学生模型的联合概率分布，p是学生模型的先验概率分布，p是教师模型的先验概率分布.根据贝叶斯公式：p＝p*p，带入公式可以得到：Mutual_loss＝p*)-log))其中，是学生模型的后验概率分布，即第二概率分布，结合图3，p＝s_logit。因此，可以构建如公式所示的损失函数。由于该损失函数和教师模型与学生模型的联合概率分布、学生模型的先验概率分布、后验概率分布相关，因此，需要计算上述的联合概率分布。第一概率分布可以用t_logit表示，第二概率分布可以用s_logit表示，其中，t_logit和s_logit的维度均是，其中，N是第一图像或第二图像的数量，C是单张图像的特征的维度，如类别的数量。联合概率分布的计算公式可以是：p＝t_logitT*s_logitT上标的T表示转置操作。因此，p的维度是。进一步地，为了获得更精准的联合概率分布，联合概率分布的计算公式可以是：p1＝*t_logit.unsqueeze).sump2＝)/2；p＝p2/p2.sum；其中，p1是t_logit和s_logit的相似度，unsqueeze是扩维运算，s_logit.unsqueeze的维度是，t_logit.unsqueeze的维度是，sum是针对第一个维度求和，因此，p1的维度是。p2是针对p1进行均值运算，p1.t是p1的转置，因此，p2的维度也是。p是针对p2进行归一化，p的维度也是。因此，基于上述的p1、p2、p的计算公式，也可以计算出联合概率分布p。408、确定所述学生模型的初始概率分布。其中，可以采用高斯分布对所述学生模型进行随机初始化，以获得所述学生模型的初始概率分布。例如，如图3所示，初始概率分布是随机化的符合N分布的高斯分布函数。可以理解的是，也可以假设初始概率分布是其他分布函数，例如拉普拉斯分布。由于高斯分布是比较普遍的分布函数，基本可以覆盖全部的变量分布情况，因此，采用高斯分布确定学生模型的初始概率分布，可以匹配学生模型的真实先验分布情况，提高学生模型的准确度。409、基于可学习的分布参数，以及所述初始概率分布，确定所述学生模型的先验概率分布。其中，学生模型的先验概率分布的计算公式可以是：p＝m+d*a；其中，p是学生模型的先验概率分布；m和d是可学习的分布参数；a是初始化概率分布，例如是符合N分布的高斯分布函数。可以理解的是，可以基于一组或多组可学习的分布参数，确定上述的先验概率分布。例如，p＝∑i其中，是第i组分布参数，N是分布参数的组数。另外，上述以多组分布参数对应的函数相加为例，还可以是加权相加。本实施例中，基于可学习的分布参数和初始概率分布，确定学生模型的先验概率分布，由于分布参数是可学习的，因此在训练过程中，可以调整分布参数，使得学生模型更好地逼近最优解，提高学生模型的精度。另外，可学习的分布参数用于确定先验概率分布，由于作用于先验过程，可以提高模型训练的灵活性，进一步提高学生模型的精度。例如，针对基于人脸图像识别年龄的场景，识别结果是可以识别出用户是儿童、成人、老人，一般来讲，成人的识别效果较好，而儿童和老人的识别效果较差，本实施例中通过调整可学习的分布参数，可以针对儿童和老人增强先验分布信息，从而提高针对儿童和老人的识别效果。其中，401-407与408-409无时序限制关系。410、基于所述联合概率分布、所述先验概率分布，以及所述学生模型的后验概率分布，构建基于高斯分布的互信息损失函数。其中，学生模型的后验概率分布即为第二概率分布，即图3中的s_logit，以及上述公式中的p。基于上述的公式，损失函数可以采用上述的联合概率分布、先验概率分布和后验概率分布计算。411、基于所述损失函数，调整模型学生模型的模型参数，以及所述可学习的分布参数。其中，训练过程可以分为多次迭代过程，每个迭代过程中，可以采用常用的参数调整算法，例如BP算法，调整模型参数以及分布参数，直至达到预设的迭代次数。将达到预设的迭代次数时的模型参数作为最终生成的学生模型的模型参数。本实施例中，利用了贝叶斯公式，基于第一概率分布和第二概率分布构建联合概率分布，基于联合概率分布、先验概率分布和后验概率分布构建互信息损失函数，因此，本实施例的互信息损失函数不同于一般的互信息损失函数，而是基于先验概率分布确定的互信息损失函数，由于先验概率分布可以反映学生模型的先验信息，通过参考先验信息，可以提高训练过程的灵活性，使得学生模型具有更好的精准度。本实施例中，基于损失函数调整可学习的分布参数，使得分布参数在学生模型的训练过程中是可调整的，可以进一步提高灵活性，提高学生模型的精度。上述描述了模型训练过程，经过训练，可以获得所训练的学生模型。在模型应用阶段，可以采用学生模型进行图像处理。图5是本公开实施例提供的一种图像处理方法的流程图，如图5所示，图像处理方法包括：501、获取待处理图像。501、采用图像特征提取模型，提取所述待处理图像的图像特征。503、基于所述图像特征，获得图像处理结果。其中，图像特征提取模型可以是采用上述任一方法训练的学生模型。在模型应用阶段，可以采用图像提取模型提取出图像特征，再基于图像特征获得图像处理结果。以人脸识别为例，待处理图像可以为人脸图像。相应地，图像特征可以是人脸图像的图像特征。基于应用场景的不同，图像特征可以输入到相关的下游任务的模型中进行处理，以输出图像处理结果。依然以人脸识别为例，人脸识别可以认为是分类任务，因此，图像特征可以输入到分类模型中，分类模型的输出是人脸识别结果，例如在多个候选人中确定出是谁的人脸图像，或者识别人脸图像对应的用户的年龄段。分类模型的具体结构可以采用各种相关技术实现，例如为全连接网络。本实施例中，图像特征提取模型是采用上述训练方法获得的学生模型，由于上述训练的学生模型的精度较高，因此采用该学生模型可以获得精度更高的图像特征，进而可以提高图像处理结果的准确度。图6是本公开实施例提供的一种图像处理模型训练装置的结构图，如图6所示，该装置600包括：第一转换模块601、第二转换模块602、构建模块603和确定模块604。第一转换模块601用于将教师模型输出的第一图像特征转换为第一概率分布；第二转换模块602用于将学生模型输出的第二图像特征转换为第二概率分布；构建模块603用于基于所述学生模型的先验概率分布，以及所述第一概率分布和所述第二概率分布，构建损失函数；调整模块604用于基于所述损失函数，调整所述学生模型的模型参数。本实施例中，将图像特征转换为概率分布，基于概率分布构建损失函数，而不是直接基于图像特征构建损失函数，由于采用了概率分布，可以使得学生模型学习到更多的知识，提高学生模型的精度。另外，构建损失函数时还考虑了学生模型的先验概率分布，可以提高灵活性，进一步提高学生模型的精度。一些实施例中，所述损失函数为互信息损失函数，所述构建模块603进一步用于：基于所述第一概率分布和所述第二概率分布，构建联合概率分布；确定所述学生模型的先验概率分布；将所述第二概率分布作为所述学生模型的后验概率分布；基于所述联合概率分布、所述先验概率分布和所述后验概率分布，构建所述互信息损失函数。本实施例中，利用了贝叶斯公式，基于第一概率分布和第二概率分布构建联合概率分布，基于联合概率分布、先验概率分布和后验概率分布构建互信息损失函数，因此，本实施例的互信息损失函数不同于一般的互信息损失函数，而是基于先验概率分布确定的互信息损失函数，由于先验概率分布可以反映学生模型的先验信息，通过参考先验信息，可以提高训练过程的灵活性，使得学生模型具有更好的精准度。一些实施例中，所述损失函数为互信息损失函数，所述构建模块603进一步用于：所述构建模块603进一步用于：确定所述学生模型的初始概率分布；基于可学习的分布参数，以及所述初始概率分布，确定所述学生模型的先验概率分布。本实施例中，基于可学习的分布参数和初始概率分布，确定学生模型的先验概率分布，由于分布参数是可学习的，因此在训练过程中，可以调整分布参数，使得学生模型更好地逼近最优解，提高学生模型的精度。另外，可学习的分布参数用于确定先验概率分布，由于作用于先验过程，可以提高模型训练的灵活性，进一步提高学生模型的精度。一些实施例中，所述装置600还包括：学习模块，用于基于所述损失函数，调整所述可学习的分布参数。通过基于可学习的分布参数确定先验概率分布，以及基于损失函数调整可学习的分布参数，分布参数在学生模型的训练过程中是可调整的，可以进一步提高灵活性，提高学生模型的精度。一些实施例中，所述构建模块603进一步用于：采用高斯分布对所述学生模型进行随机初始化，以获得所述学生模型的初始概率分布。由于高斯分布是比较普遍的分布函数，基本可以覆盖全部的变量分布情况，因此，采用高斯分布确定学生模型的初始概率分布，可以匹配学生模型的真实先验分布情况，提高学生模型的准确度。一些实施例中，所述装置600还包括：第一特征提取模块，用于采用所述教师模型，对输入的第一图像进行特征提取处理，以输出所述第一图像特征；和/或，第二特征提取模块，用于采用所述学生模型，对输入的第二图像进行特征提取处理，以输出所述第二图像特征；其中，所述第一图像和所述第二图像来自于同一张图像。本实施例中，第一图像和第二图像来自于同一张图像，结合后续的互信息损失函数，可以利用同源数据的互信息最大的特性，通过最小化后续的互信息损失函数，提升学生模型的性能。一些实施例中，所述装置600还包括：第一数据增强模块，用于对原始图像进行第一数据增强处理，以获得所述第一图像；第二数据增强模块，用于对所述原始图像进行第二数据增强处理，以获得所述第二图像；其中，所述第一数据增强处理与所述第二数据增强处理不同。本实施例中，通过对原始图像进行不同的数据增强处理，获得第一图像和第二图像，可以在较少样本量的基础上获得第一图像和第二图像，提高学生模型的精度，并且可以提高学生模型的鲁棒性。图7是本公开实施例提供的一种图像处理装置的结构图，如图7所示，该装置700包括：获取模块701、提取模块702和确定模块703。获取模块701用于获取待处理图像；提取模块702用于采用图像特征提取模型，提取所述待处理图像的图像特征；确定模块703用于基于所述图像特征，获取所述待处理图像的图像处理结果。其中，所述图像特征提取模型是采用上述任一项所述的训练方法所训练的学生模型。本实施例中，图像特征提取模型是采用上述训练方法获得的学生模型，由于上述训练的学生模型的精度较高，因此采用该学生模型可以获得精度更高的图像特征，进而可以提高图像处理结果的准确度。可以理解的是，本公开实施例中的“第一”、“第二”等只是用于区分，不表示重要程度高低、时序先后等。可以理解的是，本公开实施例中，不同实施例中的相同或相似内容可以相互参考。本公开的技术方案中，所涉及的用户个人信息的收集、存储、使用、加工、传输、提供和公开等处理，均符合相关法律法规的规定，且不违背公序良俗。根据本公开的实施例，本公开还提供了一种电子设备、一种可读存储介质和一种计算机程序产品。图8示出了可以用来实施本公开的实施例的示例电子设备800的示意性框图。电子设备旨在表示各种形式的数字计算机，诸如，膝上型计算机、台式计算机、工作台、服务器、刀片式服务器、大型计算机、和其它适合的计算机。电子设备还可以表示各种形式的移动装置，诸如，个人数字助理、蜂窝电话、智能电话、可穿戴设备和其它类似的计算装置。本文所示的部件、它们的连接和关系、以及它们的功能仅仅作为示例，并且不意在限制本文中描述的和/或者要求的本公开的实现。如图8所示，电子设备800包括计算单元801，其可以根据存储在只读存储器802中的计算机程序或者从存储单元808加载到随机访问存储器803中的计算机程序，来执行各种适当的动作和处理。在RAM 803中，还可存储电子设备800操作所需的各种程序和数据。计算单元801、ROM 802以及RAM 803通过总线804彼此相连。输入/输出接口805也连接至总线804。电子设备800中的多个部件连接至I/O接口805，包括：输入单元806，例如键盘、鼠标等；输出单元807，例如各种类型的显示器、扬声器等；存储单元808，例如磁盘、光盘等；以及通信单元809，例如网卡、调制解调器、无线通信收发机等。通信单元809允许电子设备800通过诸如因特网的计算机网络和/或各种电信网络与其他设备交换信息/数据。计算单元801可以是各种具有处理和计算能力的通用和/或专用处理组件。计算单元801的一些示例包括但不限于中央处理单元、图形处理单元、各种专用的人工智能计算芯片、各种运行机器学习模型算法的计算单元、数字信号处理器、以及任何适当的处理器、控制器、微控制器等。计算单元801执行上文所描述的各个方法和处理，例如模型训练方法或图像处理方法。例如，在一些实施例中，模型训练方法或图像处理方法可被实现为计算机软件程序，其被有形地包含于机器可读介质，例如存储单元808。在一些实施例中，计算机程序的部分或者全部可以经由ROM 802和/或通信单元809而被载入和/或安装到电子设备800上。当计算机程序加载到RAM 803并由计算单元801执行时，可以执行上文描述的模型训练方法或图像处理方法的一个或多个步骤。备选地，在其他实施例中，计算单元801可以通过其他任何适当的方式而被配置为执行模型训练方法或图像处理方法。本文中以上描述的系统和技术的各种实施方式可以在数字电子电路系统、集成电路系统、场可编程门阵列、专用集成电路、专用标准产品、芯片上系统、复杂可编程逻辑设备、计算机硬件、固件、软件、和/或它们的组合中实现。这些各种实施方式可以包括：实施在一个或者多个计算机程序中，该一个或者多个计算机程序可在包括至少一个可编程处理器的可编程系统上执行和/或解释，该可编程处理器可以是专用或者通用可编程处理器，可以从存储系统、至少一个输入装置、和至少一个输出装置接收数据和指令，并且将数据和指令传输至该存储系统、该至少一个输入装置、和该至少一个输出装置。用于实施本公开的方法的程序代码可以采用一个或多个编程语言的任何组合来编写。这些程序代码可以提供给通用计算机、专用计算机或其他可编程数据处理装置的处理器或控制器，使得程序代码当由处理器或控制器执行时使流程图和/或框图中所规定的功能/操作被实施。程序代码可以完全在机器上执行、部分地在机器上执行，作为独立软件包部分地在机器上执行且部分地在远程机器上执行或完全在远程机器或服务器上执行。在本公开的上下文中，机器可读介质可以是有形的介质，其可以包含或存储以供指令执行系统、装置或设备使用或与指令执行系统、装置或设备结合地使用的程序。机器可读介质可以是机器可读信号介质或机器可读储存介质。机器可读介质可以包括但不限于电子的、磁性的、光学的、电磁的、红外的、或半导体系统、装置或设备，或者上述内容的任何合适组合。机器可读存储介质的更具体示例会包括基于一个或多个线的电气连接、便携式计算机盘、硬盘、随机存取存储器、只读存储器、可擦除可编程只读存储器、光纤、便捷式紧凑盘只读存储器、光学储存设备、磁储存设备、或上述内容的任何合适组合。为了提供与用户的交互，可以在计算机上实施此处描述的系统和技术，该计算机具有：用于向用户显示信息的显示装置或者LCD监视器)；以及键盘和指向装置，用户可以通过该键盘和该指向装置来将输入提供给计算机。其它种类的装置还可以用于提供与用户的交互；例如，提供给用户的反馈可以是任何形式的传感反馈；并且可以用任何形式来接收来自用户的输入。可以将此处描述的系统和技术实施在包括后台部件的计算系统、或者包括中间件部件的计算系统、或者包括前端部件的计算系统、或者包括这种后台部件、中间件部件、或者前端部件的任何组合的计算系统中。可以通过任何形式或者介质的数字数据通信来将系统的部件相互连接。通信网络的示例包括：局域网、广域网和互联网。计算机系统可以包括客户端和服务器。客户端和服务器一般远离彼此并且通常通过通信网络进行交互。通过在相应的计算机上运行并且彼此具有客户端-服务器关系的计算机程序来产生客户端和服务器的关系。服务器可以是云服务器，又称为云计算服务器或云主机，是云计算服务体系中的一项主机产品，以解决了传统物理主机与VPS服务中，存在的管理难度大，业务扩展性弱的缺陷。服务器也可以为分布式系统的服务器，或者是结合了区块链的服务器。应该理解，可以使用上面所示的各种形式的流程，重新排序、增加或删除步骤。例如，本发公开中记载的各步骤可以并行地执行也可以顺序地执行也可以不同的次序执行，只要能够实现本公开公开的技术方案所期望的结果，本文在此不进行限制。上述具体实施方式，并不构成对本公开保护范围的限制。本领域技术人员应该明白的是，根据设计要求和其他因素，可以进行各种修改、组合、子组合和替代。任何在本公开的精神和原则之内所作的修改、等同替换和改进等，均应包含在本公开保护范围之内。
