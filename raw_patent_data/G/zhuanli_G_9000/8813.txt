标题title
基于图神经网络的软件页面关键信息提取方法及系统
摘要abst
本发明属于软件页面信息提取技术领域，具体涉及基于图神经网络的软件页面关键信息提取方法及系统。方法包括S1，将输入的网页图片，输出图片上所有的文本行坐标信息；S2，根据得到的文本行坐标信息，裁剪出所有的文本行并识别，得到每个文本行字符信息；S3，结合网页图片、文本行坐标信息、文本行字符信息，并通过基于图神经网络模型的文本行分类算法，输出所有文本行的类别；S4，结合文本行的类别进行键值对匹配；若匹配成功，则输出需要的键值对所对应的文本信息。系统包括文本行检测模块、文本行识别模块、文本行分类模块、文本行键值对匹配模块。本发明具有通用性强，能应用到所有的软件文本类型的特点。
权利要求书clms
1.基于图神经网络的软件页面关键信息提取方法，其特征在于，包括如下步骤；S1，将输入的网页图片通过DBNet文本检测算法，输出网页图片上所有的文本行坐标信息；S2，通过CRNN文本识别算法，同时根据得到的文本行坐标信息，裁剪出所有的文本行并进行识别，得到每个文本行字符信息；S3，结合输入的网页图片以及获得的文本行坐标信息、文本行字符信息，并通过基于图神经网络模型的文本行分类算法，输出所有文本行的类别；S4，分别提取任意两个文本行的文本行坐标信息特征和文本行字符信息特征，并进行融合获得融合特征，同时结合文本行的类别进行键值对匹配；若匹配成功，则输出所有需要的键值对所对应的文本信息；步骤S3中所述文本行的类别包括“键”，“值”和“其他”三个类别；步骤S3包括如下步骤：S31，用CNN骨干网络提取网页图片的特征，同时利用ROI Pooling层将所有文本行的特征处理成一个统一的维度；用CNN+ROI Pooling提取每个文本行的视觉特征，用长短期记忆网络LSTM提取文本行的语义特征，并将视觉特征和语义特征融合，得到融合特征，表示拼接操作，公式如下：S32，利用每个文本行的融合特征建立图神经网络模型，将每个文本行作为一个图节点构造一个无向图，所述无向图表示成，其中表示所有文本行的融合特征，表示无向图中两个节点的边的权重；考虑文本行之间的空间关系，构造特征向量其中，，表示第个文本行的中心点坐标，，表示第个文本行的中心点坐标，，表示第个文本行的宽和高，，表示第个文本行的宽和高；和表示两个文本行之间的距离；和表示两个文本行各自的宽高比；和表示两个文本行之间宽高比的差异；S33，构造两个文本行之间的空间关系其中，是一个线性变换，用于将进行升维，表示正则化，表示多层神经网络；S34，利用如下公式对无向图上的节点进行迭代，迭代次数为超参数，可按需调整：其中，表示ReLU激活函数，是一个线性变换，表示第次迭代中的第个图节点；S35，图神经网络模型构建完成。2.根据权利要求1所述的基于图神经网络的软件页面关键信息提取方法，其特征在于，步骤S4包括如下步骤：S41，对于每个文本行的文本行字符信息用长短期记忆网络LSTM提取语义特征，对于每个文本行有四个顶点的文本行坐标信息特征,,,，融合得到融合特征：其中，、分别表示第个文本行和第个文本行的语义特征；表示第个文本行的顶点坐标；表示第个文本行的顶点坐标；、表示第个文本行的宽和高；、表示第个文本行的宽和高；S42，将融合后的融合特征送到分类器中，当两个文本行不属于同一个键值对，则输出类别为0；当两个文本行属于同一个键值对，则输出类别为1。3.基于图神经网络的软件页面关键信息提取系统，应用权利要求1-2中任一项所述的基于图神经网络的软件页面关键信息提取方法，其特征在于，所述基于图神经网络的软件页面关键信息提取系统包括：文本行检测模块，用于将输入的网页图片通过DBNet文本检测算法，输出网页图片上所有的文本行坐标信息；文本行识别模块，用于通过CRNN文本识别算法，同时根据得到的文本行坐标信息，裁剪出所有的文本行并进行识别，得到每个文本行字符信息；文本行分类模块，用于结合输入的网页图片以及获得的文本行坐标信息、文本行字符信息，并通过基于图神经网络模型的文本行分类算法，输出所有文本行的类别；文本行键值对匹配模块，用于分别提取任意两个文本行的文本行坐标信息特征和文本行字符信息特征，并进行融合获得融合特征，同时结合文本行的类别进行键值对匹配。4.根据权利要求3所述的基于图神经网络的软件页面关键信息提取系统，其特征在于，还包括；键值对输出模块，用于当键值对匹配成功时，输出所有需要的键值对所对应的文本信息。5.根据权利要求3所述的基于图神经网络的软件页面关键信息提取系统，其特征在于，所述文本行分类模块还包括：图神经网络模型模块，用于构建图神经网络模型；分类模块，用于输出所有文本行的类别。
说明书desc
技术领域本发明属于软件页面信息提取技术领域，具体涉及基于图神经网络的软件页面关键信息提取方法及系统。背景技术RPA应用场景中通常会遇到网页或软件页面特定文本信息提取的任务。该任务需要借助光学字符识别技术来获取页面上所有的文字信息，然后通过一些后处理操作取出需要的字段内容。近年来，随着人工智能领域的发展，深度神经网络在OCR领域得到了广泛应用，如文档识别，证件识别，票据识别等。相较于传统OCR识别算法，深度神经网络能明显提升OCR识别的适用范围和识别准确率。最常用的卷积神经网络往往只关注图像的局部特征，忽略了局部特征之前的相互关系。图神经网络可以将图像的局部特征当作图节点，学习节点间的相互关系。在一些特定场景中如软件界面等，图像上的文本行之间有很大的相互关系，利用图神经网络可以学习到更多的有用信息。关键信息提取指的是从图像文本中提取出需要的指定的字段信息。例如，从身份证图片中提取出姓名，性别，民族，身份证号等特定字段信息。一般的软件界面上往往有很多文本信息，在实际业务中只有少数关键文本信息是有用的。如果要在所有的文本信息中提取出这些有用的关键信息，需要设计一系列复杂的后处理方法，如模板匹配等。在设计模板的时候需要考虑文本行的字符信息，文本行的位置信息等。对于不同的软件界面需要花大量的人工成本和时间成本设定不同的后处理规则。现有的关键信息提取方法一种是基于模板匹配，根据预先设定好的模板，判断模板图像和待测图像的字符串两两之间是否是匹配关系。例如在识别出图片上所有的文本信息之后根据关键字段的文本特征设定一些正则规则与图片上所有的文本行进行匹配，与对应关键字段的正则规则匹配成功的文本行就是该关键信息。另外，还有基于深度神经网络的方法，对OCR算法提取出的图片中所有的文本框进行分类。例如待测试图片是一张身份证图片，则可以将图中的所有文本框分类成姓名、民族、出生日期、地址等类别，从而完成关键信息提取。然而，基于模板匹配的方法非常依赖于图像文本的布局情况，一旦待测图像的文本布局与预先设定的模板文本布局不一致，就会导致关键信息提取错误或提取失败。此外，不同的应用软件的界面文本布局千差万别，很难设计出一种通用的匹配模板。例如，想从一张图片中提取姓名字段，一般地，需要设计一种匹配模式，先检索关键字“姓名”这个字段，然后从“姓名”字段右侧的文本框去匹配2-3个汉字的文本框。如果某个软件的界面排版不是左右排布而是上下排布，即实际的姓名在关键字“姓名”的下方。此时，原来设定的匹配模式就无法适用。因此，基于模板匹配的方法很难具有较好的通用性。基于深度神经网络分类的方法是将图片中所有的文本行都分配一个类别。例如要提取一张身份证上的信息，可以将身份证上所有的文本行字段分类成“姓名”，“性别”，“出生日期”，“住址”，“身份证号”等类别。当需要提取某个关键字段时，只需要根据关键字段相应的类别就可以提取出对应的字段信息。这种方法不需要依赖特定的模板，但是需要明确所有的类别个数。不同的应用软件上面的文本类型会有很大差异，很难穷举出所有的类别。因此，基于深度神经网络分类的方法只能用于特定的场景，也不具有很好的通用性。基于上述问题，设计一种通用性强，能应用到所有的软件文本类型的基于图神经网络的软件页面关键信息提取方法及系统，就显得十分重要。例如，申请号为CN201911163754.8的中国专利文献描述的访问网页页面的方法、装置、终端设备及服务器，该方法包括：获取目标网页的访问请求；其中，访问请求中携带有预设关键字；获取关键字在目标网页中的位置信息，以及目标网页的页面数据；根据位置信息，显示目标网页的页面数据。虽然根据关键字的位置信息显示目标网页的页面数据，可以使用户在目标网页中快捷地找到搜索的关键字的相关内容，从而提高了用户体验，但是其缺点在于，上述方法只能用于特定的场景，并不具有很好的通用性。发明内容本发明是为了克服现有技术中，现有的关键信息提取方法存在只能用于特定的场景，并不具有很好的通用性的问题，提供了一种通用性强，能应用到所有的软件文本类型的基于图神经网络的软件页面关键信息提取方法及系统。为了达到上述发明目的，本发明采用以下技术方案：基于图神经网络的软件页面关键信息提取方法，包括如下步骤；S1，将输入的网页图片通过DBNet文本检测算法，输出网页图片上所有的文本行坐标信息；S2，通过CRNN文本识别算法，同时根据得到的文本行坐标信息，裁剪出所有的文本行并进行识别，得到每个文本行字符信息；S3，结合输入的网页图片以及获得的文本行坐标信息、文本行字符信息，并通过基于图神经网络模型的文本行分类算法，输出所有文本行的类别；S4，分别提取任意两个文本行的文本行坐标信息特征和文本行字符信息特征，并进行融合获得融合特征，同时结合文本行的类别进行键值对匹配；若匹配成功，则输出所有需要的键值对所对应的文本信息。作为优选，步骤S3中所述文本行的类别包括“键”，“值”和“其他”三个类别。作为优选，步骤S3包括如下步骤：S31，用CNN骨干网络提取网页图片的特征，同时利用ROI Pooling层将所有文本行的特征处理成一个统一的维度；用CNN+ROI Pooling提取每个文本行的视觉特征，用长短期记忆网络LSTM提取文本行的语义特征，并将视觉特征和语义特征融合，得到融合特征，表示拼接操作，公式如下：S32，利用每个文本行的融合特征建立图神经网络模型，将每个文本行作为一个图节点构造一个无向图，所述无向图表示成，其中表示所有文本行的融合特征，表示无向图中两个节点的边的权重；考虑文本行之间的空间关系，构造特征向量其中，，表示第个文本行的中心点坐标，，表示第个文本行的中心点坐标，，表示第个文本行的宽和高，，表示第个文本行的宽和高；和表示两个文本行之间的距离；和表示两个文本行各自的宽高比；和表示两个文本行之间宽高比的差异。作为优选，步骤S3还包括如下步骤：S33，构造两个文本行之间的空间关系其中，是一个线性变换，用于将进行升维，表示正则化，表示多层神经网络。作为优选，步骤S3还包括如下步骤：S34，利用如下公式对无向图上的节点进行迭代，迭代次数为超参数，可按需调整：其中，表示ReLU激活函数，是一个线性变换，表示第次迭代中的第个图节点；S35，图神经网络模型构建完成。作为优选，步骤S4包括如下步骤：S41，对于每个文本行的文本行字符信息用长短期记忆网络LSTM提取语义特征，对于每个文本行有四个顶点的文本行坐标信息特征,,,，融合得到融合特征：其中，、分别表示第个文本行和第个文本行的语义特征；表示第个文本行的顶点坐标；表示第个文本行的顶点坐标；、表示第个文本行的宽和高；、表示第个文本行的宽和高。S42，将融合后的融合特征送到分类器中，当两个文本行不属于同一个键值对，则输出类别为0；当两个文本行属于同一个键值对，则输出类别为1。本发明还提供了基于图神经网络的软件页面关键信息提取系统，包括：文本行检测模块，用于将输入的网页图片通过DBNet文本检测算法，输出网页图片上所有的文本行坐标信息；文本行识别模块，用于通过CRNN文本识别算法，同时根据得到的文本行坐标信息，裁剪出所有的文本行并进行识别，得到每个文本行字符信息；文本行分类模块，用于结合输入的网页图片以及获得的文本行坐标信息、文本行字符信息，并通过基于图神经网络模型的文本行分类算法，输出所有文本行的类别；文本行键值对匹配模块，用于分别提取任意两个文本行的文本行坐标信息特征和文本行字符信息特征，并进行融合获得融合特征，同时结合文本行的类别进行键值对匹配。作为优选，基于图神经网络的软件页面关键信息提取系统还包括；键值对输出模块，用于当键值对匹配成功时，输出所有需要的键值对所对应的文本信息。作为优选，所述文本行分类模块还包括：图神经网络模型模块，用于构建图神经网络模型；分类模块，用于输出所有文本行的类别。本发明与现有技术相比，有益效果是：本发明独创性的将图神经网络应用到RPA应用软件关键信息提取中，能直接输出软件图片中所有的键值对，从而帮助提取出想要的关键信息，大大减少后期人工设定规则来查找关键信息的复杂度；本发明的关键信息提取方法融合了图像的视觉特征，文本的语义特征，文本行的位置特征，大大提升了关键信息的提取准确率；本发明的键值对匹配采用的对比学习方法，只需要少量的文本框类别标注样本，即可有很好的键值对匹配效果，系统泛化性强。附图说明图1为本发明中基于图神经网络的软件页面关键信息提取方法的一种流程图；图2为本发明中基于图神经网络的软件页面关键信息提取系统的一种功能构架图；图3为本发明中文本行分类模块的一种功能构架图；图4为本发明实施例所提供的从RPA抓取图片到提取关键信息的一种流程图。具体实施方式为了更清楚地说明本发明实施例，下面将对照附图说明本发明的具体实施方式。显而易见地，下面描述中的附图仅仅是本发明的一些实施例，对于本领域普通技术人员来讲，在不付出创造性劳动的前提下，还可以根据这些附图获得其他的附图，并获得其他的实施方式。实施例1：如图1所示，本发明提供了基于图神经网络的软件页面关键信息提取方法，包括如下步骤；S1，将输入的网页图片通过DBNet文本检测算法，输出网页图片上所有的文本行坐标信息；S2，通过CRNN文本识别算法，同时根据得到的文本行坐标信息，裁剪出所有的文本行并进行识别，得到每个文本行字符信息；S3，结合输入的网页图片以及获得的文本行坐标信息、文本行字符信息，并通过基于图神经网络模型的文本行分类算法，输出所有文本行的类别；S4，分别提取任意两个文本行的文本行坐标信息特征和文本行字符信息特征，并进行融合获得融合特征，同时结合文本行的类别进行键值对匹配；若匹配成功，则输出所有需要的键值对所对应的文本信息。进一步的，步骤S3中所述文本行的类别包括“键”，“值”和“其他”三个类别。这样分类的目的一方面可以将图片中所有的键值都提取出来，另一方面可以过滤掉一些无效的文本行。一般的分类网络往往是通过一系列的卷积操作提取图像的视觉特征，根据视觉特征来对图片进行分类。但是现在的任务是将文本行进行分类，文本行的视觉特征差异不明显，仅仅根据视觉特征来进行分类往往不能有好的分类效果。文本行的类别与它的语义信息，位置信息都有很强的关系，一些关键信息比如“名称”，“日期”等都是特定的文本，“值”一般都在“键”的右侧或下方。因此将文本行的位置信息和语义信息也作为网络的输入能提升文本行的分类准确率。如图3所示，步骤S3包括如下步骤：S31，用CNN骨干网络提取网页图片的特征，同时利用ROI Pooling层将所有文本行的特征处理成一个统一的维度；用CNN+ROI Pooling提取每个文本行的视觉特征，用长短期记忆网络LSTM提取文本行的语义特征，并将视觉特征和语义特征融合，得到融合特征，表示拼接操作，公式如下：S32，利用每个文本行的融合特征建立图神经网络模型，将每个文本行作为一个图节点构造一个无向图，所述无向图表示成，其中表示所有文本行的融合特征，表示无向图中两个节点的边的权重；考虑文本行之间的空间关系，构造特征向量其中，，表示第个文本行的中心点坐标，，表示第个文本行的中心点坐标，，表示第个文本行的宽和高，，表示第个文本行的宽和高；和表示两个文本行之间的距离；和表示两个文本行各自的宽高比；和表示两个文本行之间宽高比的差异。S33，构造两个文本行之间的空间关系其中，是一个线性变换，用于将进行升维，表示正则化，表示多层神经网络。S34，利用如下公式对无向图上的节点进行迭代，迭代次数为超参数，可按需调整：其中，表示ReLU激活函数，是一个线性变换，表示第次迭代中的第个图节点；S35，图神经网络模型构建完成。ROI Pooling是一种能将不同维度特征处理成相同维度的操作，普遍存在与主流的两阶段目标检测算法中。步骤S4包括如下步骤：S41，对于每个文本行的文本行字符信息用长短期记忆网络LSTM提取语义特征，对于每个文本行有四个顶点的文本行坐标信息特征,,,，融合得到融合特征：其中，、分别表示第个文本行和第个文本行的语义特征；表示第个文本行的顶点坐标；表示第个文本行的顶点坐标；、表示第个文本行的宽和高；、表示第个文本行的宽和高。S42，将融合后的融合特征送到分类器中，当两个文本行不属于同一个键值对，则输出类别为0；当两个文本行属于同一个键值对，则输出类别为1。本发明将关键信息提取拆分成两步，分别是文本行分类和文本行键值对匹配。文本行分类是将所有检测到的文本行分成三种类别：键，值和其他，不需要区分具体的键值类别，这样通用性大大增强，可以应用到所有的软件文本类型。文本行键值对匹配是将所有的键和值进行配对，将每一个属于“键”类别的文本行与对应的属于“值”类别的文本行绑定起来，这样只要输入某个关键信息对应的键就可以得到其对应的值。如图2所示，本发明还提供了基于图神经网络的软件页面关键信息提取系统，包括：文本行检测模块，用于将输入的网页图片通过DBNet文本检测算法，输出网页图片上所有的文本行坐标信息；文本行识别模块，用于通过CRNN文本识别算法，同时根据得到的文本行坐标信息，裁剪出所有的文本行并进行识别，得到每个文本行字符信息；文本行分类模块，用于结合输入的网页图片以及获得的文本行坐标信息、文本行字符信息，并通过基于图神经网络模型的文本行分类算法，输出所有文本行的类别；文本行键值对匹配模块，用于分别提取任意两个文本行的文本行坐标信息特征和文本行字符信息特征，并进行融合获得融合特征，同时结合文本行的类别进行键值对匹配。键值对输出模块，用于当键值对匹配成功时，输出所有需要的键值对所对应的文本信息。进一步的，所述文本行分类模块还包括：图神经网络模型模块，用于构建图神经网络模型；分类模块，用于输出所有文本行的类别。基于本发明的技术方案，在具体实施和操作过程中，以图4所示从RPA抓取图片到提取关键信息的流程图说明本发明具体实施流程。如图4所示，具体实施流程如下：1.利用RPA抓取应用软件页面的图片作为输入，并且配置需要输出的关键信息字段的名称；2.将图片输入文本检测器中，检测出图片中所有的文本行坐标；3.根据第2步检测出的文本行坐标，在原图中裁剪出所有文本行输入文本识别器中，识别出每个文本行的字符内容；4.将原图，文本检测器输出的文本行坐标，文本识别器输出的文本行内容输入文本行分类器中，得到所有文本行的类别；5.将每个属于“键”的文本行分别与所有属于“值”的文本行输入到键值对匹配器里面进行匹配，如果匹配成功则将当前的“键”与“值”绑定起来；6.根据第1步中设定的关键信息字段的名称匹配到“键”的名称；7.根据名称对应的“键”输出与之绑定的“值”。本发明独创性的将图神经网络应用到RPA应用软件关键信息提取中，能直接输出软件图片中所有的键值对，从而帮助提取出想要的关键信息，大大减少后期人工设定规则来查找关键信息的复杂度；本发明的关键信息提取方法融合了图像的视觉特征，文本的语义特征，文本行的位置特征，大大提升了关键信息的提取准确率；本发明的键值对匹配采用的对比学习方法，只需要少量的文本框类别标注样本，即可有很好的键值对匹配效果，系统泛化性强。以上所述仅是对本发明的优选实施例及原理进行了详细说明，对本领域的普通技术人员而言，依据本发明提供的思想，在具体实施方式上会有改变之处，而这些改变也应视为本发明的保护范围。
