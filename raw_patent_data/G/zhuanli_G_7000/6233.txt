标题title
一种基于异构神经网络模型的隐私计算方法
摘要abst
本发明涉及隐私计算技术领域，具体涉及一种基于异构神经网络模型的隐私计算方法，包括：建立服务节点和执行节点，参与方提供目标函数或者样本数据至服务节点；服务节点建立并训练异构神经网络模型；构建若干个子模型及主模型；子模型编号后发送给若干个参与方，主模型发给执行节点；参与方将各自的隐私数分别拆分为若干个加数的和以及若干个乘数的积；参与方使用各自分配到的加数及乘数计算子模型的输出作为中间值，将中间值发送给执行节点；执行节点将乘法子模型的中间值相乘，其余子模型的中间值相加，得子模型输出，代入主模型，获得隐私计算结果。本发明的实质性效果是：提高隐私计算的执行效率，实现数据可用不可见，促进数据要素流动。
权利要求书clms
1.一种基于异构神经网络模型的隐私计算方法，其特征在于，所述异构神经网络模型为包含至少一个乘法神经元的神经网络模型，所述乘法神经元的输入数为所连接的上一层神经元的输出按连接权系数求幂值后的乘积，输出为输入数与偏移值相乘后代入激活函数所得结果，所述隐私计算方法包括：建立服务节点和执行节点，参与隐私计算的若干个参与方提供目标函数或者样本数据至服务节点；服务节点根据目标函数或者样本数据建立并训练异构神经网络模型；服务节点构建若干个子模型，子模型与第1层神经元一一对应，子模型的输入为与对应第1层神经元连接的第0层神经元，子模型的输出为第1层神经元的输入数，乘法神经元对应子模型记为乘法子模型，将异构神经网络模型的第0层删除，将第1层神经元的输入数修改为对应子模型的输出后，作为主模型；服务节点将子模型编号后发送给若干个参与方，将主模型发给执行节点；若干个参与方将各自的隐私数分别拆分为若干个加数的和以及若干个乘数的积，加数及乘数的数量与参与方数量相同，加数及乘数均分配给若干个参与方；若干个参与方使用各自分配到的加数及乘数计算每个子模型的输出，作为子模型的中间值，将中间值关联子模型编号发送给执行节点；执行节点将乘法子模型对应的中间值相乘，其余子模型对应的中间值相加，即得子模型的输出，代入主模型，获得主模型的输出，作为隐私计算结果。2.根据权利要求1所述的一种基于异构神经网络模型的隐私计算方法，其特征在于，服务节点建立并训练异构神经网络模型的方法包括：所述服务节点根据目标函数获得样本数据或者使用参与方提供的样本数据；建立异构神经网络模型，赋予异构神经网络模型的权系数初始值；使用样本数据训练和测试异构神经网络模型，直到准确度达到预设阈值，训练后的异构神经网络模型作为目标神经网络模型。3.根据权利要求2所述的一种基于异构神经网络模型的隐私计算方法，其特征在于，所述服务节点根据目标函数获得样本数据的方法包括：向发出请求的参与方索要目标函数中每个隐私数的取值范围，若参与方未返回取值范围，则对应隐私数使用预设的初始取值范围；在每个隐私数的取值范围内，均匀生成举例数，形成隐私数的多个取值，将隐私数的举例数随机组合为一组，记为取值组；将取值组代入目标函数，获得目标函数的输出，将所述输出作为标签标记所述取值组作为样本数据。4.根据权利要求2所述的一种基于异构神经网络模型的隐私计算方法，其特征在于，若干个参与方分别将各自的隐私数取值范围划分为若干个区间，分别统计各自的隐私数落入每个区间的概率，作为区间概率，将区间概率发送给服务节点；所述服务节点随机在隐私数的取值范围内生成举例数，使举例数在区间的分布概率与区间概率相等；将隐私数的举例数随机组合为一组，记为取值组；将取值组代入目标函数，获得目标函数的输出，将所述输出作为标签标记所述取值组作为样本数据。5.根据权利要求2或3所述的一种基于异构神经网络模型的隐私计算方法，其特征在于，建立异构神经网络模型的方法包括：将隐私数视为自变量，标签值视为函数值，根据样本数据，分别建立标签值对每个隐私数的多项式拟合函数，记录多项式拟合函数中的项系数非零的项的数量；计算全部隐私数对应的项的数量的乘积，所得结果即为乘法神经元的初始数量；建立神经网络模型，在第1层加入初始数量个乘法神经元，乘法神经元与全部输入神经元连接。6.根据权利要求5所述的一种基于异构神经网络模型的隐私计算方法，其特征在于，建立标签值对每个隐私数的多项式拟合函数前，执行以下步骤：将样本数据中存在相同隐私数取值的样本数据随机剔除，使剔除后的样本数据之间不存在相同的隐私数取值；将每个样本数据中隐私数的值及标签值纳入向量，记为输入向量，使用欧式距离表示两个样本数据的距离；设置距离阈值，按照距离阈值将样本数据进行聚合，使聚合后剩余的样本数据之间的距离均大于距离阈值；使用聚合后的样本数据进行多项式拟合函数的建立。7.根据权利要求1至3任一项所述的一种基于异构神经网络模型的隐私计算方法，其特征在于，所述服务节点为每个乘法神经元生成混淆系数，将主模型中乘法神经元涉及的连接的权系数均除以对应的混淆系数，而后将主模型发送给执行节点；所述乘法子模型的输入神经元设有调整系数，所述参与方的隐私数经与调整系数相乘调整后，再拆分为若干个乘数；所述服务节点根据所述混淆系数及乘法子模型包含连接的权系数，生成每个输入神经元的调整系数，使全部输入神经元的调整系数按权系数进行幂运算后的乘积等于所述调整系数；调整所述乘法神经元对应的子模型的包含的连接的权系数，将调整后的子模型发送给参与方。8.根据权利要求1至3任一项所述的一种基于异构神经网络模型的隐私计算方法，其特征在于，参与方自身保留的加数及乘数分别称为保留加数和保留乘数，所述执行节点将收到的中间值关联子模型编号及参与方的标识进行存储；当进行一次隐私计算后，参与方因隐私数发生更新而需要再次进行隐私计算时，执行以下步骤：参与方计算更新后隐私数与更新前隐私数的差和商，分别记为差值和比值；参与方将保留加数与差值相加，将保留乘数与比值相乘；使用更新后的保留加数和保留乘数重新计算每个子模型，子模型的输出记为新中间值，参与方将新中间值关联子模型编号发送给执行节点；所述执行节点将对应子模型编号及参与方标识的中间值替换为新的中间值，重新计算子模型的输出并代入主模型，主模型的输出即为更新后的隐私数参与隐私计算的结果。
说明书desc
技术领域本发明涉及隐私计算技术领域，具体涉及一种基于异构神经网络模型的隐私计算方法。背景技术隐私计算是指在保证数据提供方不泄露原始数据的前提下，对数据进行分析计算的一系列信息技术，保障数据在流通与融合过程中的“可用不可见”。隐私计算是解决数据价值发挥的同时，会带来严重的隐私泄露风险的问题的重要途径。目前的隐私计算技术主要有基于混淆电路及不经意传输的安全多方计算技术和基于同态加密技术的同态加密计算。但混淆电路实现较为复杂或者取值跨度较大的情况时，建立的布尔电路过于复杂。导致安全多方计算的效率十分低下。目前的同态加密技术仅能够较好的解决加法的计算。用于乘法计算时，不仅效率较低，且容易出现大数溢出问题，尤其是涉及到较多乘数或者较高次幂运算时，导致对目标函数计算的误差较大，因而使用范围有限。导致目前仍然缺乏高效率的、能够实现复杂运算的隐私计算方法。因而需要继续研究新的隐私计算技术。理论上神经网络模型能够拟合任意函数。有文献记载神经网络模型本身即是一种对自然界复杂规律的函数表达形式。结合神经网络模型的隐私保护执行技术，使用神经网络模型拟合目标函数，同样能够实现隐私计算。然而神经网络模型模拟生物体的神经元运行机理，对输入信号采取加权求和的方式。对于处理输入数及标签值的取值均有限的问题，具有较高的准确度和效率。但对于涉及乘法计算、幂运算甚至指数计算时，神经网络模型通过带有权系数的加法求和方式，拟合乘法运算时，会导致神经网络模型十分庞大。其实现思路是将输入数划分为区段，从而在每个区段内获得输入数及标签值取值范围均有限的条件。划分的区段越多，则神经网络模型的准确度越高，但同时会导致神经网络模型更为复杂，影响隐私计算的效率。如中国专利CN112100628A，公开日2020年12月18日，一种保护神经网络模型安全的方法，包括：获取神经网络模型，其中包括利用训练数据训练得到的多个网络层；针对其中任意的第一网络层，在固定其他网络层参数的情况下，利用上述训练数据对该第一网络层进行第一调参，得到第一微调模型；确定该第一微调模型对应预设性能指标的第一指标值，该预设性能指标的指标值取决于对应模型，在测试数据上的测试损失和在上述训练数据上的训练损失之间的相对大小；同理，利用训练数据和测试数据对该第一网络层进行第二调参，得到第二微调模型，并确定第二指标值；基于第一指标值和第二指标值的相对大小，确定第一网络层对应的信息敏感度，在其大于预定阈值的情况下，对第一网络层进行安全处理。其技术方案提高了神经网络模型执行时对输入数据的隐私保护力度，但却降低了神经网络模型准确度。仍然需要对神经网络模型继续进行改进，以适应隐私保护的需求。发明内容本发明要解决的技术问题是：目前缺乏高效率的隐私计算方案的技术问题。提出了一种基于异构神经网络模型的隐私计算方法。为解决上述技术问题，本发明所采取的技术方案为：一种基于异构神经网络模型的隐私计算方法，所述异构神经网络模型为包含至少一个乘法神经元的神经网络模型，所述乘法神经元的输入数为所连接的上一层神经元的输出按连接权系数求幂值后的乘积，输出为输入数与偏移值相乘后代入激活函数所得结果，所述隐私计算方法包括：建立服务节点和执行节点，参与隐私计算的若干个参与方提供目标函数或者样本数据至服务节点；服务节点根据目标函数或者样本数据建立并训练异构神经网络模型；服务节点构建若干个子模型，子模型与第1层神经元一一对应，子模型的输入为与对应第1层神经元连接的第0层神经元，子模型的输出为第1层神经元的输入数，乘法神经元对应子模型记为乘法子模型，将异构神经网络模型的第0层删除，将第1层神经元的输入数修改为对应子模型的输出后，作为主模型；服务节点将子模型编号后发送给若干个参与方，将主模型发给执行节点；若干个参与方将各自的隐私数分别拆分为若干个加数的和以及若干个乘数的积，加数及乘数的数量与参与方数量相同，加数及乘数均分配给若干个参与方；若干个参与方使用各自分配到的加数及乘数计算每个子模型的输出，作为子模型的中间值，将中间值关联子模型编号发送给执行节点；执行节点将乘法子模型对应的中间值相乘，其余子模型对应的中间值相加，即得子模型的输出，代入主模型，获得主模型的输出，作为隐私计算结果。作为优选，服务节点建立并训练异构神经网络模型的方法包括：所述服务节点根据目标函数获得样本数据或者使用参与方提供的样本数据；建立异构神经网络模型，赋予异构神经网络模型的权系数初始值；使用样本数据训练和测试异构神经网络模型，直到准确度达到预设阈值，训练后的异构神经网络模型作为目标神经网络模型。作为优选，所述服务节点根据目标函数获得样本数据的方法包括：向发出请求的参与方索要目标函数中每个隐私数的取值范围，若参与方未返回取值范围，则对应隐私数使用预设的初始取值范围；在每个隐私数的取值范围内，均匀生成举例数，形成隐私数的多个取值，将隐私数的举例数随机组合为一组，记为取值组；将取值组代入目标函数，获得目标函数的输出，将所述输出作为标签标记所述取值组作为样本数据。作为优选，若干个参与方分别将各自的隐私数取值范围划分为若干个区间，分别统计各自的隐私数落入每个区间的概率，作为区间概率，将区间概率发送给服务节点；所述服务节点随机在隐私数的取值范围内生成举例数，使举例数在区间的分布概率与区间概率相等；将隐私数的举例数随机组合为一组，记为取值组；将取值组代入目标函数，获得目标函数的输出，将所述输出作为标签标记所述取值组作为样本数据。作为优选，建立异构神经网络模型的方法包括：将隐私数视为自变量，标签值视为函数值，根据样本数据，分别建立标签值对每个隐私数的多项式拟合函数，记录多项式拟合函数中的项系数非零的项的数量；计算全部隐私数对应的项的数量的乘积，所得结果即为乘法神经元的初始数量；建立神经网络模型，在第1层加入初始数量个乘法神经元，乘法神经元与全部输入神经元连接。作为优选，建立标签值对每个隐私数的多项式拟合函数前，执行以下步骤：将样本数据中存在相同隐私数取值的样本数据随机剔除，使剔除后的样本数据之间不存在相同的隐私数取值；将每个样本数据中隐私数的值及标签值纳入向量，记为输入向量，使用欧式距离表示两个样本数据的距离；设置距离阈值，按照距离阈值将样本数据进行聚合，使聚合后剩余的样本数据之间的距离均大于距离阈值；使用聚合后的样本数据进行多项式拟合函数的建立。作为优选，所述服务节点为每个乘法神经元生成混淆系数，将主模型中乘法神经元涉及的连接的权系数均除以对应的混淆系数，而后将主模型发送给执行节点；所述乘法子模型的输入神经元设有调整系数，所述参与方的隐私数经与调整系数相乘调整后，再拆分为若干个乘数；所述服务节点根据所述混淆系数及乘法子模型包含连接的权系数，生成每个输入神经元的调整系数，使全部输入神经元的调整系数按权系数进行幂运算后的乘积等于所述调整系数；调整所述乘法神经元对应的子模型的包含的连接的权系数，将调整后的子模型发送给参与方。作为优选，参与方自身保留的加数及乘数分别称为保留加数和保留乘数，所述执行节点将收到的中间值关联子模型编号及参与方的标识进行存储；当进行一次隐私计算后，参与方因隐私数发生更新而需要再次进行隐私计算时，执行以下步骤：参与方计算更新后隐私数与更新前隐私数的差和商，分别记为差值和比值；参与方将保留加数与差值相加，将保留乘数与比值相乘；使用更新后的保留加数和保留乘数重新计算每个子模型，子模型的输出记为新中间值，参与方将新中间值关联子模型编号发送给执行节点；所述执行节点将对应子模型编号及参与方标识的中间值替换为新的中间值，重新计算子模型的输出并代入主模型，主模型的输出即为更新后的隐私数参与隐私计算的结果。本发明的实质性效果是：使用异构神经网络模型能够更精简更准确的拟合目标函数，提高隐私计算的执行效率，结合神经网络模型的匿名求解过程，实现数据可用不可见；理论上神经网络模型能够拟合任意目标函数，能够扩大隐私计算的应用范围，更好的为各个产业提供数据分析服务，促进数据这一要素的流动，推动生产力的发展；提高异构神经网络模型训练的效率，减少隐私计算的准备时间，进一步提高隐私计算的效率。附图说明图1为实施例一隐私计算方法示意图。图2为实施例一神经网络模型示意图。图3为实施例一乘法神经元示意图。图4为实施例一异构神经网络模型元示意图。图5为实施例一异构神经网络模型拟合目标函数示意图。图6为实施例一建立并训练异构神经网络模型方法示意图。图7为实施例一根据目标函数获得样本数据方法示意图。图8为实施例一考虑分布概率生成样本数据方法示意图。图9为实施例一建立异构神经网络模型方法示意图。图10为实施例一建立多项式拟合函数方法示意图。图11为实施例二生成混淆系数执行主模型方法示意图。图12为实施例二隐私数更新后进行隐私计算方法示意图。图13为实施例二异构神经网络模型示意图。其中：11、输入层，12、隐藏层，13、输出层，14、加法神经元，15、乘法神经元。具体实施方式下面通过具体实施例，并结合附图，对本发明的具体实施方式作进一步具体说明。实施例一：一种基于异构神经网络模型的隐私计算方法，异构神经网络模型为包含至少一个乘法神经元15的神经网络模型，请参阅附图1，隐私计算方法包括：步骤A01）建立服务节点和执行节点，参与隐私计算的若干个参与方提供目标函数或者样本数据至服务节点，服务节点根据目标函数或者样本数据建立并训练异构神经网络模型。步骤A02）服务节点构建若干个子模型16，子模型16与第1层神经元一一对应，子模型16的输入为与对应第1层神经元连接的第0层神经元，子模型16的输出为第1层神经元的输入数，乘法神经元15对应子模型16记为乘法子模型16，将异构神经网络模型的第0层删除，将第1层神经元的输入数修改为对应子模型16的输出后，作为主模型17。步骤A03）服务节点将子模型16编号后发送给若干个参与方，将主模型17发给执行节点。步骤A04）若干个参与方将各自的隐私数分别拆分为若干个加数的和以及若干个乘数的积，加数及乘数的数量与参与方数量相同，加数及乘数均分配给若干个参与方。步骤A05）若干个参与方使用各自分配到的加数及乘数计算每个子模型16的输出，作为子模型16的中间值，将中间值关联子模型16编号发送给执行节点。步骤A06）执行节点将乘法子模型16对应的中间值相乘，其余子模型16对应的中间值相加，即得子模型16的输出，代入主模型17，获得主模型17的输出，作为隐私计算结果。参与隐私计算的参与方提供需要进行的目标函数，如求行业年度销售额总和、产品高中低档销量分布百分比，这些隐私计算需求是能够写出准确的目标函数的。对于能够准确写出并提供目标函数的隐私计算，本方案需要对目标函数进行转化，建立异构神经网络模型来拟合目标函数。神经网络模型拟合函数后，虽然计算会存在一定的误差，但对于行业年度销售总额、产品销量分布这些需求而言，少量的误差是允许的。神经网络模型具有隐私保护的求解方案，是因为神经网络模型对每个输入神经元的计算是相同的，均是加权求和，因而能够借助加法混淆来进行计算。使得在求解神经网络模型过程中，能够有效隐藏输入数。目标函数并不一定能够进行加法混淆计算，因而需要将目标函数转换为神经网络的拟合，来从形式上满足进行加法混淆计算的需求。加法混淆计算是在计算加权和时，将每个参与计算的隐私数拆分为若干个加数，若干个加数分配给若干个参与方。使得每个参与方均获得全部隐私数的一个加数，参与方分别使用对应的加数来计算加权和。这样每个参与方都将获得加权和的一个中间值。由于无法从中间值反推出加数，从而使得每个加数获得了保密。全部中间值再相加，就能够恰好复原出加权和的结果。在此基础上，只要将目标函数转换为神经网络模型，即可借助神经网络模型的隐私计算方法，实现目标函数的隐私计算。神经网络模型是一种仿生技术，仿造生物体的神经系统，也是一种机器分类技术。生物体的神经元具有若干个树突和轴突，树突短而多分枝，可接受刺激。轴突呈细索状，末端常有分支，将冲动向后传递。基于生物体的神经元结构和工作机理，本领域技术人员构建了神经网络模型。神经网络模型中的神经元，将与其连接的前一层神经元的输入数，即模仿生物体的神经冲动信号，进行权重调整后叠加，再叠加一个偏移值后代入激活函数。数学上使用加权求和的方式，模拟神经细胞树突对神经冲动的接收和叠加。激活函数即模拟生物体的神经细胞对叠加后的信号的反应，产生输出。传导到下一层神经元做同样操作，直到计算到输出神经元，输出结果。如此构建的神经网络模型具有高效和功能复杂的分类功能。如图像识别分类、文字识别分类等应用。关于神经网络模型能够拟合任意函数的广泛性，本领域公开技术资料已有记载。在本实施例中，从原理角度做简要介绍。神经网络模型通常包括输入层11、若干个隐藏层12和输出层13，神经元将与其连接的上一层神经元的输出进行加权求和。在给定神经网络模型结构的情况下，神经网络模型中连接的权系数、偏移值常量和激活函数，就能够起到根据输入数，来调节神经网络模型输出的作用。其中，Relu6函数的表达式为：Relu6 = min,6)，即与神经元连接的上一层神经元的加权和，上一层神经元的输出为xi，对应的连接权系数为ai，偏移值为b，形成特征值。当特征值小于0时，输出0，当特征值大于6时，输出6，在区间内时，输出特征值，特征值即为神经元连接的上一层神经元的输出的加权和。构建多个第1层神经元，第一个第1层神经元的偏移值b赋值0，第二个第1层神经元的偏移值赋值-6，第三个第1层神经元的偏移值赋值-12，直到第k个第1层神经元的偏移值赋值-6*k，k为正整数。为简单起见，假设这些第1层神经元仅与一个输入层11神经元连接，输入神经元输入数记为x，连接权系数设为6，如此，当x∈*x2+x3。x1^2表示x1的平方。当x1、x2、x3均取值时，S1具有相应的计算结果。权系数经过训练后，神经网络模型的输出与标签值的误差在可接受范围内。但当x2、x3仍然在内变化，仅将x1的值变为10000，标签值将远远大于x1，神经网络模型只能通过w11取较大的值，才能弥合x1与x1^2之间的误差。然而当w11取较大的值时，又无法适应x1取值较小的情况。因而只能通过上述记载的借助一些神经元将输入数划分为小区间的方式。每个小区间匹配相应的权系数w11，使得x1*w11与x1^2结果相当。但这样就会使神经网络模型的结构十分庞大。为解决神经网络模型难以适应大跨度的输入数，本实施例提出了乘法神经元15的解决方案。具体而言，请参阅附图3，为乘法神经元15的计算示意图。其输入数等于与乘法神经元15连接的上一层神经元按权系数求幂后，再相乘。再乘以偏移值b1后，代入激活函数。即乘法神经元15的输出S1=***b1。本实施例将本领域目前公开的神经元，相对的称为加法神经元14，加法神经元14与本领域目前所称神经元含义相同，因而不使用加法神经元14的称呼，而直接使用神经元称呼时，其含义不变，仍然指本领域目前所称神经元。加法神经元14的输入数In=∑ai*xi，乘法神经元15的输入数In=∏。加法神经元14的输出S1=Sigmod，乘法神经元15的输出S1=Sigmod。异构神经网络模型即为包含至少一个乘法神经元15的网络模型，如附图4所示。同样的，如附图4所示的神经网络模型的标签值同样为*x2+x3，则将w21设置为2，w22设置为1，w23设置为0，则第二个第1层神经元的输入数，In1=*x2*1，使得后续神经元仅需要处理S2+x3这一计算即可。采用适当的激活函数，如可以直接采用Relu函数，并限制x1、x2、x3为正数即可。请参阅附图5，按照图中所示构建异构神经网络模型，并设置相应权系数，不使用偏移值，异构神经网络模型的输出结果y=*x2+x3。即异构神经网络模型能准确的复原涉及多个输入数的幂运算、乘法运算的目标函数。使得异构神经网络模型能够准确的实现多项式的运算。多自变量的多项式的形式表达为：f=∑∑…∑ai1_i2_..._im*x1^i1*x2^i2*…*xm^im，其中，i1,i2,…,im∈。异构神经网络模型能够准确的复现多自变量的多项式的计算。而理论上多项式能够拟合任意函数。虽然神经网络模型和多项式理论上均能够拟合任意函数，但二者的特点却并不相同。神经网络模型不适合标签值随输入数大范围单调递增/减的运算，原因是权系数无法兼顾取小值和取大值时的误差。但神经网络模型适合标签值随输入数的变化，而反复在递增和递减之间徘徊的情况，即极值点较多的目标函数。相对的，采用多项式拟合时，若极值点较多，会导致多项式的项呈指数式增长，导致最终的多项式十分复杂。但对于大跨度的、单调递增/减的目标函数，却能够方便简单的拟合。对于单自变量而言，极值点的数量加上1，就等于多项式拟合结果中最高次项的次数n的值，n的值又决定了多项式中项的最大数量。如存在20个极值点，则会导致n等于21，对单个自变量的拟合多项式就最多有21个项。对于多自变量而言，则项的增加是指数增加的。比如，涉及两个自变量，则项数为21^2，即高达441项。进行隐私计算的参与方远不止两个，使得多项式拟合失去实际应用价值。而对于典型的神经网络模型而言，其本身就是能够实现对复杂分类规律的实现。所谓复杂分类规律即指当自变量的值不断增大时，输出结果并不是简单的单调增大，而是在一个范围内反复变化，形成大量的极值点。极值点的数量增加，而自变量及标签取值范围有限时，神经网络模型不需要改变其结构，仅需要进行大量的训练，使得权系数取值得当即可。如200×200像素的图像识别中，涉及4万个输入数，每个输入数均为归一化的灰度值，即自变量取值范围有限。假设该图像识别针对3种动物，每种动物种类赋予{1,2,3}中的一个数字表示。则标签值的取值范围也是有限的。对于给定的若干张待识别图像，按待识别图像的左上角像素的灰度值升序排列，左上角灰度值相同则顺次按右边一个像素的灰度值决定排序。排序后，可以看做是4万个输入数，即4万个自变量，以大体上递增的顺序排列，而输出的结果则在{1,2,3}之间反复徘徊。若使用多项式拟合，则乘积项的数量将无法接受。而采用神经网络模型去实现则相对容易且准确，不会因为标签值徘徊的次数增加，则变得更为复杂。相对的对于自变量相对较少但涉及幂运算、乘法运算的情况，神经网络模型的神经元数量将庞大到难以计算。如最为简单的目标函数f=x*y，对于给定的x,y取值范围，x,y∈，允许的误差为±20，则符合误差要求的神经网络模型需要将x和y均分为25段，即每段的值跨度为4，如此最大误差将控制在16以下，满足误差要求。导致第一层隐藏层12的神经元数量至少得有625个，难以真正实施。然而加入乘法神经元15后，只需要一个乘法神经元15就可以满足误差要求。能够大幅降低神经网络模型的复杂程度。当目标函数为f=e^x+9*y，即e的x次方，与9*y求和。x,y∈，允许的误差为±20。单考虑e^x，x= 9.999和x=10之间的差值约为20，可见要将自变量x的值划分为1000段，才能满足误差要求。导致第1层隐藏层12的神经元数量至少1000个。使用适当的权系数和偏移值修正，就能够满足误差要求。例如8*10^4与e^10取值接近，1.2*9^4与e^9取值接近，即使用一个乘法神经元，该乘法神经元与x对应的输入神经元连接，连接的权系数取值4，乘法神经元的偏移值取值8，该乘法神经元能够较为准确的计算出e^10的值。建立第二个乘法神经元，连接的权系数取值4，乘法神经元的偏移值取值1.2，该乘法神经元能够较为准确的计算出e^9的值。依次类推因而使用异构神经网络模型时，第1层隐藏层12的神经元数量至多10个即可实现x∈范围内e^x的拟合。已远远小于典型神经网络模型的神经元数量，且已具有可行性。实际上e^x是可以进行泰勒展开的，为泰勒展开中的每一项构建一个乘法神经元，即可更为准确的拟合e^x。e^x的泰勒展开式为：e^x=1+x+x^2/2!+…+x^n/n!+o，根据x的最大取值和允许的误差决定泰勒展开式n的值。如x=10时，泰勒展开式中的第25项的值为10^25/25！=0.64，即令泰勒展开式中n=25，忽略误差项o，即可以较低误差计算出e^x，x∈，因而在第1层隐藏层构建25个乘法神经元即可。x^n/n!对应的乘法神经元，其与x对应的输入神经元的连接权系数为n，偏移值为1/n!。当x取值范围更大时，继续增加第1层隐藏层的乘法神经元数量即可。本实施例中，所记载的自变量即指隐私数。参与方的隐私数是其经营业务数据，在其自愿用于计算行业的汇总经营数据时，以自变量的形式，参与到隐私计算中。如三家手机销售商欲获得A市本年度消费者对手机这种商品的消费热情指数。三家手机销售商分别销售三种手机，三种手机的分别为高、中、低档手机。构建目标函数为：消费热情指数=k1*三种手机总销量+k2*三种手机销量的方差+k3*高档手机销量占比。三种手机的销量分别记为x1、x2和x3，则目标函数可以表示为f=k1*Sn+k2*^2+^2+^2)/3+k3*x1/Sn，Sn=，μ=Sn/3。展开后涉及x1、x2及x3的2次项和Sn的-1次项。第1层隐藏层构建3个乘法神经元，分别计算x1、x2及x3的2次项，乘法神经元与对应的输入神经元的连接的权系数取值2即为计算2次方。第1层隐藏层再构建一个求和神经元。第2层隐藏层构建一个乘法神经元用于计算Sn的-1次项，对应的连接权系数取值为-1即可。对于任意的涉及幂运算和乘法运算的目标函数，都能够通过多项式来拟合，从而将目标函数转换为多项式的计算。乘法神经元15能够极为方便和准确的进行多项式的项的计算。在此基础上，后续隐藏层12神经元，对项进行带权重的加法运输即可。采用本实施例提供的异构神经网络模型，能够将神经网络模型和多项式拟合进行结合，使二者各自发挥长处，同时相互弥补短处。进而提高隐私计算的效率。请参阅附图6，服务节点建立并训练异构神经网络模型的方法包括：步骤B01）服务节点根据目标函数获得样本数据或者使用参与方提供的样本数据；步骤B02）建立异构神经网络模型，赋予异构神经网络模型的权系数初始值；步骤B03）使用样本数据训练和测试异构神经网络模型，直到准确度达到预设阈值，训练后的异构神经网络模型作为目标神经网络模型。理论上神经网络模型能够拟合任意函数，但当涉及幂运算和乘法运算时，为保证拟合误差在允许范围内，神经网络模型需要通过划分区间的方式实现，导致增加大量神经元。在此基础上，构建若干个乘法神经元15，能够较为准确度的计算幂运算和乘法运算部分，而后再次与其余神经元进行加权求和的运算。使用异构神经网络模型，能够使拟合结构大幅简化。因而本实施例提供的方案，即能够覆盖较大范围的目标函数，同时又能够高效率的完成计算。本方案随机的生成异构神经网络模型的结构，经过足够数量的样本数据训练后，理论上也能够获得具有一定准确度的异构神经网络模型。请参阅附图7，服务节点根据目标函数获得样本数据的方法包括：步骤C01）向发出请求的参与方索要目标函数中每个隐私数的取值范围，若参与方未返回取值范围，则对应隐私数使用预设的初始取值范围；步骤C02）在每个隐私数的取值范围内，均匀生成举例数，形成隐私数的多个取值，将隐私数的举例数随机组合为一组，记为取值组；步骤C03）将取值组代入目标函数，获得目标函数的输出，将输出作为标签标记取值组作为样本数据。在本方案中，隐私数的取值组合成取值组是任意而随机的。如隐私数x1的取值范围为，隐私数x2的取值范围为，隐私数x1及 x2均在其取值范围内均匀的取出3个数，则x1取值有{1,2,3}，x2的取值有{2,3,4}，组成取值组既可以是{{1,2},{2,4},{3,3}}也可以是{{1,3},{2,2},{3,4}}。将取值组代入目标函数获得的目标函数的输出，作为取值组的标签。使用标签标记取值组，即获得样本数据。神经网络模型的准确度，在不同的输入数取值范围内是不同的。其原因在于神经网络模型训练完成的判断条件，是以给出的样本数据为依据的。若样本数据集中在某个取值区间中，则会导致神经网络模型的在对应取值区间内的误差较小，从而使得全部样本数据的误差总和，即损失函数，满足结束训练的条件。若样本数据均匀分布，则神经网络模型在输入数范围内的准确度也较为均匀。然而，实际应用中，参与方的隐私数不可能均匀的在理论取值范围内均匀的分布。如业务的年度销售额，通常由一个较为集中的取值区间。因而在训练异构神经网络模型时，有必要在这个取值区间内具有较高的准确度，以提高最终执行隐私计算时的准确度。因此，本实施例提供了一种考虑分布概率的样本数据获得方法，作为步骤C01）至步骤C03）记载方案的替代方案。请参阅附图8，步骤C11）若干个参与方分别将各自的隐私数取值范围划分为若干个区间，分别统计各自的隐私数落入每个区间的概率，作为区间概率，将区间概率发送给服务节点；步骤C12）服务节点随机在隐私数的取值范围内生成举例数，使举例数在区间的分布概率与区间概率相等；步骤C13）将隐私数的举例数随机组合为一组，记为取值组；步骤C14）将取值组代入目标函数，获得目标函数的输出，将输出作为标签标记取值组作为样本数据。按照概率分布形成隐私数的举例数，形成的样本数据更加能够反映实际执行隐私计算时，隐私数的取值情况，因而具有更高的准确度。为了能够快速确定异构神经网络模型中，构建乘法神经元15的适宜数量，本实施例提供了以下方案。建立异构神经网络模型的方法，请参阅附图9，包括：步骤D01）将隐私数视为自变量，标签值视为函数值，根据样本数据，分别建立标签值对每个隐私数的多项式拟合函数，记录多项式拟合函数中的项系数非零的项的数量；步骤D02）计算全部隐私数对应的项的数量的乘积，所得结果即为乘法神经元15的初始数量；步骤D03）建立神经网络模型，在第1层加入初始数量个乘法神经元15，乘法神经元15与全部输入神经元连接。建立标签值对每个隐私数的多项式拟合函数前，请参阅附图10，执行以下步骤：步骤E01）将样本数据中存在相同隐私数取值的样本数据随机剔除，使剔除后的样本数据之间不存在相同的隐私数取值；步骤E02）将每个样本数据中隐私数的值及标签值纳入向量，记为输入向量，使用欧式距离表示两个样本数据的距离；步骤E03）设置距离阈值，按照距离阈值将样本数据进行聚合，使聚合后剩余的样本数据之间的距离均大于距离阈值；步骤E04）使用聚合后的样本数据进行多项式拟合函数的建立。最为准确的构建异构神经网络模型的方法为：建立多变量的多项式拟合函数，将多项式拟合函数展开为若干个乘积项的和。构建异构神经网络模型，异构神经网络模型的乘法神经元15数量与多项式拟合函数的项数量相同。且每个乘法神经元15涉及的连接权系数与乘积项中对应隐私数的指数相同，乘法神经元15的偏移值与乘积项的系数相同。但如此建立的异构神经网络模型完全抛弃了典型神经网络模型的作用。因而本实施例采用简化的处理方式，提供初始的乘法神经元15数量，能够提高异构神经网络模型的构建效率。采用本实施例提供的异构神经网络模型建立方法，使异构神经网络模型中含有若干个乘法神经元15。经过样本数据的训练，当异构神经网络模型使损失函数取值最小时，若干个乘法神经元15拟合了目标函数较低频率、较大范围的变化规律，异构神经网络模型中的其他神经元则拟合目标函数较高频率、较小范围的变化规律。因而具有更好的整体效果。本实施例的有益效果为：使用异构神经网络模型能够更精简更准确的拟合目标函数，提高隐私计算的执行效率，结合神经网络模型的匿名求解过程，实现数据可用不可见；理论上神经网络模型能够拟合任意目标函数，能够扩大隐私计算的应用范围，更好的为各个产业提供数据分析服务，促进数据这一要素的流动，推动生产力的发展；提高异构神经网络模型训练的效率，减少隐私计算的准备时间，进一步提高隐私计算的效率。实施例二：一种基于异构神经网络模型的隐私计算方法，本实施例在实施例一的基础上，提供了异构神经网络模型改进的求解方式，以使主模型17获得保密的效果。请参阅附图11，在实施例一的基础上，实施例还包括以下步骤：步骤F01）服务节点为每个乘法神经元15生成混淆系数，将主模型17中乘法神经元15涉及的连接的权系数均除以对应的混淆系数，而后将主模型17发送给执行节点；步骤F02）乘法子模型16的输入神经元设有调整系数，参与方的隐私数经与调整系数相乘调整后，再拆分为若干个乘数；步骤F03）服务节点根据混淆系数及乘法子模型16包含连接的权系数，生成每个输入神经元的调整系数，使全部输入神经元的调整系数按权系数进行幂运算后的乘积等于调整系数；步骤F04）调整乘法神经元15对应的子模型16的包含的连接的权系数，将调整后的子模型16发送给参与方。对于如附图4中所示的异构神经网络模型，拆分出两个子模型16，分别对应第1层的两个神经元。子模型16的输出值分别为T1和T2，相应的主模型17的输入为T1和T2，对异构神经网络模型进行一些调整作为主模型17，具体为删除输入层11，将第1层神经元的输入修改为对应子模型16的输出即可获得主模型17。服务节点为主模型17中乘法神经元15涉及的连接生成混淆系数r，将连接权系数除以混淆系数，即w312、w322和w332均除以r，而后再将主模型17发送给执行节点。如此执行节点将无法获得准确的主模型17，使主模型17获得保密。每个乘法神经元15的混淆系数各不相同。同时，服务节点为乘法神经元15对应的子模型16涉及的输入神经元生成调整系数。调整系数的生成方法为：使全部输入神经元的调整系数按权系数进行幂运算后的乘积等于调整系数。如混淆系数r的值为36，w312=2、w322=3和w332=1，则权系数w312对应的输入神经元的调整系数取值3，权系数w322对应的输入神经元的调整系数取值2，权系数w332对应的输入神经元的调整系数取值0.5，满足**0.5=36。即x1先乘以3，而后再拆分为若干个乘数。x2先乘以2再拆分为若干个乘数，x3先乘以0.5而后在拆分为若干个乘数。如此计算后恰好使∏xi^w3i2的值扩大了36倍，即子模型16的输出扩大了36倍。代入主模型17后，主模型17中对应的乘法神经元15涉及的连接的权系数均除以36，再与乘法神经元15的输出相乘后即可获得正确的结果。对于同样的一个混淆数，生成的调整系数具有多个组合。本实施例中需要限制乘法神经元15仅存在于第1层隐藏层12中。采用混淆系数的方案，不仅使主模型17获得保密，同时也使子模型16的输出得以保密。多个子模型16对应的乘法神经元15的混淆数不同，因而不能联立起来用于反推隐私数。在子模型16不对执行节点公开的情况下，执行节点原本即不能反推隐私数的值。但为避免服务节点生成的子模型16遭窃取，本实施例采取混淆数的方式，能够进一步提高隐私数的安全。且生成主模型17和子模型16后，服务节点将不再保留任何数据，因而不会遭到窃取。当进行一次隐私计算后，参与方因隐私数发生更新而需要再次进行隐私计算时，请参阅附图12，执行以下步骤：步骤G01）参与方自身保留的加数及乘数分别称为保留加数和保留乘数，执行节点将收到的中间值关联子模型16编号及参与方的标识进行存储；步骤G02）参参与方计算更新后隐私数与更新前隐私数的差和商，分别记为差值和比值；步骤G03）与方将保留加数与差值相加，将保留乘数与比值相乘；步骤G04）使用更新后的保留加数和保留乘数重新计算每个子模型16，子模型16的输出记为新中间值，参与方将新中间值关联子模型16编号发送给执行节点；步骤G05）执行节点将对应子模型16编号及参与方标识的中间值替换为新的中间值，重新计算子模型16的输出并代入主模型17，主模型17的输出即为更新后的隐私数参与隐私计算的结果。其余步骤同实施例一。相对于实施例一，本实施例能够使主模型17的连接的权系数获得混淆，使得主模型17保持保密状态，提高了主模型17的安全性。相对于现有技术中的安全多方计算方法，通过构建混淆电路并借助不经意传输传递加密后的隐私数。若采用安全多方计算技术，当隐私数发生变动时，就需要重新建立不经意传输，重新解算混淆电路。相当于完整的重新执行了一遍隐私计算。若采用现有技术中的同态加密技术。当隐私数更新后，同样需要获得同态加密状态下的更新后的隐私数。凡是涉及到被更新的隐私数的部分，都需要重新计算。然而其余没有涉及到更新的隐私数的部分的计算中间值，是处于同态加密状态下的。对于每个隐私数而言，其发生更新时，需要记录的中间值是不确定的，会导致需要记录大量的中间值。容易造成敏感中间值的泄露，不具有可行性。何况同态加密技术中，同一个秘钥通常只使用一次。第二次加密时，通常秘钥不同，是不能进行直接计算的。采用本实施例记载的技术方案，当多个参与方一起执行过一次隐私计算后。执行节点保留每个参与方发来的每个子模型16的值即可。需要保存的数据是固定的，数量是参与方数量与子模型16数量的乘积，关联参与方标识和子模型16编号即可。当其中一个参与方的隐私数发生了更新，因而有重新进行隐私计算的需求时。不需要通知其他参与方，也不需要其他参与方的协助。更新了隐私数的参与方自行与执行节点进行交互，就可以完成新的隐私计算过程。且当一个参与方因隐私数更新，而再次执行了隐私计算后。另一个参与方的隐私数也发生了更新。此时，第二个隐私数更新的参与方，自行与执行节点交互即可再次完成隐私计算，且再次完成的隐私计算是基于两个隐私数都更新后的值进行的。相当于执行节点能够不断的记录隐私数更新后产生的中间值，从而能够为后续发生隐私数更新的参与方再次进行隐私计算时，提供其他参与方的最新的隐私数一起进行隐私计算的结果。具有现有技术中的隐私计算所不完全具有的进步技术效果。如对于附图13所示的子模型16。参与方P1将x1拆分为x1=x11+x12+x13、x1=xm11*xm12*xm13，同样的参与方P2和参与方P3对隐私数x2和x3做同样的拆分，x2=x21+x22+x23、x2=xm21*xm22*xm23，以及x3=x31+x32+x33、x3=xm31*xm32*xm33。参与方P1获得x11、xm11、x21、xm21、x31及xm31，参与方P2 获得x12、xm12、x22、xm22、x32及xm32，参与方P3 获得x13、xm13、x23、xm23、x33及xm33。参与方P1计算第一个子模型16，得出T1_1=w11*x11+w12*x21+w13*x31，T2_1=**。参与方P2计算T1_2和T2_2，参与方P3计算T1_3和T2_3。T1_1、T2_1、T1_2、T2_2、T1_3及T2_3均发送给执行节点进行保存。执行节点随后计算两个子模型16的输出，即将T1_1、T1_2和T1_3求和，将T2_1、T2_2和T2_3求积。即得T1=w11*x1+w12*x2+w13*x3，T2=**。随后代入主模型17，获得主模型17的输出结果。一段时间后，参与方P1隐数数x1发生了更新，更新后的x1即为nx1。参与方P1执行以下步骤，参与方P2和参与方P3不需要做任何操作。参与方P1计算差值△=nx1-x1，比值△c=nx1/x1，参与方P1将保留加数x11与差值△相加，将保留乘数xm11与比值△c相乘。参与方使用经过处理的保留加数和保留乘数，重新计算每个子模型16的中间值。得出T1_1’=w11*+w12*x21+w13*x31，T2_1’=^w21)**。将T1_1’和T2_1’发送给执行节点。执行节点重新计算两个个子模型16的输出。即：T1=T1_1’+T1_2+T1_3=+w12*x21+w13*x31)++=w11*+w12*+w13*=w11*+w12*x2+w13*x3=w11*nx1+w12*x2+w13*x3；T2=T2_1’*T2_2*T2_3=^w21)** * ** * **=^w21 * ^w22 * ^w23=^w21 * ^w22 * ^w23=^w21 * ^w22 * ^w23=^w21 * ^w22 * ^w23 。可见，通过参与方P1独自更新相关的中间值，使得执行节点最终计算获得的子模型16的输出，恰好是代入更新后的隐私数值nx1的结果。从而再次执行隐私计算时，只需要一个参与方执行即可完成。借助本实施例提供的技术方案，还能够实现参与方不需要同时上线，即可完成隐私计算。假设参与方P1首先上线，因为无法获得隐私数x2和x3拆分出来的加数x21、xm21、x31和xm31，因而参与方P1无法进行子模型16的计算。此时，参与方P1生成x21、xm21、x31和xm31的猜测值，即为x21、xm21、x31和xm31赋予一个随机值。而后使用随机值计算子模型16的中间值T1_1和T2_1，并将中间值发送给执行节点。参与方P1将x21和xm21的猜测值使用参与方P2的公钥加密后发送给服务节点存储，将x31和xm31的猜测值使用参与方P3的公钥加密后发送给服务节点存储。参与方P1将自己的隐私数x1拆分出的加数和乘数发送给服务节点存储。具体的参与方P1将x12和xm12使用参与方P2的公钥加密后发送给服务节点存储，将x13和xm13使用参与方P3的公钥加密后发送给服务节点存储。随后假设参与方P2上线，查询服务节点是否已保存有x2相关的猜测值，查询获得x21和xm21，随后参与方P2将x2拆分为加数和乘数，使拆分出的加数包含x21，拆分出的乘数包含xm21，并将x21和xm21分配给参与方P1，其余加数和乘数在参与方P2和参与方P3之间分配。而后参与方P2因缺少x32和xm32无法计算子模型16的中间值，因而生成x32和xm32的猜测值。并从服务节点下载获得x12和xm12的值，从而能够完成子模型16的中间值T1_2和T2_2的计算。而后将x32和xm32的猜测值使用参与方P3的公钥加密后发送给服务节点存储。同时将x23和xm23的值使用参与方P3的公钥加密后发送给服务节点存储。参与方P3最后上线，从服务节点下载并解密获得x3有关的猜测值x31、xm31、x32和xm32，参与方P3生成x33和xm33，使x33和x31、x32满足加数拆分条件，xm33和xm31、xm32满足乘数拆分条件。同时从服务节点下载并解密获得x13、xm13、x23和xm23的值，因而也能够计算两个子模型16的中间值T1_3和T2_3。执行节点收到两个子模型16的全部中间值后，即可计算出子模型16的输出。进而计算出主模型17的输出结果。当隐私计算的参与方较多时，要求参与方全部同时在线存证困难。在此方案中，参与方借助服务节点保存相关数值，能够在参与方先后上线的情况下，完成隐私计算。使得隐私计算能够更为方便的应用到参与方较多的情况。以上的实施例只是本发明的一种较佳的方案，并非对本发明作任何形式上的限制，在不超出权利要求所记载的技术方案的前提下还有其它的变体及改型。
