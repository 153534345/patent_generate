标题title
一种加密流量识别方法、系统、终端以及存储介质
摘要abst
本申请涉及一种加密流量识别方法、系统、终端以及存储介质。包括：获取网络流量数据包，学习各个网络流量数据包字节内容之间的关联性，训练一个具有数据包编码能力的神经网络模型；通过所述神经网络模型对所述网络流量数据包的字节内容进行编码；学习所述编码后的各个网络流量数据包之间的时序关系，获取各个网络流量数据包的特征表示，并学习各个网络流量数据包的长度信息；对所述各个网络流量数据包的特征表示和长度信息进行融合以及Softmax分类，得到所述各个网络流量数据包的流量识别结果。本申请可以保证神经网络可以学习到数据包的原始字节信息和长度信息，在保持数据包信息完整性的同时达到更好的加密流量识别效果。
权利要求书clms
1.一种加密流量识别方法，其特征在于，包括：获取网络流量数据包，使用Transformer Encoder学习各个网络流量数据包字节内容之间的关联性，训练一个具有数据包编码能力的神经网络模型；通过所述神经网络模型对所述网络流量数据包的字节内容进行编码；使用Transformer学习所述编码后的各个网络流量数据包之间的时序关系，获取各个网络流量数据包的特征表示，并使用双向LSTM学习各个网络流量数据包的长度信息；对所述各个网络流量数据包的特征表示和长度信息进行融合以及Softmax分类，得到所述各个网络流量数据包的流量识别结果。2.根据权利要求1所述的加密流量识别方法，其特征在于，所述训练一个具有数据包编码能力的神经网络模型前包括：搭建加密流量识别模型，所述加密流量识别模型包括预训练层、数据包编码层、时序层、补充层和分类层，在所述加密流量识别模型的预训练层训练所述神经网络。3.根据权利要求2所述的加密流量识别方法，其特征在于，所述训练一个具有数据包编码能力的神经网络模型包括：将所有网络流量数据包按照相同的五元组：＜源IP，目标IP，源端口，目标端口，传输协议＞进行划分，每一组代表一个双向通信流；提取每个网络流量数据包在IP层以上的字节内容，并将提取的字节内容转换成16进制文件；按照设定比例分别对每个16进制文件中的字节内容进行随机掩盖，并分别在每个文件头部加入标记；使用Transformer Encoder学习所述各个网络流量数据包字节内容之间的关联性，并恢复被掩盖的字节内容，使用交叉熵作为损失函数训练所述神经网络模型。4.根据权利要求3所述的加密流量识别方法，其特征在于，所述通过所述神经网络模型对所述网络流量数据包的字节内容进行编码包括：在所述加密流量识别模型的数据包编码层，提取每个网络流量数据包在IP层以上的字节内容，并将提取的字节内容转换成16进制文件；分别在每个16进制文件的头部加入标记，并将每个16进制文件的字节内容切割或填充到预设长度；使用所述神经网络模型对每个16进制文件的字节内容分别进行编码后，使用各个标记所对应的向量作为对应网络流量数据包的向量表示。5.根据权利要求4所述的加密流量识别方法，其特征在于，所述使用Transformer学习所述编码后的各个网络流量数据包之间的时序关系，获取各个网络流量数据包的特征表示包括：在所述加密流量识别模型的时序层，使用Transformer Encoder分别处理每个网络流量数据包的向量ei，使其融合其他网络流量数据包的信息，得到每个网络流量数据包的新的向量表示vi＝Transformer；对所述每个网络流量数据包的向量表示vi进行拼接，得到每个网络流量数据包的特征表示h1＝ConcatWo；其中，Wo是神经网络的权重矩阵，Concat代表将两个向量拼接。6.根据权利要求2至5任一项所述的加密流量识别方法，其特征在于，所述使用双向LSTM学习各个网络流量数据包的长度信息包括：在所述加密流量识别模型的补充层，分别提取每个网络流量数据包的原始长度信息，构建长度序列：L＝{l1，l2，...，lm}＝{length，length，...，length}；其中li表示数据包的长度，pi代表第i个数据包，length表示提取数据包的长度信息；使用双向LSTM对所述长度序列L进行学习，得到每个网络流量数据包的长度信息h2＝Concat，LSTM←)，其中li表示数据包的长度，Concat代表将两个向量拼接。7.根据权利要求6所述的加密流量识别方法，其特征在于，所述对所述各个网络流量数据包的特征表示和长度信息进行融合以及Softmax分类包括：在所述加密流量识别模型的分类层，对所述时序层中的h1进行全连接和Softmax分类，得到预测值γ1：并计算其交叉熵损失函数值loss1；其中，W、b是神经网络待学习的参数；对所述补充层中的h2进行全连接和Softmax分类，得到预测值γ2：并计算其交叉熵损失函数值loss2；将h1、h1进行拼接，得到h3＝Concat；对h3进行全连接和Softmax分类，得到预测值γ3：并计算其交叉熵损失函数值loss3；计算loss1、loss2、loss3之和并根据计算结果采用梯度下降算法更新所述加密流量识别模型的网络参数。8.一种加密流量识别系统，其特征在于，包括：预训练模块：用于获取网络流量数据包，使用Transformer Encoder学习各个网络流量数据包字节内容之间的关联性，训练一个具有数据包编码能力的神经网络模型；数据包编码模块：用于通过所述神经网络模型对所述网络流量数据包的字节内容进行编码；特征学习模块：用于使用Transformer学习所述编码后的各个网络流量数据包之间的时序关系，获取各个网络流量数据包的特征表示；长度学习模块：用于使用双向LSTM学习各个网络流量数据包的长度信息；融合及分类模块：用于对所述各个网络流量数据包的特征表示和长度信息进行融合以及Softmax分类，得到所述各个网络流量数据包的流量识别结果。9.一种终端，其特征在于，所述终端包括处理器、与所述处理器耦接的存储器，其中，所述存储器存储有用于实现权利要求1-7任一项所述的加密流量识别方法的程序指令；所述处理器用于执行所述存储器存储的所述程序指令以控制加密流量识别。10.一种存储介质，其特征在于，存储有处理器可运行的程序指令，所述程序指令用于执行权利要求1至7任一项所述加密流量识别方法。
说明书desc
技术领域本申请属于流量识别技术领域，特别涉及一种加密流量识别方法、系统、终端以及存储介质。背景技术流量识别，旨在将不同的网络流量分类到合适的类别，是网络管理和网络空间安全中的一项基本任务。传统的流量识别方法主要采用基于端口号的方法，该方法根据IANA提供的列表进行端口匹配，来确定流量的类别。但是随着越来越多的应用程序使用动态分配的端口或通用的通信协议端口进行伪装，这种方法已经变得不可靠。同时，随着人们的安全和隐私意识的逐渐提高，当前大多数应用流量都通过了各种各样的加密协议进行了加密，如IPsec、SSL/TLS、SSH等，这使得传统的流量分类方法不再有效。近年来，一些学者使用加密流量的流特征结合机器学习方法进行建模，取得了一定的效果。具体包括：一、基于消息类型的分类方法；每一个SSL/TLS的数据包header部分都有一个字段标识了该数据包的消息类型，可以把数据包序列抽象成一组消息类型的序列，不同类别的消息类型之间有着不同概率转移关系。基于消息类型的方法就是通过建立消息类型的马尔科夫模型，学习不同消息类型的状态转移矩阵。然而，考虑到可计算问题，基于消息序列的方法基本上只能使用一阶或者二阶马尔科夫模型，也就是说它只能使用2个或3个时间步的数据进行训练，因此学习到的时间信息非常有限。同时，由于消息类型的数目非常少，这会导致许多不同的流量之间会有相似的消息类型序列，重叠的消息类型会导致流量之间区分度不高，相似消息类型的不同类别流量将无法被精确地分开。另外，对于结合握手信息的方法，在真实场景中并不是所有的SSL/TLS流量都会含有这些信息：当短时间内恢复刚刚丢失的会话时，客户端和服务器之间不需要重新进行握手，这时候的网络流量就不含有握手包信息。二、基于长度序列的分类方法；基于长度序列的方法与基于消息类型的方法类似，它将网络流抽象成一个长度序列，然后使用马尔科夫模型，或者其他机器学习方法对序列进行建模。该方法的缺点在于：仅仅用包长度来代表数据包显然是一个非常朴素的简化，势必会丢失大量的细节。当数据包的长度一样或者接近的时候，长度序列将丧失区分性。三、基于统计特征的方法；这类方法主要思想是提取网络数据包的流级别，以此来表示一个通信流，然后结合其他机器学习算法进行分类。这些统计特征一般包括数据包的平均大小、平均间隔、传输速率等，有不少开源工具提供这些特征的提取功能。该方法的缺点在于：特征被高度抽象，使得细粒度的操作无法实现；提取流统计特征需要设定一个监听间隔，比如10s，15s，这使得实时的流量分类成为不可能。发明内容本申请提供了一种加密流量识别方法、系统、终端以及存储介质，旨在至少在一定程度上解决现有技术中的上述技术问题之一。为了解决上述问题，本申请提供了如下技术方案：一种加密流量识别方法，包括以下步骤：获取网络流量数据包，使用Transformer Encoder学习各个网络流量数据包字节内容之间的关联性，训练一个具有数据包编码能力的神经网络模型；通过所述神经网络模型对所述网络流量数据包的字节内容进行编码；使用Transformer学习所述编码后的各个网络流量数据包之间的时序关系，获取各个网络流量数据包的特征表示，并使用双向LSTM学习各个网络流量数据包的长度信息；对所述各个网络流量数据包的特征表示和长度信息进行融合以及Softmax分类，得到所述各个网络流量数据包的流量识别结果。本申请实施例采取的技术方案还包括：所述训练一个具有数据包编码能力的神经网络模型包括：搭建加密流量识别模型，所述加密流量识别模型包括预训练层、数据包编码层、时序层、补充层和分类层，在所述加密流量识别模型的预训练层训练所述神经网络模型。本申请实施例采取的技术方案还包括：所述训练一个具有数据包编码能力的神经网络模型包括：将所有网络流量数据包按照相同的五元组：＜源IP，目标IP，源端口，目标端口，传输协议＞进行划分，每一组代表一个双向通信流；提取每个网络流量数据包在IP层以上的字节内容，并将提取的字节内容转换成16进制文件；按照设定比例分别对每个16进制文件中的字节内容进行随机掩盖，并分别在每个文件头部加入标记；使用Transformer Encoder学习所述各个网络流量数据包字节内容之间的关联性，并恢复被掩盖的字节内容，使用交叉熵作为损失函数训练所述神经网络模型。本申请实施例采取的技术方案还包括：所述通过所述神经网络模型对所述网络流量数据包的字节内容进行编码包括：在所述加密流量识别模型的数据包编码层，提取每个网络流量数据包在IP层以上的字节内容，并将提取的字节内容转换成16进制文件；分别在每个16进制文件的头部加入标记，并将每个16进制文件的字节内容切割或填充到预设长度；使用所述神经网络模型对每个16进制文件的字节内容分别进行编码后，使用各个标记所对应的向量作为对应网络流量数据包的向量表示。本申请实施例采取的技术方案还包括：所述使用Transformer学习所述编码后的各个网络流量数据包之间的时序关系，获取各个网络流量数据包的特征表示包括：在所述加密流量识别模型的时序层，使用Transformer Encoder分别处理每个网络流量数据包的向量ei，使其融合其他网络流量数据包的信息，得到每个网络流量数据包的新的向量表示vi＝Transformer；对所述每个网络流量数据包的向量表示vi进行拼接，得到每个网络流量数据包的特征表示h1＝ConcatWo；其中，Wo是神经网络的权重矩阵，Concat代表将两个向量拼接。本申请实施例采取的技术方案还包括：所述使用双向LSTM学习各个网络流量数据包的长度信息包括：在所述加密流量识别模型的补充层，分别提取每个网络流量数据包的原始长度信息，构建长度序列：L＝{l1,l2,…,lm}＝{length,length,…,length}；其中li表示数据包的长度，pi代表第i个数据包，length表示提取数据包的长度信息；使用双向LSTM对所述长度序列L进行学习，得到每个网络流量数据包的长度信息h2＝Concat,LSTM←)；其中li表示数据包的长度，Concat代表将两个向量拼接。本申请实施例采取的技术方案还包括：所述对所述各个网络流量数据包的特征表示和长度信息进行融合以及Softmax分类包括：在所述加密流量识别模型的分类层，对所述时序层中的h1进行全连接和Softmax分类，得到预测值γ1：并计算其交叉熵损失函数值loss1；其中，W、b是神经网络待学习的参数；对所述补充层中的h2进行全连接和Softmax分类，得到预测值γ2：并计算其交叉熵损失函数值loss2；将h1、h1进行拼接，得到h3＝Concat；对h3进行全连接和Softmax分类，得到预测值γ3：并计算其交叉熵损失函数值loss3；计算loss1、loss2、loss3之和并根据计算结果采用梯度下降算法更新所述加密流量识别模型的网络参数。本申请实施例采取的另一技术方案为：一种加密流量识别系统，包括：预训练模块：用于获取网络流量数据包，使用Transformer Encoder学习各个网络流量数据包字节内容之间的关联性，训练一个具有数据包编码能力的神经网络模型；数据包编码模块：用于通过所述神经网络模型对所述网络流量数据包的字节内容进行编码；特征学习模块：用于使用Transformer学习所述编码后的各个网络流量数据包之间的时序关系，获取各个网络流量数据包的特征表示；长度学习模块：用于使用双向LSTM学习各个网络流量数据包的长度信息；融合及分类模块：用于对所述各个网络流量数据包的特征表示和长度信息进行融合以及Softmax分类，得到所述各个网络流量数据包的流量识别结果。本申请实施例采取的又一技术方案为：一种终端，所述终端包括处理器、与所述处理器耦接的存储器，其中，所述存储器存储有用于实现所述加密流量识别方法的程序指令；所述处理器用于执行所述存储器存储的所述程序指令以控制加密流量识别。本申请实施例采取的又一技术方案为：一种存储介质，存储有处理器可运行的程序指令，所述程序指令用于执行所述加密流量识别方法。相对于现有技术，本申请实施例产生的有益效果在于：本申请实施例的加密网络流量识别方法、系统、终端以及存储介质通过构建端到端的加密流量识别模型，通过随机掩盖部分数据包字节内容并通过Transformer进行恢复的无监督预训练方法，可以很好地学习不同数据包之间的关联性，更好地表达网络流量字节，以达到更好地数据包编码能力；通过分别对特征表示、长度信息以及特征表示和长度信息的融合分别进行一次损失函数值的计算，并用三个损失函数值之和进行梯度下降更新网络参数，以保证神经网络可以学习到数据包的原始字节信息和长度信息，提高网络性能，在保持数据包信息完整性的同时达到更好的加密流量识别效果。附图说明图1是本申请第一实施例的加密流量识别方法的流程图；图2是本申请第二实施例的加密流量识别方法的流程图；图3是本申请实施例的加密流量识别模型的结构示意图；图4为本申请实施例的加密流量识别系统结构示意图；图5为本申请实施例的终端结构示意图；图6为本申请实施例的存储介质的结构示意图。具体实施方式为了使本申请的目的、技术方案及优点更加清楚明白，以下结合附图及实施例，对本申请进行进一步详细说明。应当理解，此处所描述的具体实施例仅用以解释本申请，并不用于限定本申请。针对现有技术的不足，本申请实施例的加密流量识别方法提出一个数据包级别的端到端加密流量识别框架，该框架使用数据包原始字节+长度序列的策略，采用无监督的流量预训练以及自注意力机制方法学习数据包之间的深层联系，以保持数据包的信息完整性，达到更好的识别效果。具体的，请参阅图1，是本申请第一实施例的加密流量识别方法的流程图。本申请第一实施例的加密流量识别方法包括以下步骤：S1：获取网络流量数据包，使用Transformer Encoder学习各个网络流量数据包字节内容之间的关联性，训练一个具有数据包编码能力的神经网络模型；S2：通过所述神经网络模型对所述网络流量数据包的字节内容进行编码；S3：使用Transformer学习所述编码后的各个网络流量数据包之间的时序关系，获取各个网络流量数据包的特征表示，并使用双向LSTM学习各个网络流量数据包的长度信息；S4：对所述各个网络流量数据包的特征表示和长度信息进行融合以及Softmax分类，得到所述各个网络流量数据包的流量识别结果。请参阅图2，是本申请第二实施例的加密流量识别方法的流程图。本申请第二实施例的加密流量识别方法包括以下步骤：S10：搭建一个数据包级别的端到端的加密流量识别模型；本步骤中，加密流量识别模型结构如图3所示，其包括预训练层、数据包编码层、时序层、补充层和分类层。S20：在预训练层，获取大量无监督的网络流量数据包，使用Transformer Encoder学习各个网络流量数据包字节内容之间的关联性，训练出一个具有数据包编码能力的神经网络模型；本步骤中，预训练层的训练过程具体包括：S21：将所有网络流量数据包按照相同的五元组：＜源IP，目标IP，源端口，目标端口，传输协议＞进行划分，其中，每一组代表一个双向通信流；S22：提取每个网络流量数据包在IP层以上的字节内容，并将提取的字节内容转换成16进制文件；S23：按照设定比例分别对每个16进制文件中的字节内容进行随机掩盖，并分别在每个文件头部加入标记；S24：使用Transformer Encoder学习各个网络流量数据包字节内容之间的关联性，并恢复被掩盖的字节内容，使用交叉熵作为损失函数训练出一个具有数据包编码能力的神经网络模型。上述中，本申请实施例在预训练层采用随机掩盖数据包的部分字节内容并通过Transformer进行恢复的无监督预训练方法训练神经网络模型，可以更好地表达网络流量字节，以达到更好的数据包编码能力。S30：在数据包编码层，利用预训练层训练得到的神经网络模型对网络流量数据包的每个字节内容分别进行编码，并将编码后的网络流量数据包送入时序层；本步骤中，神经网络模型对网络流量数据包进行编码的实现过程具体包括：S31：提取每个网络流量数据包在IP层以上的字节内容，并将提取的字节内容转换成16进制文件；S32：分别在每个16进制文件的头部加入标记，并将每个16进制文件的字节内容切割或填充到预设长度；S33：使用神经网络模型对每个16进制文件的字节内容分别进行编码后，分别使用各个标记所对应的向量作为对应网络流量数据包的向量表示，并将其送入时序层；上述中，本申请实施例通过在数据包编码层补充每个数据包的长度信息，防止在切割或填充时造成的长度信息丢失，尽可能地保持了数据包信息的完整性。S40：在时序层中，使用Transformer学习各个网络流量数据包之间的时序关系，获取每个网络流量数据包的特征表示；本步骤中，时序层对时序关系的学习过程具体包括：S41：使用Transformer Encoder分别处理每个网络流量数据包的向量ei，使其融合其他网络流量数据包的信息，得到每个网络流量数据包的新的向量表示vi＝Transformer；S42：对每个网络流量数据包的向量表示vi进行拼接，得到每个网络流量数据包的特征表示h1＝ConcatWo；其中，Wo是神经网络的权重矩阵，Concat代表将两个向量拼接。S50：在补充层，以所有网络流量数据包的长度信息为输入，使用双向LSTM学习数据包长度序列的隐特征；本步骤中，网络流量数据包的长度信息学习过程具体包括：S51：分别提取每个网络流量数据包的原始长度信息，构建长度序列：L＝{l1,l2,…,lm}＝{length,length,…,length}；其中li表示数据包的长度，pi代表第i个数据包，length表示提取数据包的长度信息；S52：使用双向LSTM对长度序列L进行学习，得到每个网络流量数据包的长度信息h2＝Concat,LSTM←)；其中li表示数据包的长度，Concat代表将两个向量拼接。S60：以网络流量数据包的特征表示h1和长度信息h2作为分类层的输入，通过对特征表示h1和长度信息h2进行融合以及Softmax分类，输出各个网络流量数据包的流量识别结果；本步骤中，分类层对特征表示h1和长度信息h2的融合过程具体包括：S61：对时序层中的h1进行全连接和Softmax分类，得到预测值γ1：并计算其交叉熵损失函数值loss1；其中，W、b是神经网络待学习的参数。S62：对补充层中的h2进行全连接和Softmax分类，得到预测值γ2：并计算其交叉熵损失函数值loss2；S63：对h1、h1进行拼接，得到h3＝Concat；S64：对h3进行全连接和Softmax分类，得到预测值γ3：并计算其交叉熵损失函数值loss3；S65：计算三个损失函数值之和并根据计算结果采用梯度下降算法更新网络参数。上述中，本申请实施例在分类层中对每一部分均进行一次损失函数值的计算，并用三个损失函数值之和进行梯度下降更新网络参数，以保证神经网络学习到数据包的原始字节信息和长度信息，提高网络性能。基于上述，本申请实施例的加密网络流量识别方法通过构建端到端的加密流量识别模型，在模型的预训练层，通过随机掩盖部分数据包字节内容并通过Transformer进行恢复的无监督预训练方法，可以很好地学习不同数据包之间的关联性，更好地表达网络流量字节，以达到更好地数据包编码能力；通过在数据包编码层补充数据包的长度信息，防止了在切割或填充阶段的长度信息丢失，尽可能地保持了数据包信息的完整性；在分类层中，通过分别对时序层中的特征表示、补充层中的长度信息以及特征表示和长度信息的融合分别进行一次损失函数值的计算，并用三个损失函数值之和进行梯度下降更新网络参数，以保证神经网络可以学习到数据包的原始字节信息和长度信息，提高网络性能。本申请使用端到端策略，不需要额外进行特征工程等操作，在保持数据包信息完整性的同时达到更好的加密流量识别效果。请参阅图4，是本申请实施例的加密网络流量识别系统的结构示意图。本申请实施例的加密网络流量识别系统40包括：预训练模块41：用于获取网络流量数据包，使用Transformer Encoder学习各个网络流量数据包字节内容之间的关联性，训练一个具有数据包编码能力的神经网络模型；数据包编码模块42：用于通过所述神经网络模型对所述网络流量数据包的字节内容进行编码；特征学习模块43：用于使用Transformer学习所述编码后的各个网络流量数据包之间的时序关系，获取各个网络流量数据包的特征表示；长度学习模块44：用于使用双向LSTM学习各个网络流量数据包的长度信息；融合及分类模块45：用于对所述各个网络流量数据包的特征表示和长度信息进行融合以及Softmax分类，得到所述各个网络流量数据包的流量识别结果。请参阅图5，为本申请实施例的终端结构示意图。该终端50包括处理器51、与处理器51耦接的存储器52。存储器52存储有用于实现上述加密流量识别方法的程序指令。处理器51用于执行存储器52存储的程序指令以控制加密流量识别。其中，处理器51还可以称为CPU。处理器51可能是一种集成电路芯片，具有信号的处理能力。处理器51还可以是通用处理器、数字信号处理器、专用集成电路、现成可编程门阵列或者其他可编程逻辑器件、分立门或者晶体管逻辑器件、分立硬件组件。通用处理器可以是微处理器或者该处理器也可以是任何常规的处理器等。请参阅图6，为本申请实施例的存储介质的结构示意图。本申请实施例的存储介质存储有能够实现上述所有方法的程序文件61，其中，该程序文件61可以以软件产品的形式存储在上述存储介质中，包括若干指令用以使得一台计算机设备或处理器执行本发明各个实施方式方法的全部或部分步骤。而前述的存储介质包括：U盘、移动硬盘、只读存储器、随机存取存储器、磁碟或者光盘等各种可以存储程序代码的介质，或者是计算机、服务器、手机、平板等终端设备。对所公开的实施例的上述说明，使本领域专业技术人员能够实现或使用本申请。对这些实施例的多种修改对本领域的专业技术人员来说将是显而易见的，本申请中所定义的一般原理可以在不脱离本申请的精神或范围的情况下，在其它实施例中实现。因此，本申请将不会被限制于本申请所示的这些实施例，而是要符合与本申请所公开的原理和新颖特点相一致的最宽的范围。
