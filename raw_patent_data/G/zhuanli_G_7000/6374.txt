标题title
基于ARMv8多核处理器的小型和不规则矩阵乘优化方法
摘要abst
本发明公开了一种基于ARMv8多核处理器的小型和不规则矩阵乘优化方法，利用ARMv8多核处理器实现,其步骤包括：建立矩阵存储空间，用于存放矩阵A与矩阵B相乘得到的结果矩阵C；ARMv8多核处理器对矩阵B执行打包操作，并将打包操作和小型矩阵乘的计算操作同步进行。本方法对于不同模式的矩阵乘选择不同打包策略来节省打包开销，使用更加高效的边缘微内核来处理边缘案例，此外还采用更加合理的并行化方法来并行化矩阵乘，这些对ARMv8多核处理器中的小型和不规则矩阵乘的性能进行了大幅优化，这能促进ARMV8多核处理器上其他实际应用的发展。
权利要求书clms
1.一种基于ARMv8多核处理器的小型矩阵乘优化方法，其特征在于，利用ARMv8多核处理器实现,其步骤包括：S1，对于参与相乘运算的两个矩阵，乘号左侧的矩阵称为矩阵A，乘号右侧的矩阵称为矩阵B，判断矩阵A和矩阵B是否被转置，在相乘运算中，若矩阵没被转置称为N模式，矩阵被转置称为T模式，若矩阵A为N模式，矩阵B为T模式，则将该小型矩阵乘法称为NT模式，若矩阵A为N模式，矩阵B为N模式，则将该小型矩阵乘法称为NN模式；建立矩阵存储空间，用于存放矩阵A与矩阵B相乘得到的结果矩阵C；S2,对于NT模式的小型矩阵乘，ARMv8多核处理器对矩阵B执行打包操作，并将打包操作和小型矩阵乘的计算操作同步进行；将ARMv8多核处理器中负责打包的微内核称为打包微内核，将ARMv8多核处理器中负责计算的微内核称为主微内核；为了将打包的访存开销隐藏在计算过程中，实现矩阵乘的微内核要在ARMv8处理器器中需要具有足够高的计算访存比CMR，其中CMR的计算公式和约束条件为：其中mr和nr分别为ARMv8多核处理器上的向量寄存器所能存储的最大矩阵的行数和列数，同时也是主微内核在向量寄存器上所占用的存储空间矩阵的行数和列数；C0为计算访存比CMR的下限；ARMv8多核处理器提供了32个128bit的向量寄存器，该32个128bit的向量寄存器命名为寄存器V0、V1、V2、…、V31，因此mr和nr还需要满足的约束条件为：其中j表示ARMv8多核处理器的一个向量寄存器可以加载数据元素的个数，％表示求模；以计算访存比的约束条件、mr和nr的约束条件为目标函数，使用拉格朗日乘子法，求解得到mr0和nr0，作为主微内核在向量寄存器上所占用的存储空间矩阵的行数和列数的取值；在NT模式下实现小型矩阵乘时，用于对矩阵B进行打包的微内核，所占用向量寄存器的存储空间矩阵的维度为mp×np，其中mp＝mr0,np＝nr0/N0,经过N0次调用打包微内核，得到一个主微内核实现小型矩阵乘计算所需的数据；在对矩阵B进行打包的过程中，ARMv8多核处理器沿着矩阵A的行方向访问矩阵A，沿着矩阵B的列方向访问矩阵B，使用内积公式更新矩阵C；ARMv8多核处理器在沿上述方向对矩阵A和矩阵B分别进行访问的过程中，使用mp次加载指令将矩阵A的元素存储到从V0开始依次至V的mp个向量寄存器中，并使用np次加载指令将矩阵B的元素存储到从V开始依次至V的np个向量寄存器中；ARMv8多核处理器在微内核打包过程中执行mp×np次向量乘加融合指令FMA，以产生矩阵C的N0×mp×np个中间结果元素，这些元素存储在从V依次至V31的向量寄存器中，同时将从V开始依次至V的np个向量寄存器中的前N0个元素存储到内存空间Bc，Bc为临时开辟的用于存放矩阵B的部分元素的连续内存空间，该N0个元素之间在内存空间Bc上的物理距离为nr0个元素，从V开始依次至V的np个向量寄存器中的相同位置的元素存储到内存空间Bc的相邻位置上；所述的用于打包的微内核中实现小型矩阵乘计算使用内积公式，主微内核实现小型矩阵乘计算使用外积公式；对于NN模式的小型矩阵乘，如果矩阵B的大小超过ARMv8多核处理器的一级缓存后，ARMv8多核处理器对矩阵B执行打包操作，将其打包到内存空间Bc中，并将打包操作和小型矩阵乘的计算操作同步进行，该打包操作和计算操作均通过迭代来实现，否则直接执行步骤S3；每次迭代中，将矩阵A的元素存储到从V0开始依次至V的mp个向量寄存器中，将矩阵B的元素存储到从V开始依次至V的np个向量寄存器中；从V0开始依次至V的mp个向量寄存器，在每次迭代中，每个向量寄存器都只有一个元素用来参与小型矩阵乘的计算操作，从而需要N0次迭代，才能使得每个向量寄存器中的元素均参与到小型矩阵乘的计算操作中；而从V开始依次至V的np个向量寄存器的所有元素在一次迭代中就使用完毕，在下一轮的迭代中又需要重新从矩阵B中取数据；当所有迭代完成之后，矩阵C的1行至mr0行已经被更新，内存空间Bc已经被矩阵B的打包数据填充完整；S3,ARMv8多核处理器使用内存空间Bc中的已经打包的数据来更新矩阵C的mr0行到M行的元素；步骤S2得到的内存空间Bc来提供计算矩阵C的mr0+1行至M行所需的数据，此步骤对于NN模式与NT模式，其实现流程是相同的；矩阵C的mr0+1行至M行的计算操作通过迭代来完成；ARMv8多核处理器从矩阵A中选择mr0行，对其每一行分别取N0个元素，存放到从V0开始依次至V的mr0个向量寄存器中，该操作称为取数操作，该mr0行的地址是不连续的，相互之间的距离为N0×K个字节，在N0次迭代结束后再次执行该取数操作；在每次迭代中，内存空间Bc中的元素被取出并存储到从V开始依次至V的np个向量寄存器中，将矩阵A中取出的每个元素作为标量，每次迭代中从内存空间Bc中取出nr0个元素作为向量，二者依次相乘，得到N0×mp×np个元素，存储在从V依次至V31的向量寄存器中；在矩阵C的mr0+1行至M行的计算过程中，有部分执行数据预取操作的指令被插入计算与访存指令的执行时间间隙中；数据预取操作是指在计算指令执行前，将数据从内存预先取出到缓存中；S4,当M％mr0不为0或N％nr0不为0时，调用ARMv8多核处理器中处理边缘数据的微内核，简称边缘微内核；对于边缘微内核的实现，其计算指令和访存指令需要按照计算需求进行排布，以确保计算指令所需的数据在执行计算指令前，已存放至向量寄存器中；计算指令FMA所需的数据提前通过取数据指令加载到向量寄存器中；S5,在沿着K维度进行的循环迭代结束后，将ARMv8多核处理器中存储矩阵C的相关向量寄存器中的数据存回到内存中的矩阵C。2.一种基于ARMv8多核处理器的不规则矩阵乘优化方法，其特征在于，利用ARMv8多核处理器实现,其步骤包括：S1，对于参与相乘运算的两个矩阵，乘号左侧的矩阵称为矩阵A，乘号右侧的矩阵称为矩阵B，判断矩阵A和矩阵B是否被转置，在相乘运算中，若矩阵没被转置称为N模式，矩阵被转置称为T模式，若矩阵A为N模式，矩阵B为T模式，则将该不规则矩阵乘法称为NT模式，若矩阵A为N模式，矩阵B为N模式，则将该不规则矩阵乘法称为NN模式；建立矩阵存储空间，用于存放矩阵A与矩阵B相乘得到的结果矩阵C；S2,确定对不规则形状矩阵乘的行方向和列方向的数据进行并行化处理所需要的并行线程数，为了保证并行线程之间的工作平衡，对矩阵C的行方向和列方向的数据分别进行并行化；将矩阵C划分为二维的子块网格，每个并行线程更新一个子块网格；当使用T个并行线程对矩阵C的计算负载进行划分时，每个并行线程将执行次计算矩阵乘法的操作；每个并行线程所需的内存访问次数为其中Tm和Tn分别是分配给M维和N维度数据的并行线程数，Tm×Tn＝T；对于一个子块网格的CMR，其计算公式为：为了最大化CMR，使用算术-几何平均不等式，得到该CMR的取值范围为：考虑S2中执行微内核打包的开销，取Tn的上界值，即以最大化CMR，表示向上取整；S3，在NN模式的不规则形状矩阵乘中，如果矩阵B的大小超过最后一级缓存的容量，将t×nr0个元素打包到内存空间Bc中，其中t为自然数；打包微内核中的mr和nr的取值与主内核中对应值的取值相同；小型和不规则形状的矩阵乘的t值分别设置为0和1；S4,当M％mr0不为0或N％nr0不为0时，调用ARMv8多核处理器中处理边缘数据的微内核，简称边缘微内核；对于边缘微内核的实现，其计算指令和访存指令需要按照计算需求进行排布，以确保计算指令所需的数据在执行计算指令前，已存放至向量寄存器中；计算指令FMA所需的数据提前通过取数据指令加载到向量寄存器中；S5,在沿着K维度进行的循环迭代结束后，将ARMv8多核处理器中存储矩阵C的相关向量寄存器中的数据存回到内存中的矩阵C。
说明书desc
技术领域本发明涉及高性能计算领域，尤其涉及一种基于ARMv8多核处理器的小型和不规则矩阵乘优化方法。背景技术通用矩阵乘法是从传统科学模拟到新兴的深度学习高性能计算应用的基本构建块。如何对GEMM进行优化，是一个被大量研究的领域，但现有的线性代数库方法主要针对大型和规则形状的GEMM。由于HPC工作负载的多样性和不断发展，GEMM内核的输入矩阵的大小和形状可能会因所使用的应用程序算法和输入数据而异。例如，计算流体动力学中，如有限元方法和波动方程，通常采用在小矩阵上运行的GEMM实现，以在现代多核系统上实现良好的可扩展性能。例如，流行的分子动力学模拟器CP2K在大小为5×5和23×23的矩阵上执行GEMM。又例如，用于CFD的Nek5000高阶求解器的内核严重依赖于8×8矩阵的GEMMs计算。除了这些传统的HPC应用程序之外，实现深度学习和机器学习方法等HPC应用程序建立在小的GEMM内核上，其中一些数据分析算法还需要对不规则形状的矩阵进行操作，而其中不同的矩阵维度的大小有显著差异。例如,ResNet深度神经网络的卷积核使用的GEMM计算一维等于64而另一维大于3000的矩阵。这些利用HPC求解的矩阵特性使得我们需要对GEMM计算方式进行优化。尽管像OpenBLAS和BLIS这样的传统线性代数库可以在大型和规则形状的GEMM上提供接近最佳的性能，但它们在小型GEMM上的性能通常很差。虽然现有方法在x86和GPU架构上提供了可喜的结果，但现有的解决方案不足以优化基于ARMv8的CPU架构上的小型和不规则形状GEMM。发明内容GEMM是矩阵的乘加运算操作，定义为C＝αA·B+βC，其中A和B是矩阵输入，α和β是标量输入，C是预先存在的矩阵被输出覆盖的矩阵。矩阵A表示为M×K的输入矩阵，即M行K列，矩阵B的大小为K×N,即即K行N列,C的大小是M×N,为输出矩阵。针对现有的BLAS库难以适应小型和不规则GEMM，且在基于ARMv8的CPU架构上求解小型和不规则GEMM效率偏低的问题，本发明公开了一种基于ARMv8多核处理器的小型和不规则矩阵乘优化方法。本发明公开了一种基于ARMv8多核处理器的小型矩阵乘优化方法，利用ARMv8多核处理器实现,其步骤包括：S1，对于参与相乘运算的两个矩阵，乘号左侧的矩阵称为矩阵A，乘号右侧的矩阵称为矩阵B，判断矩阵A和矩阵B是否被转置，在相乘运算中，若矩阵没被转置称为N模式，矩阵被转置称为T模式，若矩阵A为N模式，矩阵B为T模式，则将该小型矩阵乘法称为NT模式，若矩阵A为N模式，矩阵B为N模式，则将该小型矩阵乘法称为NN模式；建立矩阵存储空间，用于存放矩阵A与矩阵B相乘得到的结果矩阵C；S2,对于NT模式的小型矩阵乘，ARMv8多核处理器对矩阵B执行打包操作，并将打包操作和小型矩阵乘的计算操作同步进行。将ARMv8多核处理器中负责打包的微内核称为打包微内核，将ARMv8多核处理器中负责计算的微内核称为主微内核。为了将打包的访存开销隐藏在计算过程中，实现矩阵乘的微内核要在ARMv8处理器器中需要具有足够高的计算访存比CMR，其中CMR的计算公式和约束条件为：其中mr和nr分别为ARMv8多核处理器上的向量寄存器所能存储的最大矩阵的行数和列数，同时也是主微内核在向量寄存器上所占用的存储空间矩阵的行数和列数。C0为计算访存比CMR的下限。ARMv8多核处理器提供了32个128bit的向量寄存器，该32个128bit的向量寄存器命名为寄存器V0、V1、V2、…、V31，因此mr和nr还需要满足的约束条件为：其中j表示ARMv8多核处理器的一个向量寄存器可以加载数据元素的个数，％表示求模。以计算访存比的约束条件、mr和nr的约束条件为目标函数，使用拉格朗日乘子法，求解得到mr0和nr0，作为主微内核在向量寄存器上所占用的存储空间矩阵的行数和列数的取值。在NT模式下实现小型矩阵乘时，用于对矩阵B进行打包的微内核，所占用向量寄存器的存储空间矩阵的维度为mp×np，其中mp＝mr0,np＝nr0/N0,经过N0次调用打包微内核，得到一个主微内核实现小型矩阵乘计算所需的数据。在对矩阵B进行打包的过程中，ARMv8多核处理器沿着矩阵A的行方向访问矩阵A，沿着矩阵B的列方向访问矩阵B，使用内积公式更新矩阵C。ARMv8多核处理器在沿上述方向对矩阵A和矩阵B分别进行访问的过程中，使用mp次加载指令将矩阵A的元素存储到从V0开始依次至V的mp个向量寄存器中，并使用np次加载指令将矩阵B的元素存储到从V开始依次至V的np个向量寄存器中。ARMv8多核处理器在微内核打包过程中执行mp×np次向量乘加融合指令FMA，以产生矩阵C的N0×mp×np个中间结果元素，这些元素存储在从V依次至V31的向量寄存器中，同时将从V开始依次至V的np个向量寄存器中的前N0个元素存储到内存空间Bc，Bc为临时开辟的用于存放矩阵B的部分元素的连续内存空间，该N0个元素之间在内存空间Bc上的物理距离为nr0个元素，从V开始依次至V的np个向量寄存器中的相同位置的元素存储到内存空间Bc的相邻位置上。所述的用于打包的微内核中实现小型矩阵乘计算使用内积公式，主微内核实现小型矩阵乘计算使用外积公式。对于NN模式的小型矩阵乘，如果矩阵B的大小超过ARMv8多核处理器的一级缓存后，ARMv8多核处理器对矩阵B执行打包操作，将其打包到内存空间Bc中，并将打包操作和小型矩阵乘的计算操作同步进行，该打包操作和计算操作均通过迭代来实现，否则直接执行步骤S3。每次迭代中，将矩阵A的元素存储到从V0开始依次至V的mp个向量寄存器中，将矩阵B的元素存储到从V开始依次至V的np个向量寄存器中。从V0开始依次至V的mp个向量寄存器，在每次迭代中，每个向量寄存器都只有一个元素用来参与小型矩阵乘的计算操作，从而需要N0次迭代，才能使得每个向量寄存器中的元素均参与到小型矩阵乘的计算操作中。而从V开始依次至V的np个向量寄存器的所有元素在一次迭代中就使用完毕，在下一轮的迭代中又需要重新从矩阵B中取数据。当所有迭代完成之后，矩阵C的1行至mr0行已经被更新，内存空间Bc已经被矩阵B的打包数据填充完整。S3,ARMv8多核处理器使用内存空间Bc中的已经打包的数据来更新矩阵C的mr0行到M行的元素。步骤S2得到的内存空间Bc来提供计算矩阵C的mr0+1行至M行所需的数据，此步骤对于NN模式与NT模式，其实现流程是相同的。矩阵C的mr0+1行至M行的计算操作通过迭代来完成。ARMv8多核处理器从矩阵A中选择mr0行，对其每一行分别取N0个元素，存放到从V0开始依次至V的mr0个向量寄存器中，该操作称为取数操作，该mr0行的地址是不连续的，相互之间的距离为N0×K个字节，在N0次迭代结束后再次执行该取数操作。在每次迭代中，内存空间Bc中的元素被取出并存储到从V开始依次至V的np个向量寄存器中，将矩阵A中取出的每个元素作为标量，每次迭代中从内存空间Bc中取出nr0个元素作为向量，二者依次相乘，得到N0×mp×np个元素，存储在从V依次至V31的向量寄存器中。在矩阵C的mr0+1行至M行的计算过程中，有部分执行数据预取操作的指令被插入计算与访存指令的执行时间间隙中。数据预取操作是指在计算指令执行前，将数据从内存预先取出到缓存中。S4,当M％mr0不为0或N％nr0不为0时，调用ARMv8多核处理器中处理边缘数据的微内核，简称边缘微内核。对于边缘微内核的实现，其计算指令和访存指令需要按照计算需求进行排布，以确保计算指令所需的数据在执行计算指令前，已存放至向量寄存器中。计算指令FMA所需的数据提前通过取数据指令加载到向量寄存器中。S5,在沿着K维度进行的循环迭代结束后，将ARMv8多核处理器中存储矩阵C的相关向量寄存器中的数据存回到内存中的矩阵C。本发明公开了一种基于ARMv8多核处理器的不规则矩阵乘优化方法，利用ARMv8多核处理器实现,其步骤包括：S1，对于参与相乘运算的两个矩阵，乘号左侧的矩阵称为矩阵A，乘号右侧的矩阵称为矩阵B，判断矩阵A和矩阵B是否被转置，在相乘运算中，若矩阵没被转置称为N模式，矩阵被转置称为T模式，若矩阵A为N模式，矩阵B为T模式，则将该不规则矩阵乘法称为NT模式，若矩阵A为N模式，矩阵B为N模式，则将该不规则矩阵乘法称为NN模式；建立矩阵存储空间，用于存放矩阵A与矩阵B相乘得到的结果矩阵C；S2,确定对不规则形状矩阵乘的行方向和列方向的数据进行并行化处理所需要的并行线程数，为了保证并行线程之间的工作平衡，对矩阵C的行方向和列方向的数据分别进行并行化。将矩阵C划分为二维的子块网格，每个并行线程更新一个子块网格。当使用T个并行线程对矩阵C的计算负载进行划分时，每个并行线程将执行次计算矩阵乘法的操作。每个并行线程所需的内存访问次数为其中Tm和Tn分别是分配给M维和N维度数据的并行线程数，Tm×Tn＝T。对于一个子块网格的CMR，其计算公式为：为了最大化CMR，使用算术-几何平均不等式，得到该CMR的取值范围为：考虑S2中执行微内核打包的开销，取Tn的上界值，即以最大化CMR，表示向上取整。S3，在NN模式的不规则形状矩阵乘中，如果矩阵B的大小超过最后一级缓存的容量，将t×nr0个元素打包到内存空间Bc中，其中t为自然数。打包微内核中的mr和nr的取值与主内核中对应值的取值相同。小型和不规则形状的矩阵乘的t值分别设置为0和1。S4,当M％mr0不为0或N％nr0不为0时，调用ARMv8多核处理器中处理边缘数据的微内核，简称边缘微内核。对于边缘微内核的实现，其计算指令和访存指令需要按照计算需求进行排布，以确保计算指令所需的数据在执行计算指令前，已存放至向量寄存器中。计算指令FMA所需的数据提前通过取数据指令加载到向量寄存器中。S5,在沿着K维度进行的循环迭代结束后，将ARMv8多核处理器中存储矩阵C的相关向量寄存器中的数据存回到内存中的矩阵C。本发明的有益效果为：本方法对于不同模式的矩阵乘选择不同打包策略来节省打包开销，使用更加高效的边缘微内核来处理边缘案例，此外还采用更加合理的并行化方法来并行化矩阵乘，这些对ARMv8多核处理器中的小型和不规则矩阵乘的性能进行了大幅优化，这能促进ARMV8多核处理器上其他实际应用的发展。附图说明图1为NN模式下小型矩阵乘的内核设计；图2为NT模式下矩阵乘的打包微内核设计；图3为边缘微内核的设计；图4为NT模式下不规则矩阵乘的微内核流程图；图5为单线程小型矩阵乘的性能；图6为单线程小型矩阵乘的性能；图7为多线程不规则矩阵乘在Phytium 2000+上的性能；图8为多线程不规则矩阵乘在KP920和Thunder X2上的性能；图9为LibShalom对于CP2K中使用矩阵的性能；图10为LibShalom对于VGG中使用矩阵的性能。具体实施方式为了更好的了解本发明内容，这里给出一个实施例。图1为NN模式下小型矩阵乘的内核设计；图2为NT模式下矩阵乘的打包微内核设计；图3为边缘微内核的设计；图4为NT模式下不规则矩阵乘的微内核流程图；图5为单线程小型矩阵乘的性能；图6为单线程小型矩阵乘的性能；图7为多线程不规则矩阵乘在Phytium2000+上的性能；图8为多线程不规则矩阵乘在KP920和Thunder X2上的性能；图9为LibShalom对于CP2K中使用矩阵的性能；图10为LibShalom对于VGG中使用矩阵的性能。针对现有的BLAS库难以适应小型和不规则GEMM，且在基于ARMv8的CPU架构上求解小型和不规则GEMM效率偏低的问题，本发明公开了一种ARMv8多核处理器上小型和不规则形状矩阵乘的优化方法。本发明公开了一种基于ARMv8多核处理器的小型矩阵乘优化方法，利用ARMv8多核处理器实现,其步骤包括：S1，对于参与相乘运算的两个矩阵，乘号左侧的矩阵称为矩阵A，乘号右侧的矩阵称为矩阵B，判断矩阵A和矩阵B是否被转置，在相乘运算中，若矩阵没被转置称为N模式，矩阵被转置称为T模式，若矩阵A为N模式，矩阵B为T模式，则将该小型矩阵乘法称为NT模式，若矩阵A为N模式，矩阵B为N模式，则将该小型矩阵乘法称为NN模式；建立矩阵存储空间，用于存放矩阵A与矩阵B相乘得到的结果矩阵C；S2,对于NT模式的小型矩阵乘，ARMv8多核处理器对矩阵B执行打包操作，并将打包操作和小型矩阵乘的计算操作同步进行。将ARMv8多核处理器中负责打包的微内核称为打包微内核，将ARMv8多核处理器中负责计算的微内核称为主微内核。为了将打包的访存开销隐藏在计算过程中，实现矩阵乘的微内核要在ARMv8处理器器中需要具有足够高的计算访存比CMR，其中CMR的计算公式和约束条件为：其中mr和nr分别为ARMv8多核处理器上的向量寄存器所能存储的最大矩阵的行数和列数，同时也是主微内核在向量寄存器上所占用的存储空间矩阵的行数和列数。C0为计算访存比CMR的下限，其与ARMv8多核处理器的向量寄存器容量有关。ARMv8多核处理器提供了32个128bit的向量寄存器，该32个128bit的向量寄存器命名为寄存器V0、V1、V2、…、V31，因此mr和nr还需要满足的约束条件为：其中j表示ARMv8多核处理器的一个向量寄存器可以加载数据元素的个数，％表示求模。对于单精度浮点数而言，j＝4。以计算访存比的约束条件、mr和nr的约束条件为目标函数，使用拉格朗日乘子法，求解得到mr0和nr0，作为主微内核在向量寄存器上所占用的存储空间矩阵的行数和列数的取值。为了方便在后续计算中使用该主微内核，在NT模式下实现小型矩阵乘时，用于对矩阵B进行打包的微内核，所占用向量寄存器的存储空间矩阵的维度为mp×np，其中mp＝mr0,np＝nr0/N0,经过N0次调用打包微内核，得到一个主微内核实现小型矩阵乘计算所需的数据，其流程如图1所示。在对矩阵B进行打包的过程中，ARMv8多核处理器沿着矩阵A的行方向访问矩阵A，沿着矩阵B的列方向访问矩阵B，使用内积公式更新矩阵C。ARMv8多核处理器在沿上述方向对矩阵A和矩阵B分别进行访问的过程中，使用mp次加载指令将矩阵A的元素存储到从V0开始依次至V的mp个向量寄存器中，并使用np次加载指令将矩阵B的元素存储到从V开始依次至V的np个向量寄存器中。ARMv8多核处理器在微内核打包过程中执行mp×np次向量乘加融合指令FMA，以产生矩阵C的N0×mp×np个中间结果元素，这些元素存储在从V依次至V31的向量寄存器中，同时将从V开始依次至V的np个向量寄存器中的前N0个元素存储到内存空间Bc，Bc为临时开辟的用于存放矩阵B的部分元素的连续内存空间，该N0个元素之间在内存空间Bc上的物理距离为nr0个元素，从V开始依次至V的np个向量寄存器中的相同位置的元素存储到内存空间Bc的相邻位置上。所述的从V开始依次至V的np个向量寄存器中的相同位置的元素，例如向量V7的4个元素分别编号为a0,a1,a2,a3；向量V8的4个元素分别编号为b0,b1,b2,b3；这里的a0与b0就属于相同位置的元素。所述的用于打包的微内核中实现小型矩阵乘计算使用内积公式，主微内核实现小型矩阵乘计算使用外积公式。对于NN模式的小型矩阵乘，如果矩阵B的大小超过ARMv8多核处理器的一级缓存后，ARMv8多核处理器对矩阵B执行打包操作，将其打包到内存空间Bc中，并将打包操作和小型矩阵乘的计算操作同步进行,其流程如图2所示，该打包操作和计算操作均通过迭代来实现，否则直接执行步骤S3。每次迭代中，将矩阵A的元素存储到从V0开始依次至V的mp个向量寄存器中，将矩阵B的元素存储到从V开始依次至V的np个向量寄存器中。从V开始依次至V的np个向量寄存器中，每个向量寄存器可以装下N0个单精度浮点元素。从V0开始依次至V的mp个向量寄存器，在每次迭代中，每个向量寄存器都只有一个元素用来参与小型矩阵乘的计算操作，从而需要N0次迭代，才能使得每个向量寄存器中的元素均参与到小型矩阵乘的计算操作中。而从V开始依次至V的np个向量寄存器的所有元素在一次迭代中就使用完毕，在下一轮的迭代中又需要重新从矩阵B中取数据。上述的迭代指的是沿着矩阵A和矩阵B的K个维度进行循环的迭代。当所有迭代完成之后，矩阵C的1行至mr0行已经被更新，内存空间Bc已经被矩阵B的打包数据填充完整。S3,ARMv8多核处理器使用内存空间Bc中的已经打包的数据来更新矩阵C的mr0行到M行的元素。步骤S2得到的内存空间Bc来提供计算矩阵C的mr0+1行至M行所需的数据，此步骤对于NN模式与NT模式，其实现流程是相同的。矩阵C的mr0+1行至M行的计算操作通过迭代来完成。ARMv8多核处理器从矩阵A中选择mr0行，对其每一行分别取N0个元素，存放到从V0开始依次至V的mr0个向量寄存器中，该操作称为取数操作，该mr0行的地址是不连续的，相互之间的距离为N0×K个字节，在N0次迭代结束后再次执行该取数操作。在每次迭代中，内存空间Bc中的元素被取出并存储到从V开始依次至V的np个向量寄存器中，将矩阵A中取出的每个元素作为标量，每次迭代中从内存空间Bc中取出nr0个元素作为向量，二者依次相乘，得到N0×mp×np个元素，存储在从V依次至V31的向量寄存器中。在矩阵C的mr0+1行至M行的计算过程中，有部分执行数据预取操作的指令被插入计算与访存指令的执行时间间隙中。数据预取操作是指在计算指令执行前，将数据从内存预先取出到缓存中。在迭代操作中，使用的循环展开因子为8，即要把8轮迭代用代码实现出来，然后嵌套在循环嵌套中，而不是只实现1次循环的迭代，然后就用循环嵌套。S4,在经过前面的更新步骤后，矩阵C可能还会剩下一些边缘数据没有被更新，这是由于M％mr0或N％nr0不为0，即结果矩阵C的大小M×N不能被主微内核的大小mr×nr整除。当M％mr0不为0或N％nr0不为0时，调用ARMv8多核处理器中处理边缘数据的微内核，简称边缘微内核。对于边缘微内核的实现，其计算指令和访存指令需要按照计算需求进行排布，以确保计算指令所需的数据在执行计算指令前，已存放至向量寄存器中。计算指令FMA所需的数据提前通过取数据指令加载到向量寄存器中，如图3所示。这里的FMA是处理器的乘加融合指令，load是取数据指令。S5,在沿着K维度进行的循环迭代结束后，将ARMv8多核处理器中存储矩阵C的相关向量寄存器中的数据存回到内存中的矩阵C。对于基于ARMv8多核处理器的不规则形状矩阵乘的实现，本发明公开了一种基于ARMv8多核处理器的不规则矩阵乘优化方法，利用ARMv8多核处理器实现,其步骤包括：S1，对于参与相乘运算的两个矩阵，乘号左侧的矩阵称为矩阵A，乘号右侧的矩阵称为矩阵B，判断矩阵A和矩阵B是否被转置，在相乘运算中，若矩阵没被转置称为N模式，矩阵被转置称为T模式，若矩阵A为N模式，矩阵B为T模式，则将该小型矩阵乘法称为NT模式，若矩阵A为N模式，矩阵B为N模式，则将该小型矩阵乘法称为NN模式；建立矩阵存储空间，用于存放矩阵A与矩阵B相乘得到的结果矩阵C；S2,确定对不规则形状矩阵乘的行方向和列方向的数据进行并行化处理所需要的并行线程数，为了保证并行线程之间的工作平衡，对矩阵C的行方向和列方向的数据分别进行并行化。将矩阵C划分为二维的子块网格，每个并行线程更新一个子块网格。当使用T个并行线程对矩阵C的计算负载进行划分时，每个并行线程将执行次计算矩阵乘法的操作。每个并行线程所需的内存访问次数为其中Tm和Tn分别是分配给M维和N维度数据的并行线程数，Tm×Tn＝T。对于一个子块网格的CMR，其计算公式为：为了最大化CMR，使用算术-几何平均不等式，得到该CMR的取值范围为：如果则方程的两边将相等。换句话说，当时，CMR取得最大值。考虑S2中执行微内核打包的开销，取Tn的上界值，即以最大化CMR。我们注意到TmodTn＝0，以确保内核数量可以在并行线程之间平均分配。表示向上取整。S3，在NN模式的不规则形状矩阵乘中，如果矩阵B的大小超过最后一级缓存的容量，将t×nr0个元素打包到内存空间Bc中，其中t为自然数。打包微内核中的mr和nr的取值与主内核中对应值的取值相同。小型和不规则形状的矩阵乘的t值分别设置为0和1。这意味着前者在每次迭代中只执行图4中的step①，不规则形状矩阵乘需要执行step①和②。S4,在经过前面的更新步骤后，矩阵C可能还会剩下一些边缘数据没有被更新，这是由于M％mr0或N％nr0不为0，即结果矩阵C的大小M×N不能被主微内核的大小mr×nr整除。当M％mr0不为0或N％nr0不为0时，调用ARMv8多核处理器中处理边缘数据的微内核，简称边缘微内核。对于边缘微内核的实现，其计算指令和访存指令需要按照计算需求进行排布，以确保计算指令所需的数据在执行计算指令前，已存放至向量寄存器中。计算指令FMA所需的数据提前通过取数据指令加载到向量寄存器中，如图3所示。这里的FMA是处理器的乘加融合指令，load是取数据指令。S5,在沿着K维度进行的循环迭代结束后，将ARMv8多核处理器中存储矩阵C的相关向量寄存器中的数据存回到内存中的矩阵C。设计LibShalom的目的是为了克服在ARMv8处理器上优化小型和不规则GEMM性能不高的问题，该方法将计算与打包操作重叠看，对边缘微内核进行了高度优化，使用更加合理地并行化方法来开展优化。这里对LibShalom是否到达上述目的进行了有效性评估。图5和图6在Phyituym 2000+、KP920和ThunderX2这三个ARMv8处理器上评测单线程小型GEMM的性能。图5和图6中的、和子图分别是在Phyituym 2000+、KP920和ThunderX2这三个ARMv8处理器上评测单线程小型GEMM的性能。图7和图8展示了多线程不规则GEMM的性能。图9展示了对于CP2K中使用到的矩阵的性能，其中、和子图分别是在Phyituym2000+、KP920和ThunderX2这三个ARMv8处理器上得到的性能。图10显示了对于卷积神经网络VGG中使用到的矩阵的性能，其中、和子图分别是在Phyituym 2000+、KP920和ThunderX2这三个ARMv8处理器上得到的性能。图5和6给出了LibShalom、OpenBLAS、BLIS、ARMPL、LIBXSMM、BLASFEO的性能柱状图。实验中的数据规模M×N×K从8×8×8到120×120×120，运行20次计算平均值。图5和图6分别是热cache和冷cache的实验结果。基于图5到图6，可以得出下述结论：矩阵越小的情况下，LibShalom的性能优势越大，这是因为打包开销在矩阵越小时开销占比越大。在矩阵规模逐渐增大的情况下，LibShalom相比于第二好的BLASFEO也能取得加速，这得益于高度优化的微内核。图7和图8展示了上述方法对于多线程不规则GEMM的性能，由于LIBXSMM和BLASFEO没有对不规则GEMM做优化，因此没有被操作参照对象。基于图5到图6，可以得出下述结论：LibShalom采用的并行化方法能更好的使用处理器的各个核心，在Phyituym 2000+、KP920和ThunderX2，对比性能第二好的BLIS分别能取得1.8、1.6和1.3倍的加速；与NN模式相比，LibShalom为在NT模式下运行的不规则形状的GEMM提供了更高的性能。这是因为，与NT模式不同，在N模式下,无法沿着K维度连续访问矩阵B的元素。总的来说，LibShalom是普遍适用的，可以在代表性的ARMv8处理器上提供可移植的性能。图9展示了LibShalom对于CP2K程序中使用矩阵的性能，可以看出对于在实际应用中出现的矩阵，LibShalom依然能取得加速，这说明其可以被移植到ARM上的其他应用中。图10展示了LibShalom对于卷积神经网络VGG中使用矩阵的性能，对于在新兴的深度学习计算负载，LibShalom依然能取得加速，这说明其可以用于加速深度学习应用。以上所述仅为本申请的实施例而已，并不用于限制本申请。对于本领域技术人员来说，本申请可以有各种更改和变化。凡在本申请的精神和原理之内所作的任何修改、等同替换、改进等，均应包含在本申请的权利要求范围之内。
