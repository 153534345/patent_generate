标题title
生成模型训练方法和装置、样本生成方法和计算设备
摘要abst
公开了生成模型训练方法和装置、样本生成方法和计算设备。训练方法包括：获取已经训练的、所述生成模型中的噪声去除网络的参数，作为参考参数，所述第一训练样本集包括独立同分布的多个第一训练样本；获取第二训练样本集,第二训练样本集与第一训练样本集为同一训练样本集或者具有相同的分布；从第二训练样本集中随机选择一个第二训练样本，并确定所述第二训练样本对应的噪声水平；以及利用随机选择的每个第二训练样本以及对应的噪声水平，对生成模型中的噪声调度网络进行训练；其中，所述噪声去除网络的参数在训练所述噪声调度网络期间保持在所述参考参数不变，其中，所述噪声去除网络与反向过程相对应，并且所述噪声调度网络与正向过程相对应。
权利要求书clms
1.一种用于生成期望输出的生成模型的训练方法，包括：获取所述生成模型中的噪声去除网络的参数，作为参考参数，所述噪声去除网络已经利用第一训练样本集并基于每个第一训练样本对应的噪声水平训练得到，所述第一训练样本集包括独立同分布的多个第一训练样本；获取第二训练样本集,其中所述第二训练样本集与所述第一训练样本集为同一训练样本集或者具有相同的分布；从所述第二训练样本集中随机选择一个第二训练样本，并确定所述第二训练样本对应的噪声水平；以及利用随机选择的每个第二训练样本以及对应的噪声水平，对所述生成模型中的噪声调度网络进行训练；其中，所述噪声去除网络的参数在训练所述噪声调度网络期间保持在所述参考参数不变，其中，所述噪声去除网络与从噪声输入到期望输出的反向过程相对应，并且所述噪声调度网络与从来自所述第二训练样本集的第二训练样本到输出带有噪声的输出的正向过程相对应。2.根据权利要求1所述的训练方法，其中，从所述第二训练样本集中随机选择一个第二训练样本，并确定所述第二训练样本对应的噪声水平，包括：获取初始噪声尺度序列和索引序列，所述初始噪声尺度序列包括第一数量的噪声尺度，所述索引序列中包括第二数量的索引，所述第二数量小于等于第一数量；基于所述初始噪声尺度序列和从所述索引序列中随机选择的索引，确定所述第二训练样本对应的两个相邻噪声水平。3.根据权利要求2所述的训练方法，其中，所述索引序列的索引步长为大于1且小于所述第一数量的整数，其中，基于所述初始噪声尺度序列和从所述索引序列中随机选择的索引，确定所述第二训练样本对应的两个相邻噪声水平，包括：确定所述初始噪声尺度序列中、其索引小于等于随机选择的所述索引的第一组初始噪声尺度；基于所述第一组初始噪声尺度，确定所述第二训练样本对应的第一个噪声水平；确定所述初始噪声尺度序列中、其索引小于等于所述索引序列中随机选择的所述索引的下一个索引的第二组初始噪声尺度；以及基于所述第二组初始噪声尺度，确定所述第二训练样本对应的与第一个噪声水平相邻的第二个噪声水平。4.根据权利要求2所述的训练方法，其中,利用随机选择的每个第二训练样本以及对应的噪声水平，对噪声调度网络进行训练，包括：对于随机选择的每个第二训练样本，基于所述第二训练样本对应的噪声水平，生成所述第二训练样本的中间样本；基于所述第二训练样本的中间样本以及所述两个相邻噪声水平，利用所述噪声调度网络生成估计噪声尺度；基于所述第二训练样本的中间样本、所述两个相邻噪声水平以及所述估计噪声尺度，利用噪声去除网络计算与所述第二训练样本的中间样本相关的第一损失；调整所述噪声调度网络的参数，使得所述第一损失最小化。5.根据权利要求4所述的训练方法，其中基于中间样本以及所述两个相邻噪声水平，利用所述噪声调度网络生成估计噪声尺度，包括：基于所述两个相邻噪声水平，确定噪声尺度约束；利用所述噪声调度网络，基于所述噪声尺度约束和所述中间样本，生成噪声调度因子；基于所述噪声尺度约束以及所述噪声调度因子，生成所述估计噪声尺度。6.根据权利要求5所述的训练方法，其中，所述第一损失按照第一损失函数计算，并且所述第一损失函数为：其中，∈θ＝∈θ，其中，t为大于等于1且小于所述第二数量的正整数，∈t为噪声变量，且具有样本参考分布∈t～N,xt为所述第二训练样本的中间样本，αt为所述第二训练样本对应的噪声水平，∈θ为所述噪声去除网络∈θ基于当前参数针对所述第二训练样本的中间样本和所述对应的噪声水平时的计算结果，表示向量或矩阵的二范数的平方，μt为噪声尺度约束并且为所述第二训练样本的中间样本xt所对应的噪声尺度约束，为所述噪声调度网络基于当前参数针对所述中间样本和所述噪声尺度约束时的计算结果，作为噪声调度因子，D为xt的维数，表示向量或矩阵的二范数的平方。7.根据权利要求1所述的训练方法，其中，所述噪声去除网络通过以下方式训练：从所述第一训练样本集中随机选择第一训练样本，并基于初始噪声尺度序列确定每个第一训练样本对应的噪声水平，所述初始噪声尺度序列包括第一数量的初始噪声尺度；对于随机选择的每个第一训练样本：基于所述第一训练样本对应的噪声水平，生成所述第一训练样本的中间样本；基于所述第一训练样本的中间样本以及所述对应的噪声水平，利用噪声去除网络计算与所述第一训练样本的中间样本相关的第二损失；调整所述噪声调度网络的参数，使得第二损失最小化；其中，所述第二损失是根据第二损失函数计算的，所述第二损失函数与相对于具有样本参考分布的噪声变量、噪声去除网络针对所述第一训练样本的中间样本以及所述对应的噪声水平的计算结果之间的差异相关联。8.一种样本生成方法，包括：获取随机噪声输入、预设噪声水平、以及预设噪声尺度，分别作为第N个数据、待生成的噪声水平序列中的第N个噪声水平、待生成的噪声尺度序列中的第N个噪声尺度，N为第一数量；利用生成模型中的噪声去除网络和噪声调度网络，基于所述随机噪声输入、预设噪声水平、以及预设噪声尺度，以从N开始以一递减的索引构造所述噪声尺度序列；利用所构造的噪声尺度序列和所述生成模型中的噪声去除网络，基于待处理噪声输入生成多个推理样本，并将生成的最后一个推理样本作为新的样本进行输出，所述多个推理样本的数量与所述噪声尺度序列中的噪声尺度的数量相关联，其中，所述生成模型是根据如权利要求1-7中任一项所述的训练方法训练的。9.根据权利要求8所述的样本生成方法，其中，利用生成模型中的噪声去除网络和噪声调度网络，基于所述随机噪声输入、预设噪声水平、以及预设噪声尺度，以从N开始以一递减的索引构造所述噪声尺度序列，包括：针对从N开始以一递减的索引n，n为小于等于N且大于等于2的整数，对于第n个噪声水平：利用生成模型中的噪声去除网络，基于第n个数据、第n个噪声水平和第n个噪声尺度，生成第n-1个数据；基于第n个噪声水平和第n个噪声尺度，确定第n-1个噪声水平，基于所述第n-1个噪声水平和第n个噪声尺度，确定第n-1个噪声尺度约束；利用生成模型中的噪声调度网络，基于所述第n-1个噪声尺度约束和所述第n-1个数据，生成噪声调度因子；基于所述第n-1个噪声尺度约束以及所述噪声调度因子，生成所述第n-1个噪声尺度；利用预设噪声尺度和所生成的至少一个噪声尺度构造所述噪声尺度序列。10.根据权利要求9所述的样本生成方法，其中，利用预设噪声尺度和所生成的至少一个噪声尺度构造所述噪声尺度序列，包括：在所述第n-1个噪声水平与所述第n个噪声水平之差小于预设阈值的情况下，利用所生成的第n-1个噪声尺度到第N个噪声尺度构造所述噪声尺度序列。11.根据权利要求9或10所述的样本生成方法，其中，所述预设噪声水平、以及预设噪声尺度通过网格搜索算法从数值组合中基于特定度量标准来进行选择。12.一种用于生成期望输出的生成模型的训练装置，包括：第一获取模块，获取所述生成模型中的噪声去除网络的参数，作为参考参数，所述噪声去除网络已经利用第一训练样本集并基于每个第一训练样本对应的噪声水平训练得到的，所述第一训练样本集包括多个第一训练样本,所述多个第一训练样本为独立同分布的样本，第二获取模块，获取第二训练样本集,其中所述第二训练样本集与所述第一训练样本集为同一训练样本集或者具有相同的分布；噪声水平确定模块，从所述第二训练样本集中随机选择一个第二训练样本，并确定所述训练样本对应的噪声水平；以及训练模块，利用随机选择的每个训练样本以及对应的噪声水平，对所述生成模型中的噪声调度网络进行训练；其中，所述噪声去除网络的参数在训练所述噪声调度网络期间保持在所述参考参数不变，其中，所述噪声去除网络与从噪声输入到期望输出的反向过程相对应，并且所述噪声调度网络与从来自所述第二训练样本集的第二训练样本到输出带有噪声的输出的正向过程相对应。13.根据权利要求12所述的训练装置，其中，所述噪声水平确定模块包括：获取单元，用于获取初始噪声尺度序列和索引序列，所述初始噪声尺度序列包括第一数量的噪声尺度，所述索引序列中包括第二数量的索引，所述第二数量小于等于第一数量；确定单元，用于基于所述初始噪声尺度序列和从所述索引序列中随机选择的索引，确定所述第二训练样本对应的两个相邻噪声水平。14.根据权利要求13所述的训练装置，其中，所述训练模块包括：中间样本生成单元，用于基于所述第二训练样本对应的噪声水平，生成所述第二训练样本的中间样本；估计单元，用于基于中间样本以及所述两个相邻噪声水平，利用所述噪声调度网络生成估计噪声尺度；第一损失确定单元，基于所述中间样本、所述两个相邻噪声水平以及所述估计噪声尺度，利用噪声去除网络计算与所述中间样本相关的第二损失；调整单元，用于调整所述噪声调度网络的参数，使得所述第二损失最小化。15.一种计算设备，包括：处理器；和存储器，其上存储有指令，当所述指令被所述处理器执行时，使得所述处理器执行如权利要求1-11任一项所述的方法。
说明书desc
技术领域本申请涉及计算机领域，更具体地，涉及用于生成期望输出的生成模型的训练方法和装置、样本生成方法、以及计算设备。背景技术生成模型也称为概率生成模型，是概率统计和机器学习中的一类重要模型，指可以用于随机生成可观测数据的模型。生成模型的生成过程可以理解为通过学习训练样本集的数据分布，而使用带有一些变量的学习得到的分布来生成新的样本，生成的新样本的分布与训练样本集的真实分布接近。生成模型在高保真图像生成、高质量语音合成、自然语言生成、无监督表示学习等方面广泛应用，并取得了巨大进步。生成模型的成功架构主要分为生成性对抗网络和基于似然的方法。生成性对抗网络采用对抗性训练程序，但训练可能不稳定，并且模型难以放大或与其他GAN模型进行评估；基于似然的方法使用对数似然或替代损失作为训练目标，但它们也有内在的局限性，例如样本生成速度较慢、采用证据下界而导致样本质量不足够高。一类新兴的基于似然的模型是扩散模型能够产生较高质量的样本。然而，也存在一定的缺陷，例如去噪扩散概率模型比其他生成模型)慢两到三个数量级，因为它需要在训练期间进行数千个扩散步骤来学习训练样本集的分布，在样本生成过程时往往需要大量的去噪步骤。WaveGrad虽然作为DDPM的延伸，基于网格搜索算法可以采用较少的样本生成步骤，但是需要在训练模型之后扫描噪声调度的所有可能区域，并且采用O复杂度的数量，N为推理期间的迭代采样数量)，因此，网格搜索算法对于M和N是不可缩放的，因此样本生成速度也非常慢。因此，需要一种能够快速生成新的样本并且生成的样本具有高质量的生成模型。发明内容根据本申请的一方面，提供了一种用于生成期望输出的生成模型的训练方法，包括：获取已经利用第一训练样本集并基于每个第一训练样本对应的噪声水平训练得到的、所述生成模型中的噪声去除网络的参数，作为参考参数，所述第一训练样本集包括独立同分布的多个第一训练样本；获取第二训练样本集,其中所述第二训练样本集与所述第一训练样本集为同一训练样本集或者具有相同的分布；从所述第二训练样本集中随机选择一个第二训练样本，并确定所述第二训练样本对应的噪声水平；以及利用随机选择的每个第二训练样本以及对应的噪声水平，对所述生成模型中的噪声调度网络进行训练；其中，所述噪声去除网络的参数在训练所述噪声调度网络期间保持在所述参考参数不变，其中，所述噪声去除网络与从噪声输入到期望输出的反向过程相对应，并且所述噪声调度网络与从来自所述第二训练样本集的第二训练样本到输出带有噪声的输出的正向过程相对应。根据本申请的另一方面，还提供了一种样本生成方法，包括：获取随机噪声输入、预设噪声水平、以及预设噪声尺度，分别作为第N个数据、待生成的噪声水平序列中的第N个噪声水平、待生成的噪声尺度序列中的第N个噪声尺度，N为第一数量；利用生成模型中的噪声去除网络和噪声调度网络，基于所述随机噪声输入、预设噪声水平、以及预设噪声尺度，以从N开始以一递减的索引构造所述噪声尺度序列；利用所构造的噪声尺度序列和所述生成模型中的噪声去除网络，基于待处理噪声输入生成多个推理样本，并将生成的最后一个推理样本作为新的样本进行输出，所述多个推理样本的数量与所述噪声尺度序列中的噪声尺度的数量相关联，其中，所述生成模型是根据如上所述的训练方法训练的。根据本申请的又一方面，提供了一种用于生成期望输出的生成模型的训练装置，包括：第一获取模块，获取已经利用第一训练样本集并基于每个第一训练样本对应的噪声水平训练得到的所述生成模型中的噪声去除网络的参数，作为参考参数，所述第一训练样本集包括多个第一训练样本,所述多个第一训练样本为独立同分布的样本，第二获取模块，获取第二训练样本集,其中所述第二训练样本集与所述第一训练样本集为同一训练样本集或者具有相同的分布；噪声水平确定模块，从所述第二训练样本集中随机选择一个第二训练样本，并确定所述训练样本对应的噪声水平；以及训练模块，利用随机选择的每个训练样本以及对应的噪声水平，对所述生成模型中的噪声调度网络进行训练；其中，所述噪声去除网络的参数在训练所述噪声调度网络期间保持在所述参考参数不变，其中，所述噪声去除网络与从噪声输入到期望输出的反向过程相对应，并且所述噪声调度网络与从来自所述第二训练样本集的第二训练样本到输出带有噪声的输出的正向过程相对应。根据本申请的再一方面，还提供了一种样本生成装置，包括：获取模块用于获取随机噪声输入、预设噪声水平、以及预设噪声尺度，分别作为第N个数据、待生成的噪声水平序列中的第N个噪声水平、待生成的噪声尺度序列中的第N个噪声尺度，N为第一数量；构造模块820用于利用生成模型中的噪声去除网络和噪声调度网络，基于所述随机噪声输入、预设噪声水平、以及预设噪声尺度，以从N开始以一递减的索引构造所述噪声尺度序列；生成模块用于利用所构造的噪声尺度序列和所述生成模型中的噪声去除网络，基于待处理噪声输入生成多个推理样本，并将生成的最后一个推理样本作为新的样本进行输出，所述多个推理样本的数量与所述噪声尺度序列中的噪声尺度的数量相关联。根据本申请的另一方面，还提供了一种计算设备，包括：处理器；和存储器，其上存储有指令，所述指令在由所述处理器执行时，使得所述处理器执行如上所述的训练方法的各个步骤以及如上所述的样本生成方法的各个步骤。根据本申请的另一方面，还提供了一种计算机可读存储介质，存储有计算机程序，计算机程序被处理器执行时，使得处理器执行如上所述的训练方法的各个步骤以及如上所述的样本生成方法的各个步骤。根据本申请的又一方面，还提供了一种计算机程序产品，包括计算机程序，计算机程序被处理器执行时实现如上所述的训练方法的各个步骤以及如上所述的样本生成方法的各个步骤。根据本公开的实施例，在模型的参数化过程时考虑了正向过程和反向过程，从而能够构造更合适的噪声尺度序列，进而能够更快地反向生成新的样本。此外，由于噪声去除网络的训练可以是预先学习好的，因此可以加快训练噪声调度网络的训练速度，此外，噪声调度网络针对的是噪声尺度变量，而预测噪声尺度变量本质上是一项相对容易的任务，因此仅噪声调度网络的训练的时间开销较小。此外，通过在训练时引入步长参数，可以使模型学习在大的噪声水平之间的转换，使得生成的样本的质量较高。附图说明图1A-1B示例性地示出了基于去噪扩散模型以及基于DDPM的WaveGrad中考虑的有向图模型。图2示例性地示出了本申请提出的双边去噪扩散模型中考虑的有向图模型。图3示例性地示出了根据本申请的实施例的用于生成期望输出的生成模型的训练方法的流程示意图。图4示例性地示出了根据本申请的实施例的图2中的噪声去除网络的训练步骤的更多细节。图5示例性地示出了根据本申请的实施例的图2中的噪声调度网络的训练步骤的更多细节。图6A-6B示例性地示出了根据本申请实施例的样本生成方法的流程示意图。图7A-7B示例性地示出了根据本申请的实施例的用于生成期望输出的生成模型的训练装置的结构框图。图8示例性地示出了根据本申请实施例的样本生成装置的结构框图。图9示例性地示出了根据本申请实施例的计算设备的框图。具体实施方式为了使得本申请的目的、技术方案和优点更为明显，下面将参照附图详细描述根据本申请的示例实施例。显然，所描述的实施例仅仅是本申请的一部分实施例，而不是本申请的全部实施例，应理解，本申请不受这里描述的示例实施例的限制。在本说明书和附图中，具有基本上相同或相似步骤和元素用相同或相似的附图标记来表示，且对这些步骤和元素的重复描述将被省略。同时，在本申请的描述中，术语“第一”、“第二”等仅用于区分描述，而不能理解为指示或暗示相对重要性或排序。在进行本申请的具体描述之前，可以先对本申请中可能用到的某些术语进行简单解释。去噪扩散概率模型和去噪扩散隐式模型:基于似然的生成模型。双边去噪扩散模型:本申请提出的生成模型的另一种表述；证据下界：用于变分推理中，不易计算的分布作为证据，证据下界为该分布的最小值，该证据下界能够被计算；对数梅尔谱图均方误差：将声谱图通过梅尔尺度滤波器组，变为梅尔频谱，然后求梅尔谱图上的频率的均方误差，对用于衡量生成样本的质量的波形方面的度量；梅尔-倒频谱距离：用于衡量生成样本的质量的波形方面的度量，由音乐讯号当中的片段，可以得到一组足以代表此音乐讯号的倒频谱，而梅尔倒频谱系数即是从这个倒频谱中推得的倒频谱，梅尔倒频谱上的频带是均匀分布于梅尔刻度上的；短期客观可懂度：语音能够被听者听懂的信号占总数的百分比；语音质量的感知评估：主观语音质量评估，语音增强中常用的度量；平均意见得分：平均主观意见分，用于衡量生成样本的语音质量的主观度量。独立同分布：指一组随机变量中每个训练样本的概率分布都相同，且这些训练样本互相独立，即训练用到的所有训练样本都是独立地从这个分布上采样而得。人工智能技术是一门综合学科，涉及领域广泛，既有硬件层面的技术也有软件层面的技术。人工智能软件技术可以包括计算机视觉技术、语音处理技术、自然语言处理技术以及机器学习/深度学习等几大方向，并且这些方向是可以相互融合的。计算机视觉技术通常包括图像处理、图像识别、图像语义理解、图像检索等等。语音技术的关键技术包括语音合成技术等。如前面所述，去噪扩散概率模型或WaveGrad虽然可以生成较好质量的样本，但是由于在样本生成过程时往往需要大量的去噪步骤，或者复杂度较高以及较差的缩放特性，因此生成新的样本需要耗费更多的时间，因此需要一种能够快速生成新的样本并且生成的样本具有高质量的生成模型。目前还提出了能够较快生成新的样本的一些方法。例如，去噪扩散隐式模型或作为DDIM延伸的Diff-TTS，它公式化了一个非马尔可夫生成过程，在样本生成过程中仅采用模型的一部分，通过定义预测函数以直接预测给定潜在变量的观测变量作为样本输出，从而可以通过DDIM的整个推理轨迹的子序列产生样本，因此在保持与DDPM相同的训练过程的同时加速了推理。或者，有方法使用神经概率流ODE来实现快速确定性多步骤样本生成过程。或者，也有方法在样本生成期间使用来自分类器的梯度来引导扩散模型，但是这种知识提取和分类器技术的方向通常需要类别标签。也就是说，先前的扩散模型只考虑了反向处理形式的替代方案或使用额外的知识进行更好的条件建模。此外，样本生成步骤的减少基本上取决于噪声调度的选择，而在目前的方法中，噪声调度通常被认为是正向过程预定义的。图1A-1B示例性地示出了基于去噪扩散模型以及基于DDPM的WaveGrad中考虑的有向图模型。WaveGrad的理论与DDPM大致个，因此下面以DDPM为例进行介绍。首先，给定来自未知概率分布pdata的多个独立同分布的训练样本{x0∈RD}，生成模型，具体针对的是如在后文描述的生成模型中的得分网络或者噪声去除网络，可用于学习近似pdata的模型分布pθ。独立同分布指一组随机变量中每个训练样本的概率分布都相同，且这些训练样本互相独立，即训练用到的所有训练样本都是独立地从这个分布上采样而得。图1A的有向图中，示出了去噪扩散概率模型中定义的具有高斯过渡的离散马尔可夫链，其中由预定义的噪声尺度的递增序列参数化，用如下公式表示：其中，这可以被称为正向过程，因为逐渐地用与βt相关联的高斯噪声干扰训练样本x0的观测值，而生成多个中间样本xt，每个xt与βt相对应，并且基于链式规则，正向过程具有封闭形式的表示，如公式所示：其中，为了描述的方便，设置参数αt来指示噪声水平，其中αt＝lt，并且因此，xt可以视为是x0和一个噪声变量∈t)的线性组合，如公式所示：通过最大化证据下界，即Felbo，来学习模型的参数，以用于拟合x0的真实概率分布pdata。θ是模型的一组参数，通过学习而选择合适的一组参数，β是与噪声尺度相关的模型的一组参数，但是在DDPM中认为它是不可学习的，因此一旦噪声尺度序列确定，该组参数β则作为常量。证据下界的定义与推导方式是本领域技术人员熟知的，因此这里不再推导，公式给出推导结果:在公式中，pθ是近似x0所属的训练样本集的真实概率分布pdata的所学习的分布，但是其似然并不容易计算的，但通过使Felbo最大化也能使得pθ与pdata足够接近。在公式中，qβ为条件概率分布，已经在公式-中给出；pθ为联合分布概率，对应于反向过程，它由变分马尔可夫链建模，并且可以从pprior:＝N开始在反向上顺序计算，即输入是满足高斯分布N的变量xT，如公式-所示：∈θ为噪声去除网络，对应于反向过程，且∈θ是对得分匹配技术进行重新参数化而得出的，因此也可以称为得分网络。这里，∈θ以连续噪声水平at为条件，以连续噪声水平at为条件得到的得分网络可以用于使用不同的迭代次数进行推理，而不重新训练网络。如前面所述，要使得pθ与pdata足够接近，可以通过使Felbo最大化来实现，根据公式-，并且由于所有条件都是高斯，可以推导出Felbo最大化等同于针对于θ来最小化表示为公式：也就是说，训练的目标是通过不断调整模型的该组参数θ，使得能够最小。经过训练的∈θ网络可以使用Langevin动力学根据随机输入基于条件分布概率pθ迭代地生成新样本。以上结合图1A描述了DDPM模型中的得分网络。但是，在针对该得分网络进行参数化的过程中，仅是反向过程中的参数化，并不涉及在正向过程的参数化，因为参数集β仅作为常量，用于针对一个训练样本生成带噪的中间样本，然后利用每个训练样本以及生成的中间样本进行参数化，以训练该得分网络。也就是说，在现有的模型中，得分网络在大范围的噪声尺度上进行了训练，且成功应用于样本生成，因此已经具有良好和稳定特性。本申请出于为了加快样本生成速度以及生成高质量的样本的目的，提出基于已训练的得分网络，而对调度网络进行建模和训练，使得能够针对已训练的得分网络的参数而训练出用于调度网络的参数，从而调度网络可以快速地训练，并生成合适的一组噪声尺度，以更快地生成样本。首先，本申请提出一种双边去噪扩散模型，该模型用噪声去除网络和噪声调度网络网络，对应于正向过程，如x0到xt)来构建，通过对噪声去除网络和噪声调度网络进行训练，而实现对正向和反向过程的参数化。本申请提出的BDDM模型或方法的关键在于在模型的参数化过程中还结合了正向过程。基于此，图2示例性地示出了本申请提出的BDDM中考虑的有向图模型。该有向图模型中包括正向过程和反向过程。首先，如前文对β的定义，可以存在以下关系：αt＝lt，并且并且，希望从βt+1到βt的噪声尺度是下降的，以在努力获得高的生成质量的同时能够保持少的样本生成步骤。因此，设置噪声调度网络使得在正向上使用通过估计的βt，而不是由传统的预定义的噪声调度序列参数化，例如噪声去除网络仍使用预定义的噪声调度序列。因此，考虑到正反向过程，针对图2，引入重新参数化的正向分布，如公式所示：根据公式，可以导出以下下界不等式：如前面在DDPM模型中所述，pθ是近似x0所属的训练样本集的真实概率分布pdata的所学习的分布，但是其并不容易计算，但通过使该训练样本集的分布对应的证据下界最大化也能使得pθ与pdata足够接近。而根据公式可以看到，存在一个新的替代目标，该替代目标使用的下界比常用的证据下界更接近logpθ。因此，通过使最大化可以比通过使最大化能使得pθ与pdata更接近，这样，生成的新样本的质量将更高。而且，根据公式中推导出来的的形式，相对logpθ也更好处理。包括待学习或待优化的两组参数，第一组参数与反向过程相关，第二组参数与正向过程相关。本申请为了生成高质量的样本，需要对进行最大化。在最大化的过程中，会导出分别与反向过程相关的第一损失函数，和与正向过程相关的第二损失函数，而通过分别调整θ和的值，以分别对这两个损失函数进行最小化以实现最大化例如通过梯度下降法，这将在后续进行说明。综上分析，两组参数分别对应正反向过程，学习过程是独立的，因此在对除了噪声去除网络还设置了噪声调度网络的生成模型进行训练时，可以考虑迭代和交错的训练，即固定一组参数，更新另一组参数K次，然后交换。这种训练方式是容易设计的且可行的，但是高质量的样本的生成的收敛将非常慢，其主要原因是训练噪声去除网络需要花费大量的时间，而训练噪声调度网络所需的时间相对较少。如在前文的推导过程中所述的，在学习一组参数的同时固定另一组参数，并且，BDDM中的得分网络与现有的其他扩散模型，例如DDPM中的得分网络基本类似，因此这个性质可以允许采用已经学习好的用于得分网络的参数，而学习好的得分网络是在大范围的噪声尺度上学习的，即，从先验分布中采样噪声尺度来训练得分网络，因此无需针对任何特定的调度进行进一步的细化。基于此，本申请的实施例提供了一种用于生成期望输出的生成模型的训练方法。图3示出了根据本申请的实施例的用于生成期望输出的生成模型的训练方法的流程示意图。在本申请中，生成模型包括噪声去除网络和噪声调度网络。可选地，噪声去除网络对应于反向过程，即与从噪声输入数据到输出数据的反向过程相对应，根据后文将描述的推导过程，该噪声去除网络与参考图1A所描述的得分网络具有基本相同的表达式。噪声调度网络对应于正向过程，即与从来自训练样本集的训练样本到带有噪声的输出的正向过程相对应，如将在后文描述的，该噪声调度网络能够生成估计噪声尺度。噪声去除网络对应所述生成模型的第一组参数，噪声调度网络对应所述生成模型的第二组参数如图3所示，在步骤S310中，获取所述生成模型中的噪声去除网络的参考参数，所述噪声去除网络已经利用第一训练样本集并基于每个第一训练样本对应的噪声水平训练得到，所述第一训练样本集包括多个第一训练样本,所述多个第一训练样本为独立同分布的样本。可选地，第一训练样本集可以为各种类型的样本，例如图片和音频等。具体地，所述多个第一训练样本为独立同分布的样本，即，第一训练样本集包括的多个第一训练样本为多个独立的样本x0，每个样本的概率分布pdata是相同的。可以在该噪声去除网络的训练结束之后才进行噪声调度网络的训练，因此噪声去除网络可以如现有的DPPM或WaveGrad中的那样，在预定义的初始噪声尺度序列，例如包括1000个噪声尺度的序列上进行学习。或者，该生成模型包括现有的DPPM模型、WaveGrad模型或DDIM模型，只是针对反向过程设计了该BDDM中的噪声调度网络。初始噪声尺度序列可以预定义如下：其中，ε为预设参数，用于指示初始噪声尺度序列中的最大值，例如βT。β1至βT为单调递增的噪声尺度。t大于等于1且小于等于T包括单调递增的噪声尺度。噪声去除网络的具体训练过程将在后文结合图4详细描述。在步骤S320中，获取第二训练样本集,其中所述第二训练样本集与所述第一训练样本集为同一训练样本集或者具有相同的分布。第二训练样本集是用于训练噪声调度网络的。由于所述噪声去除网络的参数在训练所述噪声调度网络期间保持在参考参数不变，因此需要训练噪声调度网络以学习在固定的参考参数的情况下，用于适配所述参考参数的、噪声调度网络的最好的一组参数在步骤S330中，从所述第二训练样本集中随机选择一个第二训练样本，并确定所述第二训练样本对应的噪声水平。可选地，由于希望以尽可能少的步骤生成高质量的样本，例如，在前三个推理步骤就能去掉噪声的80％，因此噪声调度网络需要学习在差值较大的噪声水平之间的转变，因此可以通过以下方式来确定每个第二训练样本对应的噪声水平：获取初始噪声尺度序列和索引序列，所述初始噪声尺度序列包括第一数量的噪声尺度，所述索引序列中包括第二数量的索引，所述第二数量小于等于第一数量；基于所述初始噪声尺度序列和从所述索引序列中随机选择的索引，确定所述第二训练样本对应的两个相邻噪声水平。从索引序列中随机选择的索引用于指示针对该第二训练样本，哪个噪声水平将被应用到该第二训练样本中，且索引序列包括的索引的数量可以小于第一数量，例如，100。索引序列可以认为是一个均匀分布，要从其中进行选择索引也被称为是从其中进行采样。该索引序列可以基于步长参数τ来进行设置，其中τ大于1且小于T，此时的索引序列可以为{τ,2τ,....,T-2τ,T-τ}，其中τ表示该索引序列中两个连续噪声水平的索引之间的索引步长，可以在索引序列{τ,2τ,....,T-2τ,T-τ}中随机选择用于该训练样本的索引。τ的值会影响用于推理的步数，即τ越高，步数越少。例如，τ可以设置为200。噪声水平与索引的关系如下所示。t从均匀分布{τ,....,T-τ}中选择数据的概率是相同的。s为噪声水平的索引，下式中，t一旦确定，s＝t，s+1＝t+τ。由此，关于噪声水平的确定，可以包括：首先，确定所述初始噪声尺度序列中、其索引小于等于随机选择的所述索引的第一组初始噪声尺度；然后，基于所述第一组初始噪声尺度，确定所述第二训练样本对应的第一个噪声水平；接着，确定所述初始噪声尺度序列中、其索引小于等于所述索引序列中随机选择的所述索引的下一个索引的第二组初始噪声尺度；以及最后，基于所述第二组初始噪声尺度，确定所述第二训练样本对应的与第一个噪声水平相邻的第二个噪声水平。假设从索引序列中随机选择的索引t为τ，如前面lt的定义，可以确定lt需要索引1至t对应的t个初始噪声尺度来进行计算。lt+τ也同理，需要索引1至t+τ对应的t+τ个初始噪声尺度来进行计算。最终，通过这两组初始噪声尺度而可以得到两个相邻的噪声水平αs和αs+1，且两者的值相差比较大，这样如前面所述，可便于以尽可能少的步骤生成高质量的样本。例如，在所选择的索引为t＝2τ，且τ＝2的情况下，在步骤S340中，利用随机选择的每个第二训练样本以及对应的噪声水平，对所述生成模型中的噪声调度网络进行训练。具体的训练过程将结合图5详细描述。通过参考图3所描述的方法，在模型的参数化过程期间考虑了正向过程，从而能够构造更合适的噪声尺度序列，进而能够更快地反向生成新的样本。此外，由于噪声去除网络的训练可以预先进行，例如从先验分布中获取初始噪声尺度序列来训练得分网络，就像在其他模型中已经建立的训练过程一样，因此，噪声去除网络已经在大范围的噪声尺度上被学习，使得它不需要针对任何特定的噪声调度进行进一步的细化，从而仅训练噪声调度网络使得训练高效。下面结合图4来对图3中的步骤S310进行详细介绍。以下过程用于在训练噪声调度网络之前训练得到噪声去除网络。如图4所示，在步骤S310-1中，从所述第一训练样本集中随机选择多个第一训练样本，并基于初始噪声尺度序列确定每个第一训练样本对应的噪声水平，所述初始噪声尺度序列包括第一数量的初始噪声尺度。同样的，噪声水平用于指示多少噪声会被施加到这次所选择的第一训练样本上。每次选择的第一训练样本对应的噪声水平类似的通过以下方式确定：基于所述初始噪声尺度序列和从第二索引序列中随机选择的索引，确定所述第一训练样本对应的噪声水平，所述第二索引序列中包括的索引的数量比第一数量少1。例如，该第二索引序列可以为{1,2,....,T-2,T-1}，可以在第二索引序列{1,2,....,T-2,T-1}中随机选择用于该第一训练样本的索引。t从均匀分布{1,2,....,T-2,T-1}中选择数据的概率是相同的。该第一训练样本对应的噪声水平为αs，其中s＝t，并且αs从lt和lt+1的区间随机采样，lt和lt+1可以如前面所述通过初始噪声尺度序列得到。以下步骤S310-2到步骤S310-4均针对此次随机选择的第一训练样本执行。在步骤S310-2中，基于所述第一训练样本对应的噪声水平，生成所述第一训练样本的中间样本。设每次选择的第一训练样本为x0，如前面所述，由于在获取了所述训练样本对应的噪声水平之后，训练样本x0可以生成一个中间样本xs，基于αs，该中间样本被施加了噪声数据。在步骤S310-3中，基于所述第一训练样本的中间样本以及所述对应的噪声水平，计算所述第一训练样本的中间样本相关的第二损失。在步骤S310-4中，调整所述噪声调度网络的参数，使得第二损失最小化。例如，所述第二损失是根据第二损失函数计算的，所述第二损失函数与相对于具有样本参考分布的噪声变量、噪声去除网络针对所述第一训练样本的中间样本以及所述对应的噪声水平的计算结果之间的差异相关联。例如，第二损失函数为：其中，∈θ＝∈θ,其中，s为大于等于1且小于所述第一数量的正整数，∈s为噪声变量，且具有样本参考分布∈s～N,xs为所述第一训练样本的中间样本，αt为所述第一训练样本对应的噪声水平，∈θ为所述噪声去除网络∈θ基于当前参数针对所述第一训练样本的中间样本和所述对应的噪声水平时的计算结果，表示向量或矩阵的二范数的平方。第二损失函数可以通过以下推导过程得到。首先，在前文提及，希望将最大化，通过固定可以对进行近似，由于对应的是反向过程，因此下面的β均来自初始噪声尺度序列：接下来，计算上述KL项，根据有向图中的条件概率分布之间的关系，可以通过xt来重新参数化x0：其中，注意pθ和pθ是具有相同变量σt2的高斯分布，因此，KL项变为了两个高斯分布之间的缩放平方差：替换可将上式简化为：由此可见，第二损失函数Lscore与现有的DDPM模型或Wavegrad等中的针对得分网络的损失函数具有基本一致的形式。例如，可以调整所述噪声去除网络的参数，使得第二损失最小化。例如，可以对该第二损失函数采用梯度下降法，直至收敛，以得到使得第二损失最小化的合适的模型参数。例如，可以通过随机梯度下降法。这样，可以完成噪声去除网络的训练，并且噪声去除网络是在大范围的噪声尺度上学习的，并且因此无需针对任何特定的噪声调度进行进一步的细化，已经训练好的噪声去除网络的参数在后续训练噪声调度网络的过程中保持不变的，因此可以更快地训练噪声调度网络。以下结合图5对步骤S340中的训练噪声调度网络的过程进行详细描述。如图5所示，在步骤S340-1中，基于所述第二训练样本对应的噪声水平，生成所述第二训练样本的中间样本。在步骤S340-2中，基于所述第二训练样本的中间样本以及所述两个相邻噪声水平，利用所述噪声调度网络生成估计噪声尺度。可选地，该步骤可以具体包括：i.基于所述两个相邻噪声水平，确定噪声尺度约束；例如，中间样本xs的噪声尺度为αs，相邻的噪声尺度为αs+1，噪声尺度的具体值可以如前文所述通过初始噪声尺度序列和索引序列而计算得到。噪声约束被定义为1-αs2和βs+1中的最小值，其中ii.利用所述噪声调度网络，基于所述噪声尺度约束和所述中间样本，生成噪声调度因子；例如，噪声调度网络为噪声调度因子为的值，即所述噪声调度网络基于当前参数针对所述中间样本和所述噪声尺度约束时的计算结果。iii.基于所述噪声尺度约束以及所述噪声调度因子，生成所述估计噪声尺度例如，所述估计噪声尺度为所述噪声尺度约束以及所述噪声调度因子的乘积，即，在步骤S340-3中，基于所述第二训练样本的中间样本、所述两个相邻噪声水平以及所述估计噪声尺度，计算与所述第二训练样本的中间样本相关的第一损失。例如，所述第一损失是根据第一损失函数计算的，所述第一损失函数与相对于具有样本参考分布的噪声变量与第一系数的乘积、噪声去除网络针对所述第二训练样本的中间样本以及所述对应的噪声水平的计算结果与第二系数的乘积之间的差异相关联。第一系数由所述对应的噪声水平确定，第二系数由估计噪声尺度和对应的噪声水平确定。例如，第一损失函数为：其中，其中，t为大于等于1且小于所述第二数量的正整数，∈t为噪声变量，且具有样本参考分布∈t～N,xt为所述第二训练样本的中间样本，αt为所述第二训练样本对应的噪声水平，∈θ为所述噪声去除网络∈θ基于当前参数针对所述第二训练样本的中间样本和所述对应的噪声水平时的计算结果，表示向量或矩阵的二范数的平方，μt为噪声尺度约束并且为所述第二训练样本的中间样本xt所对应的噪声尺度约束，为所述噪声调度网络基于当前参数针对所述中间样本和所述噪声尺度约束时的计算结果，作为噪声调度因子，D为xt的维数，表示向量或矩阵的二范数的平方。对于第一损失函数的设置具有以下考虑，该第一损失函数被定义为正向和反向分布之间的KL散度项，并且本质上相当于下界和logpθ之间的差距。因此，通过最小化该损失函数，其意义在于在θ参数固定时，强制下界逐渐变为更紧的下界，从而使得pθ与pdata更接近。由于正向过程中的βt是估计的，因此下面公式中的βt是根据噪声调度网络计算的估计值。基于上述考虑，第一损失函数的推导过程如下。首先通过替换以下概率密度函数来扩展KL项：可以得到：其中，从上可知，第一损失函数的形式也比较简单，由于是可计算得到的值，所有与xt的数据分布相关的变量都可以消除，最后的形式只取决于两个变量∈t和∈θ，类似于不过二范数内的变量的标度值是不同的。此外，还应注意，保留二范数的系数和依赖于βt的Ct项，因为需要用于噪声调度网络的学习中。接下来分析和第一损失函数的关系。考虑固定的θ，和logpθ之间的差距为上述损失函数的和，即：推导如下：即，在给定αt和的情况下，在第t步处针对最小化损失函数相当于针对最大化下界通常，虽然公式中是对Lstep求和，但是出于减少训练量的考虑，一般只抽取一个Lstep同样能够保证能对模型进行优化，因此也可以相当于最小化损失函数这样，可以使得在θ参数固定的情况下，下界最大化，从而比在DDPM模型中使用的证据下界ELBO更接近logpθ，以更接近x0所属的训练样本集的真实分布pdata。这样，通过训练得到的生成模型可以生成较高质量的新的样本。在步骤S340-4中，调整所述噪声调度网络的参数，使得所述第一损失最小化。同样地，例如，可以对该第一损失函数采用梯度下降法，直至收敛，以得到使得第一损失最小化的合适的模型参数。例如，可以通过随机梯度下降法。通过参考图5描述的噪声调度网络训练过程，噪声调度网络的参数能够使得损失函数取得全局最小值，在实际应用时能够基于给定初始条件而生成对于该初始条件来说合适的噪声尺度序列，以用于更快地反向生成新的样本。另一方面，在噪声去除网络的参数能够使得对应的损失函数取得全局最小值，噪声调度网络的参数能够使得损失函数取得全局最小值时，生成的样本的质量也会提高。根据本申请的另一方面，还提供了一种样本生成方法。该方法是经由通过上述参考图3-5描述的训练方法训练后的样本生成模型来实现的，具体地，经由该样本生成模型的经训练噪声去除网络和经训练噪声调度网络来实现的。图6A-6B示出了生成样本方法的流程示意图。通过前述的训练方法，噪声去除网络预先学习一组参数，然后固定该组参数，噪声调度网络也学习了一组合适的参数，从而可以用于基于该参数来进行应用。例如，噪声调度网络可以基于学习的参数而进行噪声调度。在步骤S610中，获取随机噪声输入、预设噪声水平、以及预设噪声尺度，分别作为第N个数据x′N～N、待生成的噪声水平序列中的第N个噪声水平α′N、待生成的噪声尺度序列中的第N个噪声尺度β′N，N为第一数量。可选地，预设噪声水平和噪声尺度可以通过网格搜索算法从数值组合中基于特定度量标准来进行选择。例如，针对i,j＝1,...,9,即81种组合，对超参数执行网格搜索算法，并且使用LS-MSE度量作为选择度量。然后，存储对应于最小LS-MSE的预测水平和噪声调度，即待生成的噪声水平序列中的第N个噪声水平α′N、待生成的噪声尺度序列中的第N个噪声尺度β′N，并应用于随后的在线推理过程。注意，该搜索仅具有O的复杂度，这比WaveGrad中的传统网格搜索算法中的O高效得多。在步骤S620中，利用生成模型中的噪声去除网络和噪声调度网络，基于所述随机噪声输入、预设噪声水平、以及预设噪声尺度，以从N开始以一递减的索引构造所述噪声尺度序列。具体地，针对从N开始以一递减的索引n，n为小于等于N且大于等于2的整数，对于第n个噪声水平执行以下子步骤，以得到多个噪声尺度，如图6B所示，因此可以利用预设噪声尺度和所生成的至少一个噪声尺度构造所述噪声尺度序列。在子步骤S620-1中，利用噪声去除网络，基于第n个数据、第n个噪声水平和第n个噪声尺度，生成第n-1个数据。例如，x′n-1～pθ，其中，基于公式可知，pθ与经训练的噪声去除网络∈θ是相关的，从x′n可以得到x′n-1。在子步骤S620-2中，基于第n个噪声水平和第n个噪声尺度，确定第n-1个噪声水平。例如，这与前文所定义的βn、αn和αn-1之间的关系也是一致的。在子步骤S620-3中，基于所述第n-1个噪声水平和第n个噪声尺度，确定第n-1个噪声尺度约束。例如，μn-1＝min{1-a′n-12，β′n}。在子步骤S620-4中，利用噪声调度网络，基于所述第n-1个噪声尺度约束和所述第n-1个数据，生成噪声调度因子。在子步骤S620-5中，基于所述第n-1个噪声尺度约束以及所述噪声调度因子，生成所述第n-1个噪声尺度。例如，其中，是经训练的噪声调度网络。此外，在利用所生成的至少一个噪声尺度来构造所述噪声尺度序列时，阈值ρ可以被用来作为平衡样本质量和样本生成速度的可调节控制因子。可以根据实际情况和经验而选择不同的阈值，以生成不同长度的噪声尺度序列，例如，可以取ρ∈{1e-6,1e-6}。在所述第n-1个噪声水平与所述第n个噪声水平之差小于预设阈值的情况下，利用所生成的第n-1个中间噪声尺度到第N个中间噪声尺度构造所述噪声尺度序列，而不再继续生成新的噪声尺度。具体地，如果计算的第n-1个噪声水平相对于当前的第n个噪声水平的变化幅度已经不大，那么两者对应的噪声尺度相差也不大，因此两个样本生成步骤也比较类似，因此可以停止继续计算第n-2个噪声水平，而直接将目前已经获得的+1＝N-n+2)个噪声水平对应的噪声尺度用于构造所述噪声尺度序列。反之，如果第n-1个噪声水平与所述第n个噪声水平之差不小于预设阈值，那么噪声尺度序列包括的噪声尺度的数量仍然为N。也就是说，通过设置预设阈值，可以通过忽略引起非常弱的噪声水平α′n的改变的噪声尺度，从而可以获得一个比完整噪声调度的噪声尺度序列更短的序列。在步骤S630中，利用所构造的噪声尺度序列和所述生成模型中的噪声去除网络，基于待处理噪声输入生成多个推理样本，并将生成的最后一个推理样本作为新的样本进行输出，所述多个推理样本的数量与所述噪声尺度序列中的噪声尺度的数量相关联。具体地，获取待处理噪声输入和噪声尺度序列。例如，待处理噪声输入可以为高斯白噪声，并且该噪声尺度序列可以如参考图6B描述的生成方式来生成的，例如包括P＝N-n+2个噪声尺度，高斯白噪声可以作为第P个数据。基于该噪声尺度序列可以生成噪声水平序列。噪声水平与噪声尺度的对应计算关系已经在前文进行了描述，因此这里不再重复。然后，针对从P开始以一递减的索引p，p小于等于P且大于等于1，利用噪声去除网络，基于第p个数据、第p个噪声水平和第p个噪声尺度，生成第p-1个推理样本。例如，xp-1～pθ，其中，基于公式可知，pθ与经训练的噪声去除网络∈θ是相关的。这样，基于噪声尺度序列可以推理得到多个推理样本，将得到的最后一个推理样本作为生成的新样本。通过参考图6A-6B所述的样本生成方法，除了训练过程被加速之外，所生成的具有较短长度噪声尺度序列可以用于生成新的样本，因此可以加快样本生成速度。根据本申请的另一方面，还提供了一种用于生成期望输出的生成模型的训练装置。图7A-7B示出了根据本申请实施例的用于生成期望输出的生成模型的训练装置的结构框图。如7A所示，该训练装置700包括第一获取模块710、第二获取模块720、噪声水平确定模块730、训练模块740。第一获取模块710用于获取已经利用第一训练样本集并基于每个第一训练样本对应的噪声水平训练得到的所述生成模型中的噪声去除网络的参考参数，所述第一训练样本集包括多个第一训练样本,所述多个第一训练样本为独立同分布的样本。第二获取模块720用于获取第二训练样本集,其中所述第二训练样本集与所述第一训练样本集为同一训练样本集或者具有相同的分布。噪声水平确定模块730用于从所述训练样本集中每次随机选择一个训练样本，并确定所述训练样本对应的噪声水平；训练模块740用于利用随机选择的每个训练样本以及对应的噪声水平，对所述生成模型中的噪声调度网络进行训练。所述噪声去除网络的参数在训练所述噪声调度网络期间保持在所述参考参数不变，所述噪声去除网络与从噪声输入到期望输出的反向过程相对应，并且所述噪声调度网络与从来自所述第二训练样本集的第二训练样本到输出带有噪声的输出的正向过程相对应。图7B示出了图7A中的训练装置的更多细节。如图7B所示，噪声水平确定模块730包括：获取单元730-1，用于获取初始噪声尺度序列和索引序列，所述初始噪声尺度序列包括第一数量的噪声尺度，所述索引序列中包括的第二数量的索引，所述第二数量小于等于第一数量；确定单元730-2，用于基于所述初始噪声尺度序列和从所述索引序列中随机选择的索引，确定所述训练样本对应的两个相邻噪声水平。具体地，所述索引序列的索引步长为大于1且小于所述第一数量的整数，确定单元730-2用于：确定所述初始噪声尺度序列中、其索引小于等于随机选择的所述索引的第一组初始噪声尺度；基于所述第一组初始噪声尺度，确定所述第二训练样本对应的第一个噪声水平；确定所述初始噪声尺度序列中、其索引小于等于所述索引序列中随机选择的所述索引的下一个索引的第二组初始噪声尺度；以及基于所述第二组初始噪声尺度，确定所述第二训练样本对应的与第一个噪声水平相邻的第二个噪声水平。训练模块740包括：中间样本生成单元740-1，用于基于所述第二训练样本对应的噪声水平，生成所述第二训练样本的中间样本；估计单元740-2，用于基于中间样本以及所述两个相邻噪声水平，利用所述噪声调度网络生成估计噪声尺度；第二损失计算单元740-3，基于所述中间样本、所述两个相邻噪声水平以及所述估计噪声尺度，利用噪声去除网络计算与所述中间样本相关的第二损失；估计单元740-3用于基于中间样本以及所述两个相邻噪声水平，利用所述噪声调度网络生成估计噪声尺度；以及调整单元740-4，用于调整所述噪声调度网络的参数，使得所述第二损失最小化。可选地，估计单元730-2可以：基于所述两个相邻噪声水平，确定噪声尺度约束；利用所述噪声调度网络，基于所述噪声尺度约束和所述中间样本，生成噪声调度因子；基于所述噪声尺度约束以及所述噪声调度因子，生成所述估计噪声尺度。此外，训练模块还可以用于在训练噪声调度网络之前训练噪声去除网络，即利用第一训练样本集并基于每个第一训练样本对应的噪声水平训练该噪声去除网络，以得到该网络的参考参数。各个模块中的操作的更多细节可以参考前文参考图2-4进行的描述。在图7A-7B中，根据训练装置要进行的功能而将其划分为多个模块，然而根据不同的划分方式，训练装置可以包括更多或更少的模块，本申请对此不做限制。通过参考图7A-7B所描述的训练装置，在模型的参数化过程期间结合了正向过程和反向过程，从而能够构造更合适的噪声尺度序列，进而能够更快地反向生成新的样本。此外，由于噪声调度网络针对的是噪声尺度变量，而对噪声尺度变量进行预测和调度本质上是一项相对容易的任务，相对于噪声去除网络的训练，速度快得多，因此噪声调度网络的训练不会增加过多的时间开销。此外，噪声去除网络是先于噪声调度网络并在大范围的预定义初始噪声尺度上学习的，并且因此无需针对任何特定的噪声调度进行进一步的细化，已经训练好的噪声去除网络的参数在后续训练噪声调度网络的过程中保持不变，因此可以更快地训练噪声调度网络。根据本申请的又一方面，还提供了一种样本生成装置。图8示出了根据本申请的实施例的生成用于生成模型中的噪声尺度序列的装置800的结构框图。如图8所示，装置800包括获取模块810、构造模块820、和生成模块830。获取模块810用于获取随机噪声输入、预设噪声水平、以及预设噪声尺度，分别作为第N个数据、待生成的噪声水平序列中的第N个噪声水平、待生成的噪声尺度序列中的第N个噪声尺度，N为第一数量。可选地，所述预设噪声水平、以及预设噪声尺度通过网格搜索算法从数值组合中基于特定度量标准来进行选择。构造模块820用于利用生成模型中的噪声去除网络和噪声调度网络，基于所述随机噪声输入、预设噪声水平、以及预设噪声尺度，以从N开始以一递减的索引构造所述噪声尺度序列。生成模块830,用于利用所构造的噪声尺度序列和所述生成模型中的噪声去除网络，基于待处理噪声输入生成多个推理样本，并将生成的最后一个推理样本作为新的样本进行输出，所述多个推理样本的数量与所述噪声尺度序列中的噪声尺度的数量相关联。生成模型是根据如参考图3-5描述的方法来进行训练的。对于构造模块820的具体操作，可以包括以下：针对从N开始以一递减的索引n，n为小于等于N且大于等于2的整数，对于第n个噪声水平：利用生成模型中的噪声去除网络，基于第n个数据、第n个噪声水平和第n个噪声尺度，生成第n-1个数据；基于第n个噪声水平和第n个噪声尺度，确定第n-1个噪声水平；基于第n-1个噪声水平和第n个噪声尺度，确定第n-1个噪声尺度约束；利用生成模型中的噪声调度网络，基于第n-1个噪声尺度约束和第n-1个数据，生成噪声调度因子；基于第n-1个噪声尺度约束以及噪声调度因子，生成第n-1个噪声尺度，其中，n为小于等于N且大于等于1的整数；然后，利用预设噪声尺度和所生成的至少一个噪声尺度构造所述噪声尺度序列。此外，在所述第n-1个噪声水平与所述第n个噪声水平之差小于预设阈值的情况下，利用所生成的第n-1个噪声尺度到第N个噪声尺度构造所述噪声尺度序列。在图8中，根据训练装置要进行的功能而将其划分为多个模块，然而根据不同的划分方式，训练装置可以包括更多或更少的模块，本申请对此不做限制。通过参考图8所述的样本生成装置，除了训练过程的效率提高之外，所生成的噪声尺度序列可以用于生成新的样本，由于通过设置阈值，生成的噪声尺度序列可以包括更少数量的噪声尺度，因此，在样本生成过程中的步骤可以减少，从而可以加快样本生成的速度。为了使本申请的方案更完整，还简单介绍噪声去除网络和噪声调度网络的架构。噪声去除网络的模型架构可以采用上采样块、FILM模块和下采样块。或者，如果UBlocks和DBlocks能够沿时间维度进行上采样和下采样，则可以应用其他类型的架构来替换它们例如，Sandglasset架构也可以用来构建得分网络。可选地，期望噪声调度网络构建得到的噪声尺度序列中从β’t+1到β’t的噪声尺度是下降的，以保持较少的样本生成步骤，同时努力获得高的生成质量。因此例如可以采用sigmoid门控神经网络实现从步骤t+1到步骤t的递减噪声尺度。噪声调度网络的模型架构可以采用轻量级GALR网络。GALR最初是为语音增强而提出的，所以认为它非常适合预测噪声尺度。对于GALR网络的配置，使用8个样本的窗口长度进行编码，使用64的分段大小进行分段，并且仅使用128个隐藏维度的两个GALR块中获得。为了使噪声调度网络输出具有适当的范围和维数，将sigmoid函数应用于GALR网络的最后一个块的输出，例如使得噪声尺度的值可以在0到1之间。然后，对分段和特征维度上的结果进行平均，以获得预测比率:其中GALR表示GALR网络，AvgPool2D表示应用于分段和特征维度的平均池化操作，并且σ:＝1/。同样值得注意的是，与得分网络的成本相比，噪声调度网络的计算成本确实很小，因为预测噪声尺度变量本质上是一项相对容易得多的任务。基于GALR的噪声调度网络在能够产生稳定可靠的结果的同时，速度约比得分网络快3.6倍，这意味着训练BDDM几乎可以与训练DDPM或DDIM一样快。当然，除了GALR网络之外，最初提出的用于语音增强、噪声估计或语音分离的其他替代模型架构，例如DPRNN和ConvTasnet等也可以用于构成噪声调度网络。此外，本申请提出的方法和用作对比的基线方法都可以用Pytorch库实现的。LJ和VCTK语音数据集的得分网络是使用单个NVIDIA Tesla P40 GPU从头开始训练的，训练步数超过1M，耗时约3天。相比之下，本申请提出的方法训练噪声调度网络只需要10k步就能收敛，对于两个数据集来说都不超过一个小时。本申请提出的方法的典型使用场景包括在语音合成中产生高保真原始音频。功能包括快速、高质量的神经声码器和波形合成器。它从高斯白噪声开始，通过迭代细化将其转换为语音。可以通过提供调节信号来控制语音，例如对数标度Mel谱图。以下基于本申请提出的BDDM模型与其他相关生成模型进行比较，主要是针对语音合成任务，来更好地说明本申请的实施例的优点。用于对比的模型包括WaveGrad和Diff-TTS以及噪声估计方法的模型。NE方法通过使用对数尺度回归损失来训练噪声估计器α^t＝g以直接预测αt2,在推断时，NE需要预定义的噪声调度，例如，线性调度或斐波那契调度。采用多说话人语音合成基准VCTK来进行评估。VCTK由108个说各种口音的英语的人被以48KHz的频率采样的话语组成。分割VCTK数据集进行训练和测试：100个说话人用于训练多说话人模型，8个说话人用于测试。对44257个话语子集进行了训练，并对在保留的100个话语子集上进行了评估。在训练过程中，根据地面真实音频计算的Mel-谱图被用作调节特征。此外，使用保留子集来评估具有真实特征的合成语音。所有模型都是在同一个VCTK语音训练集上训练的，并基于一个公开可用的实现。不同模型的噪声调度的性能在LS-MSE、MCD、STOI、PESQ和MOS方面来进行比较。这些模型均采用相同的噪声去除网络。一方面是基于客观和主观度量的评价。使用了目标度量—对数-梅尔谱图均方误差和Mel-倒频谱距离，以评估原始波形和Mel-频域中生成的波形之间的一致性。此外，为了测量生成的语音相对于参考语音的噪声和失真，采用了语音增强中常用的两个度量—语音质量的感知评估和短时客观可懂度度量。平均意见得分被用作语音质量的主观度量。结果在表1中给出，其中包括了对应于8、16和21个推理步骤的三组的性能。值得注意的是，采用本申请的方法的BDDM仅用16或21步就超过了1000步WaveGrad。当减少到8步时，本申请的方法获得了与WaveGrad中昂贵的网格搜索的8步相当的性能。对于NE，可以观察到从16步到21步的退化，这同样表明了NE对于VCTK数据集的不稳定性。相比之下，本申请的方法在增加步数的同时不断提高性能。由于本申请的主要改进点在于在训练了得分网络之后训练的噪声调度网络，而得分网络其实这几个模型都是大致相同的，因此为了便于凸显出噪声调度网络的优势，在比较过程中，所有方法均采用相同的得分网络且都在VCTK上训练了1M次迭代，因此可以确定噪声调度对于提高样本生成质量和提高样本生成的效率至关重要。【表1】对于VCTK语音集上不同模型的噪声调度的性能比较从表1中看出，本申请的实施例提出的BDDM的LS-MSE和MCD能够相当于或低于其他模型，STOI、PESQ和MOS能够相当于或高于其他模型，随着步数增加，性能越好，从而表现出比其他模型更好的综合性能。另一方面是将BDDM的噪声调度网络用于不同的模型的情况分析。如前面所述，由于噪声调度网络的训练与噪声去除网络的训练是分开的，预先训练的噪声去除网络可以是现有模型中对应于反向过程的得分网络，因此本申请提出的BDDM不被限制到专门的反向过程的样本生成，而是利用不同的反向过程，包括DDPM和DDIM的。使用了另一基准语音集-LJ语音集来进行该评估。这里省略了MOS得分，因为它与STOI和PESQ高度相关。表2给出了客观分数。它们指示了，将本申请提出的方法应用到DDPM或DDIM反向过程中，会产生可比且有竞争力的结果。同时，结果显示了一些细微的差异:本申请的方法通过DDPM反向过程给出了在信号误差和一致性度量方面稍好的样本，而通过DDIM的反向过程倾向于生成在可理解性和感知度量方面更好的样本根据本申请的再一方面，还提供了一种计算设备。图9示出了根据本申请实施例的计算设备900的结构框图。该计算设备包括：处理器；和存储器，其上存储有指令，所述指令在由所述处理器执行时，使得所述处理器执行如参考图3-5所述的训练方法的各个步骤以及参考图6A-6B所述的样本生成方法的各个步骤。所述计算设备可以为计算机终端、移动终端或其它具有计算和处理能力的设备，所述计算设备还可以参与构成或包含本申请实施例所提供的训练装置。所述计算设备可以是服务器和/或用户终端，或者区块链系统中的各个节点处的计算设备。处理器可以是一种集成电路芯片，具有信号的处理能力。上述处理器可以是通用处理器、数字信号处理器、专用集成电路、现成可编程门阵列或者其他可编程逻辑器件、分立门或者晶体管逻辑器件、分立硬件组件。可以实现或者执行本申请的实施例中的公开的各方法、步骤及逻辑框图。通用处理器可以是微处理器或者该处理器也可以是任何常规的处理器等，可以是X84架构或ARM架构的。存储器可以是非易失性存储器，诸如只读存储器、可编程只读存储器、可擦除可编程只读存储器、电可擦除可编程只读存储器或闪存。应注意，本申请描述的方法的存储器旨在包括但不限于这些和任意其它适合类型的存储器。计算设备的显示屏可以是液晶显示屏或者电子墨水显示屏，计算设备的输入装置可以是显示屏上覆盖的触摸层，也可以是终端外壳上设置的按键、轨迹球或触控板，还可以是外接的键盘、触控板或鼠标等。根据本申请的另一方面，还提供了一种计算机可读存储介质，存储有计算机程序，计算机程序被处理器执行时，使得处理器执行如参考图3-5所述的训练方法的各个步骤以及参考图6A-6B所述的样本生成方法的各个步骤。根据本申请的又一方面，还提供了一种计算机程序产品，包括计算机程序，计算机程序被处理器执行时实现如参考图3-5所述的训练方法的各个步骤以及参考图6A-6B所述的样本生成方法的各个步骤。计算机程序可以存储在计算机可读存储介质中。上述提到的存储介质可以是诸如只读存储器、磁盘或光盘等的非易失性存储介质。需要说明的是，附图中的流程图和框图，图示了按照本申请各种实施例的系统、方法和计算机程序产品的可能实现的体系架构、功能和操作。在这点上，流程图或框图中的每个方框可以代表一个模块、程序段、或代码的一部分，模块、程序段、或代码的一部分包含至少一个用于实现规定的逻辑功能的可执行指令。也应当注意，在有些作为替换的实现中，方框中所标注的功能也可以以不同于附图中所标注的顺序发生。例如，两个接连地表示的方框实际上可以基本并行地执行，它们有时也可以按相反的顺序执行，这依所涉及的功能而定。也要注意的是，框图和/或流程图中的每个方框、以及框图和/或流程图中的方框的组合，可以用执行规定的功能或操作的专用的基于硬件的系统来实现，或者可以用专用硬件与计算机指令的组合来实现。一般而言，本申请的各种示例实施例可以在硬件或专用电路、软件、固件、逻辑，或其任何组合中实施。某些方面可以在硬件中实施，而其他方面可以在可以由控制器、微处理器或其他计算设备执行的固件或软件中实施。当本申请的实施例的各方面被图示或描述为框图、流程图或使用某些其他图形表示时，将理解此处描述的方框、装置、系统、技术或方法可以作为非限制性的示例在硬件、软件、固件、专用电路或逻辑、通用硬件或控制器或其他计算设备，或其某些组合中实施。在上面详细描述的本申请的示例实施例仅仅是说明性的，而不是限制性的。本领域技术人员应该理解，在不脱离本申请的原理和精神的情况下，可对这些实施例或其特征进行各种修改和组合，这样的修改应落入本申请的范围内。
