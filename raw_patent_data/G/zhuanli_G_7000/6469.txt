标题title
一种基于改进YOLOv3的遥感图像小目标检测方法
摘要abst
本发明公开了一种基于改进YOLOv3的遥感图像小目标检测方法，属于深度学习及目标检测技术领域，包括数据集预处理；优化YOLOv3网络，在Neck中加入空洞卷积组模块、特征强化模块和通道注意力机制模块；在线数据增强；前向推理；改进损失函数；选择在验证集上检测精度和召回率最高的YOLOv3网络模型载入网络等步骤。本发明通过改进损失函数和在YOLOv3原网络中加入空洞卷积组模块、特征强化模块、通道注意力机制模块以改进YOLOv3检测网络，性能明显提升，对遥感图像中的目标检测更全面，精度更高，而且提高了训练速度和整体检测精度。
权利要求书clms
1.一种基于改进YOLOv3的遥感图像小目标检测方法，其特征在于：包括以下步骤：步骤1，数据集预处理：获取训练遥感图像组成数据集，对数据集进行格式转换，并将数据集随机划分为训练验证集和测试集，在训练时采用交叉验证的方式对YOLOv3网络模型评估；步骤2，对YOLOv3网络进行优化：在Neck中加入空洞卷积组模块、特征强化模块和通道注意力机制模块；步骤3，在线数据增强：在训练集中每次随机选择相同数量的图片，对其在线图像数据增强后输入优化后的YOLOv3网络；步骤4，前向推理：优化后的YOLOv3网络中的Head负责根据融合的特征推断出物体坐标和类别，获得包围目标物体的边框坐标、物体类别和置信度；步骤5，改进损失函数：根据函数值迭代训练并更新参数，每次迭代后在验证集上评估；步骤6，训练结束：选择在验证集上检测精度和召回率最高的优化的YOLOv3网络模型载入网络。2.根据权利要求1所述的一种基于改进YOLOv3的遥感图像小目标检测方法，其特征在于：步骤1中，所述数据集预处理具体是指：将数据集标注信息变换成VOC格式，将其按9：1的比例随机划分为训练验证集和测试集，各集合互不干涉，没有相同的图片，防止数据被污染；在训练时采用交叉验证的方式对YOLOv3网络模型评估，即先将训练验证集按8：1的比例随机划分为训练集和验证集，训练集用于模型训练和权重更新，验证集用于对每轮训练结束后获得的模型评估。3.根据权利要求1所述的一种基于改进YOLOv3的遥感图像小目标检测方法，其特征在于：步骤2中，所述空洞卷积组模块能够适应多尺度图片输入，扩大网络感受野；所述特征强化模块能够将物体位置信息丰富而语义信息较少的浅层特征与物体语义信息丰富而位置信息较少的深层特征融合，融合不同分辨率的特征；所述通道注意力机制模块能够排除干扰，从复杂背景中提取对检测更为关键的物体特征信息，赋予特征各通道权值以加强全局特征。4.根据权利要求3所述的一种基于改进YOLOv3的遥感图像小目标检测方法，其特征在于：通道注意力机制模块的计算公式为：全局平均池化：式中，W、H表示特征图的宽、高，xi,j表示特征图每个通道上第i行第j列点的值；通道卷积：ω＝σ)式中，因经过全局平均池化，所以此时i＝1，yj表示第j个通道，表示yj的k个相邻通道的集合，αj表示第j个通道权重，σ表示sigmoid,ωi表示第i个权重；k的求法：式中，c表示给定通道数，γ、b分别等于2、1，odd表示最近的奇数。5.根据权利要求1所述的一种基于改进YOLOv3的遥感图像小目标检测方法，其特征在于：步骤3中，所用在线数据增强技术包括光度失真、几何失真、模拟遮挡、多图像融合；所述光度失真主要改变图片的像素点，如：随机亮度变化、随机对比度变化、随机饱和度变化、随机色度变化、添加随机噪声；所述几何失真主要改变图片的形状，如：随机裁剪、随机旋转、随机角度；所述模拟遮挡是指随机擦除图片中的小块，即将小块像素点设置为全黑；所述多图像融合是指随机裁剪一幅图像的一般部分，并替换另一张图片上相同位置的部分，或将两幅图片重叠在一起，像素点叠加。6.根据权利要求1所述的一种基于改进YOLOv3的遥感图像小目标检测方法，其特征在于：步骤5中，损失函数中的位置损失使用DIOU来计算，它同时考虑检测框与真实框的重合度，重合方向和位置关系三个因素，可以直接最小化两个目标框的距离，因此收敛得会更快；改进后的损失函数公式为：式中，LossDIOU为一张图片上总DIOU损失，Lossconfi为一张图片上总置信度损失，Losscls为一张图片上总类别损失，N为一张图片上的目标数量。7.根据权利要求1所述的一种基于改进YOLOv3的遥感图像小目标检测方法，其特征在于：步骤6中，选择在验证集上评估精度和召回率最高的模型载入网络，在测试集上获得该模型的检测效果。
说明书desc
技术领域本发明涉及深度学习及目标检测领域，尤其是一种基于改进YOLOv3的遥感图像小目标检测方法。背景技术随着深度学习和神经网络的发展，计算机视觉得以飞速发展。在此领域，目标检测与识别技术被广泛研究并应用于实践，给人们生活带来极大便利。例如应用于无人机上，可以自动地识别出遥感图像中的特定目标，可以代替人工来高效地完成这种重复工作等。然而在许多目标检测工作中存在以下问题：1、目标多为尺度小，只有几十个像素点，不利于寻找和识别；2、背景复杂，干扰因素多，如拍摄角度，光照变化、相似目标、物体遮挡等问题，容易导致误判，不利于检测。将目前常用的几个经典目标检测网络对比后，选择使用YOLOv3检测算法，该算法检测速度块，识别精度高，在该算法基础上改进会得到更好的检测性能。对该网络的改进思路：1、在基础骨干网络中，随着深度增加，每次下采样后虽然扩大了感受野，但都会使图像尺寸变小，分辨率降低，即使再经过上采样，也会造成一定的目标特征丢失。通过空洞卷积可以解决这种情况：扩大感受野，模型可以在图片中观察到更大的范围，从而能够比较全面的检测到目标；更大尺寸的特征图会包含更多的目标信息，有利于定位和分类。2、人类看事物时，在观察整个区域后会重点关注感兴趣的部分，从复杂背景中获取更有用的信息，这就是注意力机制算法。计算机视觉与人类视觉有很多相似之处，基本思想是让机器学会排除影响因素，捕捉关键信息。将这种算法用于检测中，对精度有一定提高。3、在YOLOv3真实框和预测框之间的损失函数方面，坐标损失采用均值平方和，置信度损失和类别损失上采用交叉熵，二者相加得到总体误差。使用此种方法计算损失，无法全面反映两框的位置关系、重合度和预测框需要靠拢的方向，因此需要改进损失函数。发明内容本发明需要解决的技术问题是提供一种基于改进YOLOv3的遥感图像小目标检测方法，改进后的YOLOv3检测网络，性能明显提升，对遥感图像中的目标检测更全面，精度更高，而且训练速度提高。为解决上述技术问题，本发明所采用的技术方案是：一种基于改进YOLOv3的遥感图像小目标检测方法，包括以下步骤：步骤1，数据集预处理：获取训练遥感图像组成数据集，对数据集进行格式转换，并将数据集随机划分为训练验证集和测试集，在训练时采用交叉验证的方式对YOLOv3网络模型评估；步骤2，对YOLOv3网络进行优化：在Neck中加入空洞卷积组模块、特征强化模块和通道注意力机制模块；步骤3，在线数据增强：在训练集中每次随机选择相同数量的图片，对其在线图像数据增强后输入优化后的YOLOv3网络；步骤4，前向推理：优化后的YOLOv3网络中的Head负责根据融合的特征推断出物体坐标和类别，获得包围目标物体的边框坐标、物体类别和置信度；步骤5，改进损失函数：根据函数值迭代训练并更新参数，每次迭代后在验证集上评估；步骤6，训练结束：选择在验证集上检测精度和召回率最高的优化的YOLOv3网络模型载入网络。本发明技术方案的进一步改进在于：步骤1中，所述数据集预处理具体是指：将数据集标注信息变换成VOC格式，将其按9：1的比例随机划分为训练验证集和测试集，各集合互不干涉，没有相同的图片，防止数据被污染；在训练时采用交叉验证的方式对YOLOv3网络模型评估，即先将训练验证集按8：1的比例随机划分为训练集和验证集，训练集用于模型训练和权重更新，验证集用于对每轮训练结束后获得的YOLOv3网络模型评估。本发明技术方案的进一步改进在于：步骤2中，所述空洞卷积组模块能够适应多尺度图片输入，扩大网络感受野；所述特征强化模块能够将物体位置信息丰富而语义信息较少的浅层特征与物体语义信息丰富而位置信息较少的深层特征融合，融合不同分辨率的特征；所述通道注意力机制模块能够排除干扰，从复杂背景中提取对检测更为关键的物体特征信息，赋予特征各通道权值以加强全局特征。本发明技术方案的进一步改进在于：通道注意力机制的计算公式为：全局平均池化：式中，W、H表示特征图的宽、高，xi,j表示特征图每个通道上第i行第j列点的值；通道卷积：ω＝σ)式中，因经过全局平均池化，所以此时i＝1，yj表示第j个通道，表示yj的k个相邻通道的集合，αj表示第j个通道权重，σ表示sigmoid,ωi表示第i个权重；k的求法：式中，c表示给定通道数，γ、b分别等于2、1，odd表示最近的奇数。本发明技术方案的进一步改进在于：步骤3中，所用在线数据增强技术包括光度失真、几何失真、模拟遮挡、多图像融合；所述光度失真主要改变图片的像素点，如：随机亮度变化、随机对比度变化、随机饱和度变化、随机色度变化、添加随机噪声；所述几何失真主要改变图片的形状，如：随机裁剪、随机旋转、随机角度；所述模拟遮挡是指随机擦除图片中的小块，即将小块像素点设置为全黑；所述多图像融合是指随机裁剪一幅图像的一般部分，并替换另一张图片上相同位置的部分，或将两幅图片重叠在一起，像素点叠加。本发明技术方案的进一步改进在于：步骤5中，损失函数中的位置损失使用DIOU来计算，它同时考虑检测框与真实框的重合度，重合方向和位置关系三个因素，可以直接最小化两个目标框的距离，因此收敛得会更快；改进后的损失函数公式为：式中，LossDIOU为一张图片上总DIOU损失，Lossconfi为一张图片上总置信度损失，Losscls为一张图片上总类别损失，N为一张图片上的目标数量。本发明技术方案的进一步改进在于：步骤6中，选择在验证集上评估精度和召回率最高的模型载入网络，在测试集上获得该模型的检测效果。由于采用了上述技术方案，本发明取得的技术进步是：1、本发明使用特征增强模块可以将具有较多位置信息的浅层特征与具有较多语义信息的深层特征融合，提高了Head推理层可用信息量。2、本发明使用空洞卷积组模块，在不改变分辨率的同时提高感受野；使用通道注意力机制可以让网络从复杂背景信息中提取到更多的检测信息，有利于排除干扰。3、本发明改进损失函数后，目标框更拟合。4、本发明改进后的YOLOv3检测网络，性能明显提升，对遥感图像中的目标检测更全面，精度更高，而且训练速度提高。附图说明图1是本发明中YOLOv3原结构图；图2是本发明中对YOLOv3改进的总体方案图；图3是本发明中SPP模块图；图4是本发明中为RFB模块图；图5是本发明所用的SFM空洞卷积组模块图；图6是本发明中CSP模块图；图7是本发明所用的FEM特征强化模块图；图8是本发明所用的ECA通道注意力模块图；图9是本发明中IOU、DIOU图。具体实施方式下面结合附图及实施例对本发明做进一步详细说明：本发明提供一种基于改进YOLOv3的遥感图像小目标检测方法，通过改进损失函数和在YOLOv3原网络中加入特征强化模块通道注意力机制模块的方法以提高训练速度和整体精度，所改进的方案如图2所示。本专利申请中：SPP为Spatial Pyramid Pooling的英文缩写；RFB为Receptive Field Block的英文缩写；SFM为Spatial and Field Model的英文缩写；CSP为Cross Stage Partial connections的英文缩写；FEM为Feature Enhanced Model的英文缩写；ECA为Efficient Channel Attention的英文缩写；IOU为Intersection Over Union的英文缩写；DIOU为Distance IOU的英文缩写。如图2-9所示，一种基于改进YOLOv3的遥感图像小目标检测方法，包括对数据集随机划分为训练验证集和测试集，在训练时采用交叉验证的方式对模型评估。对用于训练的图片集在线数据增强，包括几何失真、光度失真、模拟遮挡、图片融合。基础骨干网络Darknet-53负责从数据增强的图片中由浅入深地提取物体特征。在Neck中加入特征强化机制FEM，融合不同分辨率的特征；加入空洞卷积组SFM，适应多尺度输入，扩大感受野；嵌入ECA通道注意力模块，赋予特征各通道权值以加强全局特征。Head负责根据融合的特征推断出物体坐标和类别。在训练时，将Head的推断结果与目标标签作比较，根据误差函数求得误差，这里误差函数将原来的MSE改进为DIOU损失，然后使用误差反向传播法和随机梯度下降法来更新需要更新的参数；在测试时，对Head的结果做NMS处理，使每个预测框只对应一个目标，通过比较所有预测框与真实框，计算准确率；检测过程与测试过程类似，只是不再计算准确率，直接在图片上显示预测框。实施例一种基于改进YOLOv3的遥感图像小目标检测方法，具体包括以下步骤：步骤1：获取训练遥感图像组成数据集，将数据集标注信息变换成VOC格式，将其按9：1的比例随机划分为训练验证集和测试集，各集合互不干涉，没有相同的图片，防止数据被污染。训练时采用交叉验证，即先将训练验证集按8：1的比例随机划分为训练集和验证集，训练集用于模型训练和权重更新，验证集用于对每轮训练结束时获得的模型评估。步骤2：改进Neck。随着Darknet-53网络的加深，提取的目标特征会由多变少，由具体变得抽象。为了适应不同分辨率上目标位置和尺寸不一致的各种情况，同时扩大感受野，借鉴SPP和RFB网络的思想，提出SFM，如图3所示，即对将输入特征分别经过三个离心率不同的空洞卷积分支后的三个结果再与原特征在通道上叠加，最后将融合后的特征传递给下个模块。浅层特征中物体位置信息丰富，而语义信息较少，深层特征中物体语义信息丰富，而位置信息较少，为了互补二者的特征信息，借鉴CSP模块思想，提出特征强化模块FEM，使目标信息更全面。FEM将四倍下采样特征经过3×3的卷积核后与八倍下采样特征在通道上叠加，将八倍下采样特征经过3×3的卷积核后与十六倍下采样特征在通道上叠加，将两个叠加特征分别经过两个1×1的卷积核后输入下一个模块。在两个叠加特征之后分别使用通道注意力机制ECA，扩大每个特征像素的观察范围，ECA模块如图5所示。每个提取到的特征图都会有多个通道，各个通道上的特征通过叠加就可以得到完整的物体特征，为了排除干扰提取关键信息，嵌入ECA通道注意力机制，对重要的特征分量所在通道赋予加大权重值，对非重要权重所在特征赋予较小权重，然后求加权和，ECA如图5所示。Neck是YOLOv3检测网络的第二部分，如图1所标注的Neck部分。改进的Neck如图2中所标注的Neck部分。ECA模块实现了一种不降维的局部跨通道交互策略，能自适应选择一维卷积核大小，融合每个相邻k个不同通道的特征信息。首先，对输入进行全局平均池化；然后，使用1*1的卷积核完成通道卷积；其次，将通道卷积结果后经过Sigmoid函数得到各通道的权重；最后，将输入特征各层与对应层权重相乘。ECA模块嵌入的位置如图2所示，分别在两个FEM模块之后。ECA的计算公式为：全局平均池化：式中，W、H表示特征图的宽、高，xi,j表示特征图每个通道上第i行第j列点的值。通道卷积：ω＝σ)式中，因经过全局平均池化，所以此时i＝1；yj表示第j个通道；表示yj的k个相邻通道的集合；αj表示第j个通道权重；σ表示sigmoid,ωi表示第i个权重。k的求法：式中，c表示给定通道数；γ、b分别等于2、1；odd表示最近的奇数。步骤3：所用在线数据增强技术主要有光度失真、几何失真、模拟遮挡、多图像融合。光度失真主要改变图片的像素点，如：随机亮度变化、随机对比度变化、随机饱和度变化、随机色度变化、添加随机噪声。几何失真主要改变图片的形状，如：随机裁剪、随机旋转、随机角度。模拟遮挡有：随机擦除图片中的小块。多图像融合有：随机裁剪一幅图像的一般部分，并替换另一张图片上相同位置的部分，或将两幅图片重叠在一起，像素点叠加，技术有Mix_Up、Cut_Mix、style_transfer_GAN。数据增强的目的在于：1、增加训练的数据量，提高模型的泛化能力；2、增加图片多样性，提升模型的鲁棒性。步骤4：前向推理，输出结果。Head检测头YOLOv3检测网络的第三部分，如图1所标注部分。根据Neck融合的特征，输出S*S*)的张量，表示每张图片映射为S*S个小格，每个小格内有三个检测结果，每个检测结果包括一个物体的4个检测方框坐标、1个置信度、20个类别的预测分数。步骤5：计算误差，更新参数。从步骤1到步骤4为YOLOv3网络的前向推导部分，将推导结果与对应标签求得误差，将误差沿前向路径反向传播，根据梯度方向更新所有权重参数，从前向到反向为一轮迭代。误差分为位置误差、置信度误差和类别误差。位置误差使用DIOU损失，其他部分误差计算方式不变。DIOU可以直接最小化两个目标框的距离，因此收敛得会更快。IOU计算公式为：式中，A，B为真实框框和预测框，IOU是两个框的面积的交集比并集。DIOU计算公式为：式中，ρ2为两个框中心点之间的欧式距离；c2表示包围两个框最小矩形框对角的欧式距离，如图4所示。单个预测框的DIOU损失为：lossDIOU＝1-DIOU一张图片上总DIOU损失为：式中，λcood表示DIOU损失所占权重。一张图片上总置信度损失：式中，此损失分为有目标置信度损失和无目标置信度损失，表示第i个小格第j个预测框的置信度，表示第i个小格第j个真实框的置信度，表示当第i个小格第j个预测框有目标时为1，其余情况为0，表示当第i个小格第j个预测框无目标时为1，其余情况为0，λnoobj表示无目标时置信度误差权重。一张图片上总类别损失：式中，c∈classes表示物体的20个类，表示第i个小格第j个预测框中各个类别概率，表示第i个小格第j个真实框中各个类别概率，所属类别概率为1，其他类别位置为0。一张图片上总损失为：式中，N为一张图片上的目标数量。初始学习率设置为0.0001，学习衰减率设施为0.995，Batch_size设置为10，保存迭代次数为2，部分权重更新轮数设置为35，总体权重微调轮数设置为15，测试分数阈值设置为0.3，测试IOU阈值设置为0.5，输入图片大小每过几轮随机选择为32的10到19倍。训练方法采用随机梯度下降，误差反向传播，学习率衰减方法。每次训练得到的模型都需在验证集上评估精度和召回率，将评估最好的模型在测试集上测试可获得其泛化能力。步骤6：加载评估为最好的权重，输入图片，此时网络会得到多个框，利用NMS过滤得到置信度最高的框，在图片上显示包围框和目标类别及置信度。
