标题title
一种基于改进的GRNet网络的虚拟换衣方法及系统
摘要abst
本发明提供一种基于改进的GRNet网络的虚拟换衣方法，包括基于用户提供的身体数据和脸部信息进行人体建模，得到人脸3D模型和人体3D模型；获取预设衣服数据集中的衣服图像并通过点云配准进行两两配准，且进一步3D建模得到衣服3D模型；根据人体3D模型与衣服3D模型中提取的模糊特征点位，使用改进的GRNet网络对人体与衣服进行配对，得到上身效果平和且稳定的衣服3D模型；基于人脸3D模型，检测出人脸肤色，进行比色工作，以调整配对后的衣服3D模型中的衣服颜色，并展现最终虚拟换衣效果。实施本发明，可解决现有虚拟换衣效果与现实上身效果有大量误差的问题，以及给使用者更多符合身体肤色的衣服颜色搭配组合，以提高试衣体验感。
权利要求书clms
1.一种基于改进的GRNet网络的虚拟换衣方法，其特征在于，包括以下步骤：基于用户提供的身体数据和脸部信息进行人体建模，分别得到人体3D模型人脸3D模型和人体3D模型；获取预设衣服数据集中的衣服图像，并通过点云配准对所述衣服图片进行两两配准，且进一步依据配准获得地服装特征点位进行3D建模，得到衣服3D模型；从所述人体3D模型与所述衣服3D模型中提取人体轮廓和衣服轮廓具有模糊特征的点位，并基于所提取的点位，使用预先改进的GRNet网络对所述人体3D模型与所述衣服3D模型进行配对，得到配对之后以实现上身效果平和且稳定的衣服3D模型；基于所述人脸3D模型，检测出人脸肤色，且根据检测出的人脸肤色进行比色工作，然后以此调整衣服3D模型中的衣服颜色，进行模型展现，以实现最终虚拟换衣效果。2.如权利要求1所述的基于改进的GRNet网络的虚拟换衣方法，其特征在于，所述脸部信息来自于用户提供的各个方位的2D人脸照片。3.如权利要求2所述的基于改进的GRNet网络的虚拟换衣方法，其特征在于，所述人脸3D模型是基于人脸模型FTMR构成的；其中，所述人脸模型FTMR框架由两个特征提取分支、三个结构细化模块组成；其中，特征提取分支包括FFRNet和EBNet；FFRNet用于对3DMM、人脸姿态位置及光照参数进行回归；EBNet用于提取图像特征，并将提取的特征用于后续的细节细化和身份保持；结构细化模块由三个图卷积网络形成，包括一个GCN译码器解码特征提取网络FFRNet和制作详细的颜色网格顶点，GCN定义器会完善回归量，生成的顶点颜色和组合器把两种颜色生产最后的顶点颜色，最后由判别器通过对抗性训练来提高图像纹理细化模块的输出。4.如权利要求1所述的基于改进的GRNet网络的虚拟换衣方法，其特征在于，所述身体数据包括用户提供的身高、体重、胸围、腰围和臀围。5.如权利要求4所述的基于改进的GRNet网络的虚拟换衣方法，其特征在于，所述人体3D模型是基于由包裹变形分支和补偿变形分支组成的神经融合形状技术构建得到的。6.如权利要求1所述的基于改进的GRNet网络的虚拟换衣方法，其特征在于，所述通过点云配准对所述衣服图片进行两两配准的具体步骤包括：随机从两张衣服图片中按照同样的关键点选取标准，提取关键点；对选择的所有关键点分别计算其特征描述子；结合特征描述子在两个数据集中的坐标的位置，以两者之间特征和位置的相似度为基础，估算它们的对应关系，初步估计对应点对；假定数据是有噪声的，除去对配准有影响的错误的对应点对；利用剩余的正确对应关系来估算刚体变换，完成配准。7.如权利要求1所述的基于改进的GRNet网络的虚拟换衣方法，其特征在于，从所述人体3D模型与所述衣服3D模型中提取人体轮廓和衣服轮廓具有模糊特征的点位，基于所提取的点位，使用预先改进的GRNet网络对所述人体3D模型与所述衣服3D模型进行配对，得到配对之后以实现上身效果平和且稳定的衣服3D模型的具体步骤包括：给定一个查询和库对，通过深度卷积网络提取所述人体3D模型与所述衣服3D模型中人体轮廓和衣服轮廓具有模糊特征的点位，并将其输入到相似度计算中，以所有区域对相似度为图节点构建一个相似度金字塔图；在相似度金字塔图中，所有区域对相似度为图节点，两个相似度之间的关系为边，并计算两个相似度之间的相似向量；对相似向量进行改动；其中，假定缩放的比例为α，对获得的局部特征x和y执行缩放操作，执行缩放后，局部特征的坐标由变为。假定偏移的距离为，执行单纯的偏移后，局部特征的坐标由变为；经过对局部坐标先缩放后偏移的操作后，再将局部坐标带入相似向量s中以获得改动后的相似向量s’；根据改动后的相似向量，对所述衣服3D模型的大小进行调整，以得到上身效果平和且稳定的衣服3D模型。8.如权利要求1所述的基于改进的GRNet网络的虚拟换衣方法，其特征在于，所述人脸肤色是通过对所述人脸3D模型采用OpenCV库检测得到的；其中，所述OpenCV库所涉及的算法包括图像色域转换算法、颜色通道分割算法、高斯滤波算法和OSTU自动阈值算法。9.如权利要求1所述的基于改进的GRNet网络的虚拟换衣方法，其特征在于，所述配对之后的衣服3D模型中的衣服颜色调整是在Palette类库中，通过由规则选择、方案生成及颜色替换所形成的配色方案来实现的；其中，所述规则选择具体为通过对衣服代表色、风格和基于配色规则的结果进行评分与训练，得到不同颜色、风格对应的最佳规则；所述方案生成具体为以HSL为颜色模型构建规则，通过分量建立配色规则，使任何一个颜色C，可以转化为由三个分量构成的数组；所述颜色替换具体为按照配色方案中的颜色与衣服中元素的对应关系，对衣服中的元素进行颜色替换，进而完成配色。10.一种基于改进的GRNet网络的虚拟换衣系统，其特征在于，包括：人体模型构建单元，用于基于用户提供的身体数据和脸部信息进行人体建模，分别得到人脸3D模型和人体3D模型；衣服模型构建单元，用于获取预设衣服数据集中的衣服图像，并通过点云配准对所述衣服图片进行两两配准，且进一步依据配准获得地服装特征点位进行3D建模，得到衣服3D模型；人体与衣服模型匹配单元，用于从所述人体3D模型与所述衣服3D模型中提取人体轮廓和衣服轮廓具有模糊特征的点位，并基于所提取的点位，使用预先改进的GRNet网络对所述人体3D模型与所述衣服3D模型进行配对，得到配对之后以实现上身效果平和且稳定的衣服3D模型；服装配色单元，用于基于所述人脸3D模型，检测出人脸肤色，且根据检测出的人脸肤色进行比色工作，然后以此调整衣服3D模型中的衣服颜色，进行模型展现，以实现最终虚拟换衣效果。
说明书desc
技术领域本发明涉及计算机技术领域和虚拟现实技术领域，尤其涉及一种基于改进的GRNet网络的虚拟换衣方法及系统。背景技术目前，许多服装商店实现了面向消费者的线上虚拟换衣功能，依赖图像分割、三维建模、图像处理等技术以支持消费者在移动端查看衣服上身效果的需求。由于网络的日益发展，虚拟换衣功能受到了社会的广泛关注。虽然近年来有许多方法被提出，但要实现虚拟换衣效果的完整性和逼真性依旧是一个充满挑战的研究方向，它仍然有许多值得深入探索和亟待解决的问题。至今，服装商店已经积累大量的服装资源和数据，从而形成了规模巨大的服装数据集，这为服装搭配进行数据分析提供了强有力的支持，成了购物平台用户使用不可缺少的一部分。随着数据集的不断扩大以及三维建模技术的不断推进，消费者群体对虚拟换衣功能的需求也从原来二维平面上通过人体大致轮廓完成换衣处理转向侧重三维模型的真实性以及根据人体特征对图像进行更细致地分析处理，从单纯地套用服装模型到给予用户更多的服装搭配和颜色选择。因此，完成一个能够足够还原使用者身材真实情况且在细节处刻画服装特征的虚拟换衣系统，对未来发展有着十分重要的意义。但就实现上述功能而言，现面临着两个主要挑战。一是根据用户提供的自身详细数据所能实现的模型过于粗糙，不能将衣服和身体紧密贴合以凸显人物身材特征，这样会造成虚拟换衣效果与现实上身效果有大量误差的情况，对于消费者而言，这会造成浪费。二是考虑到人有不同的肤色，这直接导致相同颜色衣服的上身效果因人而异，加上大部分消费者群体对于色彩搭配方面了解甚少，不知道应该如何根据自己的肤色去选择相应颜色的衣服，也未曾学过颜色搭配相关知识，碰到需要服装组合情况的时候就难以处理。因此，有必要提出一种新的虚拟换衣方法，可以解决现有虚拟换衣效果与现实上身效果有大量误差的问题，以及尽可能地给使用者更多符合身体肤色的衣服颜色搭配组合，提高试衣体验感。发明内容本发明实施例所要解决的技术问题在于，提供一种基于改进的GRNet网络的虚拟换衣方法及系统，可以解决现有虚拟换衣效果与现实上身效果有大量误差的问题，以及给使用者更多符合身体肤色的衣服颜色搭配组合，以提高试衣体验感。为了解决上述技术问题，本发明实施例提供了一种基于改进的GRNet网络的虚拟换衣方法，包括以下步骤：基于用户提供的身体数据和脸部信息进行人体建模，分别得到人体3D模型和人脸3D模型；获取预设衣服数据集中的衣服图像，并通过点云配准对所述衣服图片进行两两配准，且进一步依据配准获得地服装特征点位进行3D建模，得到衣服3D模型；从所述人体3D模型与所述衣服3D模型中提取人体轮廓和衣服轮廓具有模糊特征的点位，并基于所提取的点位，使用预先改进的GRNet网络对所述人体3D模型与所述衣服3D模型进行配对，得到配对之后以实现上身效果平和且稳定的衣服3D模型；基于所述人脸3D模型，检测出人脸肤色，且根据检测出的人脸肤色进行比色工作，然后以此调整衣服3D模型中的衣服颜色，进行模型展现，以实现最终虚拟换衣效果。其中，所述脸部信息来自于用户提供的各个方位的2D人脸照片。其中，所述人脸3D模型是基于人脸模型FTMR构成的；其中，所述人脸模型FTMR框架由两个特征提取分支、三个结构细化模块组成；其中，特征提取分支包括FFRNet和EBNet；FFRNet用于对3DMM、人脸姿态位置及光照参数进行回归；EBNet用于提取图像特征，并将提取的特征用于后续的细节细化和身份保持；结构细化模块由三个图卷积网络形成，包括一个GCN译码器解码特征提取FFRNet和制作详细的颜色网格顶点，GCN定义器会完善回归量，生成的顶点颜色和组合器把两种颜色生产最后的顶点颜色，最后由判别器通过对抗性训练来提高图像纹理细化模块的输出。其中，所述身体数据包括用户提供的身高、体重、胸围、腰围和臀围。其中，所述人体3D模型是基于由包裹变形分支和补偿变形分支组成的神经融合形状技术构建得到的。其中，所述通过点云配准对所述衣服图片进行两两配准的具体步骤包括：随机从两张衣服图片中按照同样的关键点选取标准，提取关键点；对选择的所有关键点分别计算其特征描述子；结合特征描述子在两个数据集中的坐标的位置，以两者之间特征和位置的相似度为基础，估算它们的对应关系，初步估计对应点对；假定数据是有噪声的，除去对配准有影响的错误的对应点对；利用剩余的正确对应关系来估算刚体变换，完成配准。其中，所述从所述人体3D模型与所述衣服3D模型中提取人体轮廓和衣服轮廓具有模糊特征的点位，基于所提取的点位，使用预先改进的GRNet网络对所述人体3D模型与所述衣服3D模型进行配对，得到配对之后以实现上身效果平和且稳定的衣服3D模型的具体步骤包括：给定一个查询和库对，通过深度卷积网络提取所述人体3D模型与所述衣服3D模型中人体轮廓和衣服轮廓具有模糊特征的点位，并将其输入到相似度计算中，以所有区域对相似度为图节点构建一个相似度金字塔图；在相似度金字塔图中，所有区域对相似度为图节点，两个相似度之间的关系为边，并计算两个相似度之间的相似向量；对相似向量进行改动；其中，假定缩放的比例为α，对获得的局部特征x和y执行缩放操作，执行缩放后，局部特征的坐标由变为。假定偏移的距离为，执行单纯的偏移后，局部特征的坐标由变为；经过对局部坐标先缩放后偏移的操作后，再将局部坐标带入相似向量s中以获得改动后的相似向量s’；根据改动后的相似向量，对所述衣服3D模型的大小进行调整，以得到上身效果平和且稳定的衣服3D模型。其中，所述人脸肤色是通过对所述人脸3D模型采用OpenCV库检测得到的；其中，所述OpenCV库所涉及的算法包括图像色域转换算法、颜色通道分割算法、高斯滤波算法和OSTU自动阈值算法。其中，所述配对之后的衣服3D模型中的衣服颜色调整是在Palette类库中，通过由规则选择、方案生成及颜色替换所形成的配色方案来实现的；其中，所述规则选择具体为通过对衣服代表色、风格和基于配色规则的结果进行评分与训练，得到不同颜色、风格对应的最佳规则；所述方案生成具体为以HSL为颜色模型构建规则，通过分量建立配色规则，使任何一个颜色C，可以转化为由三个分量构成的数组；所述颜色替换具体为按照配色方案中的颜色与衣服中元素的对应关系，对衣服中的元素进行颜色替换，进而完成配色。本发明实施例还提供了一种基于改进的GRNet网络的虚拟换衣系统，包括：人体模型构建单元，用于基于用户提供的身体数据和脸部信息进行人体建模，分别得到人体3D模型和人脸3D模型；衣服模型构建单元，用于获取预设衣服数据集中的衣服图像，并通过点云配准对所述衣服图片进行两两配准，且进一步依据配准获得地服装特征点位进行3D建模，得到衣服3D模型；人体与衣服模型匹配单元，用于从所述人体3D模型与所述衣服3D模型中提取人体轮廓和衣服轮廓具有模糊特征的点位，并基于所提取的点位，使用预先改进的GRNet网络对所述人体3D模型与所述衣服3D模型进行配对，得到配对之后以实现上身效果平和且稳定的衣服3D模型；服装配色单元，用于基于所述人脸3D模型，检测出人脸肤色，且根据检测出的人脸肤色进行比色工作，然后以此调整衣服3D模型中的衣服颜色，进行模型展现，以实现最终虚拟换衣效果。实施本发明实施例，具有如下有益效果：1、针对传统网络运行的机制，本发明在原有GRNet神经网络的基础上进行改进，通过在原有GRNet神经网络的基础上对相似金字塔的相似向量进行更改，扩张网络层数等技术，弥补了人衣模型轮廓线条匹配连续性不足的问题，使得在虚拟换衣功能中，最终衣服上身效果是平和且稳定的，从而解决了现有虚拟换衣效果与现实上身效果有大量误差的问题；2、本发明在建模时更加细化模型细节，通过二次建模再比对的方式尽可能地将人体模型还原至真实水平，例如LSFM大规模人脸模型高度还原人脸，空间扫描获取人体实际点位后进行点云配准等，从而既能保证图像处理的准确，也能保证模型构建处理的质量；3、本发明利用现有调色盘技术，增加了根据人脸肤色提供服装配色方案的功能，实现的功能更加人性化，同时可以在后续实现将成型的服装搭配录入服装数据集的工作，尽可能地满足多数人群对换衣功能的需求，因此给使用者更多符合身体肤色的衣服颜色搭配组合，提高了试衣体验感。附图说明为了更清楚地说明本发明实施例或现有技术中的技术方案，下面将对实施例或现有技术描述中所需要使用的附图作简单地介绍，显而易见地，下面描述中的附图仅仅是本发明的一些实施例，对于本领域普通技术人员来讲，在不付出创造性劳动性的前提下，根据这些附图获得其他的附图仍属于本发明的范畴。图1为本发明实施例提供的基于改进的GRNet网络的虚拟换衣方法的流程图；图2为本发明实施例提供的FTMR人脸建模方法的流程示意图；图3为本发明实施例提供的基于改进的GRNet网络的虚拟换衣系统的结构示意图。具体实施方式为使本发明的目的、技术方案和优点更加清楚，下面将结合附图对本发明作进一步地详细描述。如图1所示，为本发明实施例中，提出的一种基于改进的GRNet网络的虚拟换衣方法，包括以下步骤：步骤S1、基于用户提供的身体数据和脸部信息进行人体建模，分别得到人脸3D模型和人体3D模型；具体过程为，首先，获取用户提供的身体数据包括身高、体重、胸围、腰围和臀围等，以及获取来自于用户提供的各个方位的2D人脸照片上的脸部信息。其次，在用户提供的身体数据基础上，基于由包裹变形分支和补偿变形分支组成的神经融合形状技术构建得到人体3D模型。其中，神经融合形状技术是一套崭新的建模神经网络，用来生成具有指定结构的骨骼，并且精准绑定骨骼的蒙皮权重，由两个部分组成：包裹变形分支和补偿变形分支。此时，包裹变形分支通过间接监督，学习由偏移量组成的特定骨架层次的配置参数，最后从输入角色中预测出骨架、蒙皮和权重绑定。同时与常用的动画制作工具不同，它可以准确预测与模型高度匹配的骨骼，并绑定权重。并且，利用一种神经融合形状技术，补偿变形分支可以根据输入的网络连接，来预测对应的融合形状。与此同时，根据关节旋转预测融合系数，然后基于此插值得到补偿变形。获得使用者三维后，系统会对默认的全身模型进行更改，主要体现在身高、体重、胸部、腰部、臀部三个部分，尽可能地生成与使用者实际情况相符的人体模型。最后，在用户提供的各个方位的2D人脸照片上的脸部信息的基础上，基于人脸模型FTMR构成人脸3D模型。FTMR框架由两个特征提取分支和三个结构细化模块组成。特征提取分支包括一个FFRNet和一个EBNet；FFRNet用于对3DMM、人脸姿态位置、光照参数进行回归，其中3DMM将通过PCA模型计算人脸形状S和粗糙纹理T；EBNet用于提取图像特征，这些特征将会用于后续的细节细化和身份保持。三个结构细化模块由三个图卷积网络形成，包括:一个GCN译码器解码特征提取FFRNet和制作详细的颜色网格顶点，GCN定义器会完善回归量，生成的顶点颜色和组合器把两种颜色生产最后的顶点颜色。最后由判别器通过对抗性训练来提高图像纹理细化模块的输出。步骤S2、获取预设衣服数据集中的衣服图像，并通过点云配准对所述衣服图片进行两两配准，且进一步依据配准获得地服装特征点位进行3D建模，得到衣服3D模型；具体过程为，预先设定的衣服数据集中收录了多种不同的时尚服装图像，在此数据集中的每个图像都标有类别，描述性属性，边界框和服装标记。系统对带有标记的衣服进行分类，首先按照衣服适宜人群的标记进行分类，而后继续根据码数偏大偏小分类，这么做的目的在于在制作衣服模型时使得衣服细节更加细化。对衣服数据集中的衣服取得六张从不同方向拍摄来的图片，然后使用点云配准操作。在此步骤中，通常通过应用一个估算得到的表示平移和旋转的4x4刚体变换矩阵来使一个点云数据集精确地与另一个点云数据集进行完美配准。此时，通过点云配准对所述衣服图片进行两两配准的具体步骤包括：随机从两张衣服图片中按照同样的关键点选取标准，提取关键点；对选择的所有关键点分别计算其特征描述子；结合特征描述子在两个数据集中的坐标的位置，以两者之间特征和位置的相似度为基础，估算它们的对应关系，初步估计对应点对；假定数据是有噪声的，除去对配准有影响的错误的对应点对；利用剩余的正确对应关系来估算刚体变换，完成配准。整个配准过程最重要的是关键点的提取以及关键点的特征描述，以确保对应估计的准确性和效率，这样才能保证后续流程中的刚体变换矩阵估计的无误性。通过该步骤能够进一步地细化生成的衣服3D模型，突出衣服细节，同时也提取出了可以根据人体关节点位变化而变化的特征点，这既满足了真实还原衣服上身效果的需求，也为后续的人衣模型匹配工作提供了可靠的保证。步骤S3、从所述人体3D模型与所述衣服3D模型中提取人体轮廓和衣服轮廓具有模糊特征的点位，并基于所提取的点位，使用预先改进的GRNet网络对所述人体3D模型与所述衣服3D模型进行配对，得到配对之后以实现上身效果平和且稳定的衣服3D模型；具体过程为，GRANet是基于现有的图推理网络GRNet而改进的，GRNet是基于相似金字塔理论，通过使用多尺度的全局和局部表示来学习查询和库布之间的相似性。相似度金字塔由相似度图表示，其中节点表示不同尺度服装部件之间的相似度，通过沿边缘传递消息获得最终匹配分数，在GRNet中，通过训练一个图卷积网络来解决图推理问题，从而能够对齐显著的服装组件以改进服装检索。因此，在已经获得了人体模型和衣服模型的具体特殊点位之后，可直接进行图形推理工作。即，通过金字塔相似关系之间传播的迭代，能够实现局部区域对的加权和全局匹配的增强，从而获得更精确的匹配计算。此时，步骤S3的具体步骤包括：给定一个查询和库对，通过深度卷积网络提取人体3D模型与衣服3D模型中人体轮廓和衣服轮廓具有模糊特征的点位，并将其输入到相似度计算中，以所有区域对相似度为图节点构建一个相似度金字塔图。在相似度金字塔图中，所有区域对相似度为图节点，两个相似度之间的关系为边，并计算两个相似度之间的相似向量。例如，形式上，给定一对来自同一金字塔尺度的局部特征x和y，去计算它们的相似向量s以代替相似标量；其中，相似向量s算法公式如下：对相似向量进行改动；其中，假定缩放的比例为α，对获得的局部特征x和y执行缩放操作，执行缩放后，局部特征的坐标由变为。假定偏移的距离为，执行单纯的偏移后，局部特征的坐标由变为；经过对局部坐标先缩放后偏移的操作后，再将局部坐标带入相似向量s中以获得改动后的相似向量s’。其中，相似向量s’算法公式如下：根据改动后的相似向量，衣服3D模型的大小进行调整，以得到上身效果平和且稳定的衣服3D模型。由此可见，由于人体和衣服的3D模型取决于分辨率，其建立在像素之上，在相似金字塔中核对细节轮廓时，需要对模型细节大小进行调整，所提供的坐标点对应的图形将显得像素化。对于这些与分辨率高度相关的模型，它可以在任何缩放级别上进行缩放，同时保证细节处的质量。因此，使用改进的GRNet网络，可以实现人体与衣服模型更好的匹配，使得模型重合时点位更加精确，不会出现衣服和人体关节不重合的现象，弥补了人衣模型轮廓线条匹配连续性不足的问题，使得虚拟换衣功能中最终衣服的上身效果是平和且稳定的。步骤S4、基于所述人脸3D模型，检测出人脸肤色，且根据检测出的人脸肤色进行比色工作，然后以此调整衣服3D模型中的衣服颜色，进行模型展现，以实现最终虚拟换衣效果。具体过程为，分为两个阶段，一是人脸肤色检测阶段，二是肤色比对阶段，三是生成配色方案阶段。在人脸肤色检测阶段中，人脸肤色是通过对人脸3D模型采用OpenCV库检测得到的；其中，OpenCV库所涉及的算法包括图像色域转换算法、颜色通道分割算法、高斯滤波算法和OSTU自动阈值算法。OpenCV库中的算法是基于YCrCb颜色空间的Cr分量+OTSU法阈值分割算法，该方法的原理就是将RGB图像转换到YCrCb颜色空间，提取Cr分量图像，对Cr分量进行高斯滤波，最后对Cr做自二值化阈值分割处理OSTU算法。在生成配色方案阶段中，配对之后的衣服3D模型中的衣服颜色调整是在Palette类库中，通过由规则选择、方案生成及颜色替换所形成的配色方案来实现的。经过检测后，提取出人脸的主要构成颜色和辅助构成颜色，以RGB码的形式传输到CDL模型中。CDL模型是事先训练好的比色模型，该模型的作用是接收检测出的颜色结果，将人脸颜色与已经存储的标准颜色进行比对，计算出该颜色与最邻近颜色的标准偏差并输出，再根据得到的偏差值判定该颜色的具体属性。考虑到不同人种的肤色以及穿衣风格大不相同，系统要求使用者在使用时填写其国家、民族等相关信息，在之后形成配色方案的过程中，使用到Palette类库，该类库的作用是将CDL模型的输出结果和相关信息结合，在调色盘中提取最适合的搭配颜色，以用于衣服元素中。由类库提取的颜色分为鲜活、深色鲜活、浅色鲜活、暗沉、深色暗沉、浅色暗沉六种类型，并按照规律来为衣服设置颜色。此时，配色方案中的规则选择、方案生成及颜色替换具体如下：规则选择：由AI根据代表色、风格自动挑选合适的规则。虽然配色规则具有一定的通用性，但针对不同的色彩依然有优劣之分。不同的配色规则更是产生不同的配色风格。因此，可以通过对衣服代表色、风格和基于配色规则的结果进行评分与训练，得到不同颜色、风格对应的最佳规则。方案生成：方案生成是该系统的核心部分。建立有效的配色规则，并生成合理的配色方案将直接决定结果的效果。其有两个重点，即颜色模型的选择和基于颜色模型的规则。因此，经过对比，以HSL为颜色模型构建规则，通过分量建立配色规则，使任何一个颜色C，可以转化为由三个分量构成的数组。其中，HSL定义标准且以色相、饱和度、亮度为分量，易于构建配色规则，可通过分量建立配色规则，以应用于其他颜色。由此可见，通过HSL可以使用人类的直觉来描述颜色，并挖掘其中的配色规律，继而形成配色规则。事实上在设计领域中，逐渐形成了一系列的配色方法，以及带有鲜明特色的配色规律。可以将这些方法和规律通过HSL模型，转化为规则，进而形成仓库。以HSL模型中的H分量色相为例。基于色相，服装领域可以根据色相环进行配色，并拥有一系列规律。颜色替换：按照配色方案中的颜色与衣服中元素的对应关系，对衣服中的元素进行颜色替换，进而完成配色。综上，在步骤S4中考虑到不同人种肤色不同的问题，提供了更加适合使用者肤色的服装配色方案，从而满足使用者的需求和试衣体验感。如图3所示，为本发明实施例中，提供的一种基于改进的GRNet网络的虚拟换衣系统，包括：人体模型构建单元110，用于基于用户提供的身体数据和脸部信息进行人体建模，分别得到人脸3D模型和人体3D模型；衣服模型构建单元120，用于获取预设衣服数据集中的衣服图像，并通过点云配准对所述衣服图片进行两两配准，且进一步依据配准获得地服装特征点位进行3D建模，得到衣服3D模型；人体与衣服模型匹配单元130，用于从所述人体3D模型与所述衣服3D模型中提取人体轮廓和衣服轮廓具有模糊特征的点位，并基于所提取的点位，使用预先改进的GRNet网络对所述人体3D模型与所述衣服3D模型进行配对，得到配对之后以实现上身效果平和且稳定的衣服3D模型；服装配色单元140，用于基于所述人脸3D模型，检测出人脸肤色，且根据检测出的人脸肤色进行比色工作，然后以此调整衣服3D模型中的衣服颜色，进行模型展现，以实现最终虚拟换衣效果。实施本发明实施例，具有如下有益效果：1、针对传统网络运行的机制，本发明在原有GRNet神经网络的基础上进行改进，通过在原有GRNet神经网络的基础上对相似金字塔的相似向量进行更改，扩张网络层数等技术，弥补了人衣模型轮廓线条匹配连续性不足的问题，使得在虚拟换衣功能中，最终衣服上身效果是平和且稳定的，从而解决了现有虚拟换衣效果与现实上身效果有大量误差的问题；2、本发明在建模时更加细化模型细节，通过二次建模再比对的方式尽可能地将人体模型还原至真实水平，例如FTMR模型高度增强人脸细节，空间扫描获取人体实际点位后进行点云配准等，从而既能保证图像处理的准确，也能保证模型构建处理的质量；3、本发明利用现有调色盘技术，增加了根据人脸肤色提供服装配色方案的功能，实现的功能更加人性化，同时可以在后续实现将成型的服装搭配录入服装数据集的工作，尽可能地满足多数人群对换衣功能的需求，因此给使用者更多符合身体肤色的衣服颜色搭配组合，提高了试衣体验感。值得注意的是，上述系统实施例中，所包括的各个单元只是按照功能逻辑进行划分的，但并不局限于上述的划分，只要能够实现相应的功能即可；另外，各功能单元的具体名称也只是为了便于相互区分，并不用于限制本发明的保护范围。本领域普通技术人员可以理解实现上述实施例方法中的全部或部分步骤是可以通过程序来指令相关的硬件来完成，所述的程序可以存储于一计算机可读取存储介质中，所述的存储介质，如ROM/RAM、磁盘、光盘等。以上所揭露的仅为本发明一种较佳实施例而已，当然不能以此来限定本发明之权利范围，因此依本发明权利要求所作的等同变化，仍属本发明所涵盖的范围。
