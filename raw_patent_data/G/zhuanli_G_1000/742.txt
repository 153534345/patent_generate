标题title
目标检测训练方法及电子设备、计算机可读存储介质
摘要abst
本申请公开了一种目标检测训练方法及电子设备、计算机可读存储介质。构建教师模型和学生模型，完成对教师模型的训练，以得到训练好的教师模型；计算教师模型和学生模型之间的特征蒸馏损失、响应蒸馏损失及交叉蒸馏损失，以及计算学生模型的强监督损失；并构建学生模型的总损失函数，基于总损失函数训练学生模型，优化学生模型的参数，以得到最终的学生模型。本申请通过提取多个中间层特征进行特征蒸馏让学生模型更加全面地学习教师模型的特征表示；并通过交叉蒸馏使学生模型学习教师模型的学习能力。以此提高学生模型学习教师模型的能力，从而提升学生模型检测精确度，使得学生模型能够更好地应用在设备上。
权利要求书clms
1.一种目标检测训练方法，其特征在于，包括：构建教师模型和学生模型，其中所述学生模型是通过将所述教师模型的通道数和网络层数进行缩减之后得到的；完成对所述教师模型的训练，以得到训练好的所述教师模型；计算所述教师模型和所述学生模型之间的特征蒸馏损失、响应蒸馏损失及交叉蒸馏损失，以及计算所述学生模型的强监督损失；基于所述特征蒸馏损失、所述响应蒸馏损失、所述交叉蒸馏损失和所述强监督损失构建所述学生模型的总损失函数；基于所述总损失函数训练所述学生模型，优化所述学生模型的参数，以得到最终的所述学生模型。2.根据权利要求1所述的目标检测训练方法，其特征在于，所述计算所述教师模型和所述学生模型之间的特征蒸馏损失，包括：选择所述教师模型和所述学生模型中多个相同位置的中间层的特征进行特征蒸馏，以分别得到对应的第一输出特征和第二输出特征；采用所述第一输出特征和所述第二输出特征来计算所述特征蒸馏损失。3.根据权利要求2所述的目标检测训练方法，其特征在于，计算所述第一输出特征和所述第二输出特征的特征蒸馏公式为：其中，表示特征蒸馏的输入特征；/＞表示特征蒸馏输出；/＞表示张量在通道维度上进行拼接；/＞和/＞分别表示池化核为3×3的最大值池化和均值池化；和/＞分别表示池化核为5×5的最大值池化和均值池化；/＞表示在通道维度上求最大值；/＞表示在通道维度上求均值；/＞表示输入特征最大值池化相加的和；/＞表示输入特征均值池化相加的和。4.根据权利要求3所述的目标检测训练方法，其特征在于，所述特征蒸馏损失的计算公式为：其中，mean表示求和之后求平均值；表示学生模型特征蒸馏的输出；/＞表示教师模型特征蒸馏的输出；/＞表示特征蒸馏损失；/＞表示取绝对值。5.根据权利要求1所述的目标检测训练方法，其特征在于，采用以下方式计算所述教师模型和所述学生模型之间的响应蒸馏损失：所述教师模型和学生模型的每个输出层包括三个分支的信息，分别为置信度分数、分类分数和预测框的坐标；以所述学生模型的置信度分数为预测值，所述教师模型的置信度分数为目标值，代入到二进制交叉熵损失函数中求得置信度损失；以所述学生模型的分类分数为预测值，所述教师模型的分类分数为目标值，代入到二进制交叉熵损失函数中求得分类损失；将所述教师模型和学生模型的预测框的坐标代入到位置蒸馏损失函数中求得位置蒸馏损失，位置蒸馏损失函数公式如下：其中，和/＞分别表示教师模型和学生模型的预测框的左上角点和右下角点的横、纵坐标；w和h分别表示输入图片的宽高；/＞代表教师模型和学生模型的各自预测框的左上角点之间的相对距离，/＞代表教师模型和学生模型的各自预测框的右下角点之间的相对距离；/＞表示预测框相似性比较指标；表示位置蒸馏损失；基于所述置信度损失、所述分类损失和所述位置蒸馏损失以及训练损失函数计算得到所述响应蒸馏损失。6.根据权利要求1所述的目标检测训练方法，其特征在于，采用以下方式计算所述教师模型和所述学生模型之间的交叉蒸馏损失：将原始图像输入至所述学生模型，且在所述学生模型中的输出层经过一次卷积后再输入至所述教师模型中输出层一次卷积后的网络中，以得到第一输出响应；将所述原始图像输入至所述教师模型，以得到第二输出响应；采用所述第一输出响应和所述第二输出响应计算得到所述交叉蒸馏损失。7.根据权利要求6所述的目标检测训练方法，其特征在于，所述交叉蒸馏损失的计算公式为：其中，σ表示sigmoid函数；和/＞分别表示第一输出响应和第二输出响应；BCE表示二进制交叉熵损失函数；γ表示调制因子，/＞；/＞表示交叉蒸馏损失；/＞表示取绝对值。8.根据权利要求1所述的目标检测训练方法，其特征在于，所述总损失函数的计算公式为：其中，为总损失；/＞为多个中间特征的所述特征蒸馏损失之和；/＞为三个输出层的所述响应蒸馏损失之和；/＞三个输出层的交叉蒸馏损失之和；/＞为强监督损失，/＞、/＞、/＞、/＞分别表示各损失函数的平衡系数。9.一种电子设备，其特征在于，包括存储器、处理器及存储在所述存储器上并可在所述处理器上运行的计算机程序，所述处理器执行所述程序时实现如权利要求1至8任一项所述的目标检测训练方法的步骤。10.一种计算机可读存储介质，其特征在于，所述计算机可读存储介质上存储有计算机程序，所述计算机程序被处理器执行时实现如权利要求1至8任一项所述的目标检测训练方法的步骤。
说明书desc
技术领域本申请涉及计算机视觉技术领域，尤其涉及一种目标检测训练方法及电子设备、计算机可读存储介质。背景技术目标检测技术是计算机视觉领域的重要任务之一，其旨在定位和识别出图像或者视频中的目标对象。近年来，深度学习的发展给目标检测带来了新的突破，各种高效的单阶段目标检测技术层出不穷，如YOLOv5、YOLOv7、YOLOv8、CenterNet等在各类检测任务上效果显著，这也使得越来越多的检测算法被广泛应用于各种场景中。智能监控作为目标检测算法的热点应用场景之一，具有很大的应用前景。但是在检测精度提升的同时，伴随而来的是算法模型的增大，这也提升了目标检测算法的应用难度。由于像监控摄像头、智能穿戴设备等移动设备的内存、算力等硬件配置较低，无法使用较大的算法模型，因此要使用检测精度和速度兼备的轻量型模型即学生模型。获得学生模型的方法主要有：直接设计轻量化的网络；对大的网络模型进行剪枝；知识蒸馏。基于知识蒸馏的目标检测训练方法获取学生模型的技术已广泛应用于各种场景中。但现有的基于知识蒸馏的目标检测训练方法获得的学生模型，仍存在因学习能力不足导致目标检测精确度不佳的问题。发明内容本申请提供一种目标检测训练方法及电子设备、计算机可读存储介质，用于解决学生模型因学习能力不足导致目标检测精确度不佳的问题。为了解决上述技术问题，本申请采用的一个技术方案是：提供一种目标检测训练方法。该目标检测训练方法包括：构建教师模型和学生模型，其中所述学生模型是通过将所述教师模型的通道数和网络层数进行缩减之后得到的；完成对所述教师模型的训练，以得到训练好的所述教师模型；计算所述教师模型和所述学生模型之间的特征蒸馏损失、响应蒸馏损失及交叉蒸馏损失，以及计算所述学生模型的强监督损失；基于所述特征蒸馏损失、所述响应蒸馏损失、所述交叉蒸馏损失和所述强监督损失构建所述学生模型的总损失函数，基于所述总损失函数训练所述学生模型，优化所述学生模型的参数，以得到最终的所述学生模型。通过提取多个中间层特征进行特征蒸馏让学生模型更加全面地学习教师模型的特征表示；进行响应蒸馏使得学生模型和教师模型的响应差异最小化；并通过交叉蒸馏使学生模型学习教师模型的学习能力。优选地，计算所述教师模型和所述学生模型之间的特征蒸馏损失的具体步骤包括：选择所述教师模型和所述学生模型中多个相同位置的中间层的特征进行特征蒸馏，以分别得到对应的第一输出特征和第二输出特征；采用所述第一输出特征和所述第二输出特征来计算所述特征蒸馏损失。优选地，计算所述第一输出特征和所述第二输出特征的特征蒸馏公式为：其中，表示特征蒸馏的输入特征；/＞表示特征蒸馏输出；/＞表示张量在通道维度上进行拼接；/＞和/＞分别表示池化核为3×3的最大值池化和均值池化；/＞和/＞分别表示池化核为5×5的最大值池化和均值池化；/＞表示在通道维度上求最大值；/＞表示在通道维度上求均值；/＞表示输入特征最大值池化相加的和；/＞表示输入特征均值池化相加的和。优选地，特征蒸馏损失的计算公式为：其中，mean表示求和之后求平均值；表示学生模型特征蒸馏的输出；/＞表示教师模型特征蒸馏的输出；/＞表示特征蒸馏损失；/＞表示取绝对值。优选地，计算所述教师模型和所述学生模型之间的响应蒸馏损失的具体步骤包括：所述教师模型和学生模型的每个输出层都包括了三个分支的信息，分别为置信度分数、分类分数和预测框的坐标；以所述学生模型的置信度分数为预测值，所述教师模型的置信度分数为目标值，代入到二进制交叉熵损失函数中求得置信度损失；以所述学生模型的分类分数为预测值，所述教师模型的分类分数为目标值，代入到二进制交叉熵损失函数中求得分类损失；将所述教师模型和学生模型的预测框的坐标代入到位置蒸馏损失函数中求得位置蒸馏损失，位置蒸馏损失函数公式如下：其中，和/＞分别表示教师模型和学生模型的预测框的左上角点和右下角点的横、纵坐标；w和h分别表示输入图片的宽高；/＞代表教师模型和学生模型的各自预测框的左上角点之间的相对距离，/＞代表教师模型和学生模型的各自预测框的右下角点之间的相对距离；/＞表示预测框相似性比较指标；表示位置蒸馏损失；基于所述置信度损失、所述分类损失和所述位置蒸馏损失以及训练损失函数计算得到所述响应蒸馏损失。优选地，计算所述教师模型和所述学生模型之间的交叉蒸馏损失的具体步骤包括：将原始图像输入至所述学生模型，且在所述学生模型中的输出层经过一次卷积后再输入至所述教师模型中输出层一次卷积后的网络中，以得到第一输出响应；将所述原始图像输入至所述教师模型，以得到第二输出响应；采用所述第一输出响应和所述第二输出响应计算得到所述交叉蒸馏损失。优选地，交叉蒸馏损失的计算公式为：其中，σ表示sigmoid函数；响应和第二输出响应；BCE表示二进制交叉熵损失函数；γ表示调制因子，/＞交叉蒸馏损失；/＞表示取绝对值。优选地，总损失函数的计算公式为：其中，交叉蒸馏损失之和；/＞分别表示各损失函数的平衡系数。为了解决上述问题，本申请采用的另一个技术方案是：提供一种电子设备。该电子设备包括存储器、处理器及存储在所述存储器上并可在所述处理器上运行的计算机程序，所述处理器执行所述程序时实现如上述目标检测训练方法的任一项步骤。为了解决上述问题，本申请采用的另一个技术方案是：提供一种计算机可读存储介质，该计算机可读存储介质上存储有计算机程序，该计算机程序被处理器执行时实现如上述目标检测训练方法的任一项步骤。相比现有技术，本申请的有益效果在于：本申请公开了一种目标检测训练方法及电子设备、计算机可读存储介质。构建教师模型和学生模型，完成对教师模型的训练，以得到训练好的教师模型；计算教师模型和学生模型之间的特征蒸馏损失、响应蒸馏损失及交叉蒸馏损失，以及计算学生模型的强监督损失；并构建学生模型的总损失函数；基于所述总损失函数训练所述学生模型，优化所述学生模型的参数，以得到最终的学生模型。本申请通过提取多个中间层特征进行特征蒸馏让学生模型更加全面地学习教师模型的特征表示；并通过交叉蒸馏使学生模型学习教师模型的学习能力。以此提高学生模型学习教师模型的能力，从而提升学生模型检测精确度，使得学生模型能够更好地应用在设备上。附图说明为了更清楚地说明本申请或现有技术中的技术方案，下面将对实施例或现有技术描述中所需要使用的附图作一简单地介绍，显而易见地，下面描述中的附图是本发明的一些实施例，对于本领域普通技术人员来讲，在不付出创造性劳动的前提下，还可以根据这些附图获得其他的附图。图1是本申请的目标检测训练方法一实施例的流程示意图；图2是本申请的目标检测训练方法一实施例的结构示意图；图3是图1实施例中计算特征蒸馏损失的流程示意图；图4是图1实施例中计算特征蒸馏损失的结构示意图；图5是图1实施例中计算响应蒸馏损失的流程示意图；图6是图1实施例中计算交叉蒸馏损失的流程示意图；图7是图1实施例中计算交叉蒸馏损失的结构示意图；图8是本申请电子设备一实施例的结构示意图；图9是本申请计算机可读存储介质一实施例的结构示意图。具体实施方式为使本申请的目的、技术方案和优点更加清楚，下面将结合本申请中的附图，对本发明中的技术方案进行清楚、完整地描述，显然，所描述的实施例是本发明一部分实施例，而不是全部的实施例。基于 本发明中的实施例，本领域普通技术人员在没有作出创造性劳动前提 下所获得的所有其他实施例，都属于本发明保护的范围。在本申请一个或多个实施例中使用的术语是仅仅出于描述特定实施例的目的，而非旨在限制本发明一个或多个实施例。在本申请一个或多个实施例和所附权利要求书中所使用的单数形式的“一种”、“所述”和“该”也旨在包括多数形式，除非上下文清楚地表示其他含义。还应当理解，本申请一个或多个实施例中使用的术语“和/或”是指并包含一个或多个相关联的列出项目的任何或所有可能组合。应当理解，尽管在本申请一个或多个实施例中可能采用术语第一、第二等来描述各种信息，但这些信息不应限于这些术语。这些术语仅 用来将同一类型的信息彼此区分开。例如，在不脱离本申请一个或多个实施例范围的情况下，第一也可以被称为第二，类似地，第二也可以被称为第一。取决于语境，如在此所使用的词语“如果”可以被解 释成为“在……时”或“当……时”或“响应于确定”。下面结合附图对本发明示例实施方式进行详细说明。请参阅图1，图1是本申请的目标检测训练方法一实施例的流程示意图。包括如下步骤：步骤10：构建教师模型和学生模型，其中学生模型是通过将教师模型的通道数和网络层数进行缩减之后得到的。教师模型以CSPDarkNet53为骨干网络，FPN和PAN为特征聚合网络，网络包含三个输出层，每个输出层由3个卷积操作组成，第一个卷积用于将输入特征的通道数变为固定值，之后的两个卷积操作中通道数不发生变化。其中，CSPDarkNet53为一种深度卷积神经网络，用于物体检测和图像分类，具有强大的特征提取能力，能提取图像的特征信息，供后续网络使用。FPN和PAN为目标检测中特征集合网络，旨在将不同尺度和不同阶段的特征进行融合和聚合，以提高目标检测的性能，可以将骨干网络中提取的图像特征信息进行聚合，生成更丰富、更全面的特征表示。进一步地，根据教师模型的网络结构构建学生模型；将学生模型骨干网络和特征聚合网络的中每个卷积层的输出通道数设置为教师模型的0.25倍，例如，如果教师模型的某个卷积层的输出通道数为64，那么在学生模型中可以将相应的卷积层的输出通道数减半为16；将学生模型骨干网络和特征聚合网络的中网络层数设置为教师模型的三分之一，通过减少模型中的残差模块数量来实现，例如，教师模型的某个CSP-X中残差模块为3个，那么学生模型对应的CSP-X中残差模块为1个。需要注意的是，学生模型的通道数和网络层数都进行了缩减，但其输出层的通道数与教师模型一样，且学生模型和教师模型的网络结构要保持一致。具体的教师模型和学生模型的结构请参阅图2，图2是图1目标检测训练方法实施例的结构示意图。其中，学生模型的网络结构和教师模型的网络结构一致，学生模型CSP-X模块中的残差模块对应的是教师模型的三分之一；CSP-X模块中X表示残差模块的个数，教师模型CSP-6模块的位置在学生模型上对应CSP-2模块。步骤20：完成对教师模型的训练，以得到训练好的教师模型。具体地，先收集包含目标的图片数据集，确保数据集的多样性和覆盖性。对采集到的图片进行标注，标注目标的位置、类别等信息。可以使用专业的标注工具或者开源标注工具，如LabelImg、CVAT等。按照一定比例将数据集划分为训练集和验证集。常见的比例是将数据集的70%-80%用于训练，剩余的30%-20%用于验证。可以使用Python中的sklearn库中的train_test_split函数来进行划分。然后对图片数据进行预处理，包括图像增强、尺寸调整、归一化等处理，以便模型更好地学习和泛化。然后，将标注和划分好的训练集输入到教师模型中，对教师模型进行训练，并计算对应的训练损失。具体地，训练损失函数计算公式如下：其中，L为训练损失值，和/＞分别表示分类损失和置信度损失，由二进制交叉熵损失函数计算得到；/＞表示目标框位置回归损失，使用CIoU计算得到。/＞、/＞和/＞分别表示三个损失函数的平衡系数。在本实施例中，和/＞分别被设置为0.5、1.0和0.05。在其他实施例中/＞和/＞的值可基于需求进行设定。完成损失函数计算后，通过反向传播和优化算法不断调整模型参数，使得模型在训练集上的损失函数逐渐减小。并使用验证集对训练得到的教师模型进行性能评估，以确保模型的泛化能力和性能。当教师模型在验证集上的性能达到满意水平时，即得到训练好的教师模型。步骤30：计算教师模型和学生模型之间的特征蒸馏损失、响应蒸馏损失及交叉蒸馏损失，以及计算学生模型的强监督损失。其中，计算教师模型和学生模型之间特征蒸馏损失的步骤，请参阅图3，图3是计算教师模型和学生模型之间特征蒸馏损失的流程示意图。包括如下步骤：步骤310：构建特征蒸馏模块。具体地，请参阅图4，图4为特征蒸馏模块结构示意图。具体包括将输入特征分别进行最大池化和均值池化，相加后进行张量拼接，得到最后的特征蒸馏模块的输出。其中，最大池化包括对输入特征在原通道维度上求最大值、池化核为5×5的最大值池化、池化核为3×3的最大值池化；均值池化包括对输入特征在原通道维度上求平均值、池化核为5×5的均值池化、池化核为3×3的均值池化。将得到的三个最大值相加、三个均值相加；然后将相加后值做张量拼接得到最后的特征蒸馏模块的输出。步骤311：选择教师模型和学生模型中多个相同位置的中间层的特征进行特征蒸馏，以分别得到对应的第一输出特征和第二输出特征。如图2中将教师模型和学生模型中多个相同位置的中间层的特征输入到特征蒸馏模块。具体地，将输入特征输入到特征蒸馏模块，经过蒸馏得到输出特征/＞。特征蒸馏的公式为：其中，表示特征蒸馏的输入特征；/＞表示特征蒸馏输出；/＞表示张量在通道维度上进行拼接；/＞和/＞分别表示池化核为3×3的最大值池化和均值池化；和/＞分别表示池化核为5×5的最大值池化和均值池化；/＞表示在通道维度上求最大值；/＞表示在通道维度上求均值；/＞表示输入特征最大值池化相加的和；/＞表示输入特征均值池化相加的和。在本实施例中，可以选择教师模型和学生模型中相同位置的多个中间层的特征进行特征蒸馏。这些特征可以是卷积层的输出、全连接层的输出等。将教师模型中某卷积层输出作为特征蒸馏模块的输入特征，通过上述公式得到对应的教师模型特征蒸馏的第一输出特征/＞；将学生模型中与上述教师模型相同位置的特征作为特征蒸馏模块的输入特征/＞，通过上述公式得到对应的学生模型特征蒸馏第二输出特征/＞。步骤312：采用第一输出特征和第二输出特征来计算特征蒸馏损失。具体地，将上述第一输出特征和第二输出特征/＞相减并取绝对值，然后再求和后取平均值得到对应的特征蒸馏损失/＞。则特征蒸馏损失的计算公式如下：其中，mean表示求和之后求平均值；表示学生模型特征蒸馏的输出；/＞表示教师模型特征蒸馏的输出；/＞表示特征蒸馏损失；/＞表示取绝对值。其中，mean表示求和之后求平均值通常指的是将各通道上的向量的相同位置的数相加，然后求平均值。在本实施例中，为某一层的特征蒸馏损失。将师模型和学生模型相同位置的多个中间层数的特征输入到特征蒸馏模块，得到多个第一输出特征和多个第二输出特征，然后根据特征蒸馏损失公式得到多个对应层数的特征蒸馏损失。本实施例中取了6个中间层的特征，在其他实施例中，取几个中间层的特征可根据实际情况而定，具体是取哪几个中间层也可以根据实际情况而定。进一步地，计算教师模型和学生模型之间的响应蒸馏损失的步骤，请参阅图5，图5是计算教师模型和学生模型之间的响应蒸馏损失的流程示意图。包括如下步骤：步骤501：获取教师模型和学生模型每个输出层的信息。所述教师模型和学生模型的每个输出层都包括了三个分支的信息，分别为置信度分数、分类分数和预测框的坐标。其中，置信度分数是模型对预测结果可靠性的评估。它通常表示为概率值，范围在0到1之间。如果置信度分数接近1，说明模型对预测结果非常有信心；如果置信度分数接近0，说明模型对预测结果没有信心。其中，分类分数是模型对目标类别归属的预测。它通常表示为分类概率，范围也在0到1之间。分类分数越高，说明模型认为目标属于该类别的可能性越大。其中，预测框的坐标是模型对目标位置的预测。对于图像中的目标检测任务，预测框的坐标通常表示为矩形框的左上角和右下角的坐标。这些坐标可以用于确定目标在图像中的位置。这三个分支的信息在教师模型和学生模型的输出层中都是重要的，它们分别反映了模型在置信度、类别归属和位置预测方面的性能。通过计算教师模型和学生模型之间的置信度损失、分类损失以及位置蒸馏损失，可以进一步地了解学生模型各性能是否达到最优。步骤502：根据二进制交叉熵损失函数计算置信度损失和分类损失。使用二进制交叉熵损失函数来计算置信度损失和分类损失。该损失函数通常用于二分类问题，可以衡量预测值与目标值之间的差异。将学生模型的置信度分数作为预测值，教师模型的置信度分数作为目标值；将预测值和目标值代入到二进制交叉熵损失函数中，计算得到置信度损失。同样地，将学生模型的分类损失作为预测值，教师模型的分类损失作为目标值；将预测值和目标值代入到二进制交叉熵损失函数中，计算得到分类损失。二进制交叉熵损失函数如下：其中，表示二进制交叉熵损失函数的值；Y表示目标值，/＞表示预测值。步骤503：根据教师模型和学生模型的预测框的坐标以及位置蒸馏损失函数。将教师模型和学生模型的预测框的坐标代入到位置蒸馏损失函数中求得位置蒸馏损失，位置蒸馏损失函数公式如下：其中，和/＞分别表示教师模型和学生模型的预测框的左上角点和右下角点的横、纵坐标；w和h分别表示输入图片的宽高；/＞代表教师模型和学生模型的各自预测框的左上角点之间的相对距离，/＞代表教师模型和学生模型的各自预测框的右下角点之间的相对距离；/＞表示预测框相似性比较指标；表示位置蒸馏损失。步骤504：基于置信度损失、分类损失和位置蒸馏损失以及训练损失函数计算得到响应蒸馏损失。根据步骤20中的训练损失函数，分别赋予置信度损失、分类损失和位置蒸馏损失对应的平衡系数，然后相加就得到了一个输出层的响应蒸馏损失。进一步地，计算教师模型和学生模型之间的交叉蒸馏损失的步骤，请参阅图6和图7，图6是计算教师模型和学生模型之间的交叉蒸馏损失的流程示意图、图7为交叉蒸馏的结构示意图。包括如下步骤：步骤601：将原始图像输入至学生模型，且在学生模型中的输出层经过一次卷积后再输入至教师模型中输出层一次卷积后的网络中，以得到第一输出响应。首先将原始图像输入至学生模型，学生模型会对这些特征进行一系列的卷积操作，提取出有用的特征信息。如图7中原始图像经过骨干网络和特征聚合网络后，将学生模型输出层经过一次卷积后的特征输入至教师模型中输出层一次卷积后的网络中。在教师模型中，这些特征会继续经过卷积操作，进一步提取出有用的特征信息。最终，得到第一输出响应，这个响应包含了学生模型和教师模型共同提取的特征信息。步骤602：将原始图像输入至教师模型，以得到第二输出响应。步骤603：采用第一输出响应和第二输出响应计算得到所述交叉蒸馏损失。具体地，交叉蒸馏损失函数计算公式如下：其中，σ表示sigmoid函数；和/＞分别表示第一输出响应和第二输出响应；BCE表示二进制交叉熵损失函数；γ表示调制因子，/＞；/＞表示交叉蒸馏损失；/＞表示取绝对值。在本实施例中，原始图像为包含需要检测的目标图像。教师模型和学生模型均有三个输出层，在获取交叉蒸馏损失时，需要将教师模型和学生模型相同输出层的获取对应的第一输出响应和第二输出响应。例如，将学生模型中的第一输出层经过一次卷积后再输入至教师模型中第一输出层一次卷积后的网络中，以得到第一输出响应；同样第二输出响应也为教师模型中第一输出层的响应。所以三个输出层将会获得三个交叉蒸馏损失。步骤40：基于特征蒸馏损失、响应蒸馏损失、交叉蒸馏损失和强监督损失构建学生模型的总损失函数。选取教师模型和学生模型的中间第6、8、13、17、20、23层的输出特征输入到特征蒸馏模块得到各层对应的第一输出特征和第二输出特征，然后根据特征蒸馏损失公式计算6个中间层的特征蒸馏损失，将6个中间层的特征蒸馏损失相加得的最终的总的特征蒸馏损失。同样地，将三个输出层的响应蒸馏损失相加得到总的响应蒸馏损失/＞；将三个输出层的交叉蒸馏损失相加得到总的交叉蒸馏损失/＞。进一步，使用训练数据的标注信息和学生模型的最终输出计算强监督损失，记为/＞；具体计算强监督损失步骤与上述得到教师训练损失函数的方法一致，在此不再重复解释。那么，总损失函数的计算公式如下：其中，为总损失；/＞为多个中间特征的所述特征蒸馏损失之和；/＞为三个输出层的所述响应蒸馏损失之和；/＞三个输出层的交叉蒸馏损失之和；/＞为强监督损失，/＞、/＞、/＞、/＞分别表示各损失函数的平衡系数。步骤50：基于所述总损失函数训练所述学生模型，优化所述学生模型的参数，以得到最终的学生模型。使用训练集对学生模型进行训练，并根据总损失函数计算总损失值，通过反向传播和优化算法不断调整模型参数，使得模型在训练集上的总损失值逐渐减小。并使用验证集对训练得到的学生模型进行性能评估，以确保模型的泛化能力和性能。当学生模型在验证集上的性能达到满意水平时，即得到训练好的学生模型。在本实施例中，取教师模型的各特征时，均是在已经训练完成后的教师模型上取得，此时教师模型的各种参数均已固定保持不变。本实施例中取了6个中间层的特征，在其他实施例中，取几个中间层的特征可根据实际情况而定，具体是取哪几个中间层也可以根据实际情况而定。在进行目标检测训练方法验证时，验证实验采用自制数据集共有9879张样本数据，其中训练集样本数量7903张，测试集样本数量1976张。其中实验中模型的搭建、训练和测试均在Pytorch框架下完成，同时使用CUDA和CUDNN加速计算。评估指标包括：精确度是指所有预测为正类的样本中预测正确的比例；召回率是指所有正类中被预测为正类的比例；平均精度是指以Recall为横轴，Precision为纵轴组成的曲线，曲线下的面积为AP值，AP是针对每一类别分别计算的；平均精度均值是指数据集中所有类别的AP的平均值。模型在1个16G的NVIDIA GPU上进行分布式训练，在训练过程中设置epoch为1000，batch_size为32，使用SGD优化器，初始学习率为0.01，最小学习率为0.00005，使用余弦退火学习率下降策略，权重衰减系数为0.937，置信度阈值为0.001，IOU阈值为0.6。为验证本方法的有效性，在相同的硬件设备下使用同一个数据集对不同的方法进行了实验：原始学生模型和本发明训练的学生模型。实验结果见表1：模型效果对比表。表1：模型效果对比表模型参数量：模型中所有需要学习的参数的个数，主要反映模型占用内存的大小，参数量越大，占用的内存就越多。FLOPs：指模型前向传播的计算量和计算速度，用于衡量模型的复杂度。mAP0.5:0.95：指检测框位置的准确性。mAP0.5：指检测框类别的准确性。FPS：模型每秒处理的图片数量。根据表1的实验结果可知，本发明训练的学生模型mAP0.5:0.95和mAP0.5相较于原始学生模型有明显提升，所以本发明的目标检测训练方法能够有效提高学生模型的检测精度。区别于现有技术，本申请提供一种目标检测训练方法，通过提取多个中间层特征进行特征蒸馏让学生模型更加全面地学习教师模型的特征表示；进行响应蒸馏使得学生模型和教师模型的响应差异最小化；并通过交叉蒸馏使学生模型学习教师模型的学习能力。以此提高学生模型学习教师模型的能力，来提升学生模型检测精确度，使得学生模型能够更好地应用在设备上。请参阅图8，图8是本申请电子设备一实施例的结构示意图。电子设备800包括相互耦接的存储器801和处理器802，以及存储于存储器801中，并在处理器802上运行的计算机程序，处理器802用于执行存储器801中存储的程序指令，以实现上述任一目标检测训练方法实施例的步骤。在一个具体的实施场景中，电子设备800可以包括但不限于：微型计算机、服务器。具体而言，处理器802用于控制其自身以及存储器801以实现上述任一电子设备实施例的步骤。处理器802还可以称为CPU。处理器802可能是一种集成电路芯片，具有信号的处理能力。处理器802还可以是通用处理器、数字信号处理器、专用集成电路、现场可编程门阵列或者其他可编程逻辑器件、分立门或者晶体管逻辑器件、分立硬件组件。通用处理器可以是微处理器或者该处理器也可以是任何常规的处理器等。另外，处理器802可以由集成电路芯片共同实现。请参阅图9，图9是本申请计算机可读存储介质一实施例的框架示意图。计算机可读存储介质910存储有能够被处理器运行的程序指令912，程序指令912用于实现上述任一目标检测训练实施例的步骤。该程序指令912存储于一个计算机可读存储介质910中，包括若干指令用于使得一台网络设备或处理器执行本申请各个实施例所述方法的全部或部分步骤。可选的，存储介质910可以为U盘、移动硬盘、只读存储器、随机存取存储器、磁盘或者光盘等各种可以存储程序指令912的介质。在本申请所提供的几个实施例中，应该理解到，所揭露的方法、装置，可以通过其它的方式实现。例如，以上所描述的装置实施方式仅仅是示意性的，例如，模块或单元的划分，仅仅为一种逻辑功能划分，实际实现时可以有另外的划分方式，例如单元或组件可以结合或者可以集成到另一个系统，或一些特征可以忽略，或不执行。另一点，所显示或讨论的相互之间的耦合或直接耦合或通信连接可以是通过一些接口，装置或单元的间接耦合或通信连接，可以是电性、机械或其它的形式。作为分离部件说明的单元可以是或者也可以不是物理上分开的，作为单元显示的部件可以是或者也可以不是物理单元，即可以位于一个地方，或者也可以分布到网络单元上。可以根据实际的需要选择其中的部分或者全部单元来实现本实施方式方案的目的。另外，在本申请各个实施例中的各功能单元可以集成在一个处理单元中，也可以是各个单元单独物理存在，也可以两个或两个以上单元集成在一个单元中。上述集成的单元既可以采用硬件的形式实现，也可以采用软件功能单元的形式实现。集成的单元如果以软件功能单元的形式实现并作为独立的产品销售或使用时，可以存储在一个计算机可读取存储介质中。基于这样的理解，本申请的技术方案本质上或者说对现有技术做出贡献的部分或者该技术方案的全部或部分可以以软件产品的形式体现出来，该计算机软件产品存储在一个存储介质中，包括若干指令用以使得一台计算机设备或处理器执行本申请各个实施方式方法的全部或部分步骤。而前述的存储介质包括：U盘、移动硬盘、只读存储器、随机存取存储器、磁碟或者光盘等各种可以存储程序代码的介质。以上所述仅为本申请的实施例，并非因此限制本申请的专利范围，凡是利用本申请说明书及附图内容所作的等效结构或等效流程变换，或直接或间接运用在其他相关的技术领域，均同理包括在本申请的专利保护范围内。
