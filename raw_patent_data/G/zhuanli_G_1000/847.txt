标题title
模型训练方法、面部表情迁移方法、装置、设备及介质
摘要abst
本申请公开了一种模型训练方法、面部表情迁移方法、装置、设备及介质，属于计算机技术领域。该方法包括：获取第一面部图像及第二面部图像；通过编码模型，分别对第一面部图像及第二面部图像进行编码，得到第一特征及第二特征；通过第一解码模型，对第一特征进行解码，得到第三面部图像；通过第二解码模型，对第二特征进行解码，得到第四面部图像；基于第一面部图像及第三面部图像，对第一解码模型进行训练；基于第一面部图像、第三面部图像、第二面部图像及第四面部图像，对编码模型进行训练；本申请通过训练后的编码模型及第一解码模型能够将任一面部图像转换为虚拟面部图像，保证了表情迁移的准确性。
权利要求书clms
1.一种模型训练方法，其特征在于，所述方法包括：获取第一面部图像及第二面部图像，所述第一面部图像包含虚拟面部，所述第二面部图像中的面部与所述虚拟面部不同；通过编码模型，分别对所述第一面部图像及所述第二面部图像进行编码，得到第一特征及第二特征，所述第一特征指示所述第一面部图像，所述第二特征指示所述第二面部图像；通过第一解码模型，对所述第一特征进行解码，得到第三面部图像；通过第二解码模型，对所述第二特征进行解码，得到第四面部图像；基于所述第一面部图像及所述第三面部图像，对所述第一解码模型进行训练；基于所述第一面部图像、所述第三面部图像、所述第二面部图像及所述第四面部图像，对所述编码模型进行训练；其中，所述第一解码模型及所述编码模型用于基于任一面部图像生成虚拟面部图像，所述虚拟面部图像中所述虚拟面部与所述面部图像中面部的表情相同。2.根据权利要求1所述的方法，其特征在于，获取第一面部图像，包括：基于样本表情参数，生成所述第一面部图像，所述样本表情参数指示所述第一面部图像中所述虚拟面部的表情；所述基于所述第一面部图像、所述第三面部图像、所述第二面部图像及所述第四面部图像，对所述编码模型进行训练之后，所述方法还包括：通过表情识别模型，对所述第一面部图像进行表情识别，得到预测表情参数，所述预测表情参数指示所述第一面部图像中所述虚拟面部的表情；基于所述样本表情参数及所述预测表情参数，对所述表情识别模型进行训练。3.根据权利要求2所述的方法，其特征在于，所述样本表情参数包括多个部位的样本表情参数，所述预测表情参数包括所述多个部位的预测表情参数；所述基于所述样本表情参数及所述预测表情参数，对所述表情识别模型进行训练，包括：基于所述多个部位的样本表情参数及所述多个部位的预测表情参数，确定第一损失值，所述第一损失值指示同一部位的所述样本表情参数与所述预测表情参数之间的差异；基于所述第一损失值，对所述表情识别模型进行训练。4.根据权利要求1所述的方法，其特征在于，所述基于所述第一面部图像、所述第三面部图像、所述第二面部图像及所述第四面部图像，对所述编码模型进行训练，包括：基于所述第一面部图像及所述第三面部图像，确定第二损失值，所述第二损失值指示所述第一面部图像与所述第三面部图像之间的差异；基于所述第二面部图像及所述第四面部图像，确定第三损失值，所述第三损失值指示所述第二面部图像与所述第四面部图像之间的差异；基于所述第二损失值及所述第三损失值，对所述编码模型进行训练。5.根据权利要求1所述的方法，其特征在于，所述方法还包括：在对所述编码模型及所述第一解码模型进行迭代训练的情况下，基于所述第二面部图像及所述第四面部图像，对所述第二解码模型进行训练。6.一种面部表情迁移方法，其特征在于，所述方法包括：获取任一面部图像；通过编码模型，对所述面部图像进行编码，得到所述面部图像的特征；通过第一解码模型，对所述面部图像的特征进行解码，得到虚拟面部图像，所述虚拟面部图像包含虚拟面部，且所述面部图像中的面部与所述虚拟面部图像中所述虚拟面部的表情相同；其中，所述编码模型及所述第一解码模型是基于权利要求1-5任一所述的方法训练得到。7.根据权利要求6所述的方法，其特征在于，所述通过第一解码模型，对所述面部图像的特征进行解码，得到虚拟面部图像之后，所述方法还包括：通过表情识别模型，对所述虚拟面部图像进行表情识别，得到表情参数，所述表情参数指示所述虚拟面部图像中所述虚拟面部的表情。8.根据权利要求7所述的方法，其特征在于，所述通过表情识别模型，对所述虚拟面部图像进行表情识别，得到表情参数之后，所述方法还包括：基于所述表情参数，对虚拟场景中虚拟对象的面部进行调整，以使调整后的虚拟对象的面部表情与所述面部图像中面部的表情相同。9.根据权利要求8所述的方法，其特征在于，所述表情参数包括多个部位的表情参数，每个部位的表情参数包括多个，同一部位的不同表情参数指示所述部位的不同动作；所述基于所述表情参数，对虚拟场景中虚拟对象的面部进行调整，包括：基于所述多个部位的表情参数，将同一部位的多个表情参数进行融合，得到每个部位的融合表情参数；基于所述每个部位的融合表情参数，对所述虚拟对象中所述每个部位进行调整。10.根据权利要求8所述的方法，其特征在于，所述面部图像为视频中的任一视频帧；所述基于所述表情参数，对虚拟场景中虚拟对象的面部进行调整，以使调整后的虚拟对象的面部表情与所述面部图像中面部的表情相同，包括：在得到所述视频中多个视频帧的表情参数的情况下，基于所述多个视频帧的表情参数，按照所述多个视频帧的顺序，依次对所述虚拟对象的面部进行调整，以使所述虚拟对象的面部表情随着所述视频中面部的表情变化而变化。11.一种模型训练装置，其特征在于，所述装置包括：获取模块，用于获取第一面部图像及第二面部图像，所述第一面部图像包含虚拟面部，所述第二面部图像中的面部与所述虚拟面部不同；编码模块，用于通过编码模型，分别对所述第一面部图像及所述第二面部图像进行编码，得到第一特征及第二特征，所述第一特征指示所述第一面部图像，所述第二特征指示所述第二面部图像；解码模块，用于通过第一解码模型，对所述第一特征进行解码，得到第三面部图像；所述解码模块，还用于通过第二解码模型，对所述第二特征进行解码，得到第四面部图像；训练模块，用于基于所述第一面部图像及所述第三面部图像，对所述第一解码模型进行训练；基于所述第一面部图像、所述第三面部图像、所述第二面部图像及所述第四面部图像，对所述编码模型进行训练；其中，所述第一解码模型及所述编码模型用于基于任一面部图像生成虚拟面部图像，所述虚拟面部图像中所述虚拟面部与所述面部图像中面部的表情相同。12.一种面部表情迁移装置，其特征在于，所述装置包括：获取模块，用于获取任一面部图像；编码模块，用于通过编码模型，对所述面部图像进行编码，得到所述面部图像的特征；解码模块，用于通过第一解码模型，对所述面部图像的特征进行解码，得到虚拟面部图像，所述虚拟面部图像包含虚拟面部，且所述面部图像中的面部与所述虚拟面部图像中所述虚拟面部的表情相同；其中，所述编码模型及所述第一解码模型是基于权利要求1-5任一所述的方法训练得到。13.一种计算机设备，其特征在于，所述计算机设备包括处理器和存储器，所述存储器中存储有至少一条计算机程序，所述至少一条计算机程序由所述处理器加载并执行以实现如权利要求1至5任一权利要求所述的模型训练方法所执行的操作；或者，以实现如权利要求6至10任一权利要求所述的面部表情迁移方法所执行的操作。14.一种计算机可读存储介质，其特征在于，所述计算机可读存储介质中存储有至少一条计算机程序，所述至少一条计算机程序由处理器加载并执行以实现如权利要求1至5任一权利要求所述的模型训练方法所执行的操作；或者，以实现如权利要求6至10任一权利要求所述的面部表情迁移方法所执行的操作。
说明书desc
技术领域本申请实施例涉及计算机技术领域，特别涉及一种模型训练方法、面部表情迁移方法、装置、设备及介质。背景技术面部表情迁移是指将任一对象的面部表情迁移到目标对象的面部上，且只改变目标对象的表情特征而不改变目标对象其他的面部特征。虽然目前的面部表情迁移方法能够实现面部表情的迁移，但是，目前的面部表情迁移方法的准确性差。发明内容本申请实施例提供了一种模型训练方法、面部表情迁移方法、装置、设备及介质，能够提高面部表情迁移的准确性。所述技术方案如下方面。一方面，提供了一种模型训练方法，所述方法包括：获取第一面部图像及第二面部图像，所述第一面部图像包含虚拟面部，所述第二面部图像中的面部与所述虚拟面部不同；通过编码模型，分别对所述第一面部图像及所述第二面部图像进行编码，得到第一特征及第二特征，所述第一特征指示所述第一面部图像，所述第二特征指示所述第二面部图像；通过第一解码模型，对所述第一特征进行解码，得到第三面部图像；通过第二解码模型，对所述第二特征进行解码，得到第四面部图像；基于所述第一面部图像及所述第三面部图像，对所述第一解码模型进行训练；基于所述第一面部图像、所述第三面部图像、所述第二面部图像及所述第四面部图像，对所述编码模型进行训练；其中，所述第一解码模型及所述编码模型用于基于任一面部图像生成虚拟面部图像，所述虚拟面部图像中所述虚拟面部与所述面部图像中面部的表情相同。另一方面，提供了一种面部表情迁移方法，其特征在于，所述方法包括：获取任一面部图像；通过编码模型，对所述面部图像进行编码，得到所述面部图像的特征；通过第一解码模型，对所述面部图像的特征进行解码，得到虚拟面部图像，所述虚拟面部图像包含虚拟面部，且所述面部图像中的面部与所述虚拟面部图像中所述虚拟面部的表情相同；其中，所述编码模型及所述第一解码模型是基于上述方面所述的模型训练方法训练得到。再一方面，提供了一种模型训练装置，所述装置包括：获取模块，用于获取第一面部图像及第二面部图像，所述第一面部图像包含虚拟面部，所述第二面部图像中的面部与所述虚拟面部不同；编码模块，用于通过编码模型，分别对所述第一面部图像及所述第二面部图像进行编码，得到第一特征及第二特征，所述第一特征指示所述第一面部图像，所述第二特征指示所述第二面部图像；解码模块，用于通过第一解码模型，对所述第一特征进行解码，得到第三面部图像；所述解码模块，还用于通过第二解码模型，对所述第二特征进行解码，得到第四面部图像；训练模块，用于基于所述第一面部图像及所述第三面部图像，对所述第一解码模型进行训练；基于所述第一面部图像、所述第三面部图像、所述第二面部图像及所述第四面部图像，对所述编码模型进行训练；其中，所述第一解码模型及所述编码模型用于基于任一面部图像生成虚拟面部图像，所述虚拟面部图像中所述虚拟面部与所述面部图像中面部的表情相同。在一种可能实现方式中，所述获取模块，用于基于样本表情参数，生成所述第一面部图像，所述样本表情参数指示所述第一面部图像中所述虚拟面部的表情；所述装置还包括：识别模块，用于通过表情识别模型，对所述第一面部图像进行表情识别，得到预测表情参数，所述预测表情参数指示所述第一面部图像中所述虚拟面部的表情；所述训练模块，还用于基于所述样本表情参数及所述预测表情参数，对所述表情识别模型进行训练。在另一种可能实现方式中，所述样本表情参数包括多个部位的样本表情参数，所述预测表情参数包括所述多个部位的预测表情参数；所述训练模块，用于基于所述多个部位的样本表情参数及所述多个部位的预测表情参数，确定第一损失值，所述第一损失值指示同一部位的所述样本表情参数与所述预测表情参数之间的差异；基于所述第一损失值，对所述表情识别模型进行训练。在另一种可能实现方式中，所述训练模块，用于基于所述第一面部图像及所述第三面部图像，确定第二损失值，所述第二损失值指示所述第一面部图像与所述第三面部图像之间的差异；基于所述第二面部图像及所述第四面部图像，确定第三损失值，所述第三损失值指示所述第二面部图像与所述第四面部图像之间的差异；基于所述第二损失值及所述第三损失值，对所述编码模型进行训练。在另一种可能实现方式中，所述训练模块，还用于在对所述编码模型及所述第一解码模型进行迭代训练的情况下，基于所述第二面部图像及所述第四面部图像，对所述第二解码模型进行训练。再一方面，提供了一种面部表情迁移装置，所述装置包括：获取模块，用于获取任一面部图像；编码模块，用于通过编码模型，对所述面部图像进行编码，得到所述面部图像的特征；解码模块，用于通过第一解码模型，对所述面部图像的特征进行解码，得到虚拟面部图像，所述虚拟面部图像包含虚拟面部，且所述面部图像中的面部与所述虚拟面部图像中所述虚拟面部的表情相同；其中，所述编码模型及所述第一解码模型是上述方面所述的模型训练方法训练得到。在一种可能实现方式中，所述装置还包括：识别模块，用于通过表情识别模型，对所述虚拟面部图像进行表情识别，得到表情参数，所述表情参数指示所述虚拟面部图像中所述虚拟面部的表情。在另一种可能实现方式中，所述装置还包括：调整模块，用于基于所述表情参数，对虚拟场景中虚拟对象的面部进行调整，以使调整后的虚拟对象的面部表情与所述面部图像中面部的表情相同。在另一种可能实现方式中，所述表情参数包括多个部位的表情参数，每个部位的表情参数包括多个，同一部位的不同表情参数指示所述部位的不同动作；所述调整模块，用于基于所述多个部位的表情参数，将同一部位的多个表情参数进行融合，得到每个部位的融合表情参数；基于所述每个部位的融合表情参数，对所述虚拟对象中所述每个部位进行调整。在另一种可能实现方式中，所述面部图像为视频中的任一视频帧；所述调整模块，用于在得到所述视频中多个视频帧的表情参数的情况下，基于所述多个视频帧的表情参数，按照所述多个视频帧的顺序，依次对所述虚拟对象的面部进行调整，以使所述虚拟对象的面部表情随着所述视频中面部的表情变化而变化。再一方面，提供了一种计算机设备，所述计算机设备包括处理器和存储器，所述存储器中存储有至少一条计算机程序，所述至少一条计算机程序由所述处理器加载并执行以实现如上述方面所述的模型训练方法或面部表情迁移方法所执行的操作。再一方面，提供了一种计算机可读存储介质，所述计算机可读存储介质中存储有至少一条计算机程序，所述至少一条计算机程序由处理器加载并执行以实现如上述方面所述的模型训练方法或面部表情迁移方法所执行的操作。再一方面，提供了一种计算机程序产品，包括计算机程序，所述计算机程序被处理器执行时实现如上述方面所述的模型训练方法或面部表情迁移方法所执行的操作。本申请实施例提供的方案中，对于包含不同面部的第一面部图像和第二面部图像，通过同一个编码模型，分别对第一面部图像及第二面部图像进行编码，以获取两个面部图像的特征；第一解码模型将第一面部图像的特征解码为第三面部图像，第二解码模型将第二面部图像的特征解码为第四面部图像，进而基于第一面部图像及第三面部图像，对第一解码模型进行训练；基于第一面部图像、第三面部图像、第二面部图像及第四面部图像，对编码模型进行训练，这种训练方式简单，能够保证模型的训练效率，并且，使得编码模型能够学习将面部图像编码为适用于第一解码模型的特征的能力，能够保证编码模型输出的特征适用于第一解码模型，且第一解码模型能够学习将编码模型输出的特征解码为包含虚拟面部的面部图像的能力，则通过训练后的编码模型及第一解码模型能够将任一面部图像转换为虚拟面部图像，使得虚拟面部图像包含虚拟面部、且虚拟面部的表情与输入的面部图像中表情相同，保证了面部表情迁移的准确性。附图说明为了更清楚地说明本申请实施例中的技术方案，下面将对实施例描述中所需要使用的附图作简单地介绍，显而易见地，下面描述中的附图仅仅是本申请实施例的一些实施例，对于本领域普通技术人员来讲，在不付出创造性劳动的前提下，还可以根据这些附图获得其他的附图。图1是本申请实施例提供的一种实施环境的结构示意图；图2是本申请实施例提供的一种模型训练方法的流程图；图3是本申请实施例提供的另一种模型训练方法的流程图；图4是本申请实施例提供的一种图像处理的流程图；图5是本申请实施例提供的一种训练表情识别模型的流程图；图6是本申请实施例提供的一种第一面部图像的示意图；图7是本申请实施例提供的一种面部表情迁移方法的流程图；图8是本申请实施例提供的另一种面部表情迁移方法的流程图；图9是本申请实施例提供的一种获取表情参数的流程图；图10是本申请实施例提供的一种真实面部图像与虚拟面部图像的示意图；图11是本申请实施例提供的另一种真实面部图像与虚拟面部图像的示意图；图12是本申请实施例提供的一种模型训练装置的结构示意图；图13是本申请实施例提供的另一种模型训练装置的结构示意图；图14是本申请实施例提供的一种面部表情迁移装置的结构示意图；图15是本申请实施例提供的另一种面部表情迁移装置的结构示意图；图16是本申请实施例提供的一种终端的结构示意图；图17是本申请实施例提供的一种服务器的结构示意图。具体实施方式为使本申请实施例的目的、技术方案和优点更加清楚，下面将结合附图对本申请实施方式作进一步地详细描述。本申请所使用的术语“第一”、“第二”、“第三”、“第四”等可在本文中用于描述各种概念，但除非特别说明，这些概念不受这些术语限制。这些术语仅用于将一个概念与另一个概念区分。举例来说，在不脱离本申请的范围的情况下，可以将第一面部图像称为第二面部图像，且类似地，可将第二面部图像称为第一面部图像。本申请所使用的术语“至少一个”、“多个”、“每个”、“任一”，至少一个包括一个、两个或两个以上，多个包括两个或两个以上，而每个是指对应的多个中的每一个，任一是指多个中的任意一个。举例来说，多个面部图像包括3个面部图像，而每个是指这3个面部图像中的每一个面部图像，任一是指这3个面部图像中的任意一个，能够是第一个面部图像，或者，是第二个面部图像，或者，是第三个面部图像。需要说明的是，本申请所涉及的信息、数据以及信号，均为经用户授权或者经过各方充分授权的，且相关数据的收集、使用和处理需要遵守相关国家和地区的相关法律法规和标准。例如，本申请中涉及到的面部图像、视频或虚拟面部模型都是在充分授权的情况下获取的。人工智能是利用数字计算机或者数字计算机控制的机器模拟、延伸和扩展人的智能，感知环境、获取知识并使用知识获得最佳结果的理论、方法、技术及应用系统。换句话说，人工智能是计算机科学的一个综合技术，它企图了解智能的实质，并生产出一种新的能以人类智能相似的方式做出反应的智能机器。人工智能也就是研究各种智能机器的设计原理与实现方法，使机器具有感知、推理与决策的功能。人工智能技术是一门综合学科，涉及领域广泛，既有硬件层面的技术也有软件层面的技术。人工智能基础技术一般包括如传感器、专用人工智能芯片、云计算、分布式存储、大数据处理技术、预训练模型技术、操作/交互系统、机电一体化等。其中，预训练模型又称大模型、基础模型，经过微调后可以广泛应用于人工智能各大方向下游任务。人工智能软件技术主要包括计算机视觉技术、语音处理技术、自然语言处理技术以及机器学习/深度学习等几大方向。机器学习是一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、算法复杂度理论等多门学科。专门研究计算机怎样模拟或实现人类的学习行为，以获取新的知识或技能，重新组织已有的知识结构使之不断改善自身的性能。机器学习是人工智能的核心，是使计算机具有智能的根本途径，其应用遍及人工智能的各个领域。机器学习和深度学习通常包括人工神经网络、置信网络、强化学习、迁移学习、归纳学习、示教学习等技术。计算机视觉技术计算机视觉是一门研究如何使机器“看”的科学，更进一步的说，就是指用摄影机和电脑代替人眼对目标进行识别和测量等机器视觉，并进一步做图形处理，使电脑处理成为更适合人眼观察或传送给仪器检测的图像。作为一个科学学科，计算机视觉研究相关的理论和技术，试图建立能够从图像或者多维数据中获取信息的人工智能系统。大模型技术为计算机视觉技术发展带来重要变革，SwinTransformer，ViT，V-MOE，MAE等视觉领域的预训练模型经过微调可以快速、广泛适用于下游具体任务。计算机视觉技术通常包括图像处理、图像识别、图像语义理解、图像检索、OCR、视频处理、视频语义理解、视频内容/行为识别、三维物体重建、3D技术、虚拟现实、增强现实、同步定位与地图构建等技术。本申请实施例提供的方案，基于人工智能的机器学习技术，能够实现模型训练方法，以训练用于面部表情迁移的模型，利用训练后的模型，实现了面部表情迁移方法。本申请实施例提供的模型训练方法及面部表情迁移方法，均能够由计算机设备中。可选地，该计算机设备为终端或服务器。可选地，该服务器是独立的物理服务器，或者是多个物理服务器构成的服务器集群或者分布式系统，或者是提供云服务、云数据库、云计算、云函数、云存储、网络服务、云通信、中间件服务、域名服务、安全服务、CDN、以及大数据和人工智能平台等基础云计算服务的云服务器。可选地，该终端是智能手机、平板电脑、笔记本电脑、台式计算机、智能音箱、智能手表、智能语音交互设备、智能家电及车载终端等，但并不局限于此。在一些实施例中，本申请实施例所涉及的计算机程序可被部署在一个计算机设备上执行，或者在位于一个地点的多个计算机设备上执行，又或者，在分布在多个地点且通过通信网络互连的多个计算机设备上执行，分布在多个地点且通过通信网络互连的多个计算机设备能够组成区块链系统。在一些实施例中，计算机设备提供为服务器。图1是本申请实施例提供的一种实施环境的示意图。参见图1，该实施环境包括终端101和服务器102。终端101和服务器102之间通过无线或者有线网络连接。终端101用于为服务器102提供面部图像，服务器102用于基于终端101提供的面部图像，结合第二解码模型，对编码模型及第一解码模型进行训练。在一种可能实现方式中，终端101安装有由服务器103提供服务的应用，服务器102对编码模型及第一解码模型训练完成后，能够将编码模型和第一解码模型部署服务器103中。终端101能够通过该应用实现例如面部表情迁移等功能。可选地，应用为终端101操作系统中的应用，或者为第三方提供的应用。例如，应用为表情迁移应用，表情迁移应用具有面部表情迁移的功能，当然，该表情迁移应用还能够具有其他功能，例如，点评功能、购物功能、导航功能、游戏功能等。终端101用于基于用户标识登录应用，通过应用向服务器103发送面部图像，服务器103用于接收终端101发送的面部图像，通过编码模型和第一解码模型，基于面部图像生成虚拟面部图像，且虚拟面部图像中虚拟面部与面部图像中面部的表情相同。需要说明的是，本申请实施例是以服务器103中部署训练完成的编码模型和第一解码模型为例进行说明，而在另一实施例中，服务器102用于为具有面部表情迁移功能的应用提供服务，则服务器102在训练完成的编码模型和第一解码模型，存储训练完成的编码模型和第一解码模型，以便后续通过编码模型和第一解码模型，提供面部表情迁移服务。图2是本申请实施例提供的一种模型训练方法的流程图，该方法由计算机设备执行，如图2所示，该方法包括以下步骤。201、计算机设备获取第一面部图像及第二面部图像，第一面部图像包含虚拟面部，第二面部图像中的面部与虚拟面部不同。其中，第二面部图像中的面部能够是任意形象的面部，例如，面部为人的面部、动物的面部或卡通形象的面部，虚拟面部能够是任意虚拟形象的面部，例如，虚拟面部为卡通形象的面部或虚拟场景中虚拟对象的面部。第二面部图像是不包含虚拟面部的任意面部图像，例如，第二面部图像为真实面部图像，即第二面部图像包含某个人的面部。在本申请实施例中，第一面部图像及第二面部图像相当于是属于不同类型的面部图像，以便后续通过不同类型的面部图像来训练模型，以使模型能够实现不同类型的面部图像中表情的迁移。202、计算机设备通过编码模型，分别对第一面部图像及第二面部图像进行编码，得到第一特征及第二特征，第一特征指示第一面部图像，第二特征指示第二面部图像。其中，编码模型用于对输入的图像进行编码，以获取图像的特征。编码模型能够是任意的网络模型，例如，编码模型时一个由Resnet34组成的深度网络。第一特征和第二特征均能以任意的形式表示，例如，第一特征和第二特征均能够以特征向量的形式表示，如第一特征和第二特征均是尺度为8×8的特征矩阵。在本申请实施例中，通过编码模型，对第一面部图像进行编码，得到第一特征；通过编码模型，对第二面部图像进行编码，得到第二特征。203、计算机设备通过第一解码模型，对第一特征进行解码，得到第三面部图像。其中，第一解码模型用于将面部图像的特征解码为包含虚拟面部的面部图像，第一解码模型能够为任意的网络模型，例如，第一解码模型是由多个反卷积层组成的模型。第三面部图像是由第一解码模型基于第一面部图像的特征输出的面部图像，若第一解码模型足够准确，则第一解码模型输出的第三面部图像应当与第一面部图像足够相似，但受到第一解码模型的准确性的影响，第三面部图像可能与第一面部图像存在差异，则第三面部图像中的虚拟面部可能与第一面部图像中的虚拟面部存在差异。204、计算机设备通过第二解码模型，对第二特征进行解码，得到第四面部图像。其中，第二解码模型用于将面部图像的特征解码为面部图像，第二解码模型能够为任意的网络模型，例如，第二解码模型是由多个反卷积层组成的模型。第四面部图像是由第一解码模型基于第二面部图像的特征输出的面部图像，若第二解码模型足够准确，则第二解码模型输出的第四面部图像应当与第二面部图像足够相似，但受到第二解码模型的准确性的影响，第四面部图像可能与第一面部图像存在差异，则第四面部图像中的面部可能与第一面部图像中的面部存在差异。205、计算机设备基于第一面部图像及第三面部图像，对第一解码模型进行训练；基于第一面部图像、第三面部图像、第二面部图像及第四面部图像，对编码模型进行训练。在本申请实施例中，第三面部图像与第一面部图像之间的差异，能够反映出第一解码模型的准确性，则基于第一面部图像及第三面部图像，对第一解码模型进行训练，以使提升第一解码模型的准确性，以便后续再通过第一解码模型对第一面部图像的特征进行解码时，输出的面部图像与第一面部图像的相似度增大，且输出的面部图像中虚拟面部与第一面部图像中虚拟面部的相似度增大。在本申请实施例中，第一特征及第二特征均是通过编码模型得到，第一特征不准确会导致得到的第三面部图像与第一面部图像不相似，则第一面部图像与第三面部图像之间的差异，能够反映出编码模型的准确性，并且，第二特征不准确会导致得到的第四面部图像与第二面部图像不相似，第二面部图像与第四面部图像之间的差异，也能够反映出编码模型的准确性，因此，基于第一面部图像、第三面部图像、第二面部图像及第四面部图像，对编码模型进行训练，以使后续编码模型对任一面部图像进行编码后得到的特征能够适用于第一编码模型及第二编码模型，以提升编码模型的准确性。在本申请实施例中，按照上述方式对编码模型及第一解码模型进行训练，以使编码模型能够学习将面部图像编码为适用于第一解码模型和第二解码模型的特征的能力，第一解码模型学习将编码模型输出的特征解码为包含虚拟面部的面部图像的能力，则在对编码模型及第一解码模型训练完成后，使得通过编码模型及第一解码模型，能够基于任一面部图像生成虚拟面部图像，该虚拟面部图像中包含的虚拟面部与上述训练过程中第一虚拟面部图像中的虚拟面部相同，但虚拟面部的表情可能不同，虚拟面部图像中虚拟面部与输入的面部图像中面部的表情相同。也即是，后续通过编码模型及第一解码模型能够实现表情的迁移，即将输入的面部图像中面部的表情迁移到虚拟面部上，以获取包含虚拟面部的虚拟面部图像。本申请实施例提供的方案中，对于包含不同面部的第一面部图像和第二面部图像，通过同一个编码模型，分别对第一面部图像及第二面部图像进行编码，以获取两个面部图像的特征；第一解码模型将第一面部图像的特征解码为第三面部图像，第二解码模型将第二面部图像的特征解码为第四面部图像，进而基于第一面部图像及第三面部图像，对第一解码模型进行训练；基于第一面部图像、第三面部图像、第二面部图像及第四面部图像，对编码模型进行训练，这种训练方式简单，能够保证模型的训练效率，并且，使得编码模型能够学习将面部图像编码为适用于第一解码模型的特征的能力，能够保证编码模型输出的特征适用于第一解码模型，且第一解码模型能够学习将编码模型输出的特征解码为包含虚拟面部的面部图像的能力，则通过训练后的编码模型及第一解码模型能够将任一面部图像转换为虚拟面部图像，使得虚拟面部图像包含虚拟面部、且虚拟面部的表情与输入的面部图像中表情相同，保证了面部表情迁移的准确性。在图2所示实施例的基础上，本申请实施例能够利用样本表情参数来获取包含虚拟面部的第一面部图像，以便后续基于第一面部图像训练编码模型和第一解码模型的同时，还能够基于样本表情参数及第一面部图像来训练表情识别模型，具体过程详见下述实施例。图3是本申请实施例提供的另一种模型训练方法的流程图，该方法由计算机设备执行，如图3所示，该方法包括以下步骤。301、计算机设备基于样本表情参数，生成第一面部图像，样本表情参数指示第一面部图像中虚拟面部的表情。在本申请实施例中，第一面部图像包含虚拟面部，样本表情参数指示虚拟面部的表情，基于样本表情参数来生成第一面部图像，以使第一面部图像中虚拟面部的表情与样本表情参数相匹配，以便为后续表情识别模型提供训练数据。在一种可能实现方式中，样本表情参数能够指示任意的表情，例如，样本表情参数指示眨眼、闭眼、皱眉、张嘴、瘪嘴、咧嘴，嘟嘴等各表情。可选地，样本表情参数包括多个部位的样本表情参数。其中，多个部位是指虚拟面部的多个部位，例如，多个部位包括虚拟面部的眼睛、鼻子、嘴巴和额头等。可选地，每个部位的样本表情参数包括多个，同一部位的不同样本表情参数指示该部位不同的动作。例如，嘴巴具有2个样本表情参数，第1个样本表情参数指示嘴巴张开的大小，第2个样本表情参数指示嘟嘴的程度。例如，虚拟面部中多个部位的表情参数能够构成一个130维度的样本表情参数，不同维度的样本表情参数指示同一部位的不同动作或者指示不同部位的动作。在一种可能实现方式中，该步骤301包括：基于样本表情参数，对虚拟面部模型的面部进行调整，对调整后的虚拟面部模型进行拍摄，得到第一面部图像。在本申请实施例中，虚拟面部即为虚拟面部模型的面部。该虚拟面部模型是一个三维面部模型，例如，虚拟面部模型为一个虚拟人脸模型或虚拟动物面部模型。基于样本表情参数来控制虚拟面部模型的表情，进而调整完成虚拟面部模型的表情后，能够对虚拟面部模型进行拍摄，以得到包含虚拟面部模型的表情的第一面部图像。例如，按照样本表情参数指示各个部位的动作，调整虚拟面部模型的面部，以使虚拟面部模型中各个部位的动作与样本表情参数指示的各个部位的动作相同，此时虚拟面部模型的表情与样本表情参数匹配，之后，再对虚拟面部模型进行拍摄，得到第一面部图像。可选地，虚拟面部模型能够是通过任意的数字制作平台开发的数字面部模型，在开发完成数字面部模型后，将数字面部模型导入渲染引擎中，通过渲染引擎，基于样本表情参数，对数字面部模型的表情进行调整，进而对数字面部模型的表情进行拍摄，得到第一面部图片。例如，以计算机设备为终端为例，该渲染引擎能够控制数字面部模型的表情，在将数字面部模型导入渲染引擎中，用户通过渲染引擎设置任意的样本表情参数，则通过渲染引擎基于样本表情参数来调整数字面部模型的表情，通过渲染引擎，对数字面部模型的表情进行拍摄，得到第一面部图片。例如，以计算机设备为终端为例，该渲染引擎能够控制数字面部模型的表情，在将数字面部模型导入渲染引擎中，终端能显示渲染引擎的控制界面，该控制界面中显示有数字面部模型，用户通过终端显示的控制界面，能够对数字面部模型的表情任意调整，且渲染引擎会记录对数字面部模型的调整操作，终端响应于对调整后的数字面部模型的确认操作，终端通过渲染引擎，对数字面部模型的表情进行拍摄，得到第一面部图片，并基于记录的调整操作，生成样本表情参数。需要说明的是，本申请实施例是以基于样本表情参数获取第一面部图像为例进行说明，而在另一实施例中，无需执行上述步骤301，而是采取其他方式，获取第一面部图像。302、计算机设备获取第二面部图像，第二面部图像中的面部与第一面部图像中的虚拟面部不同。在一种可能实现方式中，第二面部图像为真实面部图像，则获取第二面部图像的过程包括：对人的面部进行拍摄，得到第二面部图像。在本申请实施例中，第二面部图像包含的面部为某个人的真实面部，在对人进行拍摄时，人能够对摄像头做出各种表情，通过摄像机对人的面部进行拍摄，得到第二面部图像。在一种可能实现方式中，对人的面部进行拍摄，得到视频，从视频中提取包含面部的视频帧，作为第二面部图像。在本申请实施例中，在对人进行拍摄时，人能够对摄像头做出各种表情，通过摄像机对人的面部进行拍摄，以获取到包含人各种表情的视频，从视频中提取包含人的面部的视频帧，作为第二面部图像。303、计算机设备通过编码模型，分别对第一面部图像及第二面部图像进行编码，得到第一特征及第二特征，第一特征指示第一面部图像，第二特征指示第二面部图像。在一种可能实现方式中，在对面部图像进行编码前，还对面部图像进行尺度调整，以使调整后的面部图像的尺度为目标尺度，也即是，尺度调整过程包括：对于第一面部图像及第二面部图像中的任一面部图像，在该面部图像的尺度小于目标尺度的情况下，对该面部图像进行放大，以使放大后的面部图像的尺度为目标尺度；或者，在该面部图像的尺度大于目标尺度的情况下，对该面部图像进行裁剪，以使裁剪出的面部图像的尺度为目标尺度，且裁剪出的面部图像包含面部。其中，目标尺度为编码模型的输入图像的尺度，例如，目标尺度为256×256。在本申请实施例中，在对面部图像进行编码前，对面部图像进行尺度调整，以保证编码模型能够对输入的面部图像进行编码，保证编码的准确性。另外，在第一面部图像及第二面部图像均为目标尺度的情况下，则无需再对第一面部图像及第二面部图像的尺度进行调整。例如，目标尺度为256×256，第一面部图像和第二面部图像均是尺度为256×256的图像，通过编码模型编码分别对第一面部图像及第二面部图像进行编码，得到第一特征及第二特征，第一特征及第二特征的特征尺度均为8×8。304、计算机设备通过第一解码模型，对第一特征进行解码，得到第三面部图像。在一种可能实现方式中，第一解码模型时由多个反卷积层组成，每个反卷积层的输出特征的尺度为该反卷积层输入特征的尺度的两倍。例如，第一特征的尺度为8×8，第一解码模型包括5个反卷积层，则通过第一解码模型对第一特征进解码，每个卷积层的输出特征的尺度为该卷积层的输入特征的尺度的2倍，则通过5个卷积层得到的第三图像的尺度为256×256。305、计算机设备通过第二解码模型，对第二特征进行解码，得到第四面部图像。在一种可能实现方式中，第一解码模型与第二解码模型的结构相同，但是模型参数不同。例如，第一解码模型与第二解码模型均是由5个反卷积层组成，但是，第一解码模型与第二解码模型中反卷积层的参数不同。在本申请实施例中，第一解码模型与第二解码模型的结构相同，则通过第二解码模型对第二特征进行解码的过程，与上述通过第一解码模型对第一特征进行解码的过程同理，在此不再赘述。306、计算机设备基于第一面部图像及第三面部图像，对第一解码模型进行训练。在一种可能实现方式中，基于第一面部图像及第三面部图像，确定第二损失值，第二损失值指示第一面部图像与第三面部图像之间的差异，基于第二损失值，对第一解码模型进行训练。在本申请实施例中，通过确定第二损失值，以便将第一面部图像与第三面部图像之间的差异量化，保证第二损失值能够准确反映出第一面部图像与第三图像之间的差异，通过第二损失值对第一解码模型进行训练，以使通过训练后的第一解码模型再对第一特征进行解码得到的面部图像与第一面部图像之间的差异变小，以提升第一解码模型的准确性。307、计算机设备基于第一面部图像、第三面部图像、第二面部图像及第四面部图像，对编码模型进行训练。在一种可能实现方式中，该步骤306包括：基于第一面部图像及第三面部图像，确定第二损失值，第二损失值指示第一面部图像与第三面部图像之间的差异；基于第二面部图像及第四面部图像，确定第三损失值，第三损失值指示第二面部图像与第四面部图像之间的差异；基于第二损失值及第三损失值，对编码模型进行训练。在本申请实施例中，通过确定第二损失值，以便第一面部图像与第三面部图像之间的差异量化，通过确定第三损失值，以便第二面部图像与第四面部图像之间的差异量化，保证第二损失值能够准确反映出第一面部图像与第三图像之间的差异，且第三损失值能够准确反映出第二面部图像与第四面部图像之间的差异，则通过第二损失值及第三损失值对第一解码模型进行训练，以使通过训练后的编码模型得到的第一特征及第二特征更准确，进而保证得到的第三面部图像与第一面部图像之间的差异变小、且保证得到的第四面部图像与二面部图像之间的差异变小，以提升第一解码模型的准确性。可选地，在确定第二损失值及第三损失值的情况下，确定第二损失值与第三损失值的损失值和值，基于损失值和值，对编码模型进行训练。在本申请实施例中，编码模型、第一解码模型及第二解码模型能够组成面部图像转换器，以第一面部图像为虚拟面部图像、第二面部图像为真实面部图像为例，通过同一编码模型，分别对虚拟面部图像及真实面部图像进行编码，得到用于指示虚拟面部图像的第一特征及用于指示真实面部图像的第二特征；第一解码模型即为用于解码出虚拟面部图像的模型，第二解码模型用于解码出真实面部图像的模型，则通过第一解码模型，基于第一特征能够解码出虚拟面部图像，通过第二解码模型，基于第二特征解码出真实面部图像，进而采取图像重构损失来对第一解码模型及编码模型进行训练即可，能够提升第一解码模型及编码模型的准确性。如图4所示，将第一面部图像输入编码模型，编码模型将特征输入至第一解码模型，由第一解码模型输出第三面部图像；将第二面部图像输入编码模型，编码模型将特征输入至第二解码模型，由第二解码模型输出第四面部图像，以便通过第一面部图像、第二面部图像、第三面部图像及第四面部图像来实现模型训练。需要说明的是，本申请实施例是以对编码模型及第一解码模型进行一次训练为例进行说明，而在另一实施例中，能够按照上述步骤301-步骤307，对编码模型及第一解码模型进行迭代训练，在迭代次数达到次数阈值的情况下，或者，第二损失值及第三损失值均小于损失值阈值的情况下，或者，第二损失值与第三损失值的损失值和值小于损失值阈值的情况下，停止对编码模型及第一解码模型进行迭代训练。例如，在对编码模型及第一解码模型进行迭代训练的过程中，按照上述步骤301-步骤307，对编码模型及第一解码模型进行一次迭代后，获取下一个第一面部图像及下一个第二面部图像，获取到的第一面部图像与上次迭代所使用第一面部图像包含的虚拟面部相同但虚拟面部的表情不同；获取到的第二面部图像与上次迭代所使用的第二面部图像包含的面部相同但面部的表情不同；基于当前获取到的第一面部图像及第二面部图像，按照上述步骤303-步骤307，对编码模型及第一解码模型进行再一次迭代。在本申请实施例中，在对编码模型及第一解码模型训练完成后，第一解码模型及编码模型用于基于任一面部图像生成虚拟面部图像，虚拟面部图像中虚拟面部与面部图像中面部的表情相同。308、计算机设备通过表情识别模型，对第一面部图像进行表情识别，得到预测表情参数，预测表情参数指示第一面部图像中虚拟面部的表情。在本申请实施例中，表情识别模型用于识别面部图像中面部的表情，以获取用于指示面部图像中面部表情的表情参数。通过表情识别模型，对第一面部图像进行表情识别，得到预测表情参数，该预测表情参数能够反映出表情识别模型的准确性，以便后续基于预测表情参数来对表情识别模型进行训练。其中，表情识别模型为任意的网络模型，例如，表情识别模型是包括Backbone、Pooling层、FC层和一个Sigmoid层的网络模型。309、计算机设备基于样本表情参数及预测表情参数，对表情识别模型进行训练。在本申请实施例中，样本表情参数和预测表情参数均指示第一面部图像中虚拟面部的表情，样本表情参数为第一面部图像的真实表情参数，而预测表情参数是通过表情识别模型得到，则样本表情参数与预测表情参数之间的差异，能够反映出表情识别模型的准确性，则基于表情参数及预测表情参数，对表情识别模型进行训练，以使通过训练后的表情识别模型再对第一面部图像进行表情识别，得到的表情参数与样本表情参数之间的差异变小，进而提升表情识别模型的准确性。在一种可能实现方式中，该步骤309包括：基于样本表情参数及预测表情参数，确定第四损失值，第四损失值指示样本表情参数与预测表情参数之间的差异；基于第四损失值，对表情识别模型进行训练。在本申请实施例中，通过确定第四损失值，以便将样本表情参数及预测表情参数之间的差异量化，保证第四损失值能够准确反映出样本表情参数与预测表情参数之间的差异，以便通过第四损失值对表情识别模型进行训练，以使通过训练后的表情识别模型再对第一面部图像进行表情识别，得到的表情参数与样本表情参数之间的差异变小，以提升表情识别模型的准确性。在一种可能实现方式中，样本表情参数包括多个部位的样本表情参数，预测表情参数包括多个部位的预测表情参数；该步骤309包括：基于多个部位的样本表情参数及多个部位的预测表情参数，确定第一损失值，第一损失值指示同一部位的样本表情参数与预测表情参数之间的差异；基于第一损失值，对表情识别模型进行训练。其中，多个部位是指虚拟面部的多个部位，例如，多个部位包括虚拟面部的眼睛、鼻子、嘴巴和额头等。任一部位的样本表情参数指示该部位的表情。可选地，每个部位的样本表情参数包括多个，同一部位的不同样本表情参数指示该部位不同的动作。例如，嘴巴具有2个样本表情参数，第1个样本表情参数指示嘴巴张开的大小，第2个样本表情参数指示嘟嘴的程度。在本申请实施例中，通过确定出第一损失值，反映出每个部位的样本表情参数与预测表情参数之间的差异，以便通过第一损失值对表情识别模型进行训练，以使通过训练后的表情识别模型再对第一面部图像进行表情识别，得到的表情参数与样本表情参数之间的差异变小，以提升表情识别模型的准确性。需要说明的是，本申请实施例是以对表情识别模型进行一次迭代为例进行说明，而在另一实施例中，能够按照上述步骤308-步骤309，对表情识别模型进行迭代训练。例如，按照上述步骤301获取多个第一面部图像及每个第一面部图像对应的样本表情参数，基于每个第一面部图像及对应的表情参数，按照上述步骤308-步骤309，对表情识别模型进行一次迭代；在迭代次数达到次数阈值的情况下，或者，在第一损失值小于损失值阈值的情况下，停止对表情识别模型进行迭代训练。需要说明的是，对编码模型及第一解码模型进行训练的过程，与对表情识别模型进行训练的过程是两个完全独立的过程，本申请实施例是以在对编码模型及第一解码模型进行训练后，对表情识别模型进行说明，而在另一实施例中，还能够先对编码模型及第一解码模型进行迭代训练，在对编码模型及第一解码模型训练完成后，再按照上述步骤308-步骤309，对表情识别模型进行迭代训练；或者，先按照上述步骤308-步骤309，对表情识别模型进行迭代训练，在对表情识别模型训练完成后，再对编码模型及第一解码模型进行迭代训练。本申请实施例提供的方案中，对于包含不同面部的第一面部图像和第二面部图像，通过同一个编码模型，分别对第一面部图像及第二面部图像进行编码，以获取两个面部图像的特征；第一解码模型将第一面部图像的特征解码为第三面部图像，第二解码模型将第二面部图像的特征解码为第四面部图像，进而基于第一面部图像及第三面部图像，对第一解码模型进行训练；基于第一面部图像、第三面部图像、第二面部图像及第四面部图像，对编码模型进行训练，这种训练方式简单，能够保证模型的训练效率，并且，使得编码模型能够学习将面部图像编码为适用于第一解码模型的特征的能力，能够保证编码模型输出的特征适用于第一解码模型，且第一解码模型能够学习将编码模型输出的特征解码为包含虚拟面部的面部图像的能力，则通过训练后的编码模型及第一解码模型能够将任一面部图像转换为虚拟面部图像，使得虚拟面部图像包含虚拟面部、且虚拟面部的表情与输入的面部图像中表情相同，保证了面部表情迁移的准确性。并且，本申请实施例通过表情识别模型来识别面部图像的表情参数，但在训练表情识别模型时，如果将真实面部图像作为表情识别模型的训练数据，但是无法获取到真实面部图像准确的表情参数，这样会导致训练的表情识别模型的准确性差，而包含虚拟面部的面部图像及对应的表情参数是较容易获取到，如果将包含虚拟面部的面部图像及对应的表情参数作为表情识别模型的训练数据，能够保证训练数据充足且准确，这样会能够保证训练的表情识别模型的准确性。并且，在渲染引擎中导入虚拟面部模型的情况下，仅需设置任意的样本表情参数，并将样本表情参数输入渲染引擎，即可由渲染引擎基于虚拟面部模型来生成包含虚拟面部的面部图像，这样能够获取到大量的样本表情参数及对应的第一面部图像，为训练表情识别模型提供足够的训练数据，且训练数据获取过程简单。而考虑到在多种场景下通常会利用真实面部图像的表情参数，因此，本申请实施通过训练编码模型及第一解码模型，以便通过训练后的编码模型及第一解码模型，将真实面部图像转换为虚拟面部图像，且虚拟面部图像中虚拟面部的表情与真实面部图像中面部的表情相同，这样，通过编码模型、第一解码模型及表情识别模型之间的配合，能够识别真实面部图像的表情参数，保证表情参数的准确性。需要说明的是，本申请实施例是考虑到无法获取到大量的真实面部图像及对应的表情参数的情况下，按照上述方式训练出编码模型、第一解码模型及表情识别模型，以便通过编码模型及第一解码模型，将真实面部图像转换为包含虚拟面部的虚拟面部图像，以便通过表情识别模型，识别出虚拟面部图像的表情参数。而在能够获取到大量的真实面部图像及对应的表情参数的情况下，则仅通过真实面部图像及对应的表情参数，训练表情识别模型即可，后续通过表情识别模型直接识别出真实面部图像的表情参数。需要说明的是，在上述图3所示的实施例的基础上，在对编码模型及第一解码模型进行迭代训练的过程中，还能够同步训练第二解码模型，训练第二解码模型的过程包括：在对编码模型及第一解码模型进行迭代训练的情况下，基于第二面部图像及第四面部图像，对第二解码模型进行训练。在本申请实施例中，第二面部图像与第四面部图像之间的差异，能够反映出第二解码模型的准确性，因此，基于第二面部图像及第四面部图像，对第二解码模型进行训练，以使通过训练后的第二解码模型再对第二特征进行解码得到的面部图像与第二面部图像之间的差异变小，进而提升第二解码模型的准确性。并且，由于第二面部图像与第四面部图像之间的差异，不仅能够反映出第二解码模型的准确性，也能够反映出编码模型的准确性，因此，在对编码模型及第一解码模型进行迭代训练的过程中，对第二解码模型进行迭代训练，以尽可能提升第二解码模型的准确性，以削弱由于第二解码模型不准确而对第二面部图像与第四人面部图像之间存在差异的影响，进而使得第二面部图像与第四面部图像之间的差异仅是由编码模型导致的，进而基于第二面部图像与第四面部图像之间的差异对编码模型进行训练，能够进一步提升编码模型的准确性。例如，在对编码模型、第一解码模型及第二解码模型进行迭代训练的过程中，在一次迭代中，按照上述步骤301-步骤307，对编码模型及第一解码模型进行训练，并基于第二面部图像及第四面部图像，对第二解码模型进行训练；而后执行下一次迭代。可选地，对第二解码模型进行训练的过程包括：基于第二面部图像及第四面部图像，确定第三损失值，第三损失值指示第二面部图像与第四面部图像之间的差异；基于第三损失值，对第二解码模型进行训练。在本申请实施例中，通过确定第三损失值，以便第二面部图像与第四面部图像之间的差异量化，保证第三损失值能够准确反映出第二面部图像与第四面部图像之间的差异，则通过第三损失值对第二解码模型进行训练，以使通过训练后的第二解码模型再对第二特征进行解码时，得到的面部图像与第二面部图像之间的差异变小，以提升第二解码模型的准确性。需要说明的是，上述图3所示的实施例在对编码模型、第一解码模型及第二解码模型进行迭代训练的过程中，每次迭代利用一个第一面部图像和一个第二面部图像，而在另一实施例中，还能够在每次迭代中利用多个第一面部图像和多个第二面部图像。以第二面部图像为真实面部图像、次数阈值为200为例，使用Adam优化器来对编码模型、第一解码模型及第二解码模型进行迭代训练。在迭代训练的过程中，学习率为1e-4；Batchsize设置为128，即在每次迭代中获取128个面部图像；128个面部图像包括64个第一面部图像及64个第二面部图像，64个第一面部图像均包含相同的虚拟面部但不同的第一面部图像中虚拟面部的表情不同；64个第二面部图像均包含相同的面部但不同的第二面部图像中面部的表情不同，或者，64个第二面部图像均包含的面部不同。将128个面部图像输入编码模型，通过编码模型分别对每个面部图像进行编码，得到每个面部图像的特征，即得到64个第一特征及64个第二特征，64个第一特征与64个第一面部图像一一对应，64个第二特征与64个第二面部图像一一对应。通过第一解码模型，对每个第一特征进行解码，得到每个第一面部图像对应的第三面部图像；通过第二解码模型，对每个第二特征进行解码，得到每个第二面部图像对应的第四面部图像。基于64个第一面部图像、64个第二面部图像、64个第三面部图像及64个第四面部图像，采取以下损失函数，确定损失值；使用Adam优化器，基于损失值，编码模型进行训练。其中，用于表示损失值，/＞用于表示第一面部图像或第二面部图像，用于表示第一解码器输出的第三面部图像或第二解码器输出的第四面部图像，/＞用于表示第三面部图像对应的第一面部图像或者第四面部图像对应的第二面部图像；/＞用于表示范数。/＞对于64个第一面部图像及64个第三面部图像，基于每个第一面部图像与对应的第三面部图像之间的差异，确定损失值，该损失值指示每个第一面部图像与对应的第三面部图像之间的差异；使用Adam优化器，基于损失值，对第一解码模型进行训练。对于64个第二面部图像及64个第四面部图像，基于每个第二面部图像与对应的第四面部图像之间的差异，确定损失值，该损失值指示每个第二面部图像与对应的第四面部图像之间的差异；使用Adam优化器，基于损失值，第二解码模型进行训练。在对编码模型、第一解码模型及第二解码模型进行迭代训练的过程中，在迭代次数达到200的情况下，表示已对编码模型、第一解码模型及第二解码模型训练完成，能够通过编码模型对真实面部图像进行编码，得到真实面部图像的特征，通过第一解码模型对真实面部图像的特征进行解码，得到虚拟面部图像，虚拟面部图像中的虚拟面部与训练过程中第一面部图像中的虚拟面部相同，且虚拟面部图像中虚拟面部的表情与真实面部图像中面部的表情相同。可选地，第一面部图像相当于渲染域的面部图像，第二面部图像相当于真实域的面部图像，第一解码模型相当于渲染域解码器，第二解码模型相当于真实域解码器；将训练完成的编码模型及第一解码模型构成图片转换器，则通过图片转换器能够将真实面部图像转换为虚拟面部图像。对于获取多个第一面部图像及多个第二面部图像的方式，通过终端对用户的面部进行拍摄，得到视频，将视频中包含面部的多个视频帧作为多个第一面部图像。通过渲染引擎，基于设置的多个样本表情参数，分别对虚拟面部模型的面部进行调整，并对调整后的虚拟面部模型进行拍摄，得到多个第二面部图像。需要说明的是，上述图3所示的实施例在对表情识别模型进行迭代训练的过程中，每次迭代利用一个第一面部图像，而在另一实施例中，还能够在每次迭代中利用多个第一面部图像。本申请实施例以表情识别模型包括Backbone层、Pooling层、FC层和一个Sigmoid层为例进行说明，其中，Backbone为Resnet50；如图5所示，训练表情识别模型的过程，包括：按照上述步骤301，通过渲染引擎获取多个样本表情参数及每个样本表情参数对应的第一面部图像。例如，获取的多个第一面部图像如图6所示。在对表情识别模型进行迭代训练的过程中，Batchsize设置为B，即在每次迭代中获取B个样本表情参数及每个样本表情参数对应的第一面部图像。将获取到的B个第一面部图像作为表情识别模型的输入，通过表情识别模型，分别对每个第一面部图像进行表情识别，得到每个第一面部图像的预测表情参数。以第一面部图像的尺度为256×256为例，通过表情识别模型中的Backbone对B个第一面部图像进行特征提取，得到B个第一面部图像的特征，例如，Backbone输出B×2048×8×8的Feature Map表示B个第一面部图像的特征。Backbone输出的B×2048×8×8的Feature Map输入Pooling层，Pooling层输出B×2048的特征，再将Pooling层输出B×2048的特征输入FC层，之后将FC层输出的特征输入Sigmoid层，由Sigmoid层输出B×130的表情参数。也即是得到B个第一面部图像的表情参数，每个第一面部图像的表情参数的维度为130，不同维度的表情参数指示不同部位的表情，或者指示同一部位不同的动作。其中，FC层的参数维度是2048×130，Sigmoid层用于采取以下函数，将FC输出的B×130的表情参数的数值归一化为0-1之间。其中，用于表示输入到Sigmoid层的任一表情参数，/＞用于表示Sigmoid函数，/＞用于表示自然常数。在得到由Sigmoid层输出的B×130的表情参数的情况下，采取以下损失函数，确定损失值，基于损失值对表情识别模型进行训练。其中，用于表示损失值；/＞用于表示在每次迭代中获取的第一面部图像的数量，也即是Batchsize；/＞用于表示任一第一面部图像，/＞用于表示通过表情识别模型预测到第一面部图像/＞对应的预测表情参数，/＞用于表示第一面部图像/＞对应的样本表情参数。以对表情识别模型进行迭代训练的次数阈值为40为例，在按照上述过程对表情识别模型迭代训练40次，表示对表情识别模型训练完成。本申请实施例采取了一种半监督的方式来训练编码模型、第一解码模型及第二解码模型，在无法获取到真实面部图像对应的表情参数的情况下，按照上述方式，利用真实面部图像和虚拟面部图像训练编码模型及第一解码模型，以便通过编码模型及第一解码模型，将真实面部图像转换为虚拟面部图像，并通过虚拟面部图像及对应的样本表情参数，训练表情识别模型，以避免由于训练数据不足而导致表情识别模型不准确的情况，保证了表情识别模型的准确性。通过编码模型及第一解码模型，先将真实面部转换为虚拟面部图像，再通过表情识别模型识别虚拟面部图像的表情参数，实现了一种新的表情识别方案，使得模型训练过程简单和表情识别方案简单，提升了表情识别方案的适用范围。需要说明的是，在上述的模型训练方法的基础上，本申请实施例能够利用训练完成的编码模型及第一解码模型来实现面部表情迁移，具体过程详见下述实施例。图7是本申请实施例提供的一种面部表情迁移方法的流程图，该方法由计算及设备执行，如图7所示，该方法包括以下步骤。701、计算机设备获取任一面部图像。在本申请实施例中，该面部图像能够是任意的面部图像，例如，该面部图像为真实面部图像或者为卡通面部图像等。在一种可能实现方式中，该计算机设备提供为服务器，则获取面部图像的过程包括：终端通过摄像头对面部进行拍摄，得到面部图像，向服务器发送该面部图像，服务器接收到该面部图像。702、计算机设备通过编码模型，对面部图像进行编码，得到面部图像的特征。该步骤702与上述步骤303同理，在此不再赘述。703、计算机设备通过第一解码模型，对面部图像的特征进行解码，得到虚拟面部图像，虚拟面部图像包含虚拟面部，且面部图像中的面部与虚拟面部图像中虚拟面部的表情相同。在本申请实施例中，虚拟面部图像中的虚拟面部即为训练编码模型和第一理解模型时所用到的第一面部图像中的虚拟面部，但虚拟面部图像中虚拟面部的表情与第一面部图像中虚拟面部的表情可能不同。由于第一解码模型能够将编码模型输出的特征解码为包含虚拟面部的面部图像，且编码模型输出的面部图像的特征能够表征该面部图像，能够表征出面部图像中面部的表情，因此，通过第一解码模型对面部图像的特征进行解码，得到的虚拟面部图像中虚拟面部的表情与面部图像中面部的表情相同，实现了将面部的表情迁移到虚拟面部上。本申请实施例提供的方案中，由于第一解码模型能够对编码模型输出的特征解码为包含虚拟面部的面部图像，通过编码模型，对任一面部图像进行编码，再通过第一解码模型对编码得到的特征进行解码，得到包含虚拟面部的虚拟面部图像，且虚拟面部图像中虚拟面部的表情与面部图像中面部的表情相同，以实现表情的迁移，保证面部表情迁移的准确性。例如，以面部图像为真实面部图像为例，通过编码模型对真实面部图像进行编码，得到真实面部图像的特征，再通过第一解码模型对真实面部图像的特征进行解码，第一解码模型能够识别真实面部图像的特征，解码出包含虚拟面部的虚拟面部图像，且虚拟面部图像中虚拟面部保留了与真实面部图像中面部相同的表情，也相当于转换了真实面部图像的图片类型，将真实面部图像转换为虚拟面部图像。在上述图7所示的实施例的基础上，本申请实施例还能够通过表情识别模型对面部表情迁移得到的面部图像进行表情识别，以便利用识别得到的表情参数来调整虚拟场景中虚拟对象的面部表情，具体过程详见下述实施例。图8是本申请实施例提供的另一种面部表情迁移方法的流程图，应用于第二设备中，如图8所示，该方法包括以下步骤。801、计算机设备获取任一面部图像。802、计算机设备通过编码模型，对面部图像进行编码，得到面部图像的特征。803、计算机设备通过第一解码模型，对面部图像的特征进行解码，得到虚拟面部图像，虚拟面部图像包含虚拟面部，且面部图像中的面部与虚拟面部图像中虚拟面部的表情相同。该步骤801-步骤803与上述步骤701-步骤703同理，在此不再赘述。804、计算机设备通过表情识别模型，对虚拟面部图像进行表情识别，得到表情参数，表情参数指示虚拟面部图像中虚拟面部的表情。在本申请实施例中，通过表情识别模型，对虚拟面部图像进行表情识别，以保证得到的表情参数与虚拟面部图像中虚拟面部的表情匹配，保证表情参数的准确性。该步骤804与上述步骤308同理，在此不再赘述。805、计算机设备基于表情参数，对虚拟场景中虚拟对象的面部进行调整，以使调整后的虚拟对象的面部表情与面部图像中面部的表情相同。在本申请实施例中，在得到面部图像的表情参数的情况下，基于表情参数对虚拟场景中虚拟对象的面部进行调整，以使虚拟对象的面部表情与面部图像中面部的表情相同，实现了一种新的表情驱动方式，通过面部图像来驱动虚拟场景中虚拟对象做出与面部图像中面部相同的表情，以使虚拟对象的面部表情与面部图像中面部的表情同步，保证了对虚拟对象的面部表情进行控制的准确性，实现了高精度的表情驱动效果。其中，虚拟对象能够是任意的对象，例如，虚拟对象为卡通对象或游戏中的虚拟角色等。在一种可能实现方式中，虚拟对象对应有一个表情控制器，该表情控制器用于控制虚拟对象的面部表情，则该步骤805包括：通过表情控制器，基于表情参数，对虚拟场景中虚拟对象的面部进行调整，以使调整后的虚拟对象的面部表情与面部图像中面部的表情相同。在本申请实施例中，表情控制器能够控制虚拟对象的面部表情，则通过表情控制器，基于表情参数来调整虚拟对象的面部表情，以保证表情调整的准确性。可选地，虚拟对象对应有多个表情控制器，表情参数包括多个，表情控制器与表情参数一一对应，每个表情控制器用于控制虚拟对象的一个细微表情。例如，表情参数为130维度的表情参数，即表情参数包括130个，则虚拟对象对应有130个表情控制器。再例如，表情参数包括3个部位的表情参数，每个部位的表情参数包括5个，则虚拟对象对应有15个表情控制器。在本申请实施例中，对于任一表情参数，将该表情参数赋值为对应的表情控制器，则表情控制器按照该表情参数控制虚拟对象的面部表情，以使虚拟对象的面部呈现出相应的表情。例如，任一表情控制器用于控制虚拟对象的眼睛闭合，该表情控制器对应的表情参数为1时，表示眼睛闭合，则控制虚拟对象的眼睛闭合；该表情控制器对应的表情参数为0时，表示眼睛睁开，则控制虚拟对象的眼睛睁开；该表情控制器对应的表情参数为005时，表示眼睛半闭合，则控制虚拟对象的眼睛半闭合。在一种可能实现方式中，表情参数包括多个部位的表情参数，每个部位的表情参数包括多个，同一部位的不同表情参数指示部位的不同动作；则该步骤805包括：基于多个部位的表情参数，将同一部位的多个表情参数进行融合，得到每个部位的融合表情参数；基于每个部位的融合表情参数，对虚拟对象中每个部位进行调整。在本申请实施例中，同一部位具有多个表情参数，同一部位的不同表情参数指示该部位的不同动作，则通过将同一部位的多个表情参数进行融合，以使部位的融合表情参数能够体现出该部位所执行的动作，进而基于融合表情参数对虚拟对象中该部位进行调整，以使该部位呈现出融合表情参数所指示的动作，进而使得虚拟对象的面部呈现出表情参数所指示的表情，保证了表情控制的准确性。在一种可能实现方式中，面部图像为视频中的任一视频帧；对虚拟场景中虚拟对象的面部进行调整的过程，包括：在得到视频中多个视频帧的表情参数的情况下，基于多个视频帧的表情参数，按照多个视频帧的顺序，依次对虚拟对象的面部进行调整，以使虚拟对象的面部表情随着视频中面部的表情变化而变化。在本申请实施例中，视频包括多个视频帧，该多个视频帧包含同一面部，该视频能够反映出该面部在一段时间内的表情变化，按照上述步骤801-步骤804，能够获取到每个视频帧的表情参数，以指示视频帧中面部的表情，基于多个视频帧的表情参数，对虚拟对象的面部进行调整，以呈现出虚拟对象的面部表情随着视频中面部的表情变化而变化，进而能够体现出虚拟对象的面部表情变化的动画，以保证虚拟对象与视频中人的表情同步，保证表情迁移效果。其中，该视频是任意的视频。例如，该视频是用户通过终端对任一面部进行拍摄而得到的视频，在拍摄过程中，被拍摄面部做出各种表情。例如，视频中的视频帧为真实面部图像，用户通过终端的摄像头拍摄演员的面部，得到视频，对视频中的视频帧进行预处理，调整视频帧的尺度，例如，将视频中的视频帧的尺度调整为256×256。编码模型及第一解码模型能够构成图片转换器，通过图片转换器，能够将调整后的视频帧转换为包含虚拟面部的面部图像，即视频中的真实面部图像与虚拟面部图像一一对应，且得到的多个虚拟面部图像也能够构成一个视频；通过表情识别模型，对每个虚拟面部图像进行表情识别，得到每个虚拟面部图像的表情参数，也即是，得到每个虚拟面部图像对应的真实面部图像的表情参数；基于多个真实面部图像的表情参数，对虚拟场景中虚拟对象的面部进行调整，以使虚拟对象能够随着演员做出相同的表情。可选地，视频是终端实时获取到的视频，以计算机设备提供为服务器为例，则对虚拟对象的面部进行调整的过程包括：终端实时获取视频，向服务器实时发送视频，服务器接收到视频，按照上述步骤801-步骤805，基于视频中的视频帧，对虚拟场景中虚拟对象的面部表情进行调整，以使终端显示虚拟对象的面部表情随着视频中面部的表情变化的动画。例如，终端在显示界面中显示虚拟场景中的虚拟对象，并能够通过摄像头实时拍摄视频并向服务器发送，在服务器获取到每个视频帧的表情参数的情况下，服务器能够调整虚拟对象的面部，并由终端在显示界面中显示出虚拟对象的面部表情变化的画面。或者，在服务器获取到每个视频帧的表情参数的情况下，服务器向终端发送每个视频帧的表情参数，由终端基于表情参数对虚拟场景中虚拟对象的面部进行调整，在显示界面中显示出虚拟对象的面部表情变化的画面。本申请实施例提供的方案，能够接入视觉动作捕捉应用或插件，能捕捉面部的面部表情，将捕捉到的面部表情迁移到虚拟对象的面部，使得虚拟对象完美复刻面部的面部动作。本申请实施例提供的方案中，由于第一解码模型能够对编码模型输出的特征解码为包含虚拟面部的面部图像，通过编码模型，对任一面部图像进行编码，通过第一解码模型对编码得到的特征进行解码，得到包含虚拟面部的虚拟面部图像，且虚拟面部图像中虚拟面部的表情与面部图像中面部的表情相同，以实现表情的迁移，保证表情迁移的准确性，实现了高精度的表情驱动效果。如图9所示，本申请实施例提供的编码模型及第一解码模型能够构成图片转换器，图片转换器用于将真实面部图像转换为包含虚拟面部的虚拟面部图像，表情识别模型能够从虚拟面部图像中识别出表情参数。需要说明的是，本申请实施例提供的面部表情迁移方法，对设备的要求低，能够通过任意的摄像头来拍摄面部图像即可获取到高精度的表情参数，以实现高精度的表情捕捉，以保证后续通过表情参数来驱动虚拟面部的效果。与相关技术相比，基于本申请实施例提供的面部表情迁移方法，对虚拟对象的面部表情进行驱动时，使得虚拟形象完美复刻演员的面部动作，使得虚拟对象的面部表情更加真实生动，能够具有更好的表情驱动效果，也简化了模型训练过程和表情迁移过程。保证了模型训练效率和表情迁移效率。本申请实施例提供的方案能够应用于多种场景下，例如，应用在电影场景或其他虚拟对象控制场景下。例如，以应用在电影场景下为例，按照本申请实施例提供的方法，通过拍摄演员获取视频，通过编码模型、第一解码模型及表情识别模型，能够识别出视频中包含演员面部的视频帧的表情参数，基于表情参数来控制虚拟场景中虚拟对象的面部表情，以使虚拟对象的面部表情与演员的表情同步且一致，以便后续能够将包含虚拟对象的面部表情的动画加入在电影中，这样，无需再通过专业的设备来识别演员的表情而驱动虚拟对象的面部表情。再例如，终端通过用户标识登录应用，该应用为虚拟对象控制应用，用户通过终端中的应用，能够选择任意的虚拟对象；终端在应用界面中显示选择的虚拟对象；用户通过终端拍摄用户的面部，终端实时获取到包含用户面部的视频并向为应用提供服务的服务器发送，服务器实时接收视频，按照本申请实施例提供的方案，确定每个视频帧的表情参数，向终端发送表情参数；终端通过虚拟对象对应的表情控制器，基于表情参数控制虚拟对象的面部表情，以使终端显示的虚拟对象的面部表情与终端所拍摄的用户面部的表情同步，如图10和图11所示，使得用户能够终端通过实时拍摄用户自己而控制虚拟场景中虚拟对象的面部表情。并且，用户通过终端能够基于显示的虚拟对象的表情动画，生成视频，并能够将视频分享给其他用户。再例如，以应用在游戏场景为例，终端通过用户标识登录游戏应用，用户通过终端中的游戏应用，显示虚拟场景，虚拟场景中显示有终端所控制的虚拟对象；用户通过终端拍摄用户的面部，终端实时获取到包含用户面部的视频并向为游戏应用提供服务的服务器发送，服务器实时接收视频，按照本申请实施例提供的方案，确定每个视频帧的表情参数，向终端发送表情参数；终端通过游戏应用中虚拟对象对应的表情控制器，基于表情参数控制虚拟对象的面部表情，以使虚拟场景中虚拟对象的面部表情与终端所拍摄的用户面部的表情同步，使得用户能够终端通过实时拍摄自己而控制虚拟场景中虚拟对象的面部表情。图12是本申请实施例提供的一种模型训练装置的结构示意图，如图12所示，该装置包括：获取模块1201，用于获取第一面部图像及第二面部图像，第一面部图像包含虚拟面部，第二面部图像中的面部与虚拟面部不同；编码模块1202，用于通过编码模型，分别对第一面部图像及第二面部图像进行编码，得到第一特征及第二特征，第一特征指示第一面部图像，第二特征指示第二面部图像；解码模块1203，用于通过第一解码模型，对第一特征进行解码，得到第三面部图像；解码模块1203，还用于通过第二解码模型，对第二特征进行解码，得到第四面部图像；训练模块1204，用于基于第一面部图像及第三面部图像，对第一解码模型进行训练；基于第一面部图像、第三面部图像、第二面部图像及第四面部图像，对编码模型进行训练；其中，第一解码模型及编码模型用于基于任一面部图像生成虚拟面部图像，虚拟面部图像中虚拟面部与面部图像中面部的表情相同。在一种可能实现方式中，获取模块1201，用于基于样本表情参数，生成第一面部图像，样本表情参数指示第一面部图像中虚拟面部的表情；如图13所示，装置还包括：识别模块1205，用于通过表情识别模型，对第一面部图像进行表情识别，得到预测表情参数，预测表情参数指示第一面部图像中虚拟面部的表情；训练模块1204，还用于基于样本表情参数及预测表情参数，对表情识别模型进行训练。在另一种可能实现方式中，样本表情参数包括多个部位的样本表情参数，预测表情参数包括多个部位的预测表情参数；训练模块1204，用于基于多个部位的样本表情参数及多个部位的预测表情参数，确定第一损失值，第一损失值指示同一部位的样本表情参数与预测表情参数之间的差异；基于第一损失值，对表情识别模型进行训练。在另一种可能实现方式中，训练模块1204，用于基于第一面部图像及第三面部图像，确定第二损失值，第二损失值指示第一面部图像与第三面部图像之间的差异；基于第二面部图像及第四面部图像，确定第三损失值，第三损失值指示第二面部图像与第四面部图像之间的差异；基于第二损失值及第三损失值，对编码模型进行训练。在另一种可能实现方式中，训练模块1204，还用于在对编码模型及第一解码模型进行迭代训练的情况下，基于第二面部图像及第四面部图像，对第二解码模型进行训练。需要说明的是：上述实施例提供的模型训练装置，仅以上述各功能模块的划分进行举例说明，实际应用中，可以根据需要而将上述功能分配由不同的功能模块完成，即将计算机设备的内部结构划分成不同的功能模块，以完成以上描述的全部或者部分功能。另外，上述实施例提供的模型训练装置与模型训练方法实施例属于同一构思，其具体实现过程详见方法实施例，这里不再赘述。图14是本申请实施例提供的一种面部表情迁移装置的结构示意图，如图14所示，该装置包括：获取模块1401，用于获取任一面部图像；编码模块1402，用于通过编码模型，对面部图像进行编码，得到面部图像的特征；解码模块1403，用于通过第一解码模型，对面部图像的特征进行解码，得到虚拟面部图像，虚拟面部图像包含虚拟面部，且面部图像中的面部与虚拟面部图像中虚拟面部的表情相同；其中，编码模型及第一解码模型是基于上述实施例的模型训练方法训练得到。在一种可能实现方式中，如图15所示，装置还包括：识别模块1404，用于通过表情识别模型，对虚拟面部图像进行表情识别，得到表情参数，表情参数指示虚拟面部图像中虚拟面部的表情。在另一种可能实现方式中，如图15所示，装置还包括：调整模块1405，用于基于表情参数，对虚拟场景中虚拟对象的面部进行调整，以使调整后的虚拟对象的面部表情与面部图像中面部的表情相同。在另一种可能实现方式中，表情参数包括多个部位的表情参数，每个部位的表情参数包括多个，同一部位的不同表情参数指示部位的不同动作；调整模块1405，用于基于多个部位的表情参数，将同一部位的多个表情参数进行融合，得到每个部位的融合表情参数；基于每个部位的融合表情参数，对虚拟对象中每个部位进行调整。在另一种可能实现方式中，面部图像为视频中的任一视频帧；调整模块1405，用于在得到视频中多个视频帧的表情参数的情况下，基于多个视频帧的表情参数，按照多个视频帧的顺序，依次对虚拟对象的面部进行调整，以使虚拟对象的面部表情随着视频中面部的表情变化而变化。需要说明的是：上述实施例提供的面部表情迁移装置，仅以上述各功能模块的划分进行举例说明，实际应用中，可以根据需要而将上述功能分配由不同的功能模块完成，即将计算机设备的内部结构划分成不同的功能模块，以完成以上描述的全部或者部分功能。另外，上述实施例提供的面部表情迁移装置与面部表情迁移方法实施例属于同一构思，其具体实现过程详见方法实施例，这里不再赘述。本申请实施例还提供了一种计算机设备，该计算机设备包括处理器和存储器，存储器中存储有至少一条计算机程序，该至少一条计算机程序由处理器加载并执行以实现上述实施例的模型训练方法或面部表情迁移方法所执行的操作。可选地，计算机设备提供为终端。图16示出了本申请一个示例性实施例提供的终端1600的结构框图。终端1600包括有：处理器1601和存储器1602。处理器1601可以包括一个或多个处理核心，比如4核心处理器、8核心处理器等。处理器1601可以采用DSP、FPGA、PLA中的至少一种硬件形式来实现。处理器1601也可以包括主处理器和协处理器，主处理器是用于对在唤醒状态下的数据进行处理的处理器，也称CPU；协处理器是用于对在待机状态下的数据进行处理的低功耗处理器。在一些实施例中，处理器1601可以集成有GPU，GPU用于负责显示屏所需要显示的内容的渲染和绘制。一些实施例中，处理器1601还可以包括AI处理器，该AI处理器用于处理有关机器学习的计算操作。存储器1602可以包括一个或多个计算机可读存储介质，该计算机可读存储介质可以是非暂态的。存储器1602还可包括高速随机存取存储器，以及非易失性存储器，比如一个或多个磁盘存储设备、闪存存储设备。在一些实施例中，存储器1602中的非暂态的计算机可读存储介质用于存储至少一个计算机程序，该至少一个计算机程序用于被处理器1601所执行以实现本申请中方法实施例提供的模型训练方法或面部表情迁移方法。在一些实施例中，终端1600还可选包括有：外围设备接口1603和至少一个外围设备。处理器1601、存储器1602和外围设备接口1603之间可以通过总线或信号线相连。各个外围设备可以通过总线、信号线或电路板与外围设备接口1603相连。具体地，外围设备包括：射频电路1604、显示屏1605、摄像头组件1606、音频电路1607和电源1608中的至少一种。外围设备接口1603可被用于将I/O相关的至少一个外围设备连接到处理器1601和存储器1602。在一些实施例中，处理器1601、存储器1602和外围设备接口1603被集成在同一芯片或电路板上；在一些其他实施例中，处理器1601、存储器1602和外围设备接口1603中的任意一个或两个可以在单独的芯片或电路板上实现，本实施例对此不加以限定。射频电路1604用于接收和发射RF信号，也称电磁信号。射频电路1604通过电磁信号与通信网络以及其他通信设备进行通信。射频电路1604将电信号转换为电磁信号进行发送，或者，将接收到的电磁信号转换为电信号。可选地，射频电路1604包括：天线系统、RF收发器、一个或多个放大器、调谐器、振荡器、数字信号处理器、编解码芯片组、用户身份模块卡等等。射频电路1604可以通过至少一种无线通信协议来与其它终端进行通信。该无线通信协议包括但不限于：万维网、城域网、内联网、各代移动通信网络、无线局域网和/或WiFi网络。在一些实施例中，射频电路1604还可以包括NFC有关的电路，本申请对此不加以限定。显示屏1605用于显示UI。该UI可以包括图形、文本、图标、视频及其它们的任意组合。当显示屏1605是触摸显示屏时，显示屏1605还具有采集在显示屏1605的表面或表面上方的触摸信号的能力。该触摸信号可以作为控制信号输入至处理器1601进行处理。此时，显示屏1605还可以用于提供虚拟按钮和/或虚拟键盘，也称软按钮和/或软键盘。在一些实施例中，显示屏1605可以为一个，设置在终端1600的前面板；在另一些实施例中，显示屏1605可以为至少两个，分别设置在终端1600的不同表面或呈折叠设计；在另一些实施例中，显示屏1605可以是柔性显示屏，设置在终端1600的弯曲表面上或折叠面上。甚至，显示屏1605还可以设置成非矩形的不规则图形，也即异形屏。显示屏1605可以采用LCD、OLED等材质制备。摄像头组件1606用于采集图像或视频。可选地，摄像头组件1606包括前置摄像头和后置摄像头。前置摄像头设置在终端的前面板，后置摄像头设置在终端的背面。在一些实施例中，后置摄像头为至少两个，分别为主摄像头、景深摄像头、广角摄像头、长焦摄像头中的任意一种，以实现主摄像头和景深摄像头融合实现背景虚化功能、主摄像头和广角摄像头融合实现全景拍摄以及VR拍摄功能或者其它融合拍摄功能。在一些实施例中，摄像头组件1606还可以包括闪光灯。闪光灯可以是单色温闪光灯，也可以是双色温闪光灯。双色温闪光灯是指暖光闪光灯和冷光闪光灯的组合，可以用于不同色温下的光线补偿。音频电路1607可以包括麦克风和扬声器。麦克风用于采集用户及环境的声波，并将声波转换为电信号输入至处理器1601进行处理，或者输入至射频电路1604以实现语音通信。出于立体声采集或降噪的目的，麦克风可以为多个，分别设置在终端1600的不同部位。麦克风还可以是阵列麦克风或全向采集型麦克风。扬声器则用于将来自处理器1601或射频电路1604的电信号转换为声波。扬声器可以是传统的薄膜扬声器，也可以是压电陶瓷扬声器。当扬声器是压电陶瓷扬声器时，不仅可以将电信号转换为人类可听见的声波，也可以将电信号转换为人类听不见的声波以进行测距等用途。在一些实施例中，音频电路1607还可以包括耳机插孔。电源1608用于为终端1600中的各个组件进行供电。电源1608可以是交流电、直流电、一次性电池或可充电电池。当电源1608包括可充电电池时，该可充电电池可以是有线充电电池或无线充电电池。有线充电电池是通过有线线路充电的电池，无线充电电池是通过无线线圈充电的电池。该可充电电池还可以用于支持快充技术。本领域技术人员可以理解，图16中示出的结构并不构成对终端1600的限定，可以包括比图示更多或更少的组件，或者组合某些组件，或者采用不同的组件布置。可选地，计算机设备提供为服务器。图17是本申请实施例提供的一种服务器的结构示意图，该服务器1700可因配置或性能不同而产生比较大的差异，可以包括一个或一个以上处理器1701和一个或一个以上的存储器1702，其中，存储器1702中存储有至少一条计算机程序，至少一条计算机程序由处理器1701加载并执行以实现上述各个方法实施例提供的方法。当然，该服务器还可以具有有线或无线网络接口、键盘及输入输出接口等部件，以便进行输入输出，该服务器还可以包括其他用于实现设备功能的部件，在此不做赘述。本申请实施例还提供了一种计算机可读存储介质，该计算机可读存储介质中存储有至少一条计算机程序，该至少一条计算机程序由处理器加载并执行以实现上述实施例的模型训练方法或面部表情迁移方法所执行的操作。本申请实施例还提供了一种计算机程序产品，包括计算机程序，所述计算机程序被处理器执行时实现上述实施例的模型训练方法或面部表情迁移方法所执行的操作。本领域普通技术人员可以理解实现上述实施例的全部或部分步骤可以通过硬件来完成，也可以通过程序来指令相关的硬件完成，所述程序可以存储于一种计算机可读存储介质中，上述提到的存储介质可以是只读存储器，磁盘或光盘等。以上所述仅为本申请实施例的可选实施例，并不用以限制本申请实施例，凡在本申请实施例的精神和原则之内，所作的任何修改、等同替换、改进等，均应包含在本申请的保护范围之内。
