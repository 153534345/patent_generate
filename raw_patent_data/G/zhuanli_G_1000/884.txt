标题title
基于交叉注意力的视听语音增强方法及其模型搭建方法
摘要abst
本发明提供了一种基于交叉注意力的视听语音增强方法及其模型搭建方法，属于语音识别模型技术领域。首先，获取若干说话人的视频和相应音频的原始数据，对获取的数据集进行预处理，获取语音的梅尔特征、面部帧构建数据集；基于1D卷积构建音频预处理模块；基于ResNet‑18+CBAM和Transformer编码器网络构建面部特征处理；基于交叉注意力和Transformer解码器融合视听特征，搭建一个新的视听语音增强模型，模型搭建完成后用于混合音频增强。本发明提出的视听语音增强模型，与使用单一音频流的方法或是其他融合视听特征融合方法相比，取得了明显性能提升。
权利要求书clms
1.一种基于交叉注意力的视听语音增强模型搭建方法，其特征在于，包括以下过程：步骤1，获取若干说话人的视频和相应音频的原始数据；步骤2，对步骤1中获取的原始数据进行预处理；将视频分别处理为一帧一帧的图像，同时从原始数据中随机选取一个说话人的数据和一个噪声数据，将其中的音频按一定比例混合后对混合语音做梅尔变换得到语音的梅尔特征图，结合说话人数据对应的面部帧构建数据集，并划分为训练集、验证集和测试集；步骤3，构建基于交叉注意力的视听语音增强模型；基于Resnet18网络结构和CBAM注意力机制，构建视觉特征处理模块；基于1D卷积和高斯误差线性单元Gelu，构建音频特征处理模块；基于Transformer编码器，得到视觉特征的K,V矩阵；基于Transformer解码器，将原Transformer解码器中的第二个自注意力机制层改为交叉注意力机制层，将音频特征作为Q矩阵，解码器的输出作为K,V矩阵；其中，将混合语音的梅尔特征图和视频面部帧作为输入，模型输出为预测音频梅尔特征图，最终将梅尔特征图进行逆梅尔谱变换得到最终预测音频；步骤4，使用预处理后的数据集对构建的视听语音增强模型进行训练与测试评估，获取最终视听语音增强模型。2.如权利要求1所述的一种基于交叉注意力的视听语音增强模型搭建方法，其特征在于，所述步骤2中预处理的具体过程为：首先将每一个视频以每秒25帧进行裁剪，得到按照时间维度排列的图像，对于每一张图像使用现有的基于OpenCV库的MTCNN人脸检测器提取每张图片中的目标说话人的人脸缩略图，使用Facenet预训练模型来提取每个人脸缩略图的人脸特征，Facenet预训练模型经过训练大量人脸图片得到；然后从原始数据中随机选取一个说话人的数据和一个噪声数据，将其中的音频混合后对混合语音做短时傅里叶变换得到语音的语谱图，结合说话人数据对应的面部特征构建数据集。3.如权利要求1所述的一种基于交叉注意力的视听语音增强模型搭建方法，其特征在于：所述视觉特征处理模块由修改后的Resnet18残差网络和卷积块注意力模块CBAM组成；所述修改后的Resnet18残差网络，包括1个conv5卷积层，4个conv_res层；其中conv5层由大小为5×5步长为1的卷积核、批归一化层BN以及ReLU激活函数组成，每个conv_res层由两个相同的卷积块组成，每个卷积块包含一个大小为1×7步长为1的卷积核、BN层以及ReLU激活函数；卷积块的输入输出公式可由下式表示：y = ReLU)))))其中，x代表卷积块的输入，y代表卷积块的输出；conv_res是1×7卷积运算；修改后的Resnet18残差网络的输出作为CBAM模块的输入；所述CBAM模块由通道注意力模块和空间注意力模块组成，CBAM模块位于修改后的Resnet18残差网络之后，用于高效提取和音频相关性较大的人脸关键区域，忽略人脸之外的次要区域；所述CBAM模块的输出作为网络提取的初步视觉特征，其将用作模型中Transformer编码器输入。4.如权利要求1所述的一种基于交叉注意力的视听语音增强模型搭建方法，其特征在于：所述音频特征处理模块由2个1D卷积层和高斯误差线性单元Gelu组成；每个1D卷积层的输出维度与输入维度相同，高斯误差线性单元Gelu公式如下：代表/＞激活函数的输入，/＞即为/＞激活函数的输出；所述音频特征处理模块输出作为网络提取的初步音频特征，其将用作模型中Transformer解码器输入。5.如权利要求1所述的一种基于交叉注意力的视听语音增强模型搭建方法，其特征在于：所述Transformer编码器，包括6个Transformer编码器模块，每个Transformer编码器模块包括一个自注意力机制层和一个MLP模块；所述Transformer编码器的输入为视觉特征处理模块的输出与正弦位置编码的相加，正弦位置编码公式如下：表示位置编码矩阵中第/＞个位置，第/＞个维度的值，/＞表示模型嵌入向量的维度；所述Transformer编码器模块中，自注意力机制中的Q,K,V矩阵由编码器输入视频特征进行线性变换得到，自注意力机制输入公式如下：其中，中为编码器输入视频特征经过线性变换后的列维度，/＞为编码器输入视频特征进行线性变换得到的Q,K,V矩阵；所述MLP模块包括两个全连接层、高斯误差线性单元Gelu和层归一化LayerNorm，其中全连接层的输出维度与ransformer编码器模块输入维度相等；所述Transformer编码器模块的自注意力机制层和MLP模块均用残差结构进行连接；公式如下：其中为MLP模块输入，/＞为MLP模块输出，/＞为进行残差连接后的MLP模块输出，/＞为自注意力机制层输入，/＞为自注意力机制层输出，/＞为进行残差连接后的自注意力机制层输出；所述6个Transformer编码器模块，每个模块之前采用残差连接；公式如下：其中，为Transformer编码器模块输入，/＞为Transformer编码器模块输出，/＞为进行残差连接后Transformer编码器模块输出。6.如权利要求1所述的一种基于交叉注意力的视听语音增强模型搭建方法，其特征在于：所述Transformer解码器，包括6个Transformer解码器模块，每个Transformer解码器模块包括一个自注意力机制层、一个交叉注意力机制层和一个MLP模块；所述Transformer解码器的输入为音频特征处理模块的输出与可学习位置编码的相加；所述Transformer解码器模块中，自注意力机制中的Q,K,V矩阵由解码器输入视频特征进行线性变换得到，自注意力机制输入公式如下：其中，中为解码器输入音频特征经过线性变换后的列维度，/＞为解码器输入音频特征进行线性变换得到的Q,K,V矩阵；/＞代表/＞的转置矩阵；所述Transformer解码器模块中，交叉注意力机制中的Q矩阵由进行线性变换得到，K,V矩阵由Transformer编码器的输出进行线性变换得到，交叉注意力机制输入公式如下：其中，代表交叉注意力机制层的输出，/＞为解码器自注意力机制层的输出经过线性变换后的列维度，/＞解码器自注意力机制层的输出进行线性变换得到的Q矩阵，/＞为Transformer编码器的输出进行线性变换得到的K,V矩阵；所述MLP模块包括两个全连接层、高斯误差线性单元Gelu和层归一化LayerNorm，其中全连接层的输出维度与Transformer解码器模块输入维度相等；所述Transformer解码器模块的自注意力机制层、交叉注意力机制层和MLP模块均用残差结构进行连接；公式如下：其中为解码器中MLP模块输入，/＞为MLP模块输出，/＞为进行残差连接后的MLP模块输出；/＞为解码器中自注意力机制层输入，/＞为自注意力机制层输出，/＞为进行残差连接后的自注意力机制层输出；/＞为解码器中交叉注意力机制层输入，/＞为交叉注意力机制层输出，/＞为进行残差连接后的交叉注意力机制层输出；所述6个Transformer解码器模块组成，每个模块之前采用残差连接；公式如下：其中，为Transformer解码器模块输入，/＞为Transformer解码器模块输出，/＞为进行残差连接后Transformer解码器模块输出。7.如权利要求1所述的一种基于交叉注意力的视听语音增强模型搭建方法，其特征在于：所述Transformer解码器的输出再经过音频处理模块处理后，得到预测梅尔特征图，其与干净音频的梅尔特征图利用均方误差MSE损失函数进行训练，得到训练好的梅尔特征图，再利用逆梅尔特征变换得到最终的预测语音。8.如权利要求1所述的一种基于交叉注意力的视听语音增强模型搭建方法，其特征在于：所述步骤2中，是通过短时傅里叶变换将时域混合音频转换为语谱图，音频采样率为16kHz，音频片段长度为3s，STFT帧长为512个采样点，帧移为160个采样点，采用汉宁窗，梅尔滤波器组数为80。9.一种基于交叉注意力的视听语音增强方法，其特征在于，包括以下过程：获取包含有说话人的视频和相应音频；将获取的视频和相应音频进行处理，分别提取混合语音的梅尔特征图和视频面部帧；将混合语音的梅尔特征图和视频面部帧输入到如权利要求1至8任意一项所述的搭建方法所搭建的最终视听语音增强模型中；输出最终预测音频。10.一种视听语音增强设备，其特征在于：所述设备包括至少一个处理器和至少一个存储器，所述处理器和存储器相耦合；所述存储器中存储有如权利要求1至8任意一项所述的搭建方法所搭建的最终视听语音增强模型的计算机执行程序；所述处理器执行存储器中存储的计算机执行程序时，可以使处理器执行一种基于交叉注意力的视听语音增强方法。
说明书desc
技术领域本发明属于语音识别模型技术领域，尤其涉及一种基于交叉注意力的视听语音增强方法及其模型搭建方法。背景技术通常，正常听力的听众能够专注于特定的声学刺激，针对目标语音或感兴趣的语音，同时过滤掉其他声音，这种众所周知的现象被称为鸡尾酒会效应，因为它类似于鸡尾酒会上发生的情况，由此引发了人们对语音增强这一问题的关注。语音增强的目的是消除信号中的噪声成分同时保留干净的语音信号，提高语音质量和可懂度。随着数字信号处理技术的发展，语音增强技术也得到了很大的发展和改进。通过数字技术对语音信号进行滤波、增强、去混响等处理，语音信号的质量和清晰度得以进一步提高。基于数字信号处理技术的语音增强，可以分为传统的数字语音增强方法和基于神经网络的语音增强方法两大类。传统的数字语音增强方法通常是基于时域或频域进行信号处理的，常见的方法包括谱减法、维纳滤波法、子空间法等。其只适用于简单噪声场景，但现实中的噪声场景通常比较复杂。近年来，由于具有良好的泛化性能，可以从大量的数据中自动学习特征，应对不同的语音增强场景和任务，深度学习在语音增强领域的应用逐渐增多。众多表现良好的语音增强的模型被提出。然而，语音感知本质上是多模态的，特别是视听，因为除了到达听众耳朵的声学语音信号之外，一些有助于语音产生的发音器官的位置和运动也可能对接收者可见。神经科学和言语感知的研究表明，言语的视觉方面对人类将听觉注意力集中在特定刺激上的能力有潜在的强烈影响。2018年谷歌提出了一个基于深度学习联合视听语音分离/增强模型，相比纯音频方法显著提高了其增强性能。但上述方法对视听信息融合方面做的不够充分，如何有效地结合音视频特征，使其提高语音增强效果仍然值得探讨。发明内容针对上述问题，本发明第一方面提供了一种基于交叉注意力的视听语音增强模型搭建方法，包括以下过程：步骤1，获取若干说话人的视频和相应音频的原始数据；步骤2，对步骤1中获取的原始数据进行预处理；将视频分别处理为一帧一帧的图像，同时从原始数据中随机选取一个说话人的数据和一个噪声数据，将其中的音频按一定比例混合后对混合语音做梅尔变换得到语音的梅尔特征图，结合说话人数据对应的面部帧构建数据集，并划分为训练集、验证集和测试集；步骤3，构建基于交叉注意力的视听语音增强模型；基于Resnet18网络结构和CBAM注意力机制，构建视觉特征处理模块；基于1D卷积和高斯误差线性单元Gelu，构建音频特征处理模块；基于Transformer编码器，得到视觉特征的K,V矩阵；基于Transformer解码器，将原Transformer解码器中的第二个自注意力机制层改为交叉注意力机制层，将音频特征作为Q矩阵，解码器的输出作为K,V矩阵；其中，将混合语音的梅尔特征图和视频面部帧作为输入，模型输出为预测音频梅尔特征图，最终将梅尔特征图进行逆梅尔谱变换得到最终预测音频；步骤4，使用预处理后的数据集对构建的视听语音增强模型进行训练与测试评估，获取最终视听语音增强模型。优选的，所述步骤2中预处理的具体过程为：首先将每一个视频以每秒25帧进行裁剪，得到按照时间维度排列的图像，对于每一张图像使用现有的基于OpenCV库的MTCNN人脸检测器提取每张图片中的目标说话人的人脸缩略图，使用Facenet预训练模型来提取每个人脸缩略图的人脸特征，Facenet预训练模型经过训练大量人脸图片得到；然后从原始数据中随机选取一个说话人的数据和一个噪声数据，将其中的音频混合后对混合语音做短时傅里叶变换得到语音的语谱图，结合说话人数据对应的面部特征构建数据集。优选的，所述视觉特征处理模块由修改后的Resnet18残差网络和卷积块注意力模块CBAM组成；所述修改后的Resnet18残差网络，包括1个conv5卷积层，4个conv_res层；其中conv5层由大小为5×5步长为1的卷积核、批归一化层BN以及ReLU激活函数组成，每个conv_res层由两个相同的卷积块组成，每个卷积块包含一个大小为1×7步长为1的卷积核、BN层以及ReLU激活函数；卷积块的输入输出公式可由下式表示：y = ReLU)))))其中，x代表卷积块的输入，y代表卷积块的输出；conv_res是1×7卷积运算；修改后的Resnet18残差网络的输出作为CBAM模块的输入；所述CBAM模块由通道注意力模块和空间注意力模块组成，CBAM模块位于修改后的Resnet18残差网络之后，用于高效提取和音频相关性较大的人脸关键区域，忽略人脸之外的次要区域；所述CBAM模块的输出作为网络提取的初步视觉特征，其将用作模型中Transformer编码器输入。优选的，所述音频特征处理模块由2个1D卷积层和高斯误差线性单元Gelu组成；每个1D卷积层的输出维度与输入维度相同，高斯误差线性单元Gelu公式如下：代表/＞激活函数的输入，/＞即为/＞激活函数的输出；所述音频特征处理模块输出作为网络提取的初步音频特征，其将用作模型中Transformer解码器输入。优选的，所述Transformer编码器，包括6个Transformer编码器模块，每个Transformer编码器模块包括一个自注意力机制层和一个MLP模块；所述Transformer编码器的输入为视觉特征处理模块的输出与正弦位置编码的相加，正弦位置编码公式如下：表示位置编码矩阵中第/＞个位置，第/＞个维度的值，/＞表示模型嵌入向量的维度；所述Transformer编码器模块中，自注意力机制中的Q,K,V矩阵由编码器输入视频特征进行线性变换得到，自注意力机制输入公式如下：其中，中为编码器输入视频特征经过线性变换后的列维度，/＞为编码器输入视频特征进行线性变换得到的Q,K,V矩阵；所述MLP模块包括两个全连接层、高斯误差线性单元Gelu和层归一化LayerNorm，其中全连接层的输出维度与ransformer编码器模块输入维度相等；所述Transformer编码器模块的自注意力机制层和MLP模块均用残差结构进行连接；公式如下：其中为MLP模块输入，/＞为MLP模块输出，/＞为进行残差连接后的MLP模块输出，/＞为自注意力机制层输入，/＞为自注意力机制层输出，/＞为进行残差连接后的自注意力机制层输出；所述6个Transformer编码器模块，每个模块之前采用残差连接；公式如下：其中，为Transformer编码器模块输入，/＞为Transformer编码器模块输出，/＞为进行残差连接后Transformer编码器模块输出。优选的，所述Transformer解码器，包括6个Transformer解码器模块，每个Transformer解码器模块包括一个自注意力机制层、一个交叉注意力机制层和一个MLP模块；所述Transformer解码器的输入为音频特征处理模块的输出与可学习位置编码的相加；所述Transformer解码器模块中，自注意力机制中的Q,K,V矩阵由解码器输入视频特征进行线性变换得到，自注意力机制输入公式如下：其中，中为解码器输入音频特征经过线性变换后的列维度，/＞为解码器输入音频特征进行线性变换得到的Q,K,V矩阵；/＞代表/＞的转置矩阵；所述Transformer解码器模块中，交叉注意力机制中的Q矩阵由进行线性变换得到，K,V矩阵由Transformer编码器的输出进行线性变换得到，交叉注意力机制输入公式如下：其中，代表交叉注意力机制层的输出，/＞为解码器自注意力机制层的输出经过线性变换后的列维度，/＞解码器自注意力机制层的输出进行线性变换得到的Q矩阵，/＞为Transformer编码器的输出进行线性变换得到的K,V矩阵；所述MLP模块包括两个全连接层、高斯误差线性单元Gelu和层归一化LayerNorm，其中全连接层的输出维度与Transformer解码器模块输入维度相等；所述Transformer解码器模块的自注意力机制层、交叉注意力机制层和MLP模块均用残差结构进行连接；公式如下：其中为解码器中MLP模块输入，/＞为MLP模块输出，/＞为进行残差连接后的MLP模块输出；/＞为解码器中自注意力机制层输入，为自注意力机制层输出，/＞为进行残差连接后的自注意力机制层输出；/＞为解码器中交叉注意力机制层输入，/＞为交叉注意力机制层输出，/＞为进行残差连接后的交叉注意力机制层输出；所述6个Transformer解码器模块组成，每个模块之前采用残差连接；公式如下：其中，为Transformer解码器模块输入，/＞为Transformer解码器模块输出，/＞为进行残差连接后Transformer解码器模块输出。优选的，所述Transformer解码器的输出再经过音频处理模块处理后，得到预测梅尔特征图，其与干净音频的梅尔特征图利用均方误差MSE损失函数进行训练，得到训练好的梅尔特征图，再利用逆梅尔特征变换得到最终的预测语音，其原理是梅尔特征复原成短时傅里叶变换的功率谱，随后将其使用Griffin-Lim算法复原成音频，该算法是一种已知幅度谱，未知相位谱，通过迭代生成相位谱，并用已知的幅度谱和计算得出的相位谱，重建语音波形的方法。优选的，所述步骤2中，是通过短时傅里叶变换将时域混合音频转换为语谱图，音频采样率为16kHz，音频片段长度为3s，STFT帧长为512个采样点，帧移为160个采样点，采用汉宁窗，梅尔滤波器组数为80。本发明第二方面还提供了一种基于交叉注意力的视听语音增强方法，包括以下过程：获取包含有说话人的视频和相应音频；将获取的视频和相应音频进行处理，分别提取混合语音的梅尔特征图和视频面部帧；将混合语音的梅尔特征图和视频面部帧输入到如第一方面所述的搭建方法所搭建的最终视听语音增强模型中；输出最终预测音频。本发明第三方面还提供了一种视听语音增强设备，所述设备包括至少一个处理器和至少一个存储器，所述处理器和存储器相耦合；所述存储器中存储有如第一方面所述的搭建方法所搭建的最终视听语音增强模型的计算机执行程序；所述处理器执行存储器中存储的计算机执行程序时，可以使处理器执行一种基于交叉注意力的视听语音增强方法。本发明第四方面还提供了一种计算机可读存储介质，所述计算机可读存储介质中存储有如第一方面所述的搭建方法所搭建的最终视听语音增强模型的计算机执行程序，所述计算机执行程序被处理器执行时，可以使处理器执行一种基于交叉注意力的视听语音增强方法。与现有技术相比，本发明具有如下有益效果：本发明提出了一个基于交叉注意力的视听语音增强模型，使用交叉注意力机制来融合视听特征，并使用Transformer编码器和解码器来搭建模型，交叉注意力机制算法能让网络更好地利用视觉信息和音频信息之间的内在联系，可以实现更好的语音增强性能；针对于传统的级联融合或是加法融合模式，这两种融合方法简单直接且不需要计算，但是在模型中这种简单的融合会损失很多有用的信息，从而导致分离的音频的效果不够准确，本发明提出的融合方法在效果上明显占优；相比于单纯使用音频信号的频域特征，本发明对混合语音信号做梅尔特征变换，充分的利用语音信号信息。附图说明图1为本发明实施例1中真值频谱图。图2为本发明实施例1中混合音频频谱图。图3为本发明实施例1中预测音频频谱图。图4为本发明提出的视听语音增强模型的框架图。图5为本发明Transformer编码器模块和解码器模块中MLP模块结构图。图6为本发明Transformer编码器模块结构图。图7为本发明Transformer解码器模块结构图。图8为本发明视觉特征处理模块结构图。图9为本发明音频特征处理模块结构图。图10为本发明实施例2中视听语音增强设备结构简图。具体实施方式实施例1：本实施例通过具体实验场景，对本发明展开进一步说明。本实施例选取AVspeech和Voxceleb2数据集，AVspeech数据集是一个公开的大规模视听数据集，包括没有干扰背景信号的语音片段。这些片段的长度各不相同，在3到10秒之间，在每个片段中，视频中唯一可见的面孔和唯一可听到的声音属于一个说话的人。总的来说，该数据集包含大约4700个小时的视频片段，大约有150000个不同的演讲者，涵盖了各种各样的人、语言和面部姿势。Voxceleb2数据集包含来自YouTube的名人声音。该数据集包含5994名说话者，训练集中共有1092009个片段，测试集中有118名说话者，36237个片段。本发明训练用的每段视频为3s。选取噪声的数据集包括ESC50、MS-SNSD和VOICe，它们涵盖了不同的噪声类别，如自然声音、人类非语音声音、城市噪声和家庭声音。从中选取500条噪音，与2000条语音片段进行随机融合成200000条混合语音，同样将其以8.5:1:0.5 的比例划分成训练集、测试集和验证集。在实际场景中，也可以获取若干说话人的视频和相应音频的原始数据将视频分别处理为一帧一帧的图像，同时从原始数据中随机选取一个说话人的数据和一个噪声数据，将其中的音频按一定比例混合，混合比例根据场景需要；控制信噪比的公式如下：其中为纯净语音，/＞为噪声，/＞为加噪语音，/＞为控制信噪比系数取值范围为/＞，/＞越大信噪比越低。1.视频特征输入处理：将每一个视频以每秒25帧进行裁剪，得到3*25=75张按照时间维度排列的图像。对于每一张图像使用现有的基于OpenCV库的MTCNN人脸检测器或离线人脸检测器提取每张图片中的目标说话人的人脸缩略图。使用Facenet预训练模型来提取每个人脸缩略图的人脸特征，Facenet是通过深度可分离卷积将人脸映射到欧式空间的特征向量上，通过判断不同图片人脸特征的距离来进行人脸识别。Facenet预训练模型经过训练数百万张人脸图片得到。使用Facenet网络中空间不变的最低层，为每个侦测到的人脸缩略图提取出一个人脸嵌入向量，在本实施例中，将每个人脸嵌入向量设置为1792维。使用预训练模型提取人脸特征的原理是，每个人脸的嵌入向量保存了识别数百万张人脸图片所必要的信息，同时丢弃了图像之间不相关的变化，例如照明信息，背景信息等。有相关工作表明，从这些人脸嵌入向量恢复面部表情是可行的。也有相关工作用实验验证了，用原始图像输入和人脸嵌入向量输入没有提高语音增强模型性能。处理后的每个说话人的人脸特征维度为，n为说话人个数。由于语音增强模型说话人数为1，所以可以将视频特征转为该特征将作为模型视频流部分的输入。2.音频特征输入处理：由于人耳可以分辨的语音频率范围是0~8000Hz，根据采样定理，选取训练语音的采样率为16kHz。所以每一段初始的音频为一段一维的时间序列，其维度为。随后计算这3秒音频的短时傅里叶变换STFT。计算得到语音的时频域为一个复数域，公式为复数域的表达式:为了获取梅尔特征，需在短时傅里叶变换的基础上，求得各帧的功率谱，也就是对复数域进行取模操作，之后通过Mel滤波器组在频率与梅尔频率之间进行转换，梅尔频率和正常频率的转换公式如下：其中为梅尔频率。Mel滤波器组的原理是基于人耳的听觉系统，由于人耳只关注特定频率范围内的分量，且人耳对不同频谱信号的敏感度不同，因此Mel滤波器组为模拟人耳对频谱的非线性感知，在低频范围分布较为密集而在高频范围较为稀疏。对于具体参数，在实验中STFT所用到的帧长为512个采样点，帧移为160个采样点，采用汉宁窗；梅尔滤波器组数目选取为80。这样计算得到的梅尔特征频率为。其中298为时间维度大小，80为频率维度大小。处理后的音频特征将作为模型音频流部分的输入。其原始真值频谱图如图1所示，预处理后的混合音频频谱图如图2所示。3.视听语音增强模型结构：如图4所示，模型包括视觉特征处理模块、音频特征处理模块、Transformer编码器和Transformer解码器。Transformer编码器模块如图6所示，先将视频输入特征送入模型中的视频特征处理模块，视觉特征处理模块结构图8所示，该模块由Resnet18残差模块和卷积块注意力模块组成，这两个模块在图像处理、识别领域中均有很好的面部特征提取能力，其详细原理不再赘述。经过视觉特征处理模块的处理后，视频特征维度变为，经过上采样与音频特征在时间维度上对齐得到视频特征维度为，将其重塑为。由相关工作可以看出，口腔区域在语音分离或增强的视频特征中起着最重要的作用。然而，眼睛和脸颊等其他区域也有助于这一过程。因此，输入的视频特征经过网络模块后，网络模块可以检测到大部分嘴唇特征和其他区域的一些特征。处理后的视频特征称为/＞。将/＞与正弦曲线位置编码相加记为/＞，送入Transformer编码器中。正弦曲线位置编码公式如下。其中，表示位置编码矩阵中第/＞个位置，第/＞个维度的值；/＞表示模型嵌入向量的维度；/＞表示位置编码矩阵中第/＞个维度的值。对于视频特征/＞维度来说，298为位置向量维度，/＞的大小为/＞。每个Transformer编码器包括一个多头自注意力机制和一个MLP模块。自注意力机制中的Q,K,V矩阵由视频特征，进行线性变换得到。自注意力机制的输出为：其中为/＞经过线性变换后的列维度，在实验中设定/＞。MLP模块包括两个全连接层、高斯误差线性单元和层归一化，具体连接如图5所示。每个Transformer编码器模块的最终输出与输入视频特征/＞一致，均为。将用6个这样的编码器模块进行叠加组成最终的网络编码器部分。编码器的最终输出记为/＞。Transformer编码器模块如图7所示，解码器部分的输入为音频的梅尔特征，其首先送入网络中的音频特征处理模块，音频特征处理模块结构如图9所示，该模块由两个1D卷积层和高斯误差线性单元组成。输出维度依旧等同于音频特征输入维度。将其与可学习位置编码相加作为Transformer解码器模块的输入，记为。每个Transformer解码器模块包括一个自注意力机制，交叉注意力机制和MLP模块。解码器模块中的自注意力机制与编码器的原理相同，将输入音频特征/＞进行自注意力，其输出如下：记为，随后将自注意力输出/＞与编码器输出/＞一起用作交叉注意力的输入，将/＞进行线性变换作为Q矩阵，/＞进行线性变换作为K和V矩阵。交叉注意力的含义可以理解为注意到了视频信息的音频特征，其与人脑在处理视听特征时的原理类似。交叉注意力的输出如下：其中为/＞和/＞经过线性变换后的列维度，这两个维度从理论上来说应该是相等的，在实验中设定/＞。MLP模块包括两个全连接层、高斯误差线性单元和层归一化，这与编码器的MLP模块相同。每个Transformer解码器模块的最终输出与输入音频特征/＞一致，均为。本实施例将用6个这样的解码器模块进行叠加组成最终的网络解码器部分。解码器的最终输出将用作网络输出模块的输入。网络模型输出：将解码器的输出送入两个1D卷积层和Gelu中，特征维度保持不变依旧为。将其作为训练目标与干净语音的梅尔特征进行均方误差进行训练，得到预测语音梅尔特征。在语音重建时，选用Python的Librosa库中librosa.feature.inverse.mel_to_audio函数进行语音的重建。其函数的参数与之前提取梅尔特征时的相关参数完全一致。预测音频频谱图如图3所示。4.模型训练训练目标：干净语音的梅尔特征。损失函数：实验采用均方误差为损失函数来进行模型的训练。其具体的定义如下：和语音分离实验不同的是，语音增强只需要考虑一个人的语音，所以其损失函数不存在不同说话人之间的干扰，只需考虑预测掩码和真值掩码之间的差异。5.实验结果及评估：与其他相关语音增强模型对比实验：本实施例将本发明提出的模型与几种视听语音增强模型或纯音频模型进行了比较，包括 Audio-only CRN，一种基于CRN的纯音频语音增强模型；L2L，一种基于视听神经网络的单通道、与说话者无关的语音增强/分离模型；VSE，一种用于视觉语音增强的视听神经网络；AV-2，一种具有多个跨模态融合块的视听语音增强模型；MHCA-AVCRN，一种利用多头注意力学习视听亲和力的改进视听语音增强模型。实验的具体对比结果如表1所示。表1对比结果表1中的数据表明，通过与以上几种最近提出的利用深度神经网络的视听语音增强方法比较，我们提出的模型在各项性能上有着最优秀的结果。实施例2：如图10所示，本发明同时提供了一种视听语音增强设备，设备包括至少一个处理器和至少一个存储器，同时还包括通信接口和内部总线；存储器中存储有计算机执行程序；存储器中存储有如实施例1所述的搭建方法所搭建的最终视听语音增强模型的计算机执行程序；所述处理器执行存储器中存储的计算机执行程序时，可以使处理器执行一种基于交叉注意力的视听语音增强方法。其中内部总线可以是工业标准体系结构总线、外部设备互连总线或扩展工业标准体系结构总线等。总线可以分为地址总线、数据总线、控制总线等。为便于表示，本申请附图中的总线并不限定仅有一根总线或一种类型的总线。其中存储器可能包含高速RAM存储器，也可能还包括非易失性存储NVM，例如至少一个磁盘存储器，还可以为U盘、移动硬盘、只读存储器、磁盘或光盘等。设备可以被提供为终端、服务器或其它形态的设备。图10是为示例性示出的一种设备的框图。设备可以包括以下一个或多个组件：处理组件，存储器，电源组件，多媒体组件，音频组件，输入/输出的接口，传感器组件，以及通信组件。处理组件通常控制电子设备的整体操作，诸如与显示，电话呼叫，数据通信，相机操作和记录操作相关联的操作。处理组件可以包括一个或多个处理器来执行指令，以完成上述的方法的全部或部分步骤。此外，处理组件可以包括一个或多个模块，便于处理组件和其他组件之间的交互。例如，处理组件可以包括多媒体模块，以方便多媒体组件和处理组件之间的交互。存储器被配置为存储各种类型的数据以支持在电子设备的操作。这些数据的示例包括用于在电子设备上操作的任何应用程序或方法的指令，联系人数据，电话簿数据，消息，图片，视频等。存储器可以由任何类型的易失性或非易失性存储设备或者它们的组合实现，如静态随机存取存储器，电可擦除可编程只读存储器，可擦除可编程只读存储器，可编程只读存储器，只读存储器，磁存储器，快闪存储器，磁盘或光盘。通信组件被配置为便于电子设备和其他设备之间有线或无线方式的通信。电子设备可以接入基于通信标准的无线网络，如WiFi，2G或3G，或它们的组合。在一个示例性实施例中，通信组件经由广播信道接收来自外部广播管理系统的广播信号或广播相关信息。在一个示例性实施例中，所述通信组件还包括近场通信模块，以促进短程通信。例如，在NFC模块可基于射频识别技术，红外数据协会技术，超宽带技术，蓝牙技术和其他技术来实现。在示例性实施例中，电子设备可以被一个或多个应用专用集成电路、数字信号处理器、数字信号处理设备、可编程逻辑器件、现场可编程门阵列、控制器、微控制器、微处理器或其他电子元件实现，用于执行上述方法。实施例3：本发明还提供了一种计算机可读存储介质，所述计算机可读存储介质中存储有如实施例1所述搭建方法所搭建的最终视听语音增强模型的计算机执行程序，所述计算机执行程序被处理器执行时，可以使处理器执行一种基于交叉注意力的视听语音增强方法。具体地，可以提供配有可读存储介质的系统、装置或设备，在该可读存储介质上存储着实现上述实施例中任一实施例的功能的软件程序代码，且使该系统、装置或设备的计算机或处理器读出并执行存储在该可读存储介质中的指令。在这种情况下，从可读介质读取的程序代码本身可实现上述实施例中任何一项实施例的功能，因此机器可读代码和存储机器可读代码的可读存储介质构成了本发明的一部分。上述存储介质可以是由任何类型的易失性或非易失性存储设备或者它们的组合实现，如静态随机存取存储器，电可擦除可编程只读存储器，可擦除可编程只读存储器，可编程只读存储器，只读存储器，磁存储器，快闪存储器，磁盘或光盘、磁带等。存储介质可以是通用或专用计算机能够存取的任何可用介质。应理解存储介质耦合至处理器，从而使处理器能够从该存储介质读取信息，且可向该存储介质写入信息。当然，存储介质也可以是处理器的组成部分。处理器和存储介质可以位于专用集成电路中。当然，处理器和存储介质也可以作为分立组件存在于终端或服务器中。这里所描述的计算机可读程序指令可以从计算机可读存储介质下载到各个计算/处理设备，或者通过网络、例如因特网、局域网、广域网和/或无线网下载到外部计算机或外部存储设备。网络可以包括铜传输电缆、光纤传输、无线传输、路由器、防火墙、交换机、网关计算机和/或边缘服务器。每个计算/处理设备中的网络适配卡或者网络接口从网络接收计算机可读程序指令，并转发该计算机可读程序指令，以供存储在各个计算/处理设备中的计算机可读存储介质中。用于执行本公开操作的计算机程序指令可以是汇编指令、指令集架构指令、机器指令、机器相关指令、微代码、固件指令、状态设置数据、或者以一种或多种编程语言的任意组合编写的源代码或目标代码，所述编程语言包括面向对象的编程语言—诸如Smalltalk、C++等，以及常规的过程式编程语言—诸如“C”语言或类似的编程语言。计算机可读程序指令可以完全地在用户计算机上执行、部分地在用户计算机上执行、作为一个独立的软件包执行、部分在用户计算机上部分在远程计算机上执行、或者完全在远程计算机或服务器上执行。在涉及远程计算机的情形中，远程计算机可以通过任意种类的网络—包括局域网或广域网—连接到用户计算机，或者，可以连接到外部计算机。在一些实施例中，通过利用计算机可读程序指令的状态信息来个性化定制电子电路，例如可编程逻辑电路、现场可编程门阵列或可编程逻辑阵列，该电子电路可以执行计算机可读程序指令，从而实现本公开的各个方面。以上所述仅为本申请的优选实施例而已，并不用于限制本申请，对于本领域的技术人员来说，本申请可以有各种更改和变化。凡在本申请的精神和原则之内，所作的任何修改、等同替换、改进等，均应包含在本申请的保护范围之内。上述虽然对本发明的具体实施方式进行了描述，但并非对本发明保护范围的限制，所属领域技术人员应该明白，在本发明的技术方案的基础上，本领域技术人员不需要付出创造性劳动即可做出的各种修改或变形仍在本发明的保护范围以内。
