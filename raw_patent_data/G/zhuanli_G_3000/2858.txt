标题title
一种智能多模态组合应用的人机交互场景系统
摘要abst
本发明提供了一种智能多模态组合应用的人机交互场景系统，包括数据获取模块、特征提取模块、决策融合模块和交互模块；所述数据获取模块用于获取用户的多模态数据，所述特征提取模块用于根据多模态数据提取出各模态的特征，并根据各模态的特征预测用户在各模态所表达的各种决策及决策的概率，所述决策融合模块用于将用户在各模态表达的决策及决策概率进行分析计算得出最终决策指令，所述交互模块用于根据最终决策指令完成人机交互；本发明通过采集分析语音、手势和眼动信息，可以做出更准确的决策理解，解决了单一模态的局限性。
权利要求书clms
1.一种智能多模态组合应用的人机交互场景系统，包括数据获取模块、特征提取模块、决策融合模块和交互模块；所述数据获取模块用于获取用户的多模态数据，所述特征提取模块用于根据多模态数据提取出各模态的特征，并根据各模态的特征预测用户在各模态所表达的各种决策及决策的概率，所述决策融合模块用于将用户在各模态表达的决策及决策概率进行分析计算得出最终决策指令，所述交互模块用于根据最终决策指令完成人机交互；所述数据获取模块包括语音获取模块、手势获取模块和眼动获取模块，所述语音获取模块用于获取用户的语音信息，所述手势获取模块用于获取用户的手势动作信息，所述眼动获取模块用于获取用户的眼动信息；所述特征提取模块包括语音特征提取模块、手势特征提取模块和眼动特征提取模块，所述语音特征提取模块用于提取语音特征，并根据语音特征预测用户在语音模态的决策及语音模态决策概率；所述手势特征提取模块用于提取手势特征，并根据手势特征预测用户在手势模态的决策及手势模态决策概率；所述眼动特征提取模块用于提取眼动特征，并根据眼动特征预测用户在眼动模态的决策及眼动模态决策概率；所述决策融合模块中包含各模态下获取的所有决策，设所有决策共有条，各个决策的集合为/＞，所述决策融合模块根据各模态下获取的决策和决策概率生成以下概率矩阵：；其中，中/＞对应用户的语音模态下做出决策/＞的概率，/＞表示用户语音模态下作出决策/＞的概率，/＞中/＞对应用户的手势模态下/＞的概率，/＞表示用户手势模态下作出决策/＞的概率，/＞中/＞对应用户眼动模态下做出决策/＞的概率，代表用户眼动模态下作出决策/＞的概率，对于所有的/＞中的i满足/＞。2.根据权利要求1所述的一种智能多模态组合应用的人机交互场景系统，其特征在于，所述决策融合模块根据所述概率矩阵生成权重矩阵，所述权重矩阵的获取方式如下：计算用户在各模态上做出决策的平均概率：；其中，为用户在各模态上做出决策/＞的平均概率，/＞为用户在第/＞个模态下做出决策/＞的概率，/＞代表语音模态，/＞代表手势模态，/＞代表眼动模态；计算：；其中，代表用户在第/＞个模态下做出决策/＞的概率与平均概率之间的间距，间距越大代表该模态下做出的决策与平均决策间的关联越小；根据生成一个权重矩阵，为每个模态下的决策赋予权重，所述权重矩阵如下式：；其中，中/＞对应用户的语音模态下做出决策/＞的权重，/＞表示用户语音模态下作出决策/＞的权重，/＞中/＞对应用户的手势模态/＞做出决策/＞的权重，/＞表示用户手势模态下作出决策/＞的权重，/＞中/＞对应用户的眼动模态/＞做出决策/＞的权重，代表用户眼动模态下作出决策/＞的权重，对于所有的/＞中的i满足/＞。3.根据权利要求1所述的一种智能多模态组合应用的人机交互场景系统，其特征在于，对于权重矩阵中每个权重，满足：。4.根据权利要求1所述的一种智能多模态组合应用的人机交互场景系统，其特征在于，所述决策融合模块将概率矩阵与权重矩阵相乘生成一个最终决策判定矩阵，提取出最终决策判定矩阵中大于阈值的数值对应的决策作为最终决策指令。
说明书desc
技术领域本发明涉及多模态人机交互领域，尤其涉及一种智能多模态组合应用的人机交互场景系统。背景技术近年来，随着计算机视觉、自然语言处理、声学信号处理等领域的快速发展，多模态人机交互技术越来越成为研究的热点和应用的终点；多模态组合应用的人机交互系统将语音、图像、手势灯多种输入方式进行有效结合，实现更加灵活、智能和自然的人机交互，同时又可大大提高交互效率。查阅相关已公开技术方案，如CN114020153A现有技术公开了一种多模态人机交互方法及装置，方法包括：获取来自用户的交互文本信息；根据交互文本信息预测过渡语；根据过渡语获取对应的多模态内容，将其作为第一回复内容，将第一回复内容推送至虚拟人客户端；根据交互文本信息的答复文本信息生成对应的多模态内容，将其作为第二回复内容，将所述第二回复内容推送至虚拟人客户端；该发明通过在正式回复内容之前插入过渡语，对答复文本信息分段处理，将一轮回复变成多轮回复，提高了虚拟人的响应速度，实现了顺畅的人机交互体验；另一种典型的公开号为CN111554279A的现有技术公开了一种基于Kinect的多模态人机交互系统，实现步骤如下:构建能接受Kinect获取到的多模态数据的数据采集系统；进行声学模型与语言模型的单音素训练，得到声学识别模块；利用采集到彩色图数据建立用于训练机器学习的唇动数据集；使用基于残差神经网络的卷积神经网络的模型训练方法，利用唇动数据集训练唇读识别模型；数据采集系统、语音识别模型和唇读识别模型整合在一起，构建一个多模态的人机交互系统；该发明的多模态的人机交互系统增强了语音识别的鲁棒性；上述第一种方案的两种模态均为文本模态内容，与用户的交互性不够高；上述第二种方案其在多模态的决策层仅通过单一置信度比较完成多模态识别，适应性和准确性较低。发明内容本发明的目的在于，针对目前所存在的不足，提出了一种智能多模态组合应用的人机交互场景系统。本发明采用如下技术方案：一种智能多模态组合应用的人机交互场景系统，包括数据获取模块、特征提取模块、决策融合模块和交互模块；所述数据获取模块用于获取用户的多模态数据，所述特征提取模块用于根据多模态数据提取出各模态的特征，并根据各模态的特征预测用户在各模态所表达的各种决策及决策的概率，所述决策融合模块用于将用户在各模态表达的决策及决策概率进行分析计算得出最终决策指令，所述交互模块用于根据最终决策指令完成人机交互；所述数据获取模块包括语音获取模块、手势获取模块和眼动获取模块，所述语音获取模块用于获取用户的语音信息，所述手势获取模块用于获取用户的手势动作信息，所述眼动获取模块用于获取用户的眼动信息；所述特征提取模块包括语音特征提取模块、手势特征提取模块和眼动特征提取模块，所述语音特征提取模块用于提取语音特征，并根据语音特征预测用户在语音模态的决策及语音模态决策概率；所述手势特征提取模块用于提取手势特征，并根据手势特征预测用户在手势模态的决策及手势模态决策概率；所述眼动特征提取模块用于提取眼动特征，并根据眼动特征预测用户在眼动模态的决策及眼动模态决策概率；所述决策融合模块中包含各模态下获取的所有决策，设所有决策共有条，各个决策的集合为/＞，所述决策融合模块根据各模态下获取的决策和决策概率生成以下概率矩阵：；其中，中/＞对应用户的语音模态下做出决策/＞的概率，/＞表示用户语音模态下作出决策/＞的概率，/＞中/＞对应用户的手势模态下/＞的概率，/＞表示用户手势模态下作出决策/＞的概率，/＞中/＞对应用户眼动模态下做出决策/＞的概率，/＞代表用户眼动模态下作出决策/＞的概率，对于所有的/＞中的i满足/＞；进一步的，所述决策融合模块根据所述概率矩阵生成权重矩阵，所述权重矩阵的获取方式如下：计算用户在各模态上做出决策的平均概率：；其中，为用户在各模态上做出决策/＞的平均概率，/＞为用户在第/＞个模态下做出决策/＞的概率，/＞代表语音模态，/＞代表手势模态，/＞代表眼动模态；计算：；其中，代表用户在第/＞个模态下做出决策/＞的概率与平均概率之间的间距，间距越大代表该模态下做出的决策与平均决策间的关联越小；根据生成一个权重矩阵，为每个模态下的决策赋予权重，所述权重矩阵如下式：；其中，中/＞对应用户的语音模态下做出决策/＞的权重，/＞表示用户语音模态下作出决策/＞的权重，/＞中/＞对应用户的手势模态/＞做出决策/＞的权重，/＞表示用户手势模态下作出决策/＞的权重，/＞中/＞对应用户的眼动模态/＞做出决策/＞的权重，/＞代表用户眼动模态下作出决策/＞的权重，对于所有的/＞中的i满足/＞；进一步的，对于权重矩阵中每个权重，满足：；进一步的，所述决策融合模块将概率矩阵与权重矩阵相乘生成一个最终决策判定矩阵，提取出最终决策判定矩阵中大于阈值的数值对应的决策作为最终决策指令。本发明所取得的有益效果是：本发明通过数据获取模块采集用户的语音、手势和眼动信息；通过特征提取模块对用户的语音、手势和眼动信息进行特征提取，并根据各特征预测出各模态下的决策及决策概率；通过决策融合模块对各模态下的决策及决策概率构建概率矩阵，并根据各模态下做出同一决策的平均概率为概率矩阵提供权重，将加权后的概率矩阵作为最终决策判定矩阵，使判定的最终决策综合考虑多模态的信息，且准确性更高。附图说明从以下结合附图的描述可以进一步理解本发明。图中的部件不一定按比例绘制，而是将重点放在示出实施例的原理上。在不同的视图中，相同的附图标记指定对应的部分。图1为本发明整体模块示意图。图2为本发明各模态决策及决策概率获取流程示意图。图3为本发明在银行场景下的交互示意图。图中标号含义：1-摄像头，2-交互界面，3-麦克风。具体实施方式为了使得本发明的目的、技术方案及优点更加清楚明白，以下结合其实施例，对本发明进行进一步详细说明；应当理解，此处所描述的具体实施例仅用于解释本发明，并不用于限定本发明；对于本领域技术人员而言，在查阅以下详细描述之后，本实施例的其它系统、方法和/或特征将变得显而易见；旨在所有此类附加的系统、方法、特征和优点都包括在本说明书内；包括在本发明的范围内，并且受所附权利要求书的保护；在以下详细描述描述了所公开的实施例的另外的特征，并且这些特征根据以下将详细描述将是显而易见的。本发明实施例的附图中相同或相似的标号对应相同或相似的部件；在本发明的描述中，需要理解的是，若有术语“上”、“下”、“左”、“右”等指示的方位或位置关系为基于附图所示的方位或位置关系，仅是为了便于描述本发明和简化描述，而不是指示或暗示所指的装置或组件必须具有特定的方位，以特定的方位构造和操作，因此附图中描述位置关系的用语仅用于示例性说明，不能理解为对本专利的限制，对于本领域的普通技术人员而言，可以根据具体情况理解上述术语的具体含义。实施例一：如图1和图2所示，本实施例提供一种智能多模态组合应用的人机交互场景系统，包括数据获取模块、特征提取模块、决策融合模块和交互模块；所述数据获取模块用于获取用户的多模态数据，所述特征提取模块用于根据多模态数据提取出各模态的特征，并根据各模态的特征预测用户在各模态所表达的各种决策及决策的概率，所述决策融合模块用于将用户在各模态表达的决策及决策概率进行分析计算得出最终决策指令，所述交互模块用于根据最终决策指令完成人机交互；所述数据获取模块包括语音获取模块、手势获取模块和眼动获取模块，所述语音获取模块用于获取用户的语音信息，所述手势获取模块用于获取用户的手势动作信息，所述眼动获取模块用于获取用户的眼动信息；所述特征提取模块包括语音特征提取模块、手势特征提取模块和眼动特征提取模块，所述语音特征提取模块用于提取语音特征，并根据语音特征预测用户在语音模态的决策及语音模态决策概率；所述手势特征提取模块用于提取手势特征，并根据手势特征预测用户在手势模态的决策及手势模态决策概率；所述眼动特征提取模块用于提取眼动特征，并根据眼动特征预测用户在眼动模态的决策及眼动模态决策概率；所述决策融合模块中包含各模态下获取的所有决策，设所有决策共有条，各个决策的集合为/＞，所述决策融合模块根据各模态下获取的决策和决策概率生成以下概率矩阵：；其中，中/＞对应用户的语音模态下做出决策/＞的概率，/＞表示用户语音模态下作出决策/＞的概率，/＞中/＞对应用户的手势模态下/＞的概率，/＞表示用户手势模态下作出决策/＞的概率，/＞中/＞对应用户眼动模态下做出决策/＞的概率，/＞代表用户眼动模态下作出决策/＞的概率，对于所有的/＞中的i满足/＞；进一步的，所述决策融合模块根据所述概率矩阵生成权重矩阵，所述权重矩阵的获取方式如下：计算用户在各模态上做出决策的平均概率：；其中，为用户在各模态上做出决策/＞的平均概率，/＞为用户在第/＞个模态下做出决策/＞的概率，/＞代表语音模态，/＞代表手势模态，/＞代表眼动模态；计算：；其中，代表用户在第/＞个模态下做出决策/＞的概率与平均概率之间的间距，间距越大代表该模态下做出的决策与平均决策间的关联越小；根据生成一个权重矩阵，为每个模态下的决策赋予权重，所述权重矩阵如下式：；其中，中/＞对应用户的语音模态下做出决策/＞的权重，/＞表示用户语音模态下作出决策/＞的权重，/＞中/＞对应用户的手势模态/＞做出决策/＞的权重，/＞表示用户手势模态下作出决策/＞的权重，/＞中/＞对应用户的眼动模态/＞做出决策/＞的权重，/＞代表用户眼动模态下作出决策/＞的权重，对于所有的/＞中的i满足/＞；进一步的，对于权重矩阵中每个权重，满足：；进一步的，所述决策融合模块将概率矩阵与权重矩阵相乘生成一个最终决策判定矩阵，提取出最终决策判定矩阵中大于阈值的数值对应的决策作为最终决策指令。本实施例通过数据获取模块采集用户的语音、手势和眼动信息；通过特征提取模块对用户的语音、手势和眼动信息进行特征提取，并根据各特征预测出各模态下的决策及决策概率；通过决策融合模块获取用户的最终决策指令；多个交互方式的组合使用，可以更加方便和高效地完成交互任务，使得用户不必依赖于单一的交互方式，为用户提供更加自然、直观的交互方式，使得用户的交互体验更加顺畅、舒适，克服了单一交互方式的缺陷，例如语音识别的准确性不高、手势识别的可靠性差等，提高了交互的可靠性和适应性；通过决策融合模块对各模态下的决策及决策概率构建概率矩阵，并根据各模态下做出同一决策的平均概率为概率矩阵提供权重，将加权后的概率矩阵作为最终决策判定矩阵，使判定的最终决策综合考虑多模态的信息，且准确性更高。实施例二：本实施例应当理解为至少包含前述任一一个实施例的全部特征，并在其基础上进一步改进；本实施例提供一种智能多模态组合应用的人机交互场景系统，包括数据获取模块、特征提取模块、决策融合模块和交互模块；所述数据获取模块用于获取用户的多模态数据，所述特征提取模块用于根据多模态数据提取出各模态的特征，并根据各模态的特征预测用户在各模态所表达的各种决策及决策的概率，所述决策融合模块用于将用户在各模态表达的决策及决策概率进行分析计算得出最终决策指令，所述交互模块用于根据最终决策指令完成人机交互；所述数据获取模块包括语音获取模块、手势获取模块和眼动获取模块，所述语音获取模块用于获取用户的语音信息，所述手势获取模块用于获取用户的手势动作信息，所述眼动获取模块用于获取用户的眼动信息；所述系统还包括有人机交互设备，所述人机交互设备上设置有麦克风和红外摄像头，所述语音获取模块通过麦克风获取到用户的语音信息，所述手势获取模块和眼动获取模块通过红外摄像头获取用户的手势动作信息和眼动信息；所述人机交互设备上还设置有交互界面和交互音频输出装置，所述交互模块通过交互界面和交互音频输出装置完成人机之间的交互；所述特征提取模块包括语音特征提取模块、手势特征提取模块和眼动特征提取模块，所述语音特征提取模块用于提取语音特征，并根据语音特征预测用户在语音模态的决策及语音模态决策概率；所述手势特征提取模块用于提取手势特征，并根据手势特征预测用户在手势模态的决策及手势模态决策概率；所述眼动特征提取模块用于提取眼动特征，并根据眼动特征预测用户在眼动模态的决策及眼动模态决策概率；所述语音特征提取模块提取语音特征并获取语音模态的决策及语音模态决策概率方式如下：S101：对获取的用户语音信息进行语音预处理，所述语音预处理操作包括去除噪声、增强语音信号；S102：从预处理后的语音信息中提取语音特征，本实施例中使用MFCC技术提取语音特征；S103：将语音特征输入预训练的语音识别模型，输出语音模态的决策及语音模态决策概率；对于步骤S103中的语音识别模型，包括：输入层：用于接收输入的语音特征；中间层：包括多个循环神经网络单元，用于对输入的语音特征进行建模；输出层：将中间层的输出映射到标签序列上，所述标签序列即为识别结果的概率分布；输出层的激活函数为常用分类函数，如softmax函数；解码器：用于将标签序列解码获取识别结果，解码算法采用已知常用解码算法，如贪心算法或束搜索算法；从而获取到语音模态的决策及决策的概率；所述手势特征提取模块提取手势特征并获取手势模态的决策及手势模态决策概率方式如下：S201：对获取的用户手势动作信息进行手势预处理，所述手势预处理操作包括将手势动作信息进行去噪、二值化和灰度化处理；S202：通过图像分割技术将预处理后手势动作信息中手部部分分离；S203：通过CNN手部特征提取模型完成手部部分的手部特征的提取和选择，其中所述CNN手部特征提取模型为技术人员事先基于实验数据使用CNN建立的手部特征提取模型；S204：将S203步骤中选择出的手部特征输入到预训练的手势决策树分类器中，输出手势模态的决策及手势模态决策概率；所述眼动特征提取模块提取眼动特征并获取眼动模态的决策及眼动模态决策概率方式如下：S301：对获取的用户的眼动信息进行眼动预处理，所述眼动预处理操作包括去除噪声和对眼动误差的矫正；S302：通过CNN眼动特征提取模型完成眼动特征的提取和选择，其中所述CNN眼动特征提取模型为技术人员事先基于实验数据使用CNN建立的眼动特征提取模型；S303：将S302步骤中选择出的眼动特征输入到预训练的眼动决策树分类器中，输出眼动模态的决策及眼动模态决策概率；所述决策融合模块通过对特征提取模块中获取各模态的决策及决策概率进行加权处理获取最终决策指令，具体实施方式如下：设本系统中共有条决策，设各个决策的集合为/＞，根据各模态下获取的决策和决策概率生成以下概率矩阵：；其中，中/＞对应用户的语音模态下做出决策/＞的概率，/＞表示用户语音模态下作出决策/＞的概率，/＞中/＞对应用户的手势模态下/＞的概率，/＞表示用户手势模态下作出决策/＞的概率，/＞中/＞对应用户眼动模态下做出决策/＞的概率，/＞代表用户眼动模态下作出决策/＞的概率，对于所有的/＞中的i满足/＞；计算用户在各模态上做出决策的平均概率：；其中，为用户在各模态上做出决策/＞的平均概率，/＞为用户在第/＞个模态下做出决策/＞的概率，/＞代表语音模态，/＞代表手势模态，/＞代表眼动模态；计算：；其中，代表用户在第/＞个模态下做出决策/＞的概率与平均概率之间的间距，间距越大代表该模态下做出的决策与平均决策间的关联越小；根据生成一个权重矩阵，为每个模态下的决策赋予权重，所述权重矩阵如下式：；其中，中/＞对应用户的语音模态下做出决策/＞的权重，/＞表示用户语音模态下作出决策/＞的权重，/＞中/＞对应用户的手势模态/＞做出决策/＞的权重，/＞表示用户手势模态下作出决策/＞的权重，/＞中/＞对应用户的眼动模态/＞做出决策/＞的权重，/＞代表用户眼动模态下作出决策/＞的权重，对于所有的/＞中的i满足/＞；对于上述权重矩阵中每个权重，满足：;将概率矩阵与权重矩阵相乘生成一个最终决策判定矩阵，提取出最终就决策判定矩阵中大于阈值的数值对应的决策作为最终决策指令；所述交互模块接收决策融合模块的最终决策指令，并根据最终决策指令完成人机间的交互；当交互模块接收到的最终决策指令超过两条且相互存在矛盾时，通过交互模块中的交互音频输出装置与用户交互，以获得更精确的模态信息，如：当交互模块接收到的两条最终决策指令分别为“前进”和“后退”时，交互模块通过交互音频输出装置向用户询问：“请您确认您下一步的指令是否为前进或后退”，并根据随后的用户各模态信息生成新的最终决策指令作出交互；本系统可应用在多种交互场景中，如家居、医院或银行等等；下面提供本系统在银行场景中的应用，本系统可为银行业务办理或业务咨询提供服务，如图3所示，本系统可作为一银行智能业务办理柜台，通过摄像头和麦克风获取用户的语音信息、手势动作信息和眼动信息，通过特征提取模块和决策融合模块获取用户的决策指令，并通过交互模块根据用户的决策指令作出相应的交互；如在图3中用户发出语音信息“我需要办理XXX业务”，本系统获取到用户的决策指令，在交互界面上显示“办理XXX业务需要XX/XXX手续，请问要现在进行办理吗？”完成人机之间的交互。本实施例通过建立语音识别模型识别输出语音信息产生的决策和决策概率，通过建立CNN手部特征提取模型和手势决策树分类器输出手势信息产生的决策和决策概率，通过建立CNN眼动特征提取模型和眼动决策树分类器输出眼动信息产生的决策和决策概率，从而得到了各模态融合的基础；通过对概率矩阵进行加权获取最终决策判定矩阵从而获取到最终决策指令，系统融合的用户交互信息更广，对于决策的判定准确性更高。以上所公开的内容仅为本发明的优选可行实施例，并非因此局限本发明的保护范围，所以凡是运用本发明说明书及附图内容所做的等效技术变化，均包含于本发明的保护范围内，此外，随着技术发展其中的元素可以更新的。
