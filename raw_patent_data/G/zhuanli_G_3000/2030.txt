标题title
一种去中心化的分层联邦学习方法
摘要abst
本发明公开了一种去中心化的分层联邦学习方法，首先通过权威机构对联邦学习系统进行初始化；将初始化后的联邦学习系统分为MEC服务器领导的边缘聚合阶段和基于共识的全局聚合阶段；在边缘聚合阶段，所述MEC服务器作为领导节点收集来自组内客户端的更新模型，并聚合为中间模型；在全局聚合阶段，在区块链的辅助下通过各MEC服务器的共识来保证全局聚合结果的安全性。上述方法可以将联邦学习分为MEC服务器领导的边缘聚合和基于共识的全局聚合两阶段，从而排除恶意服务器的威胁，提高通信安全并降低系统通信开销。
权利要求书clms
1.一种去中心化的分层联邦学习方法，其特征在于，所述方法包括：步骤1、首先通过权威机构对联邦学习系统进行初始化；步骤2、将初始化后的联邦学习系统分为移动边缘计算服务器MEC领导的边缘聚合阶段和基于共识的全局聚合阶段；步骤3、在边缘聚合阶段，所述MEC服务器作为领导节点收集来自组内客户端的更新模型，并聚合为中间模型；步骤4、在全局聚合阶段，在区块链的辅助下通过各MEC服务器的共识来保证全局聚合结果的安全性。2.根据权利要求1所述去中心化的分层联邦学习方法，其特征在于，所述步骤1的过程具体为：客户端n使用权威机构公布的公共参数生成密钥对 ，并从所述权威机构处获得绑定其注册信息/＞ 的证书/＞作为唯一的身份标识符；然后用证书加入联邦学习系统中；与客户端的注册流程类似，MEC服务器m生成密钥对，并获得绑定注册信息的证书/＞；然后用证书/＞加入联邦学习系统中；其中，所述权威机构仅用于参数初始化，在运行区块链之前提供参与方的身份授权和证书颁发，在其余时间保持离线状态。3.根据权利要求1所述去中心化的分层联邦学习方法，其特征在于，在步骤3中，在每个管理周期开始时，各客户端选择相应的MEC服务器作为中间聚合节点，MEC服务器作为领导节点将本组内的成员信息发布至区块链中；在边缘聚合阶段，MEC服务器将全局模型下发至本组内的客户端，组内客户端根据区块链中公布的全局模型哈希验证模型的正确性；然后组内客户端使用本地数据训练模型，并将更新后的模型提交至作为领导节点的MEC服务器；MEC服务器收集本组内客户端上传的更新模型，通过执行安全梯度聚合得到中间模型。4.根据权利要求1所述去中心化的分层联邦学习方法，其特征在于，所述步骤4的过程具体为：在全局聚合阶段，采用共识协议PoA搭设轻量级的区块链平台；MEC服务器在执行步骤3的聚合后，将聚合的中间模型上传至共识协议PoA的权威节点；然后权威节点利用安全聚合机制将中间模型聚合，并将聚合后模型的哈希上传至区块链中，利用智能合约进行多数投票，得票数最多的模型作为全局模型；其中，所述权威节点仅将全局模型的哈希和存储地址上传至区块链中，全局模型由权威节点验证并由链下发送至各MEC服务器，再由各MEC服务器下发至各参与方客户端；各参与方客户端使用区块链中的哈希验证全局模型的有效性后，再使用本地数据进行新一轮的模型训练。5.根据权利要求1所述去中心化的分层联邦学习方法，其特征在于，所述方法还包括：在边缘聚合阶段，采用基于秘密分享的强保护方法聚合关键参数，利用可链接环签名对剩余模型参数进行弱保护；将剩余模型参数的真实值传输至MEC服务器，结合匿名机制隐藏用户身份。
说明书desc
技术领域本发明涉及联邦学习技术领域，尤其涉及一种去中心化的分层联邦学习方法。背景技术随着大数据驱动的人工智能技术的蓬勃发展，AI算法在图像处理、语音识别等领域展现出了远超过传统方法的准确率和效率，因此被广泛应用于各行各业。然而数据的有效获取与维护却成为制约其发展的瓶颈，由于不同行业逐渐加大对数据隐私与安全的重视，因此各行各业的数据基本上都是以孤岛的形式存在。联邦学习是一种由多个客户端和一个聚合服务器参与的分布式机器学习架构，客户端既可以是个人的终端设备 ，也可以代表不同的部门或企业, 它负责保存用户的个人数据或组织的私有数据，客户端在本地训练模型，并将训练后的模型参数发送给聚合服务器；聚合服务器负责聚合部分或所有客户端的模型参数，将聚合后的模型同步到客户端开始新一轮的训练。这种联合协作训练的方式可以在保证模型性能的前提下，避免个人数据的泄露, 并有效解决数据孤岛的问题。在分散式联邦学习系统中，中央服务器执行更新聚合、客户端选择和全局模型维护的中心操作。服务器需要从众多客户端收集更新信息进行聚合操作，同时还需要向这些客户端广播新的全局模型，这对网络带宽提出了很高的要求。此外云服务提供商的稳定性也会影响基于云的服务器，中央服务器可以通过偏向某些客户端而扭曲全局模型，恶意的中央服务器可以破坏模型，甚至从更新中收集客户端的隐私。故在联邦学习中，虽然拥有训练数据的参与者能委托服务器接受并聚合共享的梯度，然而恶意的用户和服务器可能会通过上传恶意的更新梯度操纵全局模型，从而影响系统通信安全。发明内容本发明的目的是提供一种去中心化的分层联邦学习方法，该方法可以将联邦学习分为MEC服务器领导的边缘聚合和基于共识的全局聚合两阶段，从而排除恶意服务器的威胁，提高通信安全并降低系统通信开销。本发明的目的是通过以下技术方案实现的：一种去中心化的分层联邦学习方法，所述方法包括：步骤1、首先通过权威机构对联邦学习系统进行初始化；步骤2、将初始化后的联邦学习系统分为移动边缘计算服务器MEC领导的边缘聚合阶段和基于共识的全局聚合阶段；步骤3、在边缘聚合阶段，所述MEC服务器作为领导节点收集来自组内客户端的更新模型，并聚合为中间模型；步骤4、在全局聚合阶段，在区块链的辅助下通过各MEC服务器的共识来保证全局聚合结果的安全性。由上述本发明提供的技术方案可以看出，上述方法可以将联邦学习分为MEC服务器领导的边缘聚合和基于共识的全局聚合两阶段，从而排除恶意服务器的威胁，提高通信安全并降低系统通信开销。附图说明为了更清楚地说明本发明实施例的技术方案，下面将对实施例描述中所需要使用的附图作简单地介绍，显而易见地，下面描述中的附图仅仅是本发明的一些实施例，对于本领域的普通技术人员来讲，在不付出创造性劳动的前提下，还可以根据这些附图获得其他附图。图1为本发明实施例提供的去中心化的分层联邦学习方法流程示意图；图2为本发明实施例所述去中心化分层联邦学习的架构示意图。具体实施方式下面结合本发明实施例中的附图，对本发明实施例中的技术方案进行清楚、完整地描述，显然，所描述的实施例仅仅是本发明一部分实施例，而不是全部的实施例，这并不构成对本发明的限制。基于本发明的实施例，本领域普通技术人员在没有做出创造性劳动前提下所获得的所有其他实施例，都属于本发明的保护范围。如图1为本发明实施例提供的去中心化的分层联邦学习方法流程示意图，所述方法包括：步骤1、首先通过权威机构对联邦学习系统进行初始化；在该步骤中，在参与模型训练前，加入联邦学习系统的客户端n和MEC服务器m均需要通过权威机构TA的身份认证，成为拥有专属注册信息的合法实体，具体来说：客户端n使用权威机构公布的公共参数生成密钥对 ，并从所述权威机构处获得绑定其注册信息/＞ 的证书/＞作为唯一的身份标识符；然后用证书/＞加入联邦学习系统中；与客户端的注册流程类似，MEC服务器m生成密钥对，并获得绑定注册信息/＞的证书/＞；然后用证书/＞加入联邦学习系统中；其中，所述权威机构仅用于参数初始化，在运行区块链之前提供参与方的身份授权和证书颁发，在其余时间保持离线状态，故权威机构与去中心化并不冲突。步骤2、将初始化后的联邦学习系统分为移动边缘计算服务器MEC领导的边缘聚合阶段和基于共识的全局聚合阶段；步骤3、在边缘聚合阶段，所述MEC服务器作为领导节点收集来自组内客户端的更新模型，并聚合为中间模型；在该步骤中，在每个管理周期开始时，各客户端选择相应的MEC服务器作为中间聚合节点，MEC服务器作为领导节点将本组内的成员信息发布至区块链中；在边缘聚合阶段，MEC服务器将全局模型下发至本组内的客户端，组内客户端根据区块链中公布的全局模型哈希验证模型的正确性；然后组内客户端使用本地数据训练模型，并将更新后的模型提交至作为领导节点的MEC服务器；MEC服务器收集本组内客户端上传的更新模型，通过执行安全梯度聚合得到中间模型。举例来说，如图2所示为本发明实施例所述去中心化分层联邦学习的架构示意图，在边缘聚合阶段，MEC服务器管理N个客户端，客户端n利用本地数据训练得到的更新模型参数为；由于基于秘密分享的强保护机制可以在完全不暴露参数下实现安全聚合，但是具有较高的通信开销，因此本实例将客户端n更新的模型参数/＞分为关键参数/＞和其它参数/＞，强保护机制仅用于聚合关键参数/＞，其它参数/＞通过基于匿名的弱保护机制聚合；最后，MEC服务器将关键参数的聚合结果/＞和其它参数的聚合结果/＞拼接后得到中间模型的参数/＞。步骤4、在全局聚合阶段，在区块链的辅助下通过各MEC服务器的共识来保证全局聚合结果的安全性。在该步骤中，在全局聚合阶段，如图2所示，采用共识协议PoA搭设轻量级的区块链平台；其中，所述共识协议PoA是一种私有区块链网络的解决方案，在PoA区块链中，一组服务器被选择为权威节点，负责检查和验证所有交易；与传统的联邦学习架构相比，共识协议PoA提供了更高的可靠性，避免了单点故障问题，与公共区块链相比，共识协议PoA的性能更高，并且对计算和通信资源占用更低，可以支撑大规模的联邦学习系统；MEC服务器在执行步骤3的聚合后，将聚合的中间模型上传至共识协议PoA的权威节点；然后权威节点利用安全聚合机制将中间模型聚合，并将聚合后模型的哈希上传至区块链中，利用智能合约进行多数投票，得票数最多的模型作为全局模型；其中，为了保持区块链的性能，所述权威节点仅将全局模型的哈希和存储地址上传至区块链中，全局模型由权威节点验证并由链下发送至各MEC服务器，再由各MEC服务器下发至各参与方客户端；各参与方客户端使用区块链中的哈希验证全局模型的有效性后，再使用本地数据进行新一轮的模型训练。另外，具体实现中，区块链支撑的分层联邦学习方法可以保证聚合结果的安全性，但是无法保护用户隐私。在边缘聚合阶段，好奇的MEC服务器可以从收集的更新梯度中提取用户的隐私信息，因此针对边缘聚合中的隐私问题，本申请采用Shamir秘密分享隐藏关键梯度，并结合匿名机制隐藏用户身份，实现在不牺牲模型精度的前提下同时保护模型安全和用户隐私，具体来说：采用基于秘密分享的强保护方法在不暴露用户更新参数真实值的情况下实现安全聚合，在聚合过程中每个客户端都需要将更新参数的碎片发送至其它所有组内客户端，具有的通信开销，因此采用基于秘密分享的强保护方法聚合关键参数，利用可链接环签名实现对剩余模型参数的弱保护，将剩余模型参数的真实值传输至MEC服务器，但是用户身份被隐藏，故MEC服务器无法将接收的梯度与组内成员身份相关联，难以针对性提取目标用户的隐私。值得注意的是，本发明实施例中未作详细描述的内容属于本领域专业技术人员公知的现有技术。综上所述，本发明实施例所述方法具有如下优点：1、本申请使用区块链取代中央服务器实现联邦学习的去中心化，将联邦学习分为MEC服务器领导的边缘聚合和基于共识的全局聚合，以排除恶意服务器的威胁，并且降低系统通信开销；2、本申请采用Shamir秘密分享隐藏关键梯度，并结合匿名机制隐藏用户身份，实现在不牺牲模型精度的前提下同时保护模型安全和用户隐私。另外，本领域普通技术人员可以理解实现上述实施例方法中的全部或部分步骤是可以通过程序来指令相关的硬件完成，相应的程序可以存储于一种计算机可读存储介质中，上述提到的存储介质可以是只读存储器，磁盘或光盘等。以上所述，仅为本发明较佳的具体实施方式，但本发明的保护范围并不局限于此，任何熟悉本技术领域的技术人员在本发明披露的技术范围内，可轻易想到的变化或替换，都应涵盖在本发明的保护范围之内。因此，本发明的保护范围应该以权利要求书的保护范围为准。本文背景技术部分公开的信息仅仅旨在加深对本发明的总体背景技术的理解，而不应当被视为承认或以任何形式暗示该信息构成已为本领域技术人员所公知的现有技术。
