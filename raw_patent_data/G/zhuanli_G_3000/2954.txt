标题title
一种增强人机协作适应性的三体协同智能决策方法和系统
摘要abst
本发明公开了一种增强人机协作适应性的三体协同智能决策方法和系统，该方法包括：S1：真人做出自身行为决策集；S2：机器人做出自身行为决策集；S3：虚拟人做出全局决策集；S4：虚拟人将上述三种不同的决策集输入智能决策模型，根据多级适应性的优先级顺序判断决策项差异，从而优化决策项，生成最终决策集。本发明设计了虚拟人‑真人‑机器人三体协同系统进行智能决策，通过虚拟人的全局感知与认知结果，解决了人机协作过程中真人与机器人的感知与认知局限性，为智能决策提供了更加全面的认知基础。
权利要求书clms
1.一种增强人机协作适应性的三体协同智能决策方法，其特征在于，包括：步骤S1：真人基于局部感知信息与认知结果，做出自身行为决策集；步骤S2：机器人基于局部感知信息与认知结果，做出自身行为决策集；步骤S3：虚拟人基于全局感知信息与认知结果，将任务目标与人机动力学状态输入多尺度神经动力学网络，做出全局决策集；步骤S4：将上述三种不同的决策集输入智能决策模型，根据多级适应性的优先级顺序判断决策项差异，从而优化决策项，生成最终决策集。2.根据权利要求1所述的三体协同智能决策方法，其特征在于，所述真人决策集是由虚拟人根据感知设备采集的真人行为信息，分析得到的真人运动原语序列、行为标签、角色标签集合；所述机器人决策集是由虚拟人根据机器人传递的自身决策意图指令信息，生成的机器人运动原语序列、行为标签、角色标签集合；所述虚拟人决策集是由虚拟人根据感知设备采集的全局感知信息，分析任务目标与人机动力学状态，最后通过多尺度神经动力学网络生成的全局运动原语序列、行为标签、角色标签集合。3.根据权利要求1所述的三体协同智能决策方法，其特征在于，所述多尺度神经动力学网络的输入数据包含真人本体状态、机器人本体状态/＞和任务感受状态，其输出结果包含期望真人本体状态/＞、期望机器人本体状态/＞、期望任务感受状态/＞。4.根据权利要求1所述的三体协同智能决策方法，其特征在于，所述多尺度神经动力学网络基于循环神经网络框架进行设计，其输入层和输出层之间包含表征短时、中时、长时三个时间尺度层次的网络模块：SSL、MSL、LSL与表征参数偏差的PBL，其中SSL、MSL、LSL均由LSTM单元组成，SSL、MSL、LSL的细胞状态通过输入和遗忘门进行自更新，门控单元与候选记忆单元的输入参数包括本层隐藏状态与相邻层的状态参数，其他层之间不进行参数共享传播；输入层和输出层只与SSL进行参数传递，不和其他网络模块直接发生数据关联。5.根据权利要求4所述的三体协同智能决策方法，其特征在于，所述多尺度神经动力学网络的网络参数采用带时间反向传播的梯度下降法进行更新，使根据高斯假设设计的关于单元状态的似然函数最大化。6.根据权利要求1所述的三体协同智能决策方法，其特征在于，所述智能决策模型结构按照多级适应性的优先级顺序判断制定最终决策方案：角色适应性作为最高优先级判断，为人机分配主动者、配合者角色；行为适应性作为第二优先级判断，为人机选择与任务状态和角色相适应的动作行为；运动适应性作为第三优先级判断，为人机修正实现行为目标的运动规划；同时，在选择最终决策方案时，根据整体评价优化函数优化决策方案各决策项。7.根据权利要求6所述的三体协同智能决策方法，其特征在于，所述整体评价优化函数的公式如下：，其中，表示决策方案的介入程度，/＞表示决策方案的任务效果，/＞表示决策集/＞的维度，/＞表示决策集/＞的维度，/＞表示决策集/＞与/＞的维度，/＞表示两项之间的异或计算，相同得0，不同得1；/＞与/＞表示最终决策方案/＞与真人决策方案/＞的对应项，/＞与/＞表示最终决策方案/＞与机器人决策方案的对应项，第一行公式表示整体优化函数的计算方法，取函数值最小的方案/＞作为最终决策方案。8.一种增强人机协作适应性的三体协同智能决策系统，包括虚拟人、机器人、真人三个参与主体，且利用权利要求1-7中任一所述三体协同智能决策方法生成最终决策。
说明书desc
技术领域本发明属于人机协作技术领域，具体涉及人机协作的智能决策领域，特别涉及了一种增强人机协作适应性水平的三体协同智能决策方法和系统。背景技术人类用户和机器人合作完成预定义任务的一般过程成为人机协作。人机协作过程中，机器人具有高精度的运动特性，人则具有更高的灵活性和自主性，人机的任务协作过程中需要应对时空的复杂性，空间复杂性主要来源于共享空间中的变化或不确定性，比如任务目标、人、机器人的位置与位置关系，时间复杂性是由任务的特性引发的，例如任务分解为一系列的子任务以及人机在任务过程中的行为动作规划。人机之间如何实现自主决策与合作配合的博弈适应性，增强协作过程中彼此的适应性是人机协作任务的重要问题。人机对彼此动作行为的理解和应对策略成为人机协作的核心问题。目前大部分的研究只关注机器人的决策方法，仅从机器人对人的认知角度开展行为意图识别技术的研究，提高了单向的行为理解准确性。但是仍不能解决人机协作的双向信息理解问题，人机认知不一致的现象仍然存在，决策习惯与决策协同性仍不能统一，无法真正地实现人机协作任务中合作博弈过程的适应趋同。发明内容发明目的：为了解决上述技术问题，本发明提出一种增强人机协作适应性水平的三体协同智能决策方法和系统，将人机协作的适应性范围划分为“运动-行为-角色”三级适应性，基于虚拟人-真人-机器人三体协同框架中各主体的不同决策方案，在人机实时协作过程中通过智能决策模型对人机协作过程做出智能决策优化，引导增强人机协作适应性水平，改善人机提高人机协作效果。本发明将人机协作定义为人与机器人需要同时参与作业，发生自然物理交互的场景，人机协作的协同性定义为人机交互的适应性，并提出一种多级适应性划分标准以梳理人机协作中的时空复杂性问题，以多级适应性分析来代替时空复杂性分析。多级适应性划分标准将人机协作中的适应性划分为运动适应性、行为适应性和角色适应性，运动适应性表征动作执行产生的任务效果，行为适应性表征行为执行产生的任务效果和人机行为匹配性，角色适应性表征人机在协作过程中扮演角色的匹配性。数学形式如下：，其中，表示系统的整体适应性，/＞表示人机的运动适应性，表示人机的行为适应性，/＞表示人机的角色适应性，/＞、/＞、/＞则分别表示对应适应性在整体适应性中的权重系数。三级适应性之间并不是完全独立的，而是具有某些客观的约束规律。例如角色适应性中人机应为一个主动者和一个配合者，否则会发生冲突导致任务失败；行为适应性在满足任务执行逻辑的条件之外，则同时受到角色适应性的限制，配合者应选择与主动者行为配合的动作，否则会发生冲突；运动适应性除了提高运动精度的目标之外，运动轨迹规划与控制同时受到角色和行为的限制，运动轨迹应与行为相符，运动规划应与角色相符。利用这种多级适应性来分析和优化决策过程，通过各级适应性之间的约束和限制可使决策方案的制定过程更具逻辑性与合理性，降低决策的时空复杂性。基于此，本发明提供一种增强人机协作适应性的三体协同智能决策方法，包括以下步骤：步骤S1：真人基于自身感知信息与认知结果，做出自身行为决策集；步骤S2：机器人基于局部感知信息与认知结果，做出自身行为决策集；步骤S3：虚拟人基于全局感知信息与认知结果，将任务目标与人机动力学状态输入多尺度神经动力学网络，做出全局决策集；步骤S4：将上述三种不同的决策集输入智能决策模型，根据多级适应性的优先级顺序判断决策项差异，从而优化决策项，生成最终决策集。进一步的，所述真人决策集是由虚拟人根据感知设备采集的真人行为信息，通过模型分析得到的真人运动原语序列、行为标签、角色标签集合；所述机器人决策集是由虚拟人根据机器人传递的自身决策意图指令信息，生成的机器人运动原语序列、行为标签、角色标签集合；所述虚拟人决策集是由虚拟人根据感知设备采集的全局感知信息，分析任务目标与人机动力学状态，最后通过多尺度神经动力学网络生成的全局运动原语序列、行为标签、角色标签集合。进一步的，所述多尺度神经动力学网络的输入数据包含真人本体状态、机器人本体状态/＞和任务感受状态/＞，输出结果包含期望真人本体状态/＞、期望机器人本体状态/＞、期望任务感受状态/＞。各数据项通过/＞函数归一化到/＞区间。进一步的，所述多尺度神经动力学网络基于循环神经网络框架进行设计，其输入层和输出层之间包含表征短时、中时、长时三个时间尺度层次的网络模块：SSL、MSL、LSL与表征参数偏差的PBL，其中SSL、MSL、LSL均由LSTM单元组成，SSL、MSL、LSL的细胞状态通过输入和遗忘门进行自更新，门控单元与候选记忆单元的输入参数包括本层隐藏状态与相邻层的状态参数，其他层之间不进行参数共享传播；输入层和输出层只与SSL进行参数传递，不和其他网络模块直接发生数据关联。进一步的，所述多尺度神经动力学网络的网络参数可采用带时间反向传播的梯度下降法进行更新，使根据高斯假设设计的关于单元状态的似然函数最大化。进一步的，所述智能决策模型结构按照多级适应性的优先级顺序判断制定最终决策方案：角色适应性作为最高优先级判断，为人机分配主动者、配合者角色；行为适应性作为第二优先级判断，为人机选择与任务状态和角色相适应的动作行为；运动适应性作为第三优先级判断，为人机修正实现行为目标的运动规划；同时，在选择最终决策方案时，根据整体评价优化函数优化决策方案各决策项。进一步的，所述整体评价优化函数的公式如下：，其中，表示决策方案的介入程度，/＞表示决策方案的任务效果，/＞表示决策集/＞的维度，/＞表示决策集/＞的维度，/＞表示决策集与/＞的维度，/＞表示两项之间的异或计算，相同得0，不同得1；/＞与/＞表示最终决策方案/＞与真人决策方案/＞的对应项，/＞与/＞表示最终决策方案/＞与机器人决策方案/＞的对应项，第一行公式表示整体优化函数的计算方法，取函数值最小的方案作为最终决策方案。此外，本发明还提供了一种增强人机协作适应性的三体协同智能决策系统，包括虚拟人、机器人、真人三个参与主体，功能层次包括感知层、认知层、决策层、执行层，由此利用上述三体协同智能决策方法生成最终决策。有益效果：1、本发明设计了虚拟人-真人-机器人三体协同系统进行智能决策，通过虚拟人的全局感知与认知结果，解决了人机协作过程中真人与机器人的感知与认知局限性，为智能决策提供了更加全面的认知基础；2、本发明在虚拟人的决策过程中设计了多尺度神经动力学网络模型，从不同的时间尺度将运动、行为、角色三个层次的决策适应性统一起来，简化人机协作适应性决策的复杂程度，并提高了决策方案的适应性效果；3、本发明设计了兼顾介入程度最小化与任务效果最优的智能决策机制，在保证决策方案任务效果的条件下，减少任务干扰的频率，提高任务的连贯性与人机的舒适性。附图说明图1是本发明实施例的整体流程图；图2是本发明实施例中多尺度神经动力学网络的结构示意图；图3是本发明实施例中SSL内部的参数传递过程图；图4是本发明实施例中多尺度神经动力学网络各层之间的参数传递过程图；图5是本发明实施例中智能决策模型的决策过程图。实施方式以下结合附图和具体的实施例对本发明作进一步详细说明。根据下面的说明，本发明的优点和特征将更清楚。如图1所示为本实施例提供的一种增强人机协作适应性的三体协同智能决策方法，应用在三体协同任务执行的实时过程中，具体步骤如下：S1：真人基于局部感知信息与认知结果，做出自身行为决策集；所述真人决策集是由虚拟人根据感知设备采集真人的视频图像，通过设备标定与识别模型得到人的状态信息，通过数据化处理生成的真人运动原语序列、行为标签、角色标签集合。特别的，在本实施例中所述t时刻运动原语序列指人的运动信息，包括但不限于，对应{位置信息、双手位置信息，接触状态，形体状态，速度，……}等信息；行为标签包括但不限于，对应动作状态和运动状态等信息，其中动作状态可表征{抓取，释放，抬升，放置，移动，转弯，……}等信息，运动状态可表征{加速，减速，匀速，静止，……}等信息；角色标签{role_play}，可表征{主导人员，配合人员}等信息。S2：机器人基于局部感知信息与认知结果，做出自身行为决策集；所述机器人决策集是由虚拟人根据机器人传递的自身决策意图指令信息，生成的机器人运动原语序列、行为标签、角色标签集合。特别的，在本实施例中当机器人包含移动平台和7自由度机械臂时，其t时刻运动原语序列包含等信息，表征{位置信息，移动平台电机信息，机械臂关节信息，末端夹爪信息，……}等。行为标签与角色标签与S1类似。S3：虚拟人基于全局感知信息与认知结果，将任务目标与人机动力学状态反馈输入多尺度神经动力学网络，做出全局决策集；所述虚拟人决策集是由虚拟人根据感知设备采集的全局感知信息，分析任务目标与人机动力学状态，最后通过多尺度神经动力学网络生成的全局运动原语序列、行为标签、角色标签集合。整体组成与所述S1，S2中类似，扩展为人与机器人的信息综合。/＞如图2所示，多尺度神经动力学网络结构包括：Ⅰ、Input Layer；Ⅱ、Short-time Scale Layer；Ⅲ、Medium-time Scale Layer；Ⅳ、Long-time Scale Layer；Ⅴ、Parametric Bias Layer；Ⅵ、Output Layer。输入层的输入数据序列格式包含真人本体状态、机器人本体状态/＞和任务感受状态/＞；输出层的输出结果序列格式包含期望真人本体状态/＞、期望机器人本体状态/＞、期望任务感受状态/＞。各数据项通过/＞函数归一化到区间。输入层和输出层之间包含表征短时、中时、长时三个时间尺度层次的网络模块：SSL、 MSL、 LSL，以及表征参数偏差的PBL，不同网络层次间按照一定的约束进行连接。网络参数的优化方式可采用带时间反向传播的梯度下降法进行更新，使根据高斯假设设计的关于单元状态的似然函数最大化。SSL表征快速动态过程，通过训练获得运动原语详细表示，最小化运动预测误差；MSL表征中速动态过程，通过训练获得行为标签表示，最小化行为选择误差；LSL表征慢速动态过程，通过训练获得角色标签表示，最小化角色选择误差。SSL、MSL、LSL均由LSTM单元组成，以SSL为例，其参数传递的网络结构如图3所示，其中与/＞表示sigmoid和tanh函数，/＞表示输入门、遗忘门、输出门等门控单元，表示向量加法，FCL表示全连接层。如图4所示，所述各层之间的连接约束包括：SSL、MSL、LSL的细胞状态通过输入和遗忘门进行自更新，门控单元与候选记忆单元的输入参数包括本层隐藏状态ht-1与相邻层的状态参数ht-1，其他层之间不进行参数共享传播，有助于改善不同时间尺度的时间动态性约束和功能层次的自组织。输入层和输出层只与SSL进行参数传递，不和其他网络模块直接发生数据关联。所述输入输出层为全连接层，神经元数目根据输入输出数据维度设置。特别的，当输入输出数据维度为32时，输入输出层的单元数均为32。SSL、MSL、LSL各层门控中的隐藏单元数目可按照数据规模与数据维度调整。特别的，当输入输出数据维度为32，每个批次样本数为64时，SSL、MSL、LSL的隐藏单元数目可分别设置为200、20、2。PBL用参数偏差来表征任务类型，单元数设置为2，可根据任务类型数目进行调整。S4：虚拟人将上述三种不同的决策集输入智能决策模型，根据多级适应性的优先级顺序判断决策项差异，从而优化决策项，生成最终决策集，并传达给各主体执行。如图5所示，智能决策模型按照多级适应性的优先级顺序判断制定最终决策方案：角色适应性作为最高优先级判断，为人机合理分配主动者、配合者角色；行为适应性作为第二优先级判断，为人机合理选择与任务状态和角色相适应的动作行为；运动适应性作为第三优先级判断，为人机修正实现行为目标的运动规划。同时，在选择最终决策方案时，设计整体评价优化函数优化决策方案各决策项。整体评价优化函数兼顾考虑生成介入程度最小与任务效果最优，优化函数的公式如下：。具体的，第一行公式表示整体优化函数的计算方法，取函数值最小的方案作为最终决策方案，第二、三行公式分别为介入程度和任务效果的计算方法，介入程度计算时分别对人和机器人的介入程度展开计算。其中，表示决策方案的介入程度，/＞表示决策方案的任务效果，/＞表示决策集/＞的维度，/＞表示决策集/＞的维度，/＞表示决策集与/＞的维度。/＞表示两项之间的异或计算，相同得0，不同得1；/＞与/＞表示最终决策方案/＞与真人决策方案/＞的对应项，/＞与/＞表示最终决策方案/＞与机器人决策方案/＞的对应项。本实施例中，所述三体协同框架中的参与主体为虚拟人、机器人、真人，功能层次包括感知层、认知层、决策层、执行层。具体的，虚拟人为分布式云端智能体，是协作过程最高级别的观察者与决策者，具有所有感知信息的集成能力与综合的智能决策能力；人与机器人是协作过程的行动者，具有局部感知能力和决策能力。感知层包括人的视/听/触觉、机器人的视/听/触觉传感器、空间图像传感器等，实时获取全局感知信息包括对环境、真人和机器人的感知信息；认知层包括三个主体的认知能力，对各自获取的感知信息做出认知判断；决策层包括三个主体的决策能力以及一个智能决策模型，对任务执行方案做出决策和调整优化；执行层包括真人与机器人的执行终端，对决策方案进行执行完成任务。上述描述仅是对本发明较佳实施例的描述，并非对本发明权利范围的任何限定，任何本领域技术人员在不脱离本发明的精神和范围内，都可以利用上述揭示的方法和技术内容对本发明技术方案做出可能的变动和修改，因此，凡是未脱离本发明技术方案的内容，依据本发明的技术实质对以上实施例所作的任何简单修改、等同变化及修饰，均属于本发明技术方案的保护范围。
