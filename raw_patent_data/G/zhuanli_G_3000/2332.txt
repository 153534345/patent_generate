标题title
基于深度强化学习的车联网动态信标广播方法及系统
摘要abst
本发明涉及一种基于深度强化学习的车联网动态信标广播方法及系统，包括设置车联网通信机制和中央深度强化学习网络的参数，以及设置每一轮训练实验环境单位时间内生成车流量和实验车辆类型比例，其中实验车辆类型包括智能体车辆与普通车辆；在每个时间步起始时刻获取确定的智能体车辆的本地状态信息，使用本地状态信息对中央深度强化学习网络进行训练，得到训练好的中央深度强化学习网络；将训练好的中央深度强化学习网络部署于模拟交通环境中用于测试。本发明能够更好地区分出不同交通风险程度的车辆并给予其合适的通信信标频率进行安全消息广播，有效地减小高风险车辆与邻近车辆共享自身信息的通信时延，在城市交通环境下有着更好的安全性。
权利要求书clms
1.一种基于深度强化学习的车联网动态信标广播方法，其特征在于：包括：设置车联网通信机制和中央深度强化学习网络的参数，以及设置每一轮训练实验环境单位时间内生成车流量和实验车辆类型比例，其中实验车辆类型包括智能体车辆与普通车辆，普通车辆用于协助智能体车辆对中央深度强化学习网络进行训练；在每个时间步起始时刻获取确定的智能体车辆的本地状态信息，使用所述智能体车辆当前时间步的本地状态信息对中央深度强化学习网络进行训练，得到训练好的中央深度强化学习网络；将训练好的中央深度强化学习网络部署于模拟交通环境中用于测试；其中，使用所述智能体车辆当前时间步的本地状态信息对中央深度强化学习网络进行训练的方法，包括：将所述智能体车辆当前时间步的本地状态信息输入至中央深度强化学习网络中，经过所述中央深度强化学习网络处理后输出所述智能体车辆当前时间步选择的信标频率，并将所述信标频率返回至对应的智能体车辆；所述智能体车辆根据接收到的所述信标频率进行信标广播，并对所述中央深度强化学习网络的参数进行更新，其中智能体车辆动态信标的信标频率决策使用一离散时间的马尔科夫决策方法。2.根据权利要求1所述的基于深度强化学习的车联网动态信标广播方法，其特征在于：在每个时间步起始时刻获取确定的智能体车辆的本地状态信息的方法，包括：对确定的智能体车辆进行车辆交通风险评估，根据车辆交通风险评估结果计算得到车辆通信需求等级，其中所述车辆交通风险评估包括直行追尾风险评估、启动追尾风险评估以及交叉路口内行驶风险评估；根据车辆通信需求等级计算得到当前信道质量/＞，将车辆通信需求等级/＞和当前信道质量/＞联合成向量/＞作为智能体车辆/＞的综合状态/＞；将智能体车辆的综合状态/＞和当前时间步/＞的邻接矩阵/＞联合成本地状态信息。3.根据权利要求1所述的基于深度强化学习的车联网动态信标广播方法，其特征在于：在中央深度强化学习网络的训练过程中采用时间步的划分机制，时间步的划分机制为分散式时间步机制。4.根据权利要求1或3所述的基于深度强化学习的车联网动态信标广播方法，其特征在于：所述中央深度强化学习网络包括多层感知器、图注意模块和DQN模块，所述图注意模块包括堆叠的两层GAT网络层，所述GAT网络层采用多头点积注意模块机制；所述DQN模块包括Q网络和目标Q网络，所述目标Q网络和所述Q网络的结构相同。5.根据权利要求4所述的基于深度强化学习的车联网动态信标广播方法，其特征在于：在智能体车辆动态信标的信标频率决策过程中，设置智能体车辆在当前时间步/＞做出动作后通信环境反馈的奖励函数/＞为：，其中，表示发射的信标被接收的数量，/＞表示上一时间步发射出去的数量，/＞表示该信标发射需求等级标准发射频率，/＞表示智能体车辆/＞在当前时间步/＞的通信需求等级，/＞表示智能体车辆/＞在当前时间步/＞的信道质量，/＞和/＞为可调节参数。6.根据权利要求5所述的基于深度强化学习的车联网动态信标广播方法，其特征在于：在中央深度强化学习网络的训练过程中，对所述中央深度强化学习网络的参数进行更新包括对目标Q网络的参数进行更新。7.根据权利要求6所述的基于深度强化学习的车联网动态信标广播方法，其特征在于：对目标Q网络的参数进行更新的方法，包括：中央深度强化学习网络在用于存放经验元组的经验回放池选取一批次经验元组，记做/＞，其中，/＞表示智能体车辆/＞当前时间步/＞的综合状态，表示智能体车辆/＞当前时间步/＞的邻接矩阵，/＞表示对应智能体车辆/＞信标频率结果的动作，/＞表示智能体车辆/＞时间步/＞的综合状态，/＞表示智能体车辆/＞时间步/＞的邻接矩阵，/＞表示智能体车辆/＞在当前时间步/＞做出动作/＞后通信环境反馈的奖励函数；将中所有的邻近车辆信息/＞和/＞输入到多层感知器中，多层感知器输出两个对应的集合为/＞和/＞，并将/＞中/＞和/＞输入到多层感知器中，得到特征向量/＞和/＞；将、/＞和/＞输入到第一层GAT网络层中获得特征向量/＞，将/＞、和/＞输入到第一层GAT网络层中获得特征向量/＞；将特征向量输入到第二层GAT网络层中获得特征向量/＞，将特征向量/＞输入到第二层GAT网络层中获得特征向量/＞；将特征向量输入到Q网络中，并将特征向量/＞输入到目标Q网络中，分别表示为/＞和；中央深度强化学习网络根据和/＞对目标Q网络的参数进行更新。8.一种基于深度强化学习的车联网动态信标广播系统，其特征在于：包括：设置模块，其用于设置车联网通信机制和中央深度强化学习网络的参数，以及设置每一轮训练实验环境单位时间内生成车流量和实验车辆类型比例，其中实验车辆类型包括智能体车辆与普通车辆，普通车辆用于协助智能体车辆对中央深度强化学习网络进行训练；训练模块，其用于在每个时间步起始时刻获取确定的智能体车辆的本地状态信息，使用所述智能体车辆当前时间步的本地状态信息对中央深度强化学习网络进行训练，得到训练好的中央深度强化学习网络；部署模块，其用于将训练好的中央深度强化学习网络部署于模拟交通环境中用于测试；其中，使用所述智能体车辆当前时间步的本地状态信息对中央深度强化学习网络进行训练的方法，包括：将所述智能体车辆当前时间步的本地状态信息输入至中央深度强化学习网络中，经过所述中央深度强化学习网络处理后输出所述智能体车辆当前时间步选择的信标频率，并将所述信标频率返回至对应的智能体车辆；所述智能体车辆根据接收到的所述信标频率进行信标广播，并对所述中央深度强化学习网络的参数进行更新，其中智能体车辆动态信标的信标频率决策使用一离散时间的马尔科夫决策方法。9.一种计算机设备，包括存储器、处理器及存储在存储器上并可在处理器上运行的计算机程序，其特征在于：所述处理器执行所述程序时实现权利要求1至7任一项所述方法的步骤。10.一种计算机可读存储介质，其上存储有计算机程序，其特征在于：该程序被处理器执行时实现权利要求1至7任一项所述方法的步骤。
说明书desc
技术领域本发明涉及车辆无线通信技术领域，尤其是指一种基于深度强化学习的车联网动态信标广播方法及系统。背景技术随着车辆间通信技术的进步，车辆不再是信息孤岛，这极大地影响着交通的格局。网联车辆可以通过V2V通信将由车载计算机、控制系统、车载传感器产生的自身状态信息进行广播，使之有效地在邻近的车辆或者多跳集范围车辆之间传播。在此基础上构建的车载自组织网络即是车联网，其在加强车辆安全和提高交通效率方面具有巨大潜力。在VANETs中，每辆车都配备了无线通信系统，车辆使用信标作为信息交换方式进而实现车辆间的相互交换信息。基于IEEE 802.11p，车辆在控制信道上周期性地广播信标消息，以向通信环境中的邻近车辆通知自身的当前状态。邻近车辆可以通过分析这些消息中的信息来感知交通风险以避免潜在的交通事故。当前存在许多车联网动态信标方法的研究，其中E. Egea-Lopez等人提出了一种公平的自适应信标频率控制方法，该方法使用一种特殊的比例梯度投影算法来解决网络效用最大化问题。该方法在多跳通信和动态场景中，能够实现公平的信标频率分配。L.Zhang等人提出了一种分布式算法来调整传输概率，该算法考虑了在每个无线链路上传输的分组的安全优点，将问题公式化为网络效用最大化问题，与其他的分布式拥塞控制算法相比，该方法能够在信道资源分配方面更好地考虑到处于关键安全地位的邻居车辆的信息传输需求。但是E.Egea-Lopez等人和L. Zhang等人提出的信标频率控制方案都制定了网络效用最大化问题来进行信标频率控制。然而，这两个方案的控制函数是基于诸如一跳集邻近的速度之和以及到一跳邻近的相对距离之和的信息来定义的，这很难精确地感知单个车辆的安全需求。Feng L 等人提出的ABC算法是基于车辆追尾危险系数的动态信标频率控制方案，该方案提出来基于追击问题的危险系数，并基于危险系数进行车辆通信信标频率分配。相较于先前的研究，ABC算法既考虑到了信道资源，也考虑不同危险等级车辆的对安全消息广播通信的需求，一定程度上解决了之前文献提出的方案在安全驾驶方面应用的不足。但是其对车辆安全消息广播通信的需求处理依旧有一些关键问题没有解决。第一，在通信方面，ABC算法只关注到信道负载这个问题，没有考虑到影响信道质量不止信道负载这一个因素。事实上，如信噪比、信标碰撞率同样会影响通信质量。而且ABC算法中，车辆通过监听信道能够感知当前环境的信道负载情况，虽然分布式V2V通信的车与车之间并不知道相互具体的信标频率，但这些车辆会基于监听到的信道负载作为信标选择的控制指标，因此在做信标频率选择时，通信环境中的车辆会不约而同地将整个信道引向信道满占用的方向。然而事实上，在城市交通的通信环境中，并不是信道利用率越高就越好，想要实现风险信息的及时共享，重点关注高风险车辆的信道需求即可。而且高负载的信道环境预留的信道资源往往不足，导致通信环境缺少冗余的信道时隙资源，难以应对一些突发事件对信道时隙资源的需求。第二，该方案在评估车辆交通风险上存在不足，方案中提出的车辆追尾危险系数只能评估两辆正在同时进行匀变速运动的车辆的前后追尾风险的交通情况，若其中一辆车不是匀变速运动则该方案的追尾危险系数公式将失效。而且该方案只适用于直线路段的车辆追尾问题，现实城市交通环境中存在不少非直线路段，如交叉路口的转弯车行道，这些路段车辆同样存在着交通风险需要去考虑。事实上，现实城市交通环境中车辆所面临的交通风险远远不止追尾碰撞，因此仅用一个适用于直线路段的追尾公式很难有效评估城市交通环境中车辆的交通风险情况。综上，在复杂的城市交通环境下，车辆的交通风险往往会受到多方面因素的影响，然而当前存在交通风险评估方法能够考虑到的交通场景有限，难以较为全面地评估复杂的城市交通场景下的车辆风险情况。发明内容为此，本发明所要解决的技术问题在于克服现有技术中存在的技术缺陷，而提出一种基于深度强化学习的车联网动态信标广播方法及系统，其能够更好地区分出不同交通风险程度的车辆并给予其合适的通信信标频率进行安全消息广播，有效地减小高风险车辆与邻近车辆共享自身信息的通信时延，在城市交通环境下有着更好的安全性。为解决上述技术问题，本发明提供了一种基于深度强化学习的车联网动态信标广播方法，包括：设置车联网通信机制和中央深度强化学习网络的参数，以及设置每一轮训练实验环境单位时间内生成车流量和实验车辆类型比例，其中实验车辆类型包括智能体车辆与普通车辆，普通车辆用于协助智能体车辆对中央深度强化学习网络进行训练；在每个时间步起始时刻获取确定的智能体车辆的本地状态信息，使用所述智能体车辆当前时间步的本地状态信息对中央深度强化学习网络进行训练，得到训练好的中央深度强化学习网络；将训练好的中央深度强化学习网络部署于模拟交通环境中用于测试；其中，使用所述智能体车辆当前时间步的本地状态信息对中央深度强化学习网络进行训练的方法，包括：将所述智能体车辆当前时间步的本地状态信息输入至中央深度强化学习网络中，经过所述中央深度强化学习网络处理后输出所述智能体车辆当前时间步选择的信标频率，并将所述信标频率返回至对应的智能体车辆；所述智能体车辆根据接收到的所述信标频率进行信标广播，并对所述中央深度强化学习网络的参数进行更新，其中智能体车辆动态信标的信标频率决策使用一离散时间的马尔科夫决策方法。在本发明的一个实施例中，在每个时间步起始时刻获取确定的智能体车辆的本地状态信息的方法，包括：对确定的智能体车辆进行车辆交通风险评估，根据车辆交通风险评估结果计算得到车辆通信需求等级，其中所述车辆交通风险评估包括直行追尾风险评估、启动追尾风险评估以及交叉路口内行驶风险评估；根据车辆通信需求等级计算得到当前信道质量/＞，将车辆通信需求等级/＞和当前信道质量/＞联合成向量/＞作为智能体车辆/＞的综合状态/＞；将智能体车辆的综合状态/＞和当前时间步/＞的邻接矩阵/＞联合成本地状态信息。在本发明的一个实施例中，在中央深度强化学习网络的训练过程中采用时间步的划分机制，时间步的划分机制为分散式时间步机制。在本发明的一个实施例中，所述中央深度强化学习网络包括多层感知器、图注意模块和DQN模块，所述图注意模块包括堆叠的两层GAT网络层，所述GAT网络层采用多头点积注意模块机制；所述DQN模块包括Q网络和目标Q网络，所述目标Q网络和所述Q网络的结构相同。在本发明的一个实施例中，在智能体车辆动态信标的信标频率决策过程中，设置智能体车辆在当前时间步做出动作后通信环境反馈的奖励函数为：，其中，表示发射的信标被接收的数量，表示上一时间步发射出去的数量，表示该信标发射需求等级标准发射频率，表示智能体车辆在当前时间步的通信需求等级，表示智能体车辆在当前时间步的信道质量，和为可调节参数。在本发明的一个实施例中，在中央深度强化学习网络的训练过程中，对所述中央深度强化学习网络的参数进行更新包括对目标Q网络的参数进行更新。在本发明的一个实施例中，对目标Q网络的参数进行更新的方法，包括：中央深度强化学习网络在用于存放经验元组的经验回放池选取一批次经验元组，记做，其中，表示智能体车辆当前时间步的综合状态，表示智能体车辆当前时间步的邻接矩阵，表示对应智能体车辆信标频率结果的动作，表示智能体车辆时间步的综合状态，表示智能体车辆时间步的邻接矩阵，表示智能体车辆在当前时间步做出动作后通信环境反馈的奖励函数；将中所有的邻近车辆信息和输入到多层感知器中，多层感知器输出两个对应的集合为和，并将中和输入到多层感知器中，得到特征向量和；将、和输入到第一层GAT网络层中获得特征向量，将、和输入到第一层GAT网络层中获得特征向量；将特征向量输入到第二层GAT网络层中获得特征向量，将特征向量输入到第二层GAT网络层中获得特征向量；将特征向量输入到Q网络中，并将特征向量输入到目标Q网络中，分别表示为和；中央深度强化学习网络根据和对目标Q网络的参数进行更新。此外，本发明还提供了一种基于深度强化学习的车联网动态信标广播系统，包括：设置模块，其用于设置车联网通信机制和中央深度强化学习网络的参数，以及设置每一轮训练实验环境单位时间内生成车流量和实验车辆类型比例，其中实验车辆类型包括智能体车辆与普通车辆，普通车辆用于协助智能体车辆对中央深度强化学习网络进行训练；训练模块，其用于在每个时间步起始时刻获取确定的智能体车辆的本地状态信息，使用所述智能体车辆当前时间步的本地状态信息对中央深度强化学习网络进行训练，得到训练好的中央深度强化学习网络；部署模块，其用于将训练好的中央深度强化学习网络部署于模拟交通环境中用于测试；其中，使用所述智能体车辆当前时间步的本地状态信息对中央深度强化学习网络进行训练的方法，包括：将所述智能体车辆当前时间步的本地状态信息输入至中央深度强化学习网络中，经过所述中央深度强化学习网络处理后输出所述智能体车辆当前时间步选择的信标频率，并将所述信标频率返回至对应的智能体车辆；所述智能体车辆根据接收到的所述信标频率进行信标广播，并对所述中央深度强化学习网络的参数进行更新，其中智能体车辆动态信标的信标频率决策使用一离散时间的马尔科夫决策方法。并且，本发明还提供一种计算机设备，包括存储器、处理器及存储在存储器上并可在处理器上运行的计算机程序，所述处理器执行所述程序时实现上述所述方法的步骤。还有，本发明还提供一种计算机可读存储介质，其上存储有计算机程序，该程序被处理器执行时实现上述所述方法的步骤。本发明的上述技术方案相比现有技术具有以下优点：本发明所述的一种基于深度强化学习的车联网动态信标广播方法及系统，其融合智能体车辆的组合信息不断的训练中央深度强化学习网络，显著提升自身的信标频率决策能力，能够更好地区分出不同交通风险程度的车辆并给予其合适的通信信标频率进行安全消息广播，有效地减小高风险车辆与邻近车辆共享自身信息的通信时延，在城市交通环境下有着更好的安全性。附图说明为了使本发明的内容更容易被清楚的理解，下面根据本发明的具体实施例并结合附图，对本发明作进一步详细的说明。图1是本发明提出的中央深度强化学习网络训练示意图。图2是本发明提出的分散式时间步划分示意图。图3是本发明提出的中央深度强化学习网络的结构示意图。图4是本发明提出的基于多头注意力的车辆状态相关性示意图。图5是本发明提出的深度强化学习实验环境示意图。图6是本发明提出的信标频率组的状态转换示意图。具体实施方式下面结合附图和具体实施例对本发明作进一步说明，以使本领域的技术人员可以更好地理解本发明并能予以实施，但所举实施例不作为对本发明的限定。本发明实施例提供一种基于深度强化学习的车联网动态信标广播方法，包括以下步骤：步骤S1：设置车联网通信机制和中央深度强化学习网络的参数，以及设置每一轮训练实验环境单位时间内生成车流量和实验车辆类型比例，其中实验车辆类型包括智能体车辆与普通车辆，普通车辆用于协助智能体车辆对中央深度强化学习网络进行训练；步骤S2：在每个时间步起始时刻获取确定的智能体车辆的本地状态信息，使用所述智能体车辆当前时间步的本地状态信息对中央深度强化学习网络进行训练，得到训练好的中央深度强化学习网络；步骤S3：将训练好的中央深度强化学习网络部署于模拟交通环境中用于测试。其中，在步骤S1中，设置车联网通信机制为基于TDMA的信标通信机制，基于TDMA的信标通信机制包括以下内容：1.时隙划分机制：在基于TDMA的MAC协议中，通信信道的资源具体表现为时隙，通信时间被划分成连续的帧，每个帧中都包含相同数量的连续时隙，帧中的时隙长度固定且连续。MAC协议选择时隙对信标进行广播，每个信标只能选择占用一个时隙。MAC协议通过时隙选择来控制信标之间的间隔，进而满足基于信标通信的安全消息广播在时延方面的性能要求。优选的，本实施例记帧长为，记时隙长度为，每帧由个时隙组成，一个时间步由个帧组成，其中为2的次幂。车辆间在组成通信环境时约定一个通信起始时间，用来协助通信车辆计算当前所处的时间对应的帧号和时隙号，对应计算公式如下：，，。2.分散式时间步机制：车辆在时刻成功接收环境中其他车辆广播的信标后进入通信环境，通过解析信标中的信息获得的当前车联网通信环境的信道信息，信道信息包括信道帧与时隙设置信息和信道通信起始时间。通信环境中的车辆根据信道帧与时隙设置信息和信道通信起始时间就可以使用公式将时间划分成具体时隙推算出该通信环境的帧序列表与时隙表，进而得出具体时间对应的帧号时隙号组。本实施例将车辆进入通信环境的时间对应的帧号记为。车辆进入新的通信环境后需要持续监听个完整的帧，在帧号为的帧进入主动的信标发射的阶段，此时帧序列作为该车辆的第一个时间步。同一通信环境内的所有车辆均采用相同的帧与时隙的划分机制，所有车辆采用全局性的帧号与时隙号，即环境中所有车辆在同一时刻的帧号时隙号组是完全相同的。而时间步的划分机制却与帧号与时隙号划分机制不一样，时间步的划分机制具有局部性，即通信环境中的车辆只知道自身时间步的划分，而并不知道环境中其他车辆时间步的划分。由于每个时间步中的帧数固定为个帧，因此车辆在确定自身通信的第一个时间步的起始时间的同时就确定了该车辆在通信环境中所有时间步的起始时间，所以在同一通信环境下车辆的时间步起始时间只受车辆进入通信环境的时间的影响。如图2所示，对于车辆，它的每个时间步可用帧序列表示为，其中为整数且。车辆在每个时间步开始的时刻进行信标频率控制，车辆选择自己的车辆通信起始帧的同时就确定了车辆以后所有进行信标决策的时间，车辆的所有信标决策时间可表示为。车辆进入通信环境的时间具有一定的随机性，因此其对应的帧号也是具有随机性的，的结果将随机地分布整数区间内。对于车辆和车辆来说，如果则表示若它们同时存在于一个通信环境则它们会有相同的信标决策时间集合，这个时间集合可以表示为，因此可以将通信环境中所有车辆的根据车辆信标决策时间将它们分成个集合，记为集合，其中。该时间步机制依据信标频率决策时间将环境中的车辆随机地分散到个组，有效避免它们的信标频率决策时间过于集中，缓解了环境中因大量的车辆同时改变信标频率而导致了通信环境急剧变化的问题，有效解决了因车辆信标频率控制朝着频率同时增大或减小而导致的通信环境中突然的信道高负载和信道空闲问题，从而提升了车联网通信的稳定性和可靠性。车辆在向通信环境中的其它成员车辆广播信标后将正式成为进入这个通信环境。车辆在时刻及其之后的每个时间步开始的时候信标决策程序做出信标频率的决策得出该时间步本车辆需要发射的信标数量，然后将这个数值传递给MAC协议。MAC协议根据过往的时隙表占用情况选择与需要发射的信标数量数值相对应的时隙作为发射时隙，车辆的通信模块将在选定的发射时隙时对信标进行广播。在信标频率方面，本发明将一个时间步设置为个帧，其中。车辆在一个帧中最多只能选一个时隙广播信标，表示车辆在一个时间步内广播z个信标。其中，在步骤S2中，在每个时间步起始时刻获取确定的智能体车辆的本地状态信息的方法，包括对确定的智能体车辆进行车辆交通风险评估，根据车辆交通风险评估结果计算得到车辆通信需求等级，其中所述车辆交通风险评估包括直行追尾风险评估、启动追尾风险评估以及交叉路口内行驶风险评估；根据车辆通信需求等级计算得到当前信道质量，将车辆通信需求等级和当前信道质量联合成向量作为智能体车辆的综合状态；将智能体车辆的综合状态和当前时间步的邻接矩阵联合成本地状态信息。本实施例将车辆交通风险依据实际状况分别进行了直行追尾风险评估、启动追尾风险评估以及交叉路口内行驶风险评估这三类车辆交通风险评估，具体包括如下内容：1.直行追尾风险评估：考虑车辆追尾的碰撞风险情况，本发明方法根据前后车的行驶速度、加速度以及当前两车的距离，通过运动学公式计算前后两车预计相撞的剩余时间。本实施例提出了碰撞剩余时间这个指标表示该问题下车辆的碰撞风险水平，对于同一车道的前后辆车的碰撞剩余时间表示为：，其中表示前后两车之间的碰撞剩余时间，表示前车的速度，表示前车加速度，表示后车速度，表示后车加速度，表示前后车辆的距离。在追尾碰撞的交通风险评估中，车辆与前后车辆之间的碰撞剩余时间越短则车辆潜在的碰撞风险越大，需要提前加大信标频率向邻近车辆及时准确地更新自身状态的需求越大。为了将这类车辆的通信需求程度进行区分，本发明为碰撞剩余时间设置了三个阈值、、，这三个阈值将该问题下车辆依据碰撞剩余时间划分为了4类，分别对应车辆通信需求等级。2.启动追尾风险评估：本发明考虑了在交叉路口外直线路段排队等待的车辆，相较于其他交通环境，城市交通环境有着数量多且密度大的交叉路口以及与之配套的交通信号灯。由于城市车辆多，且交叉路口连接各个城市路段，起着一定程度上的枢纽作用，车辆需要通过交叉路口，而交通信号灯的红灯信号通常持续30秒到90秒，少数情况甚至可能达到180秒，这就导致交叉路口外往往会聚集大量排队等待信号灯的车辆。虽然这些排队等待的车辆当前都处于相同的静止状态，但是由于等待队列的排队顺序不同，导致它们潜在的风险的不同的，需要进行相应的区分。本发明观察到在交叉路口外等待的车辆进入启动状态要达到两个条件，一是交通信号灯指令变成允许通行，二是队列前方的车辆启动并与本车有安全距离。结合这些特征，本发明提出基于禁止通行剩余时间和队列顺序的车辆风险计算方法。综合上述因数，本发明提出了启动剩余时间这个指标表示该问题下车辆的交通风险水平，路口等待车辆的启动剩余时间计算公式如下:，其中表示每辆车启动并与后车生成安全距离的反应时间，表示当前时刻交通信号灯禁止信号通行剩余时间，表示当前车辆在路口排队等待队列中的顺序，表示启动剩余时间。在排队等待的交通风险评估中，排队等待车辆的时间离信号绿灯信号越近、排队序号越靠前则车辆潜在的交通风险越大，需要提前加大信标频率向邻近车辆及时广播安全消息。由于排队等待问题中车辆处于静止状态，排队等待问题中交通风险发生的概率较小，因此排队等待车辆通常不会出现极高安全消息广播需求的情况，只需要使用信标通信为车辆启动提供必要的安全消息广播。只需占用较小的信道资源就可能满足安全消息广播，这时就可以将更多的信道资源分配给其他更有需要的车辆。本发明为启动剩余时间设置两个阈值、，阈值、将该问题下车辆分为了3类，这3类分别对应了车辆通信需求等级中的。3.交叉路口内行驶风险评估：交叉路口内的车道情况较为直线路段更为复杂，除了直行道还有转弯道，车辆不仅要关注前后车辆发生追尾碰撞的危险，也要关注与其他路段的车辆发生交通风险。同时车辆在交叉路口内行驶过程中，其交通风险也会受到交通信号灯的影响。本发明评估方法根据行驶在交叉路口内车辆的行驶状态进行交通风险评估，评估依据包括当前车辆行驶的车道类型以及当前车辆是否在行驶在信号灯黄灯相位状态下。交叉路口内车辆可以基于当前的交通环境进行分类，即依据当前车辆行驶的行驶方向以及是否处于黄灯状态下进行分类。本发明提出了交叉路口中车辆的交通风险等级这个评估指标表示该交通环境下车辆的交通风险水平，计算公式如下:，其中表示交叉路口中车辆的交通风险等级，表示交叉路口中车辆行驶的车道，为0代表在路口中的直行车道行驶，为1表示在路口中转弯车道行驶。表示车辆行驶在交叉路口时，交通信号灯的颜色，为0代表绿灯，为1代表黄灯。在交叉路口内行驶的交通风险评估中，交叉路口内车辆整体的交通风险相较于其他交通环境下的车辆要明显高许多，因此本发明根据交通信号灯的信号相位和车辆行驶路段种类将此环境下的车辆分为了2类，分别对应了车辆通信需求等级中的。上述车辆通信需求等级划分的具体划分规则包括4个规则为：规则1：通信需求等级为1对应的车辆状态为：碰撞剩余时间大于的直行车辆；启动剩余时间大于的路口等待车辆。规则2：通信需求等级为2对应的车辆状态为碰撞剩余时间在范围内的直行车辆；启动剩余时间在范围内路口等待车辆。规则3：通信需求等级为3对应的车辆状态为：碰撞剩余时间在之间的直行车辆；启动剩余时间在范围内的围内路口等待车辆；绿灯下行驶或者在黄灯下直行交叉路口内车辆即。规则4：通信需求等级为4对应的车辆状态为：碰撞剩余时间在范围内的直行车辆；在黄灯下转弯行驶的交叉路口内车辆即。其中，在步骤S2中，使用所述智能体车辆当前时间步的本地状态信息对中央深度强化学习网络进行训练的方法，包括将所述智能体车辆当前时间步的本地状态信息输入至中央深度强化学习网络中，经过所述中央深度强化学习网络处理后输出所述智能体车辆当前时间步选择的信标频率，并将所述信标频率返回至对应的智能体车辆；所述智能体车辆根据接收到的所述信标频率进行信标广播，并对所述中央深度强化学习网络的参数进行更新，其中智能体车辆动态信标的信标频率决策使用一离散时间的马尔科夫决策方法。如图3所示，中央深度强化学习网络包含两个网络模块，分别是图注意模块和DQN模块，不同经验训练部分的Q网络、GAT网络和MLP网络的参数共享。中央深度强化学习网络训练过程中除了与智能体车辆进行交互外，还会在云端记录所有车辆的状态信息，在神经网络训练过程中的邻近车辆状态集合和都由云端提供。其中，图注意模块中堆叠使用了两个GAT网络层，从而达到收集二跳集中其他车辆的信息的效果。时间步时，智能体车辆在确定了车辆关系的无向图后，就能构造当前时间步的邻接矩阵。邻接矩阵中记录车辆索引信息，其中的第一行表示的是智能体车辆索引的独热码表示，其余的行是智能体车辆的邻近车辆索引的独热码表示。在本发明中，智能体车辆使用邻接矩阵来提取其自身及其邻近车辆的信息，然后将这些提取的结果传输到图注意模块中，图注意模块的工作流程主要集中在两个GAT层对智能体车辆信息的处理操作上。如图1所示，在神经网络训练阶段，智能体车辆的训练邻近车辆的状态集合由中央深度强化学习网络根据其他车辆的反馈提供，而部署阶段智能体车辆本地状态、邻近车辆的状态集合和邻接矩阵通过自身的观测提供。这些特征结果输入到第一层GAT网络层中，第一层GAT网络层的关注模块会与之对应输出智能体车辆的特征向量，特征向量中包含智能体车辆及其一跳集中相邻车辆的状态信息。接下来，本发明通过使用邻接矩阵为智能体车辆提取相应的特征向量。然后本发明将第一层GAT网络层提取的特征向量输入到第二层GAT网络层的注意模块中，第二层GAT网络层的注意模块经过处理就会输出结果特征向量。第一层GAT网络层输出的向量特征包含了在智能体车辆的OHS范围邻近车辆的状态信息，因此第二层GAT网络层输出的特征向量可以在THS范围中获得邻近车辆的信息。本发明利用特征向量和作为DQN模块的输入，这样就使DQN模块获得处理车联网通信中暴露终端问题和隐藏终端问题的能力。如图4所示，本发明在GAT网络层采用多头点积注意模块机制，该机制使用了编码矩阵、、，这些编码矩阵将每个注意力模块的输入特征向量投影到查询、关键字和值表示中。本发明使用符号来表示每个注意力模块的输入特征向量。对于多头点积注意模块机制中的注意头，其计算以下Softmax函数：，其中，表示比例因子，表示关键表示的维数。根据多头点积注意模块机制，本发明在一个GAT网络层中设置了个注意头。对于每个实验车辆，本发明用公式对其计算得出其结果，然后对计算结果进行加权操作，接着把这些加权的值相加作为注意头的输出结果。最后，本发明将这个注意头的输出结构拼接起来传入送到一个非线性ReLU激活函数中，该激活函数将输出智能体车辆的特征向量：。通过上述操作，特征向量收集智能体车辆的OHS中每个邻近车辆的加权信息表示。DQN模块采用了Q网络替代Q-Learning中的Q表格， Q网络利用其深度神经网络的拟合能力逼近动作值函数值函数，Q网络的结构中包括若干个卷积层和全连接层，中央深度强化学习网络的权重参数，记做。DQN模块还在Q网络之外增加了一个目标Q网络，记做，其神经网络模型的权重参数，记做。目标Q网络采用与Q网络完全一样的神经网络结构。所有智能体车辆在每一回合训练结束后将获得经验元组，并将经验元组上传给中央深度强化学习网络，中央深度强化学习网络将这些经验元组存放在经验回放容器中，以供经验回放训练，本发明称该经验回放容器为经验回放池，记为。在深度强化学习训练过程中，如图5所示，本发明将所有参与实验的车辆分为两类，分别为智能体车辆和普通车辆。智能体车辆在信标频率选择方面采用可选信标频率组作为动作空间，在信标频率控制上使用中央深度强化学习网络进行控制。普通车辆在信标频率选择方面采用可选信标频率组作为动作空间，在信标频率控制机制上采用基于状态机的信标控制方法。智能体车辆在每个时间步开始时将本地状态信息上传给深中央深度强化学习网络，中央深度强化学习网络处理后返回给智能体车辆一个适合的动作。表示智能体车辆在其时间步时选择的信标频率，即该智能体车辆在这一个时间步将要发射信标的数量，将智能体的动作空间表示为，动作空间大小为，动作空间集合表示为。在神经网络的训练过程中，如图5所示，中央深度强化学习网络与智能体车辆进行交互，每个智能体车辆定期向处于云端服务器的中央深度强化学习网络传输自己的状态，中央深度强化学习网络处理智能体车辆上传的信息，得到动作结果并返回给相应的智能体车辆，然后智能体车辆将动作结果转化为自身信标频率进行信标广播，与通信环境进行交互后向中央深度强化学习网络反馈自身新的状态和经验元组。与此同时，训练过程中的云端服务器会通过系统对所有车辆的实时状态进行记录。本发明采用分布式经验回收以及均匀回放的方式对神经网络进行训练，这样能够有效地消除经验样本之间的关联性，从而有效减少由函数近似导致的估计偏差问题，进而使神经网络在训练过程中更好地收敛。在神经网络的训练过程中，采用时间步的划分机制是提出的分散式时间步机制，分散式时间步机制根据智能体车辆信标决策时间集合的情况将所有的智能体车辆分为个集合，训练环境中的智能体车辆不再全部集中在固定的时间点进行信标频率决策，从而避免了在强化学习训练过程中智能体车辆同时改变信标频率导致训练环境发生剧烈变化。除此之外，分散式时间步机制也有效缓解了中央深度强化学习网络处理智能体车辆上传信息的压力。从单个的智能体车辆视角而言，它们每个时间步与中央深度强化学习网络交互一次，即每隔帧与中央深度强化学习网络进行一次交互。而由于所有的智能体车辆依据信标决策时间集合被分为个集合，所有的智能体车辆随机分布在这个集合中，因此对于中央深度强化学习网络来说，它在每个帧都在处理智能体传来的信息，而不是以每个时间步个帧的间隔进行集中式处理，这样就让中央深度强化学习网络与智能体交互的压力就极大地分散了。在中央深度强化学习网络的训练过程中，对所述中央深度强化学习网络的参数进行更新包括对目标Q网络的参数进行更新，对目标Q网络的参数进行更新的方法，包括：1）中央深度强化学习网络在用于存放经验元组的经验回放池选取一批次经验元组，记做，其中，表示智能体车辆当前时间步的综合状态，表示智能体车辆当前时间步的邻接矩阵，表示对应智能体车辆信标频率结果的动作，表示智能体车辆时间步的综合状态，表示智能体车辆时间步的邻接矩阵，表示智能体车辆在当前时间步做出动作后通信环境反馈的奖励函数；2)将中所有的邻近车辆信息和输入到多层感知器中，多层感知器输出两个对应的集合为和，并将中和输入到多层感知器中，得到特征向量和；3)将、和输入到第一层GAT网络层中获得特征向量，将、和输入到第一层GAT网络层中获得特征向量；4)将特征向量输入到第二层GAT网络层中获得特征向量，将特征向量输入到第二层GAT网络层中获得特征向量；5)将特征向量输入到Q网络中，并将特征向量输入到目标Q网络中，分别表示为和；6)中央深度强化学习网络使用公式对目标Q网络的参数进行更新。其中，在步骤S3中，在模拟交通环境的部署测试过程中，每个智能体车辆将会有一套本地的中央深度强化学习网络用来进行信标频率决策，这个本地的中央深度强化学习网络的参数采用的是上述强化学习训练成功后的中央深度强化学习网络的参数。本发明提出的方法能够根据当前信道质量、车辆通信需求等级的组合信息、邻近车辆状态信息以及关系矩阵使用神经网络得到相应的信标频率。智能体车辆可以通过不断训练神经网络，提升自身的信标频率决策能力。该方法结合了GAT技术和DQN技术, 神经网络中的图注意模块使用掩蔽的自注意层进行图形结构数据的操作，有效地克服了当前图形卷积类方法的对邻近车辆状态信息特征提取方面的缺点，从而更好地实现了车辆之间状态关系的感知；深度Q网络模块规避了传统数值判断方法需要大量设置固定阈值的问题并解决了传统强化学习方法中对输入信息有限且动作空间大小受限的问题，从而实现了更加高效的信标频率控制,有着更好的邻近车辆状态感知能力和信标频率选择能力。相较于之前的文献中提出的解决方案，基于深度强化学习方法的信标频率控制算法能够更好地区分出不同交通风险程度的车辆并给予其合适的通信信标频率进行安全消息广播，有效地减小高风险车辆与邻近车辆共享自身信息的通信时延，在城市交通环境下有着更好的安全性。下面通过具体的实施方式对本发明提出的一种基于深度强化学习的车联网动态信标广播方法进行阐述。1.实验车辆的信标频率控制策略：智能体车辆采用深度强化学习方法与中央深度强化学习网络进行交互获得信标频率结果，其动作空间集合表示为。普通车辆采用状态机方法，本发明将普通车辆信标频率分为个档位，记为可选信标频率组，分别表示车辆在一个时间步发射1个信标、车辆一个时间步发射2个信标、车辆一个时间步发射个信标以及车辆一个时间步发射个信标。本发明将这个频率分为三个信标频率组、、，分别记为、、。和作为最小信标频率和最大信标频率，作为中间信标频率组。在基于状态机的信标频率控制方法中，车辆根据自身当前的信道质量和通信需求等级的变化，在、和这三个信标频率组中动态地转移自身所处的信标频率组状态，选择相应合适的信标频率组。信标频率组的状态转换如图6所示。车辆的通信需求等级越大，意味着车辆需求越高信标频率。然而，过高的信标频率可能导致严重的信道过载和信标碰撞，从而降低实际有效的安全消息广播效率。因此，车辆在进行信标频率控制时需要综合自身通信需求和信道质量做出权衡。信标频率组的状态转移根据以下三条规则进行：规则1：当车辆信标频率组处于时，如果且则转移到，如果且则转换到；当车辆信标频率组处于时，若通信需求等级增大，则信标频率组向着信标频率更高的信标频率组转换。若此时信道质量较差，增大信标频率则可能导致信标碰撞率显著增加，所以信标频率组在这种情况下，车辆信标频率应该保持在低水平下。规则2：当车辆信标频率组处于时，如果则转换到，如果且则转换到；车辆信标频率组处于时，若信道质量较差则易发生信标碰撞，因此车辆应该减小信标频率以减轻通信信道负载，从而缓解信标碰撞情况。车辆通信需求等级降低可以降低信标频率释放信道资源，减轻信道负载，从而实现更高效地安全消息广播。规则3：当车辆信标频率组处于时，如果且则转换到，如果且则转换到；当车辆信标频率组处于时，若车辆通信需求等级提升到高等级且信道质量良好的情况下，这时信标频率应该尽可能增大。若车辆通信需求等级较低且信道质量普通，这时信标频率应该尽降低避免过度占用信道资源。由于判断阈值、、和的设置决定了车辆通信需求和信道质量之间的权衡。本发明可以根据具体应用的要求进行设置。例如，如果需要更好的信道质量来提高信标信息的有效传输比例，可以设置较小的和。2.通信信道质量：向量表示车辆的综合状态，其中车辆通信需求等级在前文已经描述了，在此详细描述信道质量的技术方法。在信道感知方面，本发明采用了B. Liu等人提出的信道质量计算公式，该公式考虑到了通信信道信噪比、邻近车辆数量、信标碰撞数量等因素，能够更加合理地帮助车辆根据当前信道情况做出高效的信标频率控制。对城市交通环境中的车联网通信的研究中，本发明发现除了车辆主动的行为如调整信标频率、发射功率外，信道环境也会极大影响车联网通信效果。其中信标比是最具有代表性的一个因素，其计算公式入下：，其中和分别代表信号和噪声的有效功率。本发明采用了B. Liu等人提出的信道质量计算公式对车辆当前所处的信道质量进行评估，信道质量的计算公式如下：，其中表示一跳集内的车辆数，表示过去一个段时间内的平均碰撞数，SNR信噪比代表信道环境的信噪比，代表调节参数。3.训练环境中车辆类型比例调整机制：本发明将中央深度强化学习网络进行的训练过程依据环境中的车辆种类将整个过程分为两个阶段。第一个阶段中智能体车辆与普通车辆在训练环境中共存，普通车辆作为训练环境的一部分协助智能体车辆对中央深度强化学习网络进行训练。第一个阶段本发明在每轮实验的实验环境中分别设置环境单位时间内生成车流量和实验车辆种类比例。环境单位时间内生成车流量控制环境车辆生成总量，实验车辆种类比例控制智能体车辆与普通车辆比例。在第一个阶段中起始的训练轮次中环境单位时间内生成车流量和实验车辆种类比例数值较小，仅有一辆智能体车辆在实验环境中，此时训练环境中车辆较少且智能体车辆占总实验车辆比例也较低，随着强化学习训练的进行，环境单位时间内生成车流量和实验车辆种类比例都会逐步增大。环境单位时间内生成车流量在增大的一定数值后不再增大，而实验车辆种类比例接下来每一轮强化学习训练中逐步增大，直至强化学习训练环境中全部都是智能体车辆。第二个阶段训练环境中不再有普通车辆而只存在智能体车辆，此时和都采用固定的数值。4.神经网络的训练与部署的描述：在神经网络的训练过程中，中央深度强化学习网络与智能体车辆进行交互，每个智能体车辆定期向处于云端服务器的中央深度强化学习网络传输自己的状态，中央深度强化学习网络处理智能体车辆上传的信息，得到动作结果并返回给相应的智能体车辆，然后智能体车辆将动作结果转化为自身信标频率进行信标广播，与通信环境进行交互后向中央深度强化学习网络反馈自身新的状态和经验元组。与此同时，训练过程中的云端服务器会通过系统对所有车辆的实时状态进行记录。在模拟交通环境的部署测试过程中，每个智能体车辆将会有一套本地的中央深度强化学习网络用来进行信标频率决策，这个本地的中央深度强化学习网络的参数采用的是上述强化学习训练成功后的中央深度强化学习网络的参数。相应于上述方法的实施例，本发明实施例还提供一种计算机设备，包括存储器、处理器及存储在存储器上并可在处理器上运行的计算机程序，所述处理器执行所述程序时实现上述所述方法的步骤。还有，本发明还提供一种计算机可读存储介质，其上存储有计算机程序，该程序被处理器执行时实现上述所述方法的步骤。相应于上述方法的实施例，本发明实施例还提供一种基于深度强化学习的车联网动态信标广播系统，包括：设置模块，其用于设置车联网通信机制和中央深度强化学习网络的参数，以及设置每一轮训练实验环境单位时间内生成车流量和实验车辆类型比例，其中实验车辆类型包括智能体车辆与普通车辆，普通车辆用于协助智能体车辆对中央深度强化学习网络进行训练；训练模块，其用于在每个时间步起始时刻获取确定的智能体车辆的本地状态信息，使用所述智能体车辆当前时间步的本地状态信息对中央深度强化学习网络进行训练，得到训练好的中央深度强化学习网络；部署模块，其用于将训练好的中央深度强化学习网络部署于模拟交通环境中用于测试；其中，使用所述智能体车辆当前时间步的本地状态信息对中央深度强化学习网络进行训练的方法，包括：将所述智能体车辆当前时间步的本地状态信息输入至中央深度强化学习网络中，经过所述中央深度强化学习网络处理后输出所述智能体车辆当前时间步选择的信标频率，并将所述信标频率返回至对应的智能体车辆；所述智能体车辆根据接收到的所述信标频率进行信标广播，并对所述中央深度强化学习网络的参数进行更新，其中智能体车辆动态信标的信标频率决策使用一离散时间的马尔科夫决策方法。本实施例的基于深度强化学习的车联网动态信标广播系统用于实现前述的基于深度强化学习的车联网动态信标广播方法的实施例部分，所以，其具体实施方式可以参照相应的各个部分实施例的描述，在此不再展开介绍。另外，由于本实施例的基于深度强化学习的车联网动态信标广播系统用于实现前述的基于深度强化学习的车联网动态信标广播方法，因此其作用与上述方法的作用相对应，这里不再赘述。本领域内的技术人员应明白，本申请的实施例可提供为方法、系统、或计算机程序产品。因此，本申请可采用完全硬件实施例、完全软件实施例、或结合软件和硬件方面的实施例的形式。而且，本申请可采用在一个或多个其中包含有计算机可用程序代码的计算机可用存储介质上实施的计算机程序产品的形式。本申请是参照根据本申请实施例的方法、设备、和计算机程序产品的流程图和／或方框图来描述的。应理解可由计算机程序指令实现流程图和／或方框图中的每一流程和／或方框、以及流程图和／或方框图中的流程和／或方框的结合。可提供这些计算机程序指令到通用计算机、专用计算机、嵌入式处理机或其他可编程数据处理设备的处理器以产生一个机器，使得通过计算机或其他可编程数据处理设备的处理器执行的指令产生用于实现在流程图一个流程或多个流程和／或方框图一个方框或多个方框中指定的功能的装置。这些计算机程序指令也可存储在能引导计算机或其他可编程数据处理设备以特定方式工作的计算机可读存储器中，使得存储在该计算机可读存储器中的指令产生包括指令装置的制造品，该指令装置实现在流程图一个流程或多个流程和／或方框图一个方框或多个方框中指定的功能。这些计算机程序指令也可装载到计算机或其他可编程数据处理设备上，使得在计算机或其他可编程设备上执行一系列操作步骤以产生计算机实现的处理，从而在计算机或其他可编程设备上执行的指令提供用于实现在流程图一个流程或多个流程和／或方框图一个方框或多个方框中指定的功能的步骤。显然，上述实施例仅仅是为清楚地说明所作的举例，并非对实施方式的限定。对于所属领域的普通技术人员来说，在上述说明的基础上还可以做出其它不同形式变化或变动。这里无需也无法对所有的实施方式予以穷举。而由此所引申出的显而易见的变化或变动仍处于本发明创造的保护范围之中。
