标题title
一种基于内容感知融合特征的视频质量评价方法
摘要abst
本发明提供了一种基于内容感知融合特征的视频质量评价方法，包括：步骤1、构建用于提取输入图像特征的多方向差异化二阶微分高斯滤波特征提取模块；步骤2、基于多方向差异化二阶微分高斯滤波特征提取模块与深度卷积神经网络搭建残差特征提取网络模型，将视频逐帧输入到残差特征提取网络模型中，得到每一帧图像的内容感知特征；步骤3、对内容感知特征降维后输入到门控制递归神经网络GRU中，对长时依赖关系建模得到视频不同时刻的质量元素以及权重；步骤4、基于不同时刻的质量元素以及权重确定视频最终的质量分数。本发明提出的视频质量评价方法通过提取视频的内容感知特征，能够实现更准确的视频质量评价效果。
权利要求书clms
1.一种基于内容感知融合特征的视频质量评价方法，其特征在于，包括：步骤1、构建用于提取输入图像特征的多方向差异化二阶微分高斯滤波特征提取模块；步骤2、基于多方向差异化二阶微分高斯滤波特征提取模块与深度卷积神经网络搭建残差特征提取网络模型，将视频逐帧输入到残差特征提取网络模型中，得到每一帧图像的内容感知特征；步骤3、对内容感知特征降维后输入到门控制递归神经网络GRU中，对长时依赖关系建模得到视频不同时刻的质量元素以及权重；步骤4、基于不同时刻的质量元素以及权重确定视频最终的质量分数。2.根据权利要求1所述的基于内容感知融合特征的视频质量评价方法，其特征在于，所述步骤1的子步骤为：步骤1.1、构建多方向差异化二阶微分高斯核及其方向导数；步骤1.2、将输入图像与多方向二阶差异化微分高斯方向导数进行卷积操作完成特征信息提取。3.根据权利要求1或2所述的基于内容感知融合特征的视频质量评价方法，其特征在于，所述步骤2的子步骤为：步骤2.1、对输入视频逐帧拆帧得到T张RGB三通道彩色图像；步骤2.2、将获得的图像统一缩放至224像素×224像素；步骤2.3、将步骤2.2得到的图像经一个2D卷积层输出维度为112×112×64的图像特征；步骤2.4、将步骤2.2得到的图像输入到多方向差异化二阶微分高斯滤波特征提取模块进行特征提取，将提取的特征与步骤2.3输出的特征进行融合，融合特征的维度为112×112×72,再对融合特征经卷积操作将通道数恢复到64维；步骤2.5、将64维融合特征送入最大池化层，输出特征的维度为56×56×64；步骤2.6、建立Bottleneck卷积结构，将步骤2.5中输出特征输入到Bottleneck卷积结构输出特征Wt，特征Wt包含多个特征图，其中t取值为1-T；步骤2.7、对特征Wt中每个特征图进行空间全局池化，再通过空间全局平均池化和空间全局标准差池化联合操作获得特征图中的内容感知特征。4.根据权利要求3所述的基于内容感知融合特征的视频质量评价方法，其特征在于，所述步骤2.5中，最大池化层和尺寸为3×3，步长为2，填充维度为1。5.根据权利要求3所述的基于内容感知融合特征的视频质量评价方法，其特征在于，所述步骤2.6中，建立Bottleneck卷积结构具体过程为：步骤2.6.1、设置2D卷积层Conv_2D_2，卷积核个数为C1，卷积核大小为1×1,步长为1,填充维度为0；步骤2.6.2、设置2D卷积层Conv_2D_3，卷积核个数为C1,卷积核大小为7×7，步长为1,填充维度为1；步骤2.6.3、设置2D卷积层Conv_2D_4，卷积核个数为C2,卷积核大小为1×1，步长为1,填充维度为0；步骤2.6.4、将2D卷积层Conv_2D_2、Conv_2D_3、Conv_2D_4依次连接得到一个卷积模块命名为Bottleneck-A结构；步骤2.6.5、将Bottleneck-A结构中三个2D卷积层的卷积核个数分别设为2C1、2C1、2C2得到Bottleneck-B结构；同样的，将卷积核个数分别设置为4C1、4C1、4C2和8C1、8C1、8C2得到Bottleneck-C结构和Bottleneck-D；步骤2.6.6、将3个Bottleneck-A结构、4个Bottleneck-B结构、6个Bottleneck-C结构、3个Bottleneck-D结构依次连接得到Bottleneck卷积结构。6.根据权利要求1或2所述的基于内容感知融合特征的视频质量评价方法，其特征在于，所述步骤3的子步骤为：步骤3.1、通过全连接层FC_1对内容感知特征进行降维得到降维特征；步骤3.2、将降维特征送入能整合调整又能学习长时依赖关系的门控制递归神经网络GRU；步骤3.3、以GRU网络的隐层状态作为综合特征，计算t时刻的隐层状态，得到整合特征；步骤3.4、整合特征输入全连接层FC_2得到t时刻的质量分数；步骤3.5、将前几帧中最低的质量分数作为t时刻的记忆质量元素；步骤3.6、在第t帧构建当前质量元素，并在接下来的几帧中对质量分数进行加权，为具有低质量分数的帧分配较大的权重。7.根据权利要求6所述的基于内容感知融合特征的视频质量评价方法，其特征在于，所述步骤3.5中，记忆质量元素为：其中，表示记忆质量元素，/＞表示所有时刻的索引集合，/＞、/＞分别表示t时刻和k时刻的质量分数，s是与时刻t相关的一个超参数。8.根据权利要求7所述的基于内容感知融合特征的视频质量评价方法，其特征在于，所述步骤3.6中，当前质量元素为：其中，为当前质量元素，/＞为权重，采用softmin函数定义，/＞表示相关时刻的索引集合，e表示自然常数，s是一个与时间相关的超参数。9.根据权利要求6所述的基于内容感知融合特征的视频质量评价方法，其特征在于，所述步骤4的子步骤为：步骤4.1、线性结合记忆质量元素与当前质量元素得到主观帧时刻的近似质量分数；步骤4.2、将近似质量分数进行时间全局平均池化后得到最终的视频质量分数。10.根据权利要求9所述的基于内容感知融合特征的视频质量评价方法，其特征在于，所述步骤4.1中，近似质量分数计算方法为：其中，表示近似质量分数，/＞表示记忆质量元素，/＞为当前质量元素，r为平衡记忆质量元素和当前质量元素贡献的一个超参数。/＞
说明书desc
技术领域本发明涉及计算机视觉领域，特别涉及一种基于内容感知融合特征的视频质量评价方法。背景技术近年来，随着智能设备在人类生产生活中的普遍应用，每天都会产生数量庞大的视频素材，但由于各种现实环境和硬件设备性能的限制，视频的质量会发生无可避免的不同程度上的损失，导致该视频无法在实际应用场景中使用，因此在将视频应用于实际场景之前对视频进行质量评价是必要的。目前常用的视频质量评价方法主要分为主观质量评价和客观质量评价两大类。主观质量评价是由人主观的对各种不同质量的视频进行打分，该方法虽然直接、简单，却受到有限的人力、时间等资源的限制，且不同人对同一段视频存在主观偏差导致没有一个统一评分标准，导致无法实现大规模实际应用。客观视频质量评价按照有无原始无损视频信息又可分为全参考、半参考和无参考三种类别。由于真实应用场景中大概率不存在无损视频作为真实对比，无参考视频质量评价已然成为目前研究的重点。随着深度学习技术的不断进步和发展，该技术已经逐渐广泛应用实际生活中，对于无参考视频质量评价而言，虽然现阶段存在一些无参考质量评价的方法，但还是有着很多壁垒无法突破：未充分考虑人类视觉特性、传统方法需要大量提取手工特征费时费力、未充分考虑图像的各种特征信息等。发明内容针对现有技术中存在的问题，提供了一种基于内容感知融合特征的视频质量评价方法，通过多方向差异化二阶微分高斯滤波特征提取模块与深度卷积神经网络来获取视频图像的内容感知特征，再由门控制递归神经网络GRU对长时依赖关系建模获取质量分数，结合权重确定视频质量。本发明采用的技术方案如下：一种基于内容感知融合特征的视频质量评价方法，包括：步骤1、构建用于提取输入图像特征的多方向差异化二阶微分高斯滤波特征提取模块；步骤2、基于多方向差异化二阶微分高斯滤波特征提取模块与深度卷积神经网络搭建残差特征提取网络模型，将视频逐帧输入到残差特征提取网络模型中，得到每一帧图像的内容感知特征；步骤3、对内容感知特征降维后输入到门控制递归神经网络GRU中，对长时依赖关系建模得到视频不同时刻的质量元素以及权重；步骤4、基于不同时刻的质量元素以及权重确定视频最终的质量分数。进一步的，所述步骤1的子步骤为：步骤1.1、构建多方向差异化二阶微分高斯核及其方向导数；在构建时，方向个数优选为8；步骤1.2、将输入图像与多方向二阶差异化微分高斯方向导数进行卷积操作完成特征信息提取。进一步的，所述步骤2的子步骤为：步骤2.1、对输入视频逐帧拆帧得到T张RGB三通道彩色图像；步骤2.2、将获得的图像统一缩放至224像素×224像素；步骤2.3、将步骤2.2得到的图像经一个2D卷积层输出维度为112×112×64的图像特征；步骤2.4、将步骤2.2得到的图像输入到多方向差异化二阶微分高斯滤波特征提取模块进行特征提取，将提取的特征与步骤2.3输出的特征进行融合，融合特征的维度为112×112×72,再对融合特征经卷积操作将通道数恢复到64维；步骤2.5、将64维融合特征送入最大池化层，输出特征的维度为56×56×64；步骤2.6、建立Bottleneck卷积结构，将步骤2.5中输出特征输入到Bottleneck卷积结构输出特征Wt，特征Wt包含多个特征图，其中t取值为1-T；步骤2.7、对特征Wt中每个特征图进行空间全局池化，再通过空间全局平均池化和空间全局标准差池化联合操作获得特征图中的内容感知特征。进一步的，所述步骤2.5中，最大池化层和尺寸为3×3，步长为2，填充维度为1。进一步的，所述步骤2.6中建立Bottleneck卷积结构具体过程为：步骤2.6.1、设置2D卷积层Conv_2D_2，卷积核个数为C1，卷积核大小为1×1,步长为1,填充维度为0；步骤2.6.2、设置2D卷积层Conv_2D_3，卷积核个数为C1,卷积核大小为7×7，步长为1,填充维度为1；步骤2.6.3、设置2D卷积层Conv_2D_4，卷积核个数为C2,卷积核大小为1×1，步长为1,填充维度为0；步骤2.6.4、将2D卷积层Conv_2D_2、Conv_2D_3、Conv_2D_4依次连接得到一个卷积模块命名为Bottleneck-A结构；步骤2.6.5、将Bottleneck-A结构中三个2D卷积层的卷积核个数分别设为2C1、2C1、2C2得到Bottleneck-B结构；同样的，将卷积核个数分别设置为4C1、4C1、4C2和8C1、8C1、8C2得到Bottleneck-C结构和Bottleneck-D；步骤2.6.6、将3个Bottleneck-A结构、4个Bottleneck-B结构、6个Bottleneck-C结构、3个Bottleneck-D结构依次连接得到Bottleneck卷积结构。进一步的，所述步骤3的子步骤为：步骤3.1、通过全连接层FC_1对内容感知特征进行降维得到降维特征；步骤3.2、将降维特征送入能整合调整又能学习长时依赖关系的门控制递归神经网络GRU；步骤3.3、以GRU网络的隐层状态作为综合特征，计算t时刻的隐层状态，得到整合特征；步骤3.4、整合特征输入全连接层FC_2得到t时刻的质量分数；步骤3.5、将前几帧中最低的质量分数作为t时刻的记忆质量元素；步骤3.6、在第t帧构建当前质量元素，并在接下来的几帧中对质量分数进行加权，为具有低质量分数的帧分配较大的权重。进一步的，所述步骤3.5中，记忆质量元素为：其中，表示记忆质量元素，/＞表示所有时刻的索引集合，/＞、/＞表示t时刻和k时刻的质量分数，s是与时刻t相关的一个超参数。进一步的，所述步骤3.6中，当前质量元素为：其中，为当前质量元素，/＞为权重，采用softmin函数定义，表示相关时刻的索引集合，e表示自然常数。进一步的，所述步骤4的子步骤为：步骤4.1、线性结合记忆质量元素与当前质量元素得到主观帧时刻的近似质量分数；步骤4.2、将近似质量分数进行时间全局平均池化后得到最终的视频质量分数。进一步的，所述步骤4.1中，近似质量分数计算方法为：其中，表示近似质量分数，/＞表示记忆质量元素，/＞为当前质量元素，r为平衡记忆质量元素和当前质量元素贡献的一个超参数。与现有技术相比，采用上述技术方案的有益效果包括：1、构建的多方向差异化二阶微分高斯滤波特征提取模块能够提取图像中的丰富的边缘特征信息。2、将构建的特征提取模块与深度卷积神经网络结合后得到的特征提取网络模型具有识别不同内容信息的能力。3、本发明中提到的递归神经网络GRU能够有效建模视频中不同时刻质量元素的长时依赖关系。由此，本发明提出的视频质量评价方法能够实现更准确的视频质量评价效果。附图说明图1为本发明提出的视频质量评价方法流程图。图2为本发明一实施例中提取内容感知特征的示意图。图3为本发明一实施例中长时依赖关系建模与视频质量评价示意图。具体实施方式下面详细描述本申请的实施例，所述实施例的示例在附图中示出，其中自始至终相同或类似的标号表示相同或类似的模块或具有相同或类似功能的模块。下面通过参考附图描述的实施例是示例性的，仅用于解释本申请，而不能理解为对本申请的限制。相反，本申请的实施例包括落入所附加权利要求书的精神和内涵范围内的所有变化、修改和等同物。实施例1针对现有技术中未充分考虑人类视觉特性、传统方法需要大量提取手工特征费时费力、未充分考虑图像的各种特征信息等缺陷，参见图1，本实施例提出了一种基于内容感知融合特征的视频质量评价方法，包括：步骤1、构建用于提取输入图像特征的多方向差异化二阶微分高斯滤波特征提取模块；步骤2、基于多方向差异化二阶微分高斯滤波特征提取模块与深度卷积神经网络搭建残差特征提取网络模型，将视频逐帧输入到残差特征提取网络模型中，得到每一帧图像的内容感知特征；步骤3、对内容感知特征降维后输入到门控制递归神经网络GRU中，对长时依赖关系建模得到视频不同时刻的质量元素以及权重；步骤4、基于不同时刻的质量元素以及权重确定视频最终的质量分数。本实施例步骤1中，方向个数选取为8，通过多方向差异化二阶微分高斯滤波特征提取模块获取图像不同角度的梯度信息。本实施例中，通过步骤1中建立的多方向差异化二阶微分高斯滤波特征提取模块完成梯度信息的提取，在配合深度卷积神经网络完成内容感知特征的提取，其中，多方向差异化二阶微分高斯滤波特征提取模块和深度卷积神经网络可组成残差特征提取网络模型。步骤3中的门控制递归神经网络GRU既能够整合特征又能够学习到长时依赖关系。实施例2在实施例1的基础上，本实施例对步骤1中多方向差异化二阶微分高斯滤波特征提取模块及特征提取方法进行进一步说明，具体如下：构建多方向差异化二阶微分高斯核以及其方向导数/＞，具体如下所示：其中，和/＞分别表示图像中的像素横坐标和纵坐标；/＞表示差异化因子；/＞；/＞，/＞表示选取的角度值，计算公式为：，m的取值范围为/＞，/＞表示选取的方向个数，M的取值范围为任意正整数。本实施例中，选取方向数M=8获得图像不同角度的梯度信息；在进行特征提取时，将输入图像I与多方向二阶差异化微分高斯方向导数进行卷积操作以实现提取特征信息的目的，具体操作如下公式所示：其中，表示图像特征。实施例3在实施例1或2的基础上，如图2所示，本实施例对步骤2中提取内容感知特征的具体过程进行进一步说明，需要说明的是图2中特征提取模块是指多方向差异化二阶微分高斯滤波特征提取模块：步骤2.1、对于输入的视频素材，将视频素材进行逐帧拆帧得到T张RGB三通道彩色图像；步骤2.2、将获得图像，其中t的取值范围为1～T，的图像尺寸通过图像处理resize操作统一缩放至大小为224像素×224像素；步骤2.3、设置2D卷积层Conv_2D_1，卷积核个数为64，卷积核大小为7×7，步长为2，填充维度为3，经过B2操作后的图像经过Conv_2D_1后输出维度为112×112×64；步骤2.4、将步骤2.2得到的图像输入到多方向差异化二阶微分高斯滤波特征提取模块进行特征提取，此时输出特征的维度为112×112×8，之后再与步骤2.3输出的特征进行concat特征融合操作，融合特征的维度为112×112×72,随后将融合特征送入一个1×1×64卷积将通道数恢复到64维；步骤2.5、将通道数为64维的融合特征送入一个核尺寸为3×3,步长为2,填充维度为1的最大池化层，此时输出特征的维度为56×56×64；步骤2.6、建立Bottleneck卷积结构，将步骤2.5中输出特征输入到Bottleneck卷积结构输出特征Wt，特征Wt包含多个特征图，其中t取值为1-T；步骤2.7、对特征Wt中每个特征图进行空间全局池化，再通过空间全局平均池化和空间全局标准差池化联合操作获得特征图中特征Ft：经过多方向差异化二阶微分高斯滤波特征提取模块以及深度卷积神经网络融合后的特征Ft具有区分不同内容的信息的能力，因此该特征具有内容感知特性。实施例4在实施例3的基础上，本实施例提出了具体的Bottleneck卷积结构构建过程，具体如下：步骤2.6.1、设置2D卷积层Conv_2D_2，卷积核个数为C1，卷积核大小为1×1,步长为1,填充维度为0；步骤2.6.2、设置2D卷积层Conv_2D_3，卷积核个数为C1,卷积核大小为7×7，步长为1,填充维度为1；步骤2.6.3、设置2D卷积层Conv_2D_4，卷积核个数为C2,卷积核大小为1×1，步长为1,填充维度为0；步骤2.6.4、将2D卷积层Conv_2D_2、Conv_2D_3、Conv_2D_4依次连接得到一个卷积模块命名为Bottleneck-A结构；步骤2.6.5、将Bottleneck-A结构中三个2D卷积层的卷积核个数分别设为2C1、2C1、2C2得到Bottleneck-B结构；同样的，将卷积核个数分别设置为4C1、4C1、4C2和8C1、8C1、8C2得到Bottleneck-C结构和Bottleneck-D；步骤2.6.6、将3个Bottleneck-A结构、4个Bottleneck-B结构、6个Bottleneck-C结构、3个Bottleneck-D结构依次连接得到Bottleneck卷积结构。实施例5在实施例3或4的基础上，如图3所示，本实施例针对利用具有门控制的递归神经网络建模长时依赖关系以及获取质量元素的具体过程进行进一步说明。具体的：步骤3.1、通一个全连接层FC_1对内容感知特征进行降维得到降维特征Xt；其中，和/＞为全连接层FC_1中的两个参数，分别表示缩放比例和偏置项。步骤3.2、将降维特征送入能整合调整又能学习长时依赖关系的门控制递归神经网络GRU；步骤3.3、以GRU网络的隐层状态作为综合特征，计算t时刻的隐层状态，得到整合特征；本实施例中，隐层的初始值为h0，t时刻的隐层状态整合特征ht由t时刻的输入特征Xt和前一时刻的隐层状态ht-1计算得到：步骤3.4、整合特征输入另一个全连接层FC_2得到t时刻的质量分数qt；其中，和/＞为全连接层FC_2中的两个参数，分别表示缩放比例和偏置项。步骤3.5、将前几帧中最低的质量分数作为t时刻的记忆质量元素；其中，表示记忆质量元素，/＞表示所有时刻的索引集合，/＞、/＞表示t时刻和k时刻的质量分数，s是与时刻t相关的一个超参数。步骤3.6、为了模拟人类对于视频质量下降记忆深刻，对视频质量提升感知能力不强的现象，本实施例中，在第t帧构建当前质量元素，并在接下来的几帧中对质量分数进行加权，为具有低质量分数的帧分配较大的权重，具体方法为：其中，为当前质量元素，/＞为权重，采用softmin函数定义，表示相关时刻的索引集合，e表示自然常数。/＞实施例6在实施例5的基础上，本实施例对步骤4中的视频最终质量分数获取方法进行进一步说明，具体的：步骤4.1、线性结合记忆质量元素与当前质量元素得到主观帧时刻的近似质量分数；其中，r为平衡记忆质量元素和当前质量元素贡献的一个超参数。步骤4.2、将近似质量分数进行时间全局平均池化后得到最终的视频质量分数Q。基于前述实施例1-6任一实施例均可较好的实现本发明，准确的获取一端视频的质量分数。需要说明的是，在本发明实施例的描述中，除非另有明确的规定和限定，术语“设置”、“连接”应做广义理解，例如，可以是固定连接，也可以是可拆卸连接，或一体地连接；可以是直接连接，也可以通过中间媒介间接连接。对于本领域的普通技术人员而言，可以具体情况理解上述术语在本发明中的具体含义；实施例中的附图用以对本发明实施例中的技术方案进行清楚、完整地描述，显然，所描述的实施例是本发明一部分实施例，而不是全部的实施例。通常在此处附图中描述和示出的本发明实施例的组件可以以各种不同的配置来布置和设计。尽管上面已经示出和描述了本申请的实施例，可以理解的是，上述实施例是示例性的，不能理解为对本申请的限制，本领域的普通技术人员在本申请的范围内可以对上述实施例进行变化、修改、替换和变型。
