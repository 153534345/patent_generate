标题title
一种基于多模态特征融合的声音场景分类方法
摘要abst
本发明提供了一种基于多模态特征融合的声音场景分类方法，包括提取原始声音的梅尔声谱图，并在梅尔声谱图基础上提取一阶差分梅尔声谱图；基于梅尔声谱图以及一阶差分梅尔声谱图构建特征提取网络；将提取的梅尔声谱图以及一阶差分梅尔声谱图输入到特征提取网络中进行特征提取以及特征融合；将经过特征提取网络后得到的梅尔声谱图的深度特征图和一阶差分梅尔声谱图的深度特征图进行降维得到2个具有高级语义信息特征向量，最后将2个特征向量进行融合，并预测输出。本发明的方法能够有效提高声音场景的识别准确率，且提高了鲁棒性。
权利要求书clms
1.一种基于多模态特征融合的声音场景分类方法，其特征在于：包括如下步骤：步骤1：提取原始声音的梅尔声谱图，并在梅尔声谱图基础上提取一阶差分梅尔声谱图；步骤2：基于梅尔声谱图以及一阶差分梅尔声谱图构建特征提取网络；步骤3：将提取的梅尔声谱图以及一阶差分梅尔声谱图输入到特征提取网络中进行特征提取以及特征融合；步骤4：将经过特征提取网络后得到的梅尔声谱图的深度特征图和一阶差分梅尔声谱图的深度特征图进行降维得到2个具有高级语义信息的特征向量，最后将2个特征向量进行融合，并预测输出。2.根据权利要求1所述的一种基于多模态特征融合的声音场景分类方法，其特征在于：所述步骤1具体包括：步骤101：将数据集中的原始声音进行采样、量化、分帧、以及加窗处理，得到原始声音的短时信号；步骤102：将处理后的短时信号进行短时傅里叶变换，得到声音的线性频率谱；步骤103：将声音的线性频率谱经过梅尔滤波器得到声音的梅尔声谱图；步骤104：将得到的梅尔声谱图进行一阶差分处理，得到声音的一阶差分梅尔声谱图。3.根据权利要求1所述的一种基于多模态特征融合的声音场景分类方法，其特征在于：所述步骤2中特征提取网络包括特征提取模块和特征融合模块，所述特征提取模块包括梅尔声谱图子网络与一阶差分梅尔声谱图子网络，两个子网络并行训练，具有相同的网络结构，两个子网络之间嵌入特征融合模块。4.根据权利要求3所述的一种基于多模态特征融合的声音场景分类方法，其特征在于：所述特征提取模块的实现过程如下：将声音的梅尔声谱图和一阶差分梅尔声谱图输入到梅尔声谱图子网络与一阶差分梅尔声谱图子网络，两个子网络分支并行训练，具有相同的网络结构，以卷积神经网络为基础，逐层对输入特征图进行特征提取，得到特征图的高级信息。5.根据权利要求3所述的一种基于多模态特征融合的声音场景分类方法，其特征在于：所述特征融合模块的实现过程如下：将输入的梅尔声谱图和一阶差分梅尔声谱图相加后除2得到公共部分，梅尔声谱图和一阶差分梅尔声谱图相减后除2得到差异部分，然后对公共部分和差异部分做全局平均池化的空间压缩操作得到全局向量，然后将得到的全局向量输入tanh激活函数，以获得融合后的权重向量，再将此权重向量分别与公共部分和差异部分逐通道元素相乘，得到公共特征和差异特征，把公共特征与差异特征再次相加,然后将公共特征与差异特征相加后的特征与原输入的梅尔声谱图逐元素相加，得到融合后的梅尔声谱图，把公共特征与差异特征再次相减，然后公共特征与差异特征相减后的特征再与原输入的一阶差分梅尔声谱图逐元素相加，得到融合后的一阶差分梅尔声谱图。6.根据权利要求1所述的一种基于多模态特征融合的声音场景分类方法，其特征在于：所述步骤4包括：将经过特征提取网络后得到的梅尔声谱图的深度特征图与一阶差分梅尔声谱图的深度特征图，分别用2个1×1的卷积核对深度特征图的通道数降维到分类数目，然后用全局平均池化生成2个具有高级语义信息的特征向量，将2个特征向量进行融合得到融合向量，融合向量送到Softmax层中得出预测结果。
说明书desc
技术领域本发明属于音频场景识别技术领域，尤其是涉及一种基于多模态特征融合的声音场景分类方法。背景技术声音的非语音信号中包含了丰富的信息内容，例如，在公园、购物中心、巴士等场景下，众多声音事件交织在一起形成环境声音，这些环境声音是我们感知和理解周围环境的重要依据。声音场景分类旨在通过计算机研究声音中所包含的环境信息，比如通过嘈杂的人群声和商品推销声分析出当前所处环境可能是在商场中。声音场景分类研究主要是基于传统算法和深度学习算法，伴随计算机硬件的提高与深度学习算法的发展，基于深度学习的声音场景分类成为声学场景分类任务的主流。目前，声学场景分类任务在特征处理上多采用梅尔声谱图，在网络结构上多采用卷积神经网络。目前大多数声学场景分类方法都是借鉴计算机视觉分类方法，很少考虑到声音本身的特性，针对声学场景分类的专有算法很少，总体识别准确率仍然较低。同时声学场景分类所使用的数据集较少，很难满足大规模网络的训练和部署。综上所述，针对声学场景分类任务的设计有效的特征处理方法和网络结构，用有限的数据得到准确率更高，鲁棒性更好的模型，仍然是很有挑战的任务。发明内容有鉴于此，本发明提出了一种基于多模态特征融合的声音场景分类方法，能够有效提高声音场景的识别准确率，且提高了鲁棒性。为达到上述目的，本发明的技术方案是这样实现的：一种基于多模态特征融合的声音场景分类方法，包括如下步骤：步骤1：提取原始声音的梅尔声谱图，并在梅尔声谱图基础上提取一阶差分梅尔声谱图；步骤2：基于梅尔声谱图以及一阶差分梅尔声谱图构建特征提取网络；步骤3：将提取的梅尔声谱图以及一阶差分梅尔声谱图输入到特征提取网络中进行特征提取以及特征融合；步骤4：将经过特征提取网络后得到梅尔声谱图的深度特征图和一阶差分梅尔声谱图的深度特征图进行降维得到2个具有高级语义信息特征向量，最后将2个特征向量进行融合，并预测输出。进一步的，所述步骤1具体包括：步骤101：将数据集中的原始声音进行采样、量化、分帧、以及加窗处理，得到原始声音的短时信号；步骤102：将处理后的短时信号进行短时傅里叶变换，得到声音的线性频率谱；步骤103：将声音的线性频率谱经过梅尔滤波器得到声音的梅尔声谱图；步骤104：将梅尔声谱图进行一阶差分处理，得到声音的一阶差分梅尔声谱图。进一步的，所述步骤2中特征提取网络包括特征提取模块和特征融合模块，所述特征提取模块包括梅尔声谱图子网络与一阶差分梅尔声谱图子网络，两个子网络并行训练，具有相同的网络结构，两个子网络之间嵌入特征融合模块。进一步的，所述步骤3中进行特征提取的实现过程如下：将声音的梅尔声谱图和一阶差分梅尔声谱图输入到梅尔声谱图子网络与一阶差分梅尔声谱图子网络，两个子网络分支并行训练，具有相同的网络结构，以卷积神经网络为基础，逐层对输入特征图进行特征提取，得到特征图的高级信息。进一步的，所述特征融合模块的实现过程如下：将输入的梅尔声谱图和一阶差分梅尔声谱相加后除2得到公共部分，梅尔声图谱和一阶差分梅尔声谱图相减后除2得到差异部分，然后对公共部分和差异部分做全局平均池化的空间压缩操作得到全局向量，然后将得到的全局向量输入tanh激活函数，以获得融合后的权重向量，再将此权重向量分别与公共部分和差异部分逐通道元素相乘，得到公共特征和差异特征，把公共特征与差异特征再次相加,然后将公共特征与差异特征相加后的特征与原输入的梅尔声谱图逐元素相加，得到融合后的梅尔声谱图。把公共特征与差异特征再次相减，然后公共特征与差异特征相减后的特征再与原输入的一阶差分梅尔声谱图逐元素相加，得到融合后的一阶差分梅尔声谱图。进一步的，所述步骤4中，将经过特征提取网络后得到的梅尔声谱图的深度特征图与一阶差分梅尔声谱图的深度特征图，分别用2个1×1的卷积核对深度特征图的通道数降维到分类数目，然后用全局平均池化生成2个具有高级语义信息的特征向量，将2个特征向量进行融合得到融合向量，融合向量送到Softmax层中得出预测结果。相对于现有技术，本发明所述的一种基于多模态特征融合的声音场景分类方法具有以下优势：本发明提供了一种基于多模态特征融合的声音场景分类方法，梅尔声谱图描述了一帧语音信号的能量谱包络，反应了声音的静态信息，一阶差分梅尔声谱图描述了声音中频率随时间的动态信息，本发明将声音中的静态信息与动态信息融合起来，在保留原始特征基础上，也进行了对应的差异补偿，进一步强化了静态信息与动态信息的联系，有效地提高了声音场景分类的准确率和鲁棒性。附图说明构成本发明的一部分的附图用来提供对本发明的进一步理解，本发明的示意性实施例及其说明用于解释本发明，并不构成对本发明的不当限定。在附图中：图1为本发明的一种基于多模态特征融合的声音场景分类方法流程示意图；图2为本发明的输入声音的梅尔声谱图以及一阶差分梅尔声谱图；图3为本发明的基于梅尔声谱图与一阶差分梅尔声谱图特征融合模块结构示意图；图4为本发明的基于梅尔声谱图与一阶差分梅尔声谱图特征融合模块中的采用的一种通道注意力过程示意图；图5为本发明的一种基于多模态特征融合的声音场景分类方法具体实施流程示意图；图6为本发明的基于残差连接的特征融合模块示意图。具体实施方式需要说明的是，在不冲突的情况下，本发明中的实施例及实施例中的特征可以相互组合。在本发明的描述中，需要理解的是，术语“中心”、“纵向”、“横向”、“上”、“下”、“前”、“后”、“左”、“右”、“竖直”、“水平”、“顶”、“底”、“内”、“外”等指示的方位或位置关系为基于附图所示的方位或位置关系，仅是为了便于描述本发明和简化描述，而不是指示或暗示所指的装置或元件必须具有特定的方位、以特定的方位构造和操作，因此不能理解为对本发明的限制。此外，术语“第一”、“第二”等仅用于描述目的，而不能理解为指示或暗示相对重要性或者隐含指明所指示的技术特征的数量。由此，限定有“第一”、“第二”等的特征可以明示或者隐含地包括一个或者更多个该特征。在本发明的描述中，除非另有说明，“多个”的含义是两个或两个以上。在本发明的描述中，需要说明的是，除非另有明确的规定和限定，术语“安装”、“相连”、“连接”应做广义理解，例如，可以是固定连接，也可以是可拆卸连接，或一体地连接；可以是机械连接，也可以是电连接；可以是直接相连，也可以通过中间媒介间接相连，可以是两个元件内部的连通。对于本领域的普通技术人员而言，可以通过具体情况理解上述术语在本发明中的具体含义。下面将参考附图并结合实施例来详细说明本发明。本发明提供了一种基于多模态特征融合的声音场景分类方法，首先对输入的声音提取梅尔声谱图，在此基础上提取一阶差分梅尔声谱图，如图2所示，依次送入两个子网络分支中进行训练，如图1所示，训练过程中，借助基于梅尔声谱图与一阶差分梅尔声谱图特征融合模块来融合梅尔声谱图和一阶差分梅尔声谱图，更好的提取和融合声音所包含的动态信息和静态信息，经过子网络提取特征后，对梅尔声谱图的深度特征图和一阶差分梅尔声谱图的深度特征图进行降维得到2个特征向量，最后将2个特征向量进行融合，并预测输出。具体步骤如下：提取原始声音的梅尔声谱图以及一阶差分梅尔声谱图1.将数据集中的原始声音进行采样，量化，分帧，加窗，得到原始声音的短时信号。2.将处理后的短时信号进行短时傅里叶变换, 具体计算过程可用下式表示：；其中，是一维的声音信号，/＞是窗函数，N是帧长，p是帧移，r是对时域的采样点，f是对频域的采样点，取值在0到N-1之间，m是全体整数，j是虚数单位。通过短时傅里叶变换计算特定帧中特定频率分量的能量值，可以得到二维的线性频率谱。3.得到声音信号的梅尔声谱图，如图2左图所示。经过梅尔滤波器得到的梅尔频率和单位为Hz的线性频率之间的关系如下式所示。；其中，w是单位为Hz的线性频率，mel是梅尔滤波器得到的梅尔频率。4.在此基础上，继续得到声音的一阶差分梅尔声谱图，如图2右图所示，一阶差分梅尔声谱图计算公式如下：；式中，t表示第几帧，M通常取2，X指的就是梅尔声谱图中的系数。将提取的梅尔声谱图和一阶差分梅尔声谱图输入到特征提取网络中，如图1所示，特征提取网络由梅尔声谱图分支与一阶差分梅尔声谱图分支组成，两个分支并行训练，具有相同的网络结构，包含特征提取部分和特征融合部分。1.特征提取部分首先依次将声音的梅尔声谱图和一阶差分梅尔声谱图输入到子网络A与子网络B，其中，子网络A为梅尔声谱图网络，子网络B为一阶差分梅尔声谱图网络，两个子网络分支并行训练，具有相同的网络结构，以卷积神经网络为基础，逐层对输入特征图进行特征提取，得到特征图的高级信息。具体公式如下：；式中，I是输入特征图，W是滤波器权重，O是输出特征图，i是特征图的行索引，k是特征图的列索引，u是取值在0到i的全体整数，v是取值在0到k的全体整数。2.特征融合模块DMFF模块嵌入在子网络A和B之间，DMFF模块具体如图3所示，将梅尔声谱图和一阶差分梅尔声谱图相加后除2得到公共部分，梅尔声谱图和一阶差分梅尔声谱图相减后除2得到差异部分/＞，然后对/＞和/＞做全局平均池化的空间压缩操作得到全局向量，然后将得到的全局向量输入tanh激活函数，以获得融合后的权重向量，再将此权重向量分别与/＞和/＞逐通道元素相乘，具体如图4所示，得到公共特征和差异特征，把公共特征与差异特征再次相加,然后将公共特征与差异特征相加后的特征与原输入的梅尔声谱图逐元素相加，得到融合后的梅尔声谱图/＞。把公共特征与差异特征再次相减，然后公共特征与差异特征相减后的特征再与原输入的一阶差分梅尔声谱图逐元素相加，得到融合后的一阶差分梅尔声谱图/＞。具体公式如下所示：；；；；其中，和分别代表梅尔声谱图与一阶差分梅尔声谱图的公共部分和差异部分，和分别代表梅尔声谱图与一阶差分梅尔声谱图，和代表融合后的梅尔声谱图和一阶差分梅尔声谱图，GAP代表全局平均池化，代表tanh激活函数，和分别代表逐元素相加和相乘。3.特征融合部分。梅尔声谱图和一阶差分梅尔声谱图都有各自独立的特征，这些特征混合了声音中静态信息和动态信息，简单的线性组合无法准确的去利用这些差异信息。因此，将梅尔声谱图和一阶差分梅尔声谱图用公共部分和差异部分结合进行表示，梅尔声谱图和一阶差分梅尔声谱图相加后除2得到公共部分，梅尔声谱图和一阶差分梅尔声谱图相减后除2得到差异部分，具体公式如下：；；其中，和/＞分别表示梅尔声谱图与一阶差分梅尔声谱图。公共部分反映了2个声谱图所共同的特征，差异部分反映了2个声谱图所捕获的独立特征信息。为了充分利用梅尔声谱图与一阶差分梅尔声谱图之间的公共信息与差异信息，将基于梅尔声谱图与一阶差分梅尔声谱图的特征融合模块嵌入到特征提取子网络A与子网络B之间，每次经过卷积层得到的梅尔声谱图/＞与一阶差分梅尔声谱图/＞输入到DMFF中，经过梅尔声谱图/＞和一阶差分梅尔声谱图/＞公共部分和差异部分的深度融合，将融合后的梅尔声谱图/＞与融合后的一阶差分梅尔声谱图/＞分别送回子网络A与子网络B中继续卷积进行特征提取。经特征提取网络后，将梅尔声谱图与一阶差分梅尔声谱图提取到具有高级语义信息的特征向量融合1.经子网络A和子网络B提取特征后，分别得到梅尔声谱图的深度特征图与一阶差分梅尔声谱图的深度特征图，分别用2个1×1的卷积核对深度特征图的通道数降维到分类数目，然后用全局平均池化生成2个具有高级语义信息的特征向量和/＞。如下式所示：；；2.将2个特征向量进行融合得到，具体过程如下式所示：；；其中，是一组逐渐学习的可训练参数。3.将融合向量送到Softmax层中得出预测结果，具体如下式所示：；其中，是预测为第i类的概率，/＞为所有概率总和。下面通过具体的实例说明本发明的方案。采用2048个FFT点的短时傅里叶变换，窗口大小为40 ms，跳跃长度为20 ms，使用 256维梅尔声谱图作为基本特征，初始学习速率设置为 0.001，并通过热重启随机梯度下降进行调度。使用动量为0.9的SGD优化器。批次大小和历代数分别设置为24和500。对于每个10s的音频段生成大小为256×501的，梅尔声谱图，采用随机剪裁，生成256×251的梅尔声谱图，同时提取该梅尔声谱图的一阶差分梅尔声谱图，大小同样是256×251。特征提取网络由梅尔声谱图子网络与一阶差分梅尔声谱图子网络组成，两个子网络并行训练，具有相同的网络结构，特征提取网络以ResNet作为基础，具体包括一个输入卷积层，4个残差块。输入卷积层的卷积核大小为7x8，步幅为2，输入通道数为1，输出通道数为64，批大小为24，分别得到24×64×64×64的梅尔声谱图与一阶差分梅尔声谱图，更大的核与步幅使得网络输入层有更大的感受野去学习全局信息。第一个残差块由2个的卷积层组成，卷积核大小都是3x3，步幅为1，第二，三，四个残差块也是由2个卷积层组成，卷积核大小都是3x3，步幅分别为2和1。如图5所示，并在梅尔声谱图子网络与一阶差分梅尔声谱图子网络之间嵌入基于梅尔声谱图与一阶差分梅尔声谱图的特征融合模块。将和/＞送入DMFF模块进行特征融合，如图6所示，输出DMFF分别得到与/＞，将融合后的梅尔声谱图/＞与融合后的一阶差分梅尔声谱图/＞分别送回梅尔声谱图子网络与一阶差分梅尔声谱图子网络中继续卷积进行特征提取。接着再次重复以上过程进行特征融合和特征提取，最终经过卷积5分别得到/＞与/＞。与大小为24×512×8×8，然后2个1×1的卷积核对深度特征图的通道数进行降维到10，然后用全局平均池化生成2个具有高级语义信息的特征向量和，将这2个特征向量进行加权融合得到，经Softmax产生最终的分类预测。本发明在DCASE2020task1移动开发数据集上验证提出方法的性能，该数据集共由四种不同音频数据录制设备采集。数据集总时长为 64 小时，所有音频数据都被裁剪成 10秒时长的音频片段，数据格式为单通道，44.1 KHz采样率和24 比特量化精度。声音场景涉及室内、室外和交通工具，共十类，包括飞机场、室内购物中心、地铁站、步行街、公共广场、车流量中等的街道、乘坐电车、乘坐巴士、乘坐地铁、城市公园。我们使用13965个音频片段和2970个音频片段分别按照官方协议对模型进行训练和评估。为证明所提方法的有效性，在表1中列出了本发明与其他几种先进方法的性能对比。实验结果说明，本方法在评估数据集上的平均准确率达到了74.2%，本发明能够有效提高声音场景的识别准确率，且提高了鲁棒性。表1以上所述仅为本发明的较佳实施例而已，并不用以限制本发明，凡在本发明的精神和原则之内，所作的任何修改、等同替换、改进等，均应包含在本发明的保护范围之内。
