标题title
一种三维场景匹配交互方法、装置、设备及存储介质
摘要abst
本发明公开了一种三维场景匹配交互方法、装置、设备及存储介质，依托图像采集技术、三维检索技术以及人机交互技术，在真实的应用场景中，采集用户视野中的二维的VR图像。通过提供的基于场景的模型匹配算法，通过三维模型库中与场景物体相似模型匹配检索算法以及用户虚拟视野中三维模型随用户姿态主动调整技术，实现沉浸式人机交互的效果。
权利要求书clms
1.一种三维场景匹配交互方法，其特征在于，包括：获取当前时刻用户视野中的二维图像及视角信息、焦距信息、景深信息；所述二维图像包括目标物体；利用所述视角信息、所述焦距信息、所述景深信息将所述二维图像与三维模型库中的三维模型进行匹配，获得与所述目标物体相似的目标三维模型；获取当前时刻用户头部的姿态数据，利用所述姿态数据确定用户的头部位姿与所述目标三维模型的相对运动关系；根据所述姿态数据确定图像选取框的倾角、图像选取框的中心点与所述目标物体的对应位置关系；结合所述图像选取框的倾角、所述图像选取框的中心点与所述目标物体的对应位置关系以及所述相对运动关系，将所述目标三维模型调整至目标位姿并放入所述图像选取框内。2.根据权利要求1所述的三维场景匹配交互方法，其特征在于，获取当前时刻用户视野中的二维图像及视角信息、焦距信息、景深信息；包括：通过图像采集模块采集像素分量，所述图像采集模块包括若干光传感组件；检测视野中的光线，通过三元色滤色器排列在各自的光传感组件方格上形成马赛克彩色滤色阵列；通过对得到的各个颜色信息进行插值处理，得到每个像素点的绿色分量、红色分量、蓝色分量；根据用户的人体姿态及动作进行判定并将信号传入多视图模型中，获得当前时刻用户视野中的二维图像及视角信息、焦距信息、景深信息。3.根据权利要求1所述的三维场景匹配交互方法，其特征在于，利用所述视角信息、所述焦距信息、所述景深信息将所述二维图像与三维模型库中的三维模型进行匹配，获得与所述目标物体相似的目标三维模型；包括：通过所述二维图像获取所述用户与所述目标物体之间的几何距离；利用所述几何距离、所述视角信息、所述焦距信息以及所述景深信息结合三维轮廓匹配模型在所述三维模型库中选择对应轮廓相近的若干备选三维模型；通过特征匹配方法由若干所述备选三维模型中获得所述目标三维模型。4.根据权利要求3所述的三维场景匹配交互方法，其特征在于，所述特征匹配方法，包括：获取所述二维图像包含的图像特征以及若干所述备选三维模型的若干模型特征；利用特征映射模型将所述图像特征分别和若干所述模型特征在统一的特征空间中进行映射，根据所述图像特征与若干所述模型特征各自之间的距离获得若干相似度值；将相似度值最高的所述模型特征对应的所述备选三维模型作为所述目标三维模型。5.根据权利要求1所述的三维场景匹配交互方法，其特征在于，所述用户头部的姿态数据包括头部所处位置、头部转动角度以及头部转动方向。6.根据权利要求5所述的三维场景匹配交互方法，其特征在于，获取当前时刻所述用户头部的姿态数据，包括：获取陀螺仪采集到的当前头部的侧倾角度；同时结合固定式定位器追踪头戴式显示器上光子感应器的信息，获得当前时刻所述用户头部的姿态数据。7.一种三维场景匹配交互装置，其特征在于，所述装置包括：二维图像获取单元，用于获取当前时刻用户视野中的二维图像及视角信息、焦距信息、景深信息；所述二维图像包括目标物体；目标三维模型获取单元，用于利用所述视角信息、所述焦距信息、所述景深信息将所述二维图像与三维模型库中的三维模型进行匹配，获得与所述目标物体相似的目标三维模型；相对运动关系确定单元，用于获取当前时刻用户头部的姿态数据，利用所述姿态数据确定所述用户的头部位姿与所述目标三维模型的相对运动关系；对应位置关系确定单元，用于根据所述姿态数据确定图像选取框的倾角、图像选取框的中心点与所述目标物体的对应位置关系；目标三维模型调整单元，用于结合图像选取框的倾角、所述图像选取框的中心点与所述目标物体的对应位置关系以及所述相对运动关系，将所述目标三维模型调整至目标位姿并放入所述图像选取框内。8.一种三维场景匹配交互设备，其特征在于，所述设备包括处理器以及存储器：所述存储器用于存储程序代码，并将所述程序代码传输给所述处理器；所述处理器用于根据所述程序代码中的指令执行权利要求1-6任一项所述的三维场景匹配交互方法。9.一种计算机可读存储介质，其特征在于，所述计算机可读存储介质用于存储程序代码，所述程序代码用于执行权利要求1-6任一项所述的三维场景匹配交互方法。
说明书desc
技术领域本发明涉及虚拟现实技术领域，特别是涉及一种三维场景匹配交互方法、装置、设备及存储介质。背景技术虚拟现实技术是一种可以创建和体验虚拟世界的计算机仿真系统，它利用计算机生成一种模拟环境。通过VR技术，用户得以构建一个多源信息融合的、人机无缝交互式的三维动态视景和实体行为仿真系统。虚实结合的三维场景匹配技术是随着计算机软硬件的发展而开始拥有应用需求的一种新型显示匹配技术。虚实结合技术能够将虚拟环境融合到用户周围的真实场景中,从而提供直观和增强的使用体验；而三维匹配技术在三维空间中拥有更高操作自由度，从而形成更加直观与真实的感受。现有技术中的VR系统中，双目立体视觉系统起了很大作用。双目立体视觉系统由左右双目光波导显示模组和视觉传感器组成。数字图像的获取是立体视觉的信息来源。常用的立体视觉图像一般由不同位置的两台摄像机经过移动或者旋转拍摄同一幅场景，获取立体图像。图像获取的方式有多种，主要由具体运用的场合和目的决定。然而，双目立体视觉系统在实现时用户的两只眼睛看到的不同图像是分别产生的，通常需要显示在不同的显示器上。有的系统采用单个显示器，用户带上特殊的眼镜后，一只眼睛只能看到奇数帧图像，另一只眼睛只能看到偶数帧图像，奇、偶帧之间的不同也就是视差就产生了立体感。可见，现有技术中采用双目立体视觉系统在向提供用户立体视觉图像时，需要设置两个显示器或者需要特殊的眼镜，增加了设备制作成本。同时，现有技术中在对用户头部进行跟踪时，通常采用单纯的视觉建图算法，然而单纯的视觉SLAM在相机的快速运动中，会出现运动模糊、帧间重叠区域小，导致特征匹配难度高、鲁棒性差，定位精度低。发明内容鉴于上述问题，本发明提供用于克服上述问题或者至少部分地解决上述问题的一种三维场景匹配交互方法、装置、设备及存储介质。本发明提供了如下方案：一种三维场景匹配交互方法，包括：获取当前时刻用户视野中的二维图像及视角信息、焦距信息、景深信息；所述二维图像包括目标物体；利用所述视角信息、所述焦距信息、所述景深信息将所述二维图像与三维模型库中的三维模型进行匹配，获得与所述目标物体相似的目标三维模型；获取当前时刻用户头部的姿态数据，利用所述姿态数据确定所述用户的头部位姿与所述目标三维模型的相对运动关系；根据所述姿态数据确定图像选取框的倾角、图像选取框的中心点与所述目标物体的对应位置关系；结合所述图像选取框的倾角、所述图像选取框的中心点与所述目标物体的对应位置关系以及所述相对运动关系，将所述目标三维模型调整至目标位姿并放入所述图像选取框内。优选地：获取当前时刻用户视野中的二维图像及视角信息、焦距信息、景深信息；包括：通过图像采集模块采集像素分量，所述图像采集模块包括若干光传感组件；检测视野中的光线，通过三元色滤色器排列在各自的光传感组件方格上形成马赛克彩色滤色阵列；通过对得到的各个颜色信息进行插值处理，得到每个像素点的绿色分量、红色分量、蓝色分量；根据所述用户的人体姿态及动作进行判定并将信号传入多视图模型中，获得当前时刻用户视野中的二维图像及视角信息、焦距信息、景深信息。优选地：利用所述视角信息、所述焦距信息、所述景深信息将所述二维图像与三维模型库中的三维模型进行匹配，获得与所述目标物体相似的目标三维模型；包括：通过所述二维图像获取所述用户与所述目标物体之间的几何距离；利用所述几何距离、所述视角信息、所述焦距信息以及所述景深信息结合三维轮廓匹配模型所述三维模型库中选择对应轮廓相近的若干备选三维模型；通过特征匹配方法由若干所述备选三维模型中获得所述目标三维模型。优选地：所述特征匹配方法，包括：获取所述二维图像包含的图像特征以及若干所述备选三维模型的若干模型特征；利用特征映射模型将所述图像特征分别和若干所述模型特征在统一的特征空间中进行映射，根据所述图像特征与若干所述模型特征各自之间的距离获得若干相似度值；将相似度值最高的所述模型特征对应的所述备选三维模型作为所述目标三维模型。优选地：所述用户头部的姿态数据包括头部所处位置、头部转动角度以及头部转动方向。优选地：获取当前时刻用户头部的姿态数据，包括：获取陀螺仪采集到的当前头部的侧倾角度；同时结合固定式定位器追踪头戴式显示器上光子感应器的信息，获得当前时刻所述用户头部的姿态数据。一种三维场景匹配交互装置，所述装置包括：二维图像获取单元，用于获取当前时刻用户视野中的二维图像及视角信息、焦距信息、景深信息；所述二维图像包括目标物体；目标三维模型获取单元，用于利用所述视角信息、所述焦距信息、所述景深信息将所述二维图像与三维模型库中的三维模型进行匹配，获得与所述目标物体相似的目标三维模型；相对运动关系确定单元，用于获取当前时刻用户头部的姿态数据，利用所述姿态数据确定所述用户的头部位姿与所述目标三维模型的相对运动关系；对应位置关系确定单元，用于根据所述姿态数据确定图像选取框的倾角、图像选取框的中心点与所述目标物体的对应位置关系；目标三维模型调整单元，用于结合图像选取框的倾角、所述图像选取框的中心点与所述目标物体的对应位置关系以及所述相对运动关系，将所述目标三维模型调整至目标位姿并放入所述图像选取框内。一种三维场景匹配交互设备，所述设备包括处理器以及存储器：所述存储器用于存储程序代码，并将所述程序代码传输给所述处理器；所述处理器用于根据所述程序代码中的指令执行上述的三维场景匹配交互方法。一种计算机可读存储介质，所述计算机可读存储介质用于存储程序代码，所述程序代码用于执行上述的三维场景匹配交互方法。根据本发明提供的具体实施例，本发明公开了以下技术效果：本申请实施例提供的一种三维场景匹配交互方法、装置、设备及存储介质，依托图像采集技术、三维检索技术以及人机交互技术，在真实的应用场景中，采集用户视野中的二维的VR图像。通过提供的基于场景的模型匹配算法，通过三维模型库中与场景物体相似模型匹配检索算法以及用户虚拟视野中三维模型随用户姿态主动调整技术，实现沉浸式人机交互的效果。当然，实施本发明的任一产品并不一定需要同时达到以上所述的所有优点。附图说明为了更清楚地说明本发明实施例或现有技术中的技术方案，下面将对实施例中所需要使用的附图作简单地介绍。显而易见地，下面描述中的附图仅仅是本发明的一些实施例，对于本领域普通技术人员来说，在不付出创造性劳动的前提下，还可以根据这些附图获得其他的附图。图1是本发明实施例提供的一种三维场景匹配交互方法的流程图；图2是本发明实施例提供的基于场景的模型匹配框图；图3是本发明实施例提供的人机交互方案示意图；图4是本发明实施例提供的基于二维图像的三维模型检索示意图；图5是本发明实施例提供的一种三维场景匹配交互装置的示意图；图6是本发明实施例提供的一种三维场景匹配交互设备的示意图。具体实施方式下面将结合本发明实施例中的附图，对本发明实施例中的技术方案进行清楚、完整地描述。显然，所描述的实施例仅仅是本发明的一部分实施例，而不是全部的实施例。基于本发明中的实施例，本领域普通技术人员所获得的所有其他实施例，都属于本发明保护的范围。参见图1，为本发明实施例提供的一种三维场景匹配交互方法，如图1所示，该方法可以包括：S101：获取当前时刻用户视野中的二维图像及视角信息、焦距信息、景深信息；所述二维图像包括目标物体；具体的，通过图像采集模块采集像素分量，所述图像采集模块包括若干光传感组件；检测视野中的光线，通过三元色滤色器排列在各自的光传感组件方格上形成马赛克彩色滤色阵列；通过对得到的各个颜色信息进行插值处理，得到每个像素点的绿色分量、红色分量、蓝色分量；根据所述用户的人体姿态及动作进行判定并将信号传入多视图模型中，获得当前时刻用户视野中的二维图像及视角信息、焦距信息、景深信息。S102：利用所述视角信息、所述焦距信息、所述景深信息将所述二维图像与三维模型库中的三维模型进行匹配，获得与所述目标物体相似的目标三维模型；具体的，通过所述二维图像获取所述用户与所述目标物体之间的几何距离；利用所述几何距离、所述视角信息、所述焦距信息以及所述景深信息结合三维轮廓匹配模型所述三维模型库中选择对应轮廓相近的若干备选三维模型；通过特征匹配方法由若干所述备选三维模型中获得所述目标三维模型。获取所述二维图像包含的图像特征以及若干所述备选三维模型的若干模型特征；利用特征映射模型将所述图像特征分别和若干所述模型特征在统一的特征空间中进行映射，根据所述图像特征与若干所述模型特征各自之间的距离获得若干相似度值；将相似度值最高的所述模型特征对应的所述备选三维模型作为所述目标三维模型。S103：获取当前时刻用户头部的姿态数据，利用所述姿态数据确定所述用户的头部位姿与所述目标三维模型的相对运动关系；具体的，所述用户头部的姿态数据包括头部所处位置、头部转动角度以及头部转动方向。获取陀螺仪采集到的当前头部的侧倾角度；同时结合固定式定位器追踪头戴式显示器上光子感应器的信息，获得当前时刻所述用户头部的姿态数据。S104：根据所述姿态数据确定图像选取框的倾角、图像选取框的中心点与所述目标物体的对应位置关系；S105：结合图像选取框的倾角、所述图像选取框的中心点与所述目标物体的对应位置关系以及所述相对运动关系，将所述目标三维模型调整至目标位姿并放入所述图像选取框内。本申请实施例提供的三维场景匹配交互方法，依托图像采集技术、三维检索技术以及人机交互技术，在真实的应用场景中，采集用户视野中的二维的VR图像。通过提供的基于场景的模型匹配算法，通过三维模型库中与场景物体相似模型匹配检索算法以及用户虚拟视野中三维模型随用户姿态主动调整技术，实现沉浸式人机交互的效果。下面对本申请实施例提供的三维场景匹配交互方法进行详细介绍。虚拟现实技术是一种可以创建和体验虚拟世界的计算机仿真系统，它利用计算机生成一种模拟环境。通过VR技术，用户得以构建一个多源信息融合的、人机无缝交互式的三维动态视景和实体行为仿真系统。鉴于此，本申请实施例依托图像采集技术、三维检索技术以及人机交互技术，在真实的应用场景中，采集用户视野中的二维的VR图像。提供了基于场景的模型匹配算法，主要包括三维模型库中与场景物体相似模型匹配检索算法，以及用户虚拟视野中三维模型随用户姿态主动调整技术，实现沉浸式人机交互的效果。如图2、图3所示，本申请实施例提供的方法引入轮廓匹配模型与特征匹配模型，从三维模型库中检索出与场景中物体最相似的三维模型，再利用VR眼镜的姿态信息并将检索得到的模型与对应的输入场景物体进行对齐。实现对真实应用场景中的二维图像进行三维模型匹配，同时提升用户与虚拟模型之间的交互体验。该方法可以分为三个技术阶段，包括感知、检索和交互三个部分，具体实现流程如下：感知：以多传感器为支撑，获取物体二维多视图图像。VR图像采集依托多传感器技术采集用户视野中的图像，即通过图像采集模块采集像素分量，具体的，通过广角、标准以及长焦镜头，检测视野中的光线，如自然光、人工光；通过三元色滤色器排列在各自的光传感组件方格上形成马赛克彩色滤色阵列，最终通过对得到的各个颜色信息进行插值处理，得到每个像素点的绿色分量、红色分量、蓝色分量；同时，根据人体姿态及动作进行判定并将信号传入设计的多视图模型中，从而获得当前时刻用户视野中的二维图像及其视角、焦距、景深等信息。检索：以二维图像为输入，检索其对应的三维模型。本申请实施例从建立图像和三维模型之间的关联性出发，利用单张VR头盔采集的图像检索出与其相似的三维模型，从而实现基于二维图像的三维检索。从宏观上，分析二维图像的几何距离、视角、焦距、景深等信息，借助设计的二维到三维轮廓匹配模型，从三维模型库中选择对应的模型。此外，从微观上，分析图像特征和三维模型的特征匹配关系，借助设计的特征映射模型，将输入的图像和三维模型库中的模型在统一的特征空间中进行映射，并根据特征之间的距离判断两者的相似程度，从而充分建立图像和三维模型的相关性，最终输出一个与目标物体相似的目标三维模型，实现过程如图4所示。交互：以人体姿态、动作为依据，调整三维模型位置。为了保证在头部位姿发生变化时，实现三维模型的相应几何变换，提高用户与模型间的紧密交互，本申请实施例通过陀螺仪获得当前头部的侧倾角度；同时结合固定式定位器，追踪头戴式显示器上光子感应器的信息，从而记录当前时刻的头部姿态数据。在进行头部姿态数据获取定位头部姿态时，还可以通过双目SLAM与I MU互补方式获得。混合现实增强显示眼镜通常使用于复杂状况的环境下，实现眼镜的自主空间感知十分重要，同步定位与建图算法是空间感知定位算法的核心技术。单纯的视觉SLAM在相机的快速运动中，会出现运动模糊、帧间重叠区域小，导致特征匹配难度高、鲁棒性差，定位精度低。而I MU针对短时间内的快速运动、相机旋转姿态等提供较好的估计，同时相机信息可有效解决I MU的静态漂移问题。单目视觉SLAM则有着初始化的尺度不确定及跟踪的尺度漂移等缺陷，选择双目SLAM与I MU互补，可以实现相机即头部的快速跟踪定位。视觉及I MU惯性测量间的耦合方法包含松耦合和紧耦合。松耦合时两者相互独立，分别计算，采用自动铝箔及相应的方法对系统姿态数据进行估计，紧耦合则通过利用视觉的图像特征和I MU积分的位置、方向和速度融合，输出优化后的位置、方向和速度。相对于松耦合，紧耦合需要更多的计算，需要系统更多的实时性能，且确定一部分信息时则无法进行计算。为了计算的实时性，提高计算帧频和鲁棒性，选用松耦合的方式进行计算。通过优化和改进的方式融合视觉数据和惯性数据信息，建立视觉惯性里程表，通过协调惯性测量及视觉来进行优化求解，实现改进、优化并融合的目标。对用户头部进行跟踪定位后，即可根据采集手部信息相机的内外参等参数实现对用户手势交互空间的定位。通过整合陀螺仪和固定式定位器这两部分数据，结合设计的头部位姿模型，获得的头部所处位置、转动角度以及转动方向等数据，以大致确定头部位姿与三维模型间的相对运动关系，并确定图像选取框的倾角和图像选取框的中心点与物体的对应位置关系，实现当头部旋转时准确地将三维物体放入图像选取框中，使得目标三维模型的呈现给用户的视角随着头部的旋转进行相应的转动。该图像选取框的倾角可以根据图像选取框的预设角度与头部转动角度之间的差，在头部位姿发生变化时，三维物体也能做出相应的调整，实现动作与模型的三维匹配。参见图5，本申请实施例还可以提供一种三维场景匹配交互装置，如图5所示，该装置可以包括：二维图像获取单元501，用于获取当前时刻用户视野中的二维图像及视角信息、焦距信息、景深信息；所述二维图像包括目标物体；目标三维模型获取单元502，用于利用所述视角信息、所述焦距信息、所述景深信息将所述二维图像与三维模型库中的三维模型进行匹配，获得与所述目标物体相似的目标三维模型；相对运动关系确定单元503，用于获取当前时刻用户头部的姿态数据，利用所述姿态数据确定所述用户的头部位姿与所述目标三维模型的相对运动关系；对应位置关系确定单元504，用于根据所述姿态数据确定图像选取框的倾角、图像选取框的中心点与所述目标物体的对应位置关系；目标三维模型调整单元505，用于结合图像选取框的倾角、所述图像选取框的中心点与所述目标物体的对应位置关系以及所述相对运动关系，将所述目标三维模型调整至目标位姿并放入所述图像选取框内。本申请实施例还可以提供一种三维场景匹配交互设备，所述设备包括处理器以及存储器：所述存储器用于存储程序代码，并将所述程序代码传输给所述处理器；所述处理器用于根据所述程序代码中的指令执行上述的三维场景匹配交互方法的步骤。如图6所示，本申请实施例提供的一种三维场景匹配交互设备，可以包括：处理器10、存储器11、通信接口12和通信总线13。处理器10、存储器11、通信接口12均通过通信总线13完成相互间的通信。在本申请实施例中，处理器10可以为中央处理器、特定应用集成电路、数字信号处理器、现场可编程门阵列或者其他可编程逻辑器件等。处理器10可以调用存储器11中存储的程序，具体的，处理器10可以执行三维场景匹配交互方法的实施例中的操作。存储器11中用于存放一个或者一个以上程序，程序可以包括程序代码，程序代码包括计算机操作指令，在本申请实施例中，存储器11中至少存储有用于实现以下功能的程序：获取当前时刻用户视野中的二维图像及视角信息、焦距信息、景深信息；所述二维图像包括目标物体；利用所述视角信息、所述焦距信息、所述景深信息将所述二维图像与三维模型库中的三维模型进行匹配，获得与所述目标物体相似的目标三维模型；获取当前时刻用户头部的姿态数据，利用所述姿态数据确定所述用户的头部位姿与所述目标三维模型的相对运动关系；根据所述姿态数据确定图像选取框的倾角、图像选取框的中心点与所述目标物体的对应位置关系；结合图像选取框的倾角、所述图像选取框的中心点与所述目标物体的对应位置关系以及所述相对运动关系，将所述目标三维模型调整至目标位姿并放入所述图像选取框内。在一种可能的实现方式中，存储器11可包括存储程序区和存储数据区，其中，存储程序区可存储操作系统，以及至少一个功能所需的应用程序等；存储数据区可存储使用过程中所创建的数据，如初始化数据等。此外，存储器11可以包括高速随机存取存储器，还可以包括非易失性存储器，例如至少一个磁盘存储器件或其他易失性固态存储器件。通信接口12可以为通信模块的接口，用于与其他设备或者系统连接。当然，需要说明的是，图6所示的结构并不构成对本申请实施例中三维场景匹配交互设备的限定，在实际应用中三维场景匹配交互设备可以包括比图6所示的更多或更少的部件，或者组合某些部件。本申请实施例还可以提供一种计算机可读存储介质，所述计算机可读存储介质用于存储程序代码，所述程序代码用于执行上述的三维场景匹配交互方法的步骤。需要说明的是，在本文中，诸如第一和第二等之类的关系术语仅仅用来将一个实体或者操作与另一个实体或操作区分开来，而不一定要求或者暗示这些实体或操作之间存在任何这种实际的关系或者顺序。而且，术语“包括”、“包含”或者其任何其他变体意在涵盖非排他性的包含，从而使得包括一系列要素的过程、方法、物品或者设备不仅包括那些要素，而且还包括没有明确列出的其他要素，或者是还包括为这种过程、方法、物品或者设备所固有的要素。在没有更多限制的情况下，由语句“包括一个……”限定的要素，并不排除在包括所述要素的过程、方法、物品或者设备中还存在另外的相同要素。通过以上的实施方式的描述可知，本领域的技术人员可以清楚地了解到本申请可借助软件加上必需的通用硬件平台的方式来实现。基于这样的理解，本申请的技术方案本质上或者说对现有技术做出贡献的部分可以以软件产品的形式体现出来，该计算机软件产品可以存储在存储介质中，如ROM/RAM、磁碟、光盘等，包括若干指令用以使得一台计算机设备执行本申请各个实施例或者实施例的某些部分所述的方法。本说明书中的各个实施例均采用递进的方式描述，各个实施例之间相同相似的部分互相参见即可，每个实施例重点说明的都是与其他实施例的不同之处。尤其，对于系统或系统实施例而言，由于其基本相似于方法实施例，所以描述得比较简单，相关之处参见方法实施例的部分说明即可。以上所描述的系统及系统实施例仅仅是示意性的，其中所述作为分离部件说明的单元可以是或者也可以不是物理上分开的，作为单元显示的部件可以是或者也可以不是物理单元，即可以位于一个地方，或者也可以分布到多个网络单元上。可以根据实际的需要选择其中的部分或者全部模块来实现本实施例方案的目的。本领域普通技术人员在不付出创造性劳动的情况下，即可以理解并实施。以上所述仅为本发明的较佳实施例而已，并非用于限定本发明的保护范围。凡在本发明的精神和原则之内所作的任何修改、等同替换、改进等，均包含在本发明的保护范围内。
