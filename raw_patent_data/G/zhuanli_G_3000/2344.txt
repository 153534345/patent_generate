标题title
一种云服务数据信息安全管理方法及系统
摘要abst
本发明涉及数据处理技术领域，尤其涉及一种云服务数据信息安全管理方法及系统。所述方法包括以下步骤：对初始数据集进行混淆加密处理，生成混淆加密数据；对混淆加密数据进行数据验证标记，生成验证加密数据；对验证加密数据进行风险筛选处理，生成优化特征集；将优化特征集与风险评估数据进行对应整合，并进行编码处理，生成风险特征向量；对风险特征向量进行数据指纹计算，生成风险特征向量的数据指纹；将数据指纹与用户验证信息进行数据指纹索引表的Merkle树建立，生成Merkle树；对Merkle树进行完整性验证存储处理，生成验证区块存储数据。本发明通过对数据进行验证加密及风险筛选，保障了云服务器存储的信息安全。
权利要求书clms
1.一种云服务数据信息安全管理方法，其特征在于，包括以下步骤：步骤S1：获取云服务器的初始数据；利用预设的混淆参数对初始数据集进行混淆加密处理，生成混淆加密数据；步骤S2：获取用户虹膜数据与用户身份信息；根据用户虹膜数据与用户身份信息进行用户验证信息提取，生成用户验证信息；根据用户验证信息对混淆加密数据进行数据验证标记，生成验证加密数据；步骤S3：利用线性判别分析对验证加密数据进行特征提取处理，生成原始特征集；利用深度学习算法原始特征集进行数据风险预测处理，生成风险评估数据；步骤S4：根据风险评估数据对原始特征集进行风险筛选处理，生成优化特征集；将优化特征集与风险评估数据进行对应整合，并进行编码处理，生成风险特征向量；步骤S5：利用哈希函数对风险特征向量进行数据指纹计算，生成风险特征向量的数据指纹；将数据指纹与用户验证信息进行索引关系建立，生成数据指纹索引表；步骤S6：利用数据指纹索引表进行数据指纹索引表的Merkle树建立，生成Merkle树；对Merkle树进行完整性验证存储处理，从而生成验证区块存储数据。2.根据权利要求1所述的云服务数据信息安全管理方法，其特征在于，步骤S1包括以下步骤：步骤S11：获取云服务器的初始数据集；步骤S12：对初始数据集进行数据异常值剔除，生成清洗数据集；步骤S13：利用主成分分析法对清洗数据集进行关键信息提取处理，生成关键信息数据；步骤S14：利用关键信息数据对清洗数据集进行缺失值填充，生成修正数据集；步骤S15：利用数据信息降噪公式对修正数据集进行数据降噪处理，生成降噪数据集；步骤S16：利用预设的数据集格式对降噪数据集进行数据格式标准化转换，生成标准数据集；步骤S17：利用预设的混淆参数对标准数据集进行混淆打乱处理，生成混淆数据集；步骤S18：利用非对称加密技术对混淆数据集进行数据加密处理，生成混淆加密数据。3.根据权利要求2所述的云服务数据信息安全管理方法，其特征在于，步骤S15中的数据信息降噪公式如下所示：式中，K表示为降噪数据集，n表示为修正数据集的数据总数，xi表示为第i个修正数据集的原始数据，a表示为允许滤波器的最大滤波能力，b表示为滤波器的频率，c表示为滤波器的振幅，d表示为允许的最大滤波能力，t表示为处理信号涉及的时间，τ表示为降噪数据集的异常调整值。4.根据权利要求3所述的云服务数据信息安全管理方法，其特征在于，步骤S2包括以下步骤：步骤S21：获取用户虹膜数据与用户身份信息；步骤S22：利用灰度共生矩阵对用户虹膜数据进行虹膜纹理特征提取处理，生成虹膜特征数据；步骤S23：利用快速傅里叶变换技术对虹膜特征数据进行频谱图转换，生成虹膜频谱图；步骤S24：利用小波变换技术对虹膜频谱图进行虹膜小波提取，生成虹膜小波数据；步骤S25：利用字符编码对虹膜小波数据进行数据编码，生成虹膜数字信号；步骤S26：利用字符编码对用户身份信息进行数据编码，生成身份信息数字信号；步骤S27：将虹膜数字信号与身份信息数字信号进行数据整合，以生成用户验证信息；步骤S28：根据用户验证信息对混淆加密数据进行数据验证标记，生成验证加密数据。5.根据权利要求4所述的云服务数据信息安全管理方法，其特征在于，步骤S3包括以下步骤：步骤S31：利用线性判别分析对验证加密数据进行特征提取处理，生成原始特征集；步骤S32：利用深度学习算法建立原始特征集的风险评估映射关系，生成初始风险评估模型；步骤S33：获取云服务器的历史风险评估数据；步骤S34：利用历史风险评估数据对初始风险评估模型进行模型训练，生成风险评估模型；步骤S35：利用风险评估模型对原始特征集进行数据风险评估预测处理，生成风险评估数据。6.根据权利要求5所述的云服务数据信息安全管理方法，其特征在于，步骤S4包括以下步骤：步骤S41：利用预设的信息风险评估阈值对风险评估数据进行信息风险判断，当风险评估数据大于信息风险评估阈值时，返回步骤S15，当风险评估数据不大于信息风险评估阈值时，将原始特征集标记为优化特征集；步骤S42：将优化特征集与风险评估数据进行对应整合，并进行编码处理，生成风险特征向量。7.根据权利要求6所述的云服务数据信息安全管理方法，其特征在于，步骤S5包括以下步骤：步骤S51：利用哈希函数对风险特征向量进行哈希计算，从而生成风险特征哈希值；步骤S52：利用风险特征哈希值构建风险特征向量的数据指纹；步骤S53：将数据指纹与用户验证信息进行数据关联，以构建数据指纹关联数据；步骤S54：获取云服务器的索引键信息；步骤S55：利用索引键信息将数据指纹关联数据建立数据与云服务器的索引关系，以生成数据指纹索引表。8.根据权利要求7所述的云服务数据信息安全管理方法，其特征在于，步骤S6包括以下步骤：步骤S61：利用哈希函数对数据指纹索引表进行哈希计算，从而生成数据指纹索引哈希值；步骤S62：利用区块链网络将数据指纹索引哈希值进行数据指纹索引表的Merkle树建立，生成Merkle树；步骤S63：利用预设的区块链分块阈值将Merkle树进行分块存储处理，从而生成原始区块存储数据；步骤S64：利用云服务数据安全验证共识算法对原始区块存储数据进行数据完整性计算，从而生成原始区块存储数据的完整性验证数据；步骤S65：利用完整性验证阈值对完整性验证数据进行完整性判断，当完整性验证数据不小于完整性验证阈值时，将原始区块存储数据标记为验证区块存储数据，当完整性验证数据小于完整性验证阈值时，将原始区块存储数据剔除。9.根据权利要求8所述的云服务数据信息安全管理方法，其特征在于，步骤S64中的云服务数据安全验证共识算法如下所示：式中，F表示为完整性验证数据，m表示为原始区块存储数据的节点数量，zj表示为第j个节点的验证数据，ui表示为第j个节点的信任权重，A表示为节点平均大小，y表示为原始区块存储数据的原始数据，o表示为根据初始数据集生成的完整性权重信息，g表示为原始数据的完整性信任阈值，表示为变量y的导数，rj表示为第j个节点生成的哈希值，k表示为数据指纹索引哈希值长度生成的安全权重信息，δ表示为完整性验证数据的异常调整值。10.一种云服务数据信息安全管理系统，其特征在于，包括：数据预处理模块，用于获取云服务器的初始数据；利用预设的混淆参数对初始数据集进行混淆加密处理，生成混淆加密数据；数据验证模块，用于获取用户虹膜数据与用户身份信息；根据用户虹膜数据与用户身份信息进行用户验证信息提取，生成用户验证信息；根据用户验证信息对混淆加密数据进行数据验证标记，生成验证加密数据；风险评估模块，利用线性判别分析对验证加密数据进行特征提取处理，生成原始特征集；利用深度学习算法原始特征集进行数据风险预测处理，生成风险评估数据；数据编码模块：根据风险评估数据对原始特征集进行风险筛选处理，生成优化特征集；将优化特征集与风险评估数据进行对应整合，并进行编码处理，生成风险特征向量；数据指纹建立模块：利用哈希函数对风险特征向量进行数据指纹计算，生成风险特征向量的数据指纹；将数据指纹与用户验证信息进行索引关系建立，生成数据指纹索引表；数据存储模块：利用数据指纹索引表进行数据指纹索引表的Merkle树建立，生成Merkle树；对Merkle树进行完整性验证存储处理，从而生成验证区块存储数据。
说明书desc
技术领域本发明涉及数据处理技术领域，尤其涉及一种云服务数据信息安全管理方法及系统。背景技术随着云计算技术的快速发展，云服务在各个领域得到广泛应用，云服务提供了便利的存储和处理大量数据的方式，便捷人们的生活方式。然而，传统的数据安全管理方法无法满足云服务环境下的安全需求，数据可能被第三方截取，并且对于信息中存在的风险也无法预知及判断。发明内容基于此，本发明提供一种云服务数据信息安全管理方法及系统，以解决至少一个上述技术问题。为实现上述目的，一种云服务数据信息安全管理方法，包括以下步骤：步骤S1：获取云服务器的初始数据；利用预设的混淆参数对初始数据集进行混淆加密处理，生成混淆加密数据；步骤S2：获取用户虹膜数据与用户身份信息；根据用户虹膜数据与用户身份信息进行用户验证信息提取，生成用户验证信息；根据用户验证信息对混淆加密数据进行数据验证标记，生成验证加密数据；步骤S3：利用线性判别分析对验证加密数据进行特征提取处理，生成原始特征集；利用深度学习算法原始特征集进行数据风险预测处理，生成风险评估数据；步骤S4：根据风险评估数据对原始特征集进行风险筛选处理，生成优化特征集；将优化特征集与风险评估数据进行对应整合，并进行编码处理，生成风险特征向量；步骤S5：利用哈希函数对风险特征向量进行数据指纹计算，生成风险特征向量的数据指纹；将数据指纹与用户验证信息进行索引关系建立，生成数据指纹索引表；步骤S6：利用数据指纹索引表进行数据指纹索引表的Merkle树建立，生成Merkle树；对Merkle树进行完整性验证存储处理，从而生成验证区块存储数据。本发明通过使用预设的混淆参数对初始数据集进行混淆加密处理，可以有效保护数据的机密性，防止未经授权的访问者获得敏感信息。结合用户虹膜数据和身份信息进行用户验证信息提取，可以增加对用户身份的确认准确性，提高系统的安全性。利用用户验证信息对混淆加密数据进行数据验证标记，确保数据的完整性，防止数据在传输或存储过程中被篡改或损坏。通过使用线性判别分析对验证加密数据进行特征提取处理，生成原始特征集。然后，利用深度学习算法进行数据风险预测处理，生成风险评估数据。这有助于系统识别潜在的数据安全风险并提前采取相应措施，根据风险评估数据对原始特征集进行筛选处理，生成优化特征集，这可以减少特征集中存在的风险元素，提高数据的安全性和可靠性。通过对风险特征向量进行哈希函数计算，生成数据指纹，将数据指纹与用户验证信息建立索引关系，生成数据指纹索引表。这有助于快速准确地定位和访问数据，提高系统的数据查询效率。利用数据指纹索引表建立Merkle树，并对Merkle树进行完整性验证存储处理，从而生成验证区块存储数据，这种存储方式可以防止数据的篡改和丢失，并提供数据的可追溯性和完整性保证。因此，本发明的数据安全管理方法通过对数据的加密及用户自身信息进行验证，防止被第三方截取或破坏，对于信息中存在的风险也能甄别判定，筛选出满足风险阈值的信息，提高了数据的安全性，满足了云服务环境下的安全需求。优选地，步骤S1包括以下步骤：步骤S11：获取云服务器的初始数据集；步骤S12：对初始数据集进行数据异常值剔除，生成清洗数据集；步骤S13：利用主成分分析法对清洗数据集进行关键信息提取处理，生成关键信息数据；步骤S14：利用关键信息数据对清洗数据集进行缺失值填充，生成修正数据集；步骤S15：利用数据信息降噪公式对修正数据集进行数据降噪处理，生成降噪数据集；步骤S16：利用预设的数据集格式对降噪数据集进行数据格式标准化转换，生成标准数据集；步骤S17：利用预设的混淆参数对标准数据集进行混淆打乱处理，生成混淆数据集；步骤S18：利用非对称加密技术对混淆数据集进行数据加密处理，生成混淆加密数据。本发明获得云服务器上存储的原始数据集，为后续数据处理和加密提供基础。通过剔除异常值，可以消除数据集中的错误或异常数据，提高数据的准确性和质量。主成分分析可以从原始数据集中提取关键信息，降低数据维度，减少冗余信息，同时保持数据的重要特征，为后续处理提供更高效的数据表示。填充缺失值可以修复数据集中的空缺部分，使得数据集更完整，减少因缺失数据而导致的信息丢失，提高后续分析的可靠性和准确性，利用主要特征信息进行填充，大大提高了数据的准确性。通过数据降噪处理，可以减少数据集中的噪声、干扰和不必要的变动，提高数据的清晰度和可解释性，从而提高后续分析和加密的效果。数据格式标准化可以使数据集符合特定的规范和格式要求，确保数据的一致性和互操作性，方便后续处理和加密的实施。混淆打乱处理可以使数据集中的特征关系变得难以理解和分析，增加数据的隐蔽性和安全性，防止未经授权的访问者获取敏感信息。非对称加密技术可以对混淆数据集进行强大的加密，确保数据在传输和存储过程中的机密性和安全性，防止数据泄露和被篡改。优选地，步骤S15中的数据信息降噪公式如下所示：式中，K表示为降噪数据集，n表示为修正数据集的数据总数，xi表示为第i个修正数据集的原始数据，a表示为允许滤波器的最大滤波能力，b表示为滤波器的频率，c表示为滤波器的振幅，d表示为允许的最大滤波能力，t表示为处理信号涉及的时间，τ表示为降噪数据集的异常调整值。本发明利用一种数据信息降噪公式，该数学公式充分考虑了修正数据集的数据总数n、第i个修正数据集的原始数据xi、允许滤波器的最大滤波能力a、滤波器的频率b、滤波器的振幅c、允许的最大滤波能力d、处理信号涉及的时间t以及函数之间的相互作用关系，以形成函数关系式：即，该函数关系式通过去除修正数据集中的噪声和干扰，能够显著提高数据的质量。噪声和干扰可能来自于数据采集过程中的传感器误差、通信干扰或其他环境因素，通过降噪公式的应用，可以获得更加干净和准确的数据，减少数据中的误差，提高数据的可靠性和准确性。在降噪过程中采用了对数变换和正弦函数处理，这有助于保留原始数据的重要特征，通过对数变换，可以平衡数据集中较大和较小值之间的差异，使得数据更具可比性和一致性，正弦函数处理则有助于处理周期性信号，保留信号的频率特征，这样降噪后的数据仍然能够反映原始信号的重要特征，有助于后续的数据分析和应用。降噪公式中的参数a、b、c、d和t可以根据实际需求进行调节，以适应不同类型和特征的数据，例如通过调节参数a和d，可以控制滤波器的滤波能力，使其适应不同程度的噪声干扰；参数b和c的调节可以改变滤波器对不同频率和振幅的信号的响应，以适应不同频域特征的数据；参数t的调节则可以改变滤波器对不同时间尺度上的信号的响应，适应不同时间序列的数据特征，这种灵活性使得降噪方法能够适应不同数据场景的需求，并提供更准确的降噪效果。利用降噪数据集的异常调整值τ对函数关系式进行调整修正，减少异常数据或误差项带来的误差影响，从而更准确地生成降噪数据集K，提高了对修正数据集进行数据降噪处理的准确性和可靠性。同时该公式中的调整值可以根据实际情况进行调整，应用于不同的修正数据集中，提高了算法的灵活性与适用性。优选地，步骤S2包括以下步骤：步骤S21：获取用户虹膜数据与用户身份信息；步骤S22：利用灰度共生矩阵对用户虹膜数据进行虹膜纹理特征提取处理，生成虹膜特征数据；步骤S23：利用快速傅里叶变换技术对虹膜特征数据进行频谱图转换，生成虹膜频谱图；步骤S24：利用小波变换技术对虹膜频谱图进行虹膜小波提取，生成虹膜小波数据；步骤S25：利用字符编码对虹膜小波数据进行数据编码，生成虹膜数字信号；步骤S26：利用字符编码对用户身份信息进行数据编码，生成身份信息数字信号；步骤S27：将虹膜数字信号与身份信息数字信号进行数据整合，以生成用户验证信息；步骤S28：根据用户验证信息对混淆加密数据进行数据验证标记，生成验证加密数据。本发明通过获取用户的虹膜数据和身份信息，可以用于进行身份验证和数据关联，确保只有合法用户能够访问和操作相关数据。通过灰度共生矩阵分析虹膜图像的纹理特征，可以提取出与个体虹膜唯一相关的特征数据，这些特征数据在后续的虹膜识别过程中起到关键作用，可以准确地识别和区分不同的虹膜。通过应用快速傅里叶变换，可以将虹膜特征数据从时域转换到频域，得到虹膜的频谱表示。频谱图能够捕捉虹膜数据的频率特征，使得后续的特征处理和匹配更加高效和准确。小波变换是一种时频域分析方法，通过将频谱图进行小波变换，可以进一步提取虹膜数据的局部特征和频率成分，虹膜小波数据能够更加准确地表征虹膜的结构和纹理信息，提高虹膜识别的精度和可靠性。通过字符编码，将虹膜小波数据转换为数字信号的形式，数字信号的表示形式更便于存储、传输和处理，可以方便地在计算机系统中进行进一步的处理和分析。对用户身份信息进行字符编码，将其转换为数字信号的形式，这样可以确保身份信息的安全性和一致性，同时方便与虹膜数据进行关联和匹配。将虹膜数字信号和身份信息数字信号进行整合，形成完整的用户验证信息，这个验证信息包含了虹膜特征和身份信息的关联，用于后续的身份验证和数据访问控制。利用用户验证信息对混淆加密数据进行验证标记，确保数据的完整性和合法性，通过验证加密数据的生成，可以防止未经授权的用户对数据进行篡改或访问，保护数据的安全性和隐私性。优选地，步骤S3包括以下步骤：步骤S31：利用线性判别分析对验证加密数据进行特征提取处理，生成原始特征集；步骤S32：利用深度学习算法建立原始特征集的风险评估映射关系，生成初始风险评估模型；步骤S33：获取云服务器的历史风险评估数据；步骤S34：利用历史风险评估数据对初始风险评估模型进行模型训练，生成风险评估模型；步骤S35：利用风险评估模型对原始特征集进行数据风险评估预测处理，生成风险评估数据。本发明通过线性判别分析，可以从验证加密数据中提取出具有判别性能力的特征，这些特征可以用于后续的风险评估和预测，帮助识别数据中存在的风险和异常。通过深度学习算法，可以建立原始特征集与风险评估之间的映射关系，这样的模型可以学习数据特征和风险之间的复杂关系，提供更准确和全面的风险评估能力。获取云服务器的历史风险评估数据可以提供过去的风险情况和趋势信息，这些数据可以作为训练和验证风险评估模型的依据，帮助模型更好地理解和预测当前的风险情况。通过利用历史风险评估数据对初始模型进行训练，可以不断优化模型的预测能力和准确性，训练后的风险评估模型能够更好地捕捉和预测数据中的风险特征，提供更可靠的风险评估结果。利用训练好的风险评估模型，对原始特征集进行预测处理，可以生成针对数据的风险评估结果，这些结果可以指示数据中的潜在风险，帮助用户和系统决策者了解数据安全状况，并采取相应的风险管理措施。优选地，步骤S4包括以下步骤：步骤S41：利用预设的信息风险评估阈值对风险评估数据进行信息风险判断，当风险评估数据大于信息风险评估阈值时，返回步骤S15，当风险评估数据不大于信息风险评估阈值时，将原始特征集标记为优化特征集；步骤S42：将优化特征集与风险评估数据进行对应整合，并进行编码处理，生成风险特征向量。本发明通过与预设的信息风险评估阈值进行比较，能够判断数据的信息风险程度，根据判断结果，可以及时识别出高风险的数据，从而采取针对性的措施进行进一步的处理和保护。将风险评估数据不大于信息风险评估阈值的原始特征集标记为优化特征集，通过标记识别出风险较低的数据，以便后续的优化处理和进一步的数据分析，并且将风险较高的数据返回步骤S15再重新进行加密，保障了数据的安全性。将优化特征集与风险评估数据进行整合，并进行编码处理，可以将特征和风险评估结果相对应地组合在一起，这样的整合和编码能够为后续的数据指纹索引和存储提供标识和检索的便利性，方便快速地识别和访问特定的风险特征数据。优选地，步骤S5包括以下步骤：步骤S51：利用哈希函数对风险特征向量进行哈希计算，从而生成风险特征哈希值；步骤S52：利用风险特征哈希值构建风险特征向量的数据指纹；步骤S53：将数据指纹与用户验证信息进行数据关联，以构建数据指纹关联数据；步骤S54：获取云服务器的索引键信息；步骤S55：利用索引键信息将数据指纹关联数据建立数据与云服务器的索引关系，以生成数据指纹索引表。本发明哈希函数可以将风险特征向量转换为固定长度的哈希值，通过哈希计算，可以将复杂的风险特征向量映射为较短的哈希值，提供一种高效、唯一且紧凑的数据表示方式，这有助于减少数据的存储空间需求和索引计算的复杂度，同时保护数据的隐私和安全。通过使用风险特征哈希值，可以构建风险特征向量的数据指纹，数据指纹是对数据内容的唯一表示，类似于数据的摘要或指纹，它具有较小的尺寸并保持数据的完整性，可用于快速检索、比对和识别数据。将数据指纹与用户验证信息进行关联，可以建立数据指纹关联数据，这种关联可以确保数据指纹与相应的用户身份验证信息一起存储和管理，从而实现数据与用户的关联和权限控制，数据指纹关联数据可以用于快速识别和检索特定用户的数据，提高数据的访问效率和安全性。获取云服务器的索引键信息是为了建立数据指纹与云服务器的索引关系，索引键信息可以是唯一标识云服务器的关键属性，如服务器ID、地址或其他识别信息，这些信息将用于构建数据指纹的索引关系，以便快速定位和访问存储在云服务器上的相关数据。利用索引键信息，可以将数据指纹关联数据与云服务器建立索引关系，这样可以生成数据指纹索引表，用于记录和管理数据指纹关联数据的索引信息。数据指纹索引表提供了一种高效的索引结构，能够快速检索和定位特定数据的存储位置，提高数据的访问速度和效率。优选地，步骤S6包括以下步骤：步骤S61：利用哈希函数对数据指纹索引表进行哈希计算，从而生成数据指纹索引哈希值；步骤S62：利用区块链网络将数据指纹索引哈希值进行数据指纹索引表的Merkle树建立，生成Merkle树；步骤S63：利用预设的区块链分块阈值将Merkle树进行分块存储处理，从而生成原始区块存储数据；步骤S64：利用云服务数据安全验证共识算法对原始区块存储数据进行数据完整性计算，从而生成原始区块存储数据的完整性验证数据；步骤S65：利用完整性验证阈值对完整性验证数据进行完整性判断，当完整性验证数据不小于完整性验证阈值时，将原始区块存储数据标记为验证区块存储数据，当完整性验证数据小于完整性验证阈值时，将原始区块存储数据剔除。本发明通过哈希计算，可以将数据指纹索引表转换为唯一的哈希值，数据指纹索引哈希值的生成确保了数据指纹索引表的完整性和一致性，可以用于后续的Merkle树建立和数据完整性验证。通过使用区块链网络，可以将数据指纹索引哈希值构建为Merkle树，Merkle树是一种基于哈希的二叉树结构，能够高效地验证数据的完整性和一致性，它可以有效地防止数据篡改和欺骗，提供了一种安全可靠的数据存储和验证机制。根据预设的区块链分块阈值将Merkle树进行分块存储处理，生成原始区块存储数据，这样的分块存储方式有助于提高数据的存储效率和访问速度，同时方便对数据进行管理和验证。通过云服务数据安全验证共识算法，对原始区块存储数据进行数据完整性计算，生成原始区块存储数据的完整性验证数据，这样的计算可以确保原始区块存储数据的完整性，验证数据的一致性和正确性。根据预设的完整性验证阈值，对完整性验证数据进行判断。当完整性验证数据不小于完整性验证阈值时，将原始区块存储数据标记为验证区块存储数据，表示数据完整性得到验证，当完整性验证数据小于完整性验证阈值时，将原始区块存储数据剔除，说明数据可能存在篡改或不完整。优选地，步骤S64中的云服务数据安全验证共识算法如下所示：式中，F表示为完整性验证数据，m表示为原始区块存储数据的节点数量，zj表示为第j个节点的验证数据，ui表示为第j个节点的信任权重，A表示为节点平均大小，y表示为原始区块存储数据的原始数据，o表示为根据初始数据集生成的完整性权重信息，g表示为原始数据的完整性信任阈值，表示为变量y的导数，rj表示为第j个节点生成的哈希值，k表示为数据指纹索引哈希值长度生成的安全权重信息，δ表示为完整性验证数据的异常调整值。本发明利用一种云服务数据安全验证共识算法，该数学公式充分考虑了原始区块存储数据的节点数量m、第j个节点的验证数据zj、第j个节点的信任权重ui、节点平均大小A、原始区块存储数据的原始数据y、根据初始数据集生成的完整性权重信息o、原始数据的完整性信任阈值g、变量y的导数第j个节点生成的哈希值rj、数据指纹索引哈希值长度生成的安全权重信息k以及函数之间的相互作用关系，以形成函数关系式：即，该函数关系式中计算公式将原始区块存储数据的节点验证数据进行加权求和，并应用一系列数学运算，包括对数、指数、三角函数等，以生成完整性验证数据，这个计算过程综合了多个因素，能够综合考虑数据节点的验证结果、信任权重以及数据的完整性特征，从而提供了对数据完整性的综合评估。通过考虑多个节点的验证数据，计算公式可以更准确地评估数据的完整性，每个节点的验证数据被加权平均，其中节点的信任权重用于反映其可信度，通过多节点的参与，可以减少单个节点的潜在错误或恶意行为对数据完整性的影响，提高数据验证的可靠性。计算公式中的根据初始数据集生成的完整性权重信息，用于衡量数据的完整性，这个信息提供了对数据完整性的参考基准，可以与验证数据进行比较，以判断数据的完整性程度。计算公式中的完整性信任阈值是用于判断数据完整性的阈值，当完整性验证数据超过该阈值时，表示数据具有较高的完整性，可以被标记为验证区块存储数据，这个阈值的设定可以根据具体情况进行调整，以满足对数据完整性的要求。计算公式中的哈希值和安全权重信息用于表示数据指纹索引哈希值的安全性，哈希值的引入可以提高数据的抗篡改能力，而安全权重信息则可用于调整数据完整性的计算结果，增强数据完整性验证的可靠性。利用完整性验证数据的异常调整值δ对函数关系式进行调整修正，减少异常数据或误差项带来的误差影响，从而更准确地生成完整性验证数据F，提高了对原始区块存储数据进行数据完整性计算的准确性和可靠性。同时该公式中的权重信息、阈值以及调整值可以根据实际情况进行调整，应用于不同的原始区块存储数据中，提高了算法的灵活性与适用性。在本说明书中，提供了一种云服务数据信息安全管理系统，包括：数据预处理模块，用于获取云服务器的初始数据；利用预设的混淆参数对初始数据集进行混淆加密处理，生成混淆加密数据；数据验证模块，用于获取用户虹膜数据与用户身份信息；根据用户虹膜数据与用户身份信息进行用户验证信息提取，生成用户验证信息；根据用户验证信息对混淆加密数据进行数据验证标记，生成验证加密数据；风险评估模块，利用线性判别分析对验证加密数据进行特征提取处理，生成原始特征集；利用深度学习算法原始特征集进行数据风险预测处理，生成风险评估数据；数据编码模块：根据风险评估数据对原始特征集进行风险筛选处理，生成优化特征集；将优化特征集与风险评估数据进行对应整合，并进行编码处理，生成风险特征向量；数据指纹建立模块：利用哈希函数对风险特征向量进行数据指纹计算，生成风险特征向量的数据指纹；将数据指纹与用户验证信息进行索引关系建立，生成数据指纹索引表；数据存储模块：利用数据指纹索引表进行数据指纹索引表的Merkle树建立，生成Merkle树；对Merkle树进行完整性验证存储处理，从而生成验证区块存储数据。本申请有益效果在于，本发明混淆加密和非对称加密技术，以及其他步骤中的加密处理，保护了数据的隐私和机密性，混淆加密和非对称加密可以有效地对数据进行加密和解密，防止未经授权的访问者获取敏感数据，这种加密方法确保了数据在存储和传输过程中的安全性，使得即使数据被非法获取，也无法解读其中的内容。数据验证标记和完整性验证数据计算，保障了数据的完整性和一致性，通过验证标记和完整性验证，可以检测到数据被篡改或损坏的情况，防止恶意攻击者对数据进行未授权的修改，这样可以确保数据在存储和传输过程中的完整性，使得数据在各个环节都保持一致和可靠。用户身份验证信息提取和关联，以及后续步骤中的用户验证信息使用，确保了数据的安全访问和操作，通过用户身份验证，只有经过验证的用户才能访问和操作数据，避免了未经授权的访问和数据泄露的风险，这种身份验证和权限控制机制可以有效地保护数据免受未授权用户的访问。特征提取、风险评估和风险筛选，对数据进行风险预测和优化处理，通过对数据的特征提取和风险评估，可以识别出潜在的数据安全风险，进一步通过风险筛选，可以剔除高风险的数据或采取相应的措施进行风险降低，从而提高数据的质量和安全性。数据指纹索引和Merkle树的建立，提供了高效的数据索引和存储机制，数据指纹的计算和索引关系的建立，使得数据的检索和验证更加快速和准确，Merkle树的使用可以高效地验证数据的完整性，确保数据在存储和传输过程中不受损坏和篡改。通过区块链技术的应用和哈希计算的使用，提升了数据的安全性和防护能力，区块链技术提供了分布式、不可篡改的数据存储和验证机制，防止数据的篡改和删除，哈希计算提供了数据的唯一标识和摘要，增强了数据的完整性和抗篡改能力，这些技术的应用提升了云服务数据的安全性，保护数据免受恶意攻击和未授权访问的威胁。附图说明图1为本发明一种云服务数据信息安全管理方法的步骤流程示意图；图2为图1中步骤S2的详细实施步骤流程示意图；图3为图1中步骤S3的详细实施步骤流程示意图；图4为图1中步骤S5的详细实施步骤流程示意图；图5为图1中步骤S6的详细实施步骤流程示意图；本发明目的的实现、功能特点及优点将结合实施例，参照附图做进一步说明。具体实施方式下面结合附图对本发明专利的技术方法进行清楚、完整的描述，显然，所描述的实施例是本发明的一部分实施例，而不是全部的实施例。基于本发明中的实施例，本领域所属的技术人员在没有做出创造性劳动前提下所获得的所有其他实施例，都属于本发明保护的范围。此外，附图仅为本发明的示意性图解，并非一定是按比例绘制。图中相同的附图标记表示相同或类似的部分，因而将省略对它们的重复描述。附图中所示的一些方框图是功能实体，不一定必须与物理或逻辑上独立的实体相对应。可以采用软件形式来实现功能实体，或在一个或多个硬件模块或集成电路中实现这些功能实体，或在不同网络和/或处理器方法和/或微控制器方法中实现这些功能实体。应当理解的是，虽然在这里可能使用了术语“第一”、“第二”等等来描述各个单元，但是这些单元不应当受这些术语限制。使用这些术语仅仅是为了将一个单元与另一个单元进行区分。举例来说，在不背离示例性实施例的范围的情况下，第一单元可以被称为第二单元，并且类似地第二单元可以被称为第一单元。这里所使用的术语“和/或”包括其中一个或更多所列出的相关联项目的任意和所有组合。为实现上述目的，请参阅图1至图5，本发明提供一种云服务数据信息安全管理方法，所述方法包括：步骤S1：获取云服务器的初始数据；利用预设的混淆参数对初始数据集进行混淆加密处理，生成混淆加密数据；步骤S2：获取用户虹膜数据与用户身份信息；根据用户虹膜数据与用户身份信息进行用户验证信息提取，生成用户验证信息；根据用户验证信息对混淆加密数据进行数据验证标记，生成验证加密数据；步骤S3：利用线性判别分析对验证加密数据进行特征提取处理，生成原始特征集；利用深度学习算法原始特征集进行数据风险预测处理，生成风险评估数据；步骤S4：根据风险评估数据对原始特征集进行风险筛选处理，生成优化特征集；将优化特征集与风险评估数据进行对应整合，并进行编码处理，生成风险特征向量；步骤S5：利用哈希函数对风险特征向量进行数据指纹计算，生成风险特征向量的数据指纹；将数据指纹与用户验证信息进行索引关系建立，生成数据指纹索引表；步骤S6：利用数据指纹索引表进行数据指纹索引表的Merkle树建立，生成Merkle树；对Merkle树进行完整性验证存储处理，从而生成验证区块存储数据。本发明通过使用预设的混淆参数对初始数据集进行混淆加密处理，可以有效保护数据的机密性，防止未经授权的访问者获得敏感信息。结合用户虹膜数据和身份信息进行用户验证信息提取，可以增加对用户身份的确认准确性，提高系统的安全性。利用用户验证信息对混淆加密数据进行数据验证标记，确保数据的完整性，防止数据在传输或存储过程中被篡改或损坏。通过使用线性判别分析对验证加密数据进行特征提取处理，生成原始特征集。然后，利用深度学习算法进行数据风险预测处理，生成风险评估数据。这有助于系统识别潜在的数据安全风险并提前采取相应措施，根据风险评估数据对原始特征集进行筛选处理，生成优化特征集，这可以减少特征集中存在的风险元素，提高数据的安全性和可靠性。通过对风险特征向量进行哈希函数计算，生成数据指纹，将数据指纹与用户验证信息建立索引关系，生成数据指纹索引表。这有助于快速准确地定位和访问数据，提高系统的数据查询效率。利用数据指纹索引表建立Merkle树，并对Merkle树进行完整性验证存储处理，从而生成验证区块存储数据，这种存储方式可以防止数据的篡改和丢失，并提供数据的可追溯性和完整性保证。因此，本发明的数据安全管理方法通过对数据的加密及用户自身信息进行验证，防止被第三方截取或破坏，对于信息中存在的风险也能甄别判定，筛选出满足风险阈值的信息，提高了数据的安全性，满足了云服务环境下的安全需求。本发明实施例中，参考图1所述，为本发明一种云服务数据信息安全管理方法的步骤流程示意图，在本实例中，所述云服务数据信息安全管理方法包括以下步骤：步骤S1：获取云服务器的初始数据；利用预设的混淆参数对初始数据集进行混淆加密处理，生成混淆加密数据；本发明实施例中，首先获取云服务器上存储的初始数据集，利用预设的混淆参数对初始数据集进行混淆加密处理，使用AES对称加密算法和密钥"abc123"对数据进行加密，生成混淆加密数据，通过这一步骤，我们成功地对云服务器上的初始数据进行了保护和加密，为后续的安全管理提供了基础。步骤S2：获取用户虹膜数据与用户身份信息；根据用户虹膜数据与用户身份信息进行用户验证信息提取，生成用户验证信息；根据用户验证信息对混淆加密数据进行数据验证标记，生成验证加密数据；本发明实施例中，首先获取用户提供的虹膜数据和身份信息。通过虹膜扫描仪获取虹膜数据，并让用户输入姓名和身份证号码作为身份信息，根据用户虹膜数据和身份信息进行用户验证信息提取，生成用户验证信息，使用虹膜识别算法对虹膜数据进行识别，并将识别结果与用户身份信息进行匹配，提取出用户的验证信息，如用户ID和认证时间。然后根据用户验证信息对混淆加密数据进行数据验证标记，生成验证加密数据，将用户验证信息与混淆加密数据关联起来，为每个数据记录添加验证标记字段，以确保数据的验证和安全性，成功地将用户验证信息与混淆加密数据进行了关联，为后续的数据安全管理提供了基础。步骤S3：利用线性判别分析对验证加密数据进行特征提取处理，生成原始特征集；利用深度学习算法原始特征集进行数据风险预测处理，生成风险评估数据；本发明实施例中，利用线性判别分析对验证加密数据进行特征提取处理，生成原始特征集，通过线性判别分析，可以从验证加密数据中提取出具有判别性的关键特征，如数据的统计属性和频率分布等，接下来，利用深度学习算法对原始特征集进行数据风险预测处理，生成风险评估数据。通过使用深度学习模型，可以对原始特征集进行复杂特征表示学习，并预测每个数据样本的风险评估结果，成功地将验证加密数据转化为具有风险评估的数据，为后续的风险筛选和数据安全管理提供了基础。步骤S4：根据风险评估数据对原始特征集进行风险筛选处理，生成优化特征集；将优化特征集与风险评估数据进行对应整合，并进行编码处理，生成风险特征向量；本发明实施例中，首先根据风险评估数据对原始特征集进行风险筛选处理，生成优化特征集，根据风险评估数据的结果，选择保留风险较低的特征，从原始特征集中移除或降低风险较高的特征，从而得到优化特征集。将优化特征集与风险评估数据进行对应整合，并进行编码处理，生成风险特征向量，将每个数据样本的优化特征集与相应的风险评估数据进行整合，形成风险特征向量，可以采用二进制编码、独热编码或其他编码方式，将特征向量转化为计算机可处理的形式，成功地将原始特征集优化并与风险评估数据关联，为后续的数据指纹索引和数据安全管理提供了基础。步骤S5：利用哈希函数对风险特征向量进行数据指纹计算，生成风险特征向量的数据指纹；将数据指纹与用户验证信息进行索引关系建立，生成数据指纹索引表；本发明实施例中，利用哈希函数对风险特征向量进行数据指纹计算，生成风险特征向量的数据指纹，通过应用SHA-256哈希函数，将风险特征向量转化为固定长度的数据指纹，将数据指纹与用户验证信息进行索引关系建立，生成数据指纹索引表，将每个数据样本的数据指纹与相应的用户验证信息关联起来，建立索引关系，可以创建一个数据指纹索引表，其中包含每个条目的数据指纹和相应的用户验证信息，如用户ID，成功地生成了数据指纹索引表，为后续的Merkle树建立和数据完整性验证存储提供了基础。步骤S6：利用数据指纹索引表进行数据指纹索引表的Merkle树建立，生成Merkle树；对Merkle树进行完整性验证存储处理，从而生成验证区块存储数据。本发明实施例中，利用数据指纹索引表进行数据指纹索引表的Merkle树建立，生成Merkle树，通过使用数据指纹索引表中的数据指纹作为叶子节点，并利用哈希函数计算每一层父节点的哈希值，构建出了一棵Merkle树，对Merkle树进行完整性验证存储处理，生成验证区块存储数据，通过将Merkle树的根哈希值与预先存储的根哈希值进行比对，可以验证数据的完整性，一致的根哈希值表示数据没有被篡改，而不一致的根哈希值则可能意味着数据篡改的风险，从而生成了验证区块存储数据，以确保数据的完整性和安全性。优选地，步骤S1包括以下步骤：步骤S11：获取云服务器的初始数据集；步骤S12：对初始数据集进行数据异常值剔除，生成清洗数据集；步骤S13：利用主成分分析法对清洗数据集进行关键信息提取处理，生成关键信息数据；步骤S14：利用关键信息数据对清洗数据集进行缺失值填充，生成修正数据集；步骤S15：利用数据信息降噪公式对修正数据集进行数据降噪处理，生成降噪数据集；步骤S16：利用预设的数据集格式对降噪数据集进行数据格式标准化转换，生成标准数据集；步骤S17：利用预设的混淆参数对标准数据集进行混淆打乱处理，生成混淆数据集；步骤S18：利用非对称加密技术对混淆数据集进行数据加密处理，生成混淆加密数据。本发明获得云服务器上存储的原始数据集，为后续数据处理和加密提供基础。通过剔除异常值，可以消除数据集中的错误或异常数据，提高数据的准确性和质量。主成分分析可以从原始数据集中提取关键信息，降低数据维度，减少冗余信息，同时保持数据的重要特征，为后续处理提供更高效的数据表示。填充缺失值可以修复数据集中的空缺部分，使得数据集更完整，减少因缺失数据而导致的信息丢失，提高后续分析的可靠性和准确性，利用主要特征信息进行填充，大大提高了数据的准确性。通过数据降噪处理，可以减少数据集中的噪声、干扰和不必要的变动，提高数据的清晰度和可解释性，从而提高后续分析和加密的效果。数据格式标准化可以使数据集符合特定的规范和格式要求，确保数据的一致性和互操作性，方便后续处理和加密的实施。混淆打乱处理可以使数据集中的特征关系变得难以理解和分析，增加数据的隐蔽性和安全性，防止未经授权的访问者获取敏感信息。非对称加密技术可以对混淆数据集进行强大的加密，确保数据在传输和存储过程中的机密性和安全性，防止数据泄露和被篡改。本发明实施例中，从云服务器上获取初始数据集，例如可以获取存储在数据库中的一系列表格数据，包括用户信息、交易记录等。对初始数据集进行异常值检测和剔除，例如可以使用统计方法或机器学习算法来识别和剔除数据中的异常值，得到清洗数据集。使用主成分分析法对清洗数据集进行降维处理，提取其中的关键信息，例如通过计算数据的协方差矩阵和特征值分解，得到具有较高方差贡献的主成分，生成关键信息数据。根据关键信息数据，对清洗数据集中的缺失值进行填充处理，例如可以使用插值方法或机器学习模型，通过关键信息数据作为数据集来预测并填充缺失值，得到修正数据集。应用数据信息降噪公式对修正数据集进行降噪处理，例如可以使用信噪比或小波变换等方法来去除数据中的噪声，得到降噪数据集。根据预设的数据集格式要求，对降噪数据集进行格式标准化转换，例如将数据转换为特定的数据类型、单位或统一的数据结构，生成符合要求的标准数据集。利用预设的混淆参数对标准数据集进行混淆打乱处理，例如可以使用随机排列或置换等技术来打乱数据的顺序和关联性，生成混淆数据集。使用非对称加密技术对混淆数据集进行加密处理，生成混淆加密数据，例如可以使用公钥加密算法对数据进行加密，确保只有私钥持有者能够解密并访问数据。优选地，步骤S15中的数据信息降噪公式如下所示：式中，K表示为降噪数据集，n表示为修正数据集的数据总数，xi表示为第i个修正数据集的原始数据，a表示为允许滤波器的最大滤波能力，b表示为滤波器的频率，c表示为滤波器的振幅，d表示为允许的最大滤波能力，t表示为处理信号涉及的时间，τ表示为降噪数据集的异常调整值。本发明利用一种数据信息降噪公式，该数学公式充分考虑了修正数据集的数据总数n、第i个修正数据集的原始数据xi、允许滤波器的最大滤波能力a、滤波器的频率b、滤波器的振幅c、允许的最大滤波能力d、处理信号涉及的时间t以及函数之间的相互作用关系，以形成函数关系式：即，该函数关系式通过去除修正数据集中的噪声和干扰，能够显著提高数据的质量。噪声和干扰可能来自于数据采集过程中的传感器误差、通信干扰或其他环境因素，通过降噪公式的应用，可以获得更加干净和准确的数据，减少数据中的误差，提高数据的可靠性和准确性。在降噪过程中采用了对数变换和正弦函数处理，这有助于保留原始数据的重要特征，通过对数变换，可以平衡数据集中较大和较小值之间的差异，使得数据更具可比性和一致性，正弦函数处理则有助于处理周期性信号，保留信号的频率特征，这样降噪后的数据仍然能够反映原始信号的重要特征，有助于后续的数据分析和应用。降噪公式中的参数a、b、c、d和t可以根据实际需求进行调节，以适应不同类型和特征的数据，例如通过调节参数a和d，可以控制滤波器的滤波能力，使其适应不同程度的噪声干扰；参数b和c的调节可以改变滤波器对不同频率和振幅的信号的响应，以适应不同频域特征的数据；参数t的调节则可以改变滤波器对不同时间尺度上的信号的响应，适应不同时间序列的数据特征，这种灵活性使得降噪方法能够适应不同数据场景的需求，并提供更准确的降噪效果。利用降噪数据集的异常调整值τ对函数关系式进行调整修正，减少异常数据或误差项带来的误差影响，从而更准确地生成降噪数据集K，提高了对修正数据集进行数据降噪处理的准确性和可靠性。同时该公式中的调整值可以根据实际情况进行调整，应用于不同的修正数据集中，提高了算法的灵活性与适用性。优选地，步骤S2包括以下步骤：步骤S21：获取用户虹膜数据与用户身份信息；步骤S22：利用灰度共生矩阵对用户虹膜数据进行虹膜纹理特征提取处理，生成虹膜特征数据；步骤S23：利用快速傅里叶变换技术对虹膜特征数据进行频谱图转换，生成虹膜频谱图；步骤S24：利用小波变换技术对虹膜频谱图进行虹膜小波提取，生成虹膜小波数据；步骤S25：利用字符编码对虹膜小波数据进行数据编码，生成虹膜数字信号；步骤S26：利用字符编码对用户身份信息进行数据编码，生成身份信息数字信号；步骤S27：将虹膜数字信号与身份信息数字信号进行数据整合，以生成用户验证信息；步骤S28：根据用户验证信息对混淆加密数据进行数据验证标记，生成验证加密数据。本发明通过获取用户的虹膜数据和身份信息，可以用于进行身份验证和数据关联，确保只有合法用户能够访问和操作相关数据。通过灰度共生矩阵分析虹膜图像的纹理特征，可以提取出与个体虹膜唯一相关的特征数据，这些特征数据在后续的虹膜识别过程中起到关键作用，可以准确地识别和区分不同的虹膜。通过应用快速傅里叶变换，可以将虹膜特征数据从时域转换到频域，得到虹膜的频谱表示。频谱图能够捕捉虹膜数据的频率特征，使得后续的特征处理和匹配更加高效和准确。小波变换是一种时频域分析方法，通过将频谱图进行小波变换，可以进一步提取虹膜数据的局部特征和频率成分，虹膜小波数据能够更加准确地表征虹膜的结构和纹理信息，提高虹膜识别的精度和可靠性。通过字符编码，将虹膜小波数据转换为数字信号的形式，数字信号的表示形式更便于存储、传输和处理，可以方便地在计算机系统中进行进一步的处理和分析。对用户身份信息进行字符编码，将其转换为数字信号的形式，这样可以确保身份信息的安全性和一致性，同时方便与虹膜数据进行关联和匹配。将虹膜数字信号和身份信息数字信号进行整合，形成完整的用户验证信息，这个验证信息包含了虹膜特征和身份信息的关联，用于后续的身份验证和数据访问控制。利用用户验证信息对混淆加密数据进行验证标记，确保数据的完整性和合法性，通过验证加密数据的生成，可以防止未经授权的用户对数据进行篡改或访问，保护数据的安全性和隐私性。作为本发明的一个实例，参考图2所示，为图1中步骤S2的详细实施步骤流程示意图，在本实例中所述步骤S2包括：步骤S21：获取用户虹膜数据与用户身份信息；本发明实施例中，获取用户提供的虹膜数据和身份信息，例如通过虹膜扫描仪获取用户的虹膜图像，并让用户输入姓名和身份证号码作为身份信息。步骤S22：利用灰度共生矩阵对用户虹膜数据进行虹膜纹理特征提取处理，生成虹膜特征数据；本发明实施例中，利用灰度共生矩阵对用户虹膜图像进行纹理特征提取处理。灰度共生矩阵可以计算图像中像素间的灰度分布关系，例如计算虹膜图像中像素对之间的灰度共生矩阵，并提取出纹理特征，如对比度、能量、熵等，生成虹膜特征数据。步骤S23：利用快速傅里叶变换技术对虹膜特征数据进行频谱图转换，生成虹膜频谱图；本发明实施例中，利用快速傅里叶变换技术将虹膜特征数据转换为频谱图。傅里叶变换可以将信号从时域转换为频域，例如对虹膜特征数据应用快速傅里叶变换，将其转换为频谱图，得到表示频域特征的虹膜频谱图。步骤S24：利用小波变换技术对虹膜频谱图进行虹膜小波提取，生成虹膜小波数据；本发明实施例中，利用小波变换技术对虹膜频谱图进行小波提取处理。小波变换可以捕捉信号中的局部特征，例如对虹膜频谱图应用小波变换，提取出与虹膜特征相关的小波系数，生成虹膜小波数据。步骤S25：利用字符编码对虹膜小波数据进行数据编码，生成虹膜数字信号；本发明实施例中，将虹膜小波数据进行字符编码处理，将其转换为数字信号，例如可以使用ASCII编码将虹膜小波数据转换为对应的数字序列，生成表示虹膜的数字信号。步骤S26：利用字符编码对用户身份信息进行数据编码，生成身份信息数字信号；本发明实施例中，对用户身份信息进行字符编码处理，将其转换为数字信号，例如使用特定的字符编码标准如UTF-8，将用户身份信息转换为对应的数字序列，生成表示身份信息的数字信号。步骤S27：将虹膜数字信号与身份信息数字信号进行数据整合，以生成用户验证信息；本发明实施例中，将虹膜数字信号和身份信息数字信号进行整合，以生成用户的验证信息，例如可以将虹膜数字信号和身份信息数字信号按照特定的规则进行组合，生成唯一表示用户验证信息的数字信号。步骤S28：根据用户验证信息对混淆加密数据进行数据验证标记，生成验证加密数据。本发明实施例中，根据用户的验证信息对混淆加密数据进行数据验证标记，例如可以为每个数据记录添加验证标记字段，并将用户验证信息与相应的数据记录进行关联，生成验证加密数据。优选地，步骤S3包括以下步骤：步骤S31：利用线性判别分析对验证加密数据进行特征提取处理，生成原始特征集；步骤S32：利用深度学习算法建立原始特征集的风险评估映射关系，生成初始风险评估模型；步骤S33：获取云服务器的历史风险评估数据；步骤S34：利用历史风险评估数据对初始风险评估模型进行模型训练，生成风险评估模型；步骤S35：利用风险评估模型对原始特征集进行数据风险评估预测处理，生成风险评估数据。本发明通过线性判别分析，可以从验证加密数据中提取出具有判别性能力的特征，这些特征可以用于后续的风险评估和预测，帮助识别数据中存在的风险和异常。通过深度学习算法，可以建立原始特征集与风险评估之间的映射关系，这样的模型可以学习数据特征和风险之间的复杂关系，提供更准确和全面的风险评估能力。获取云服务器的历史风险评估数据可以提供过去的风险情况和趋势信息，这些数据可以作为训练和验证风险评估模型的依据，帮助模型更好地理解和预测当前的风险情况。通过利用历史风险评估数据对初始模型进行训练，可以不断优化模型的预测能力和准确性，训练后的风险评估模型能够更好地捕捉和预测数据中的风险特征，提供更可靠的风险评估结果。利用训练好的风险评估模型，对原始特征集进行预测处理，可以生成针对数据的风险评估结果，这些结果可以指示数据中的潜在风险，帮助用户和系统决策者了解数据安全状况，并采取相应的风险管理措施。作为本发明的一个实例，参考图3所示，为图1中步骤S3的详细实施步骤流程示意图，在本实例中所述步骤S3包括：步骤S31：利用线性判别分析对验证加密数据进行特征提取处理，生成原始特征集；本发明实施例中，通过线性判别分析对验证加密数据进行特征提取处理，生成原始特征集，例如对于验证加密数据，可以提取其统计属性、频率分布等关键特征，形成原始特征集。步骤S32：利用深度学习算法建立原始特征集的风险评估映射关系，生成初始风险评估模型；本发明实施例中，利用深度学习算法对原始特征集建立风险评估映射关系，生成初始风险评估模型，例如可以使用深度神经网络模型，通过训练将原始特征集与相应的风险评估结果建立映射关系，生成初始风险评估模型。步骤S33：获取云服务器的历史风险评估数据；本发明实施例中，从云服务器获取历史风险评估数据，这些数据包含了先前对数据风险进行评估的结果，例如可以获取存储在数据库中的历史风险评估记录，包括数据的风险等级、异常情况等。步骤S34：利用历史风险评估数据对初始风险评估模型进行模型训练，生成风险评估模型；本发明实施例中，利用历史风险评估数据对初始风险评估模型进行模型训练，生成更精确的风险评估模型，例如可以使用历史风险评估数据作为训练集，对初始风险评估模型进行优化和调整，以提高模型的准确性和预测能力。步骤S35：利用风险评估模型对原始特征集进行数据风险评估预测处理，生成风险评估数据。本发明实施例中，利用训练好的风险评估模型对原始特征集进行数据风险评估预测处理，生成风险评估数据，例如将原始特征集输入到风险评估模型中，模型根据学习到的映射关系预测数据的风险等级或概率，生成相应的风险评估数据。优选地，步骤S4包括以下步骤：步骤S41：利用预设的信息风险评估阈值对风险评估数据进行信息风险判断，当风险评估数据大于信息风险评估阈值时，返回步骤S15，当风险评估数据不大于信息风险评估阈值时，将原始特征集标记为优化特征集；步骤S42：将优化特征集与风险评估数据进行对应整合，并进行编码处理，生成风险特征向量。本发明通过与预设的信息风险评估阈值进行比较，能够判断数据的信息风险程度，根据判断结果，可以及时识别出高风险的数据，从而采取针对性的措施进行进一步的处理和保护。将风险评估数据不大于信息风险评估阈值的原始特征集标记为优化特征集，通过标记识别出风险较低的数据，以便后续的优化处理和进一步的数据分析，并且将风险较高的数据返回步骤S15再重新进行加密，保障了数据的安全性。将优化特征集与风险评估数据进行整合，并进行编码处理，可以将特征和风险评估结果相对应地组合在一起，这样的整合和编码能够为后续的数据指纹索引和存储提供标识和检索的便利性，方便快速地识别和访问特定的风险特征数据。本发明实施例中，利用预设的信息风险评估阈值对风险评估数据进行判断，例如设定一个信息风险评估阈值，若风险评估数据超过该阈值，则认为数据存在高风险；若风险评估数据不超过该阈值，则认为数据风险可接受。若风险评估数据大于信息风险评估阈值，则返回到步骤S15，重新处理数据。若风险评估数据不大于信息风险评估阈值，则将原始特征集标记为优化特征集，作为后续处理的输入。将优化特征集与风险评估数据进行对应整合，并进行编码处理，生成风险特征向量，例如将优化特征集和风险评估数据按照一定的规则进行整合，可以将它们拼接在一起形成一个新的特征向量，对该特征向量进行编码处理，使用二进制编码、独热编码等方式，生成表示风险特征的向量。优选地，步骤S5包括以下步骤：步骤S51：利用哈希函数对风险特征向量进行哈希计算，从而生成风险特征哈希值；步骤S52：利用风险特征哈希值构建风险特征向量的数据指纹；步骤S53：将数据指纹与用户验证信息进行数据关联，以构建数据指纹关联数据；步骤S54：获取云服务器的索引键信息；步骤S55：利用索引键信息将数据指纹关联数据建立数据与云服务器的索引关系，以生成数据指纹索引表。本发明哈希函数可以将风险特征向量转换为固定长度的哈希值，通过哈希计算，可以将复杂的风险特征向量映射为较短的哈希值，提供一种高效、唯一且紧凑的数据表示方式，这有助于减少数据的存储空间需求和索引计算的复杂度，同时保护数据的隐私和安全。通过使用风险特征哈希值，可以构建风险特征向量的数据指纹，数据指纹是对数据内容的唯一表示，类似于数据的摘要或指纹，它具有较小的尺寸并保持数据的完整性，可用于快速检索、比对和识别数据。将数据指纹与用户验证信息进行关联，可以建立数据指纹关联数据，这种关联可以确保数据指纹与相应的用户身份验证信息一起存储和管理，从而实现数据与用户的关联和权限控制，数据指纹关联数据可以用于快速识别和检索特定用户的数据，提高数据的访问效率和安全性。获取云服务器的索引键信息是为了建立数据指纹与云服务器的索引关系，索引键信息可以是唯一标识云服务器的关键属性，如服务器ID、地址或其他识别信息，这些信息将用于构建数据指纹的索引关系，以便快速定位和访问存储在云服务器上的相关数据。利用索引键信息，可以将数据指纹关联数据与云服务器建立索引关系，这样可以生成数据指纹索引表，用于记录和管理数据指纹关联数据的索引信息。数据指纹索引表提供了一种高效的索引结构，能够快速检索和定位特定数据的存储位置，提高数据的访问速度和效率。作为本发明的一个实例，参考图4所示，为图1中步骤S5的详细实施步骤流程示意图，在本实例中所述步骤S5包括：步骤S51：利用哈希函数对风险特征向量进行哈希计算，从而生成风险特征哈希值；本发明实施例中，利用哈希函数对风险特征向量进行哈希计算，生成风险特征哈希值。哈希函数将风险特征向量作为输入，经过特定的计算过程，生成一个固定长度的哈希值，例如使用SHA-256、MD5等常见的哈希函数算法，将风险特征向量转换为对应的哈希值。步骤S52：利用风险特征哈希值构建风险特征向量的数据指纹；本发明实施例中，利用风险特征哈希值构建风险特征向量的数据指纹，将风险特征哈希值作为数据指纹的一部分，用于表示该风险特征向量的唯一标识，例如将风险特征哈希值与其他相关数据结合起来形成数据指纹，可以使用特定的数据结构来组织数据指纹。步骤S53：将数据指纹与用户验证信息进行数据关联，以构建数据指纹关联数据；本发明实施例中，将数据指纹与用户验证信息进行数据关联，以构建数据指纹关联数据，例如将数据指纹与用户的验证信息进行关联，形成数据指纹关联数据。这样可以确保数据指纹与用户验证信息之间的一致性和关联性。步骤S54：获取云服务器的索引键信息；本发明实施例中，获取云服务器的索引键信息，这些索引键信息可以用于建立数据指纹与云服务器之间的索引关系，例如可以获取云服务器存储数据的索引信息，如数据表名、行标识等。步骤S55：利用索引键信息将数据指纹关联数据建立数据与云服务器的索引关系，以生成数据指纹索引表。本发明实施例中，利用索引键信息将数据指纹关联数据与云服务器之间建立索引关系，生成数据指纹索引表，例如根据索引键信息将数据指纹关联数据与相应的云服务器数据进行匹配和关联，形成数据指纹索引表。这样可以方便地通过数据指纹进行索引和检索。优选地，步骤S6包括以下步骤：步骤S61：利用哈希函数对数据指纹索引表进行哈希计算，从而生成数据指纹索引哈希值；步骤S62：利用区块链网络将数据指纹索引哈希值进行数据指纹索引表的Merkle树建立，生成Merkle树；步骤S63：利用预设的区块链分块阈值将Merkle树进行分块存储处理，从而生成原始区块存储数据；步骤S64：利用云服务数据安全验证共识算法对原始区块存储数据进行数据完整性计算，从而生成原始区块存储数据的完整性验证数据；步骤S65：利用完整性验证阈值对完整性验证数据进行完整性判断，当完整性验证数据不小于完整性验证阈值时，将原始区块存储数据标记为验证区块存储数据，当完整性验证数据小于完整性验证阈值时，将原始区块存储数据剔除。本发明通过哈希计算，可以将数据指纹索引表转换为唯一的哈希值，数据指纹索引哈希值的生成确保了数据指纹索引表的完整性和一致性，可以用于后续的Merkle树建立和数据完整性验证。通过使用区块链网络，可以将数据指纹索引哈希值构建为Merkle树，Merkle树是一种基于哈希的二叉树结构，能够高效地验证数据的完整性和一致性，它可以有效地防止数据篡改和欺骗，提供了一种安全可靠的数据存储和验证机制。根据预设的区块链分块阈值将Merkle树进行分块存储处理，生成原始区块存储数据，这样的分块存储方式有助于提高数据的存储效率和访问速度，同时方便对数据进行管理和验证。通过云服务数据安全验证共识算法，对原始区块存储数据进行数据完整性计算，生成原始区块存储数据的完整性验证数据，这样的计算可以确保原始区块存储数据的完整性，验证数据的一致性和正确性。根据预设的完整性验证阈值，对完整性验证数据进行判断。当完整性验证数据不小于完整性验证阈值时，将原始区块存储数据标记为验证区块存储数据，表示数据完整性得到验证，当完整性验证数据小于完整性验证阈值时，将原始区块存储数据剔除，说明数据可能存在篡改或不完整。作为本发明的一个实例，参考图5所示，为图1中步骤S6的详细实施步骤流程示意图，在本实例中所述步骤S6包括：步骤S61：利用哈希函数对数据指纹索引表进行哈希计算，从而生成数据指纹索引哈希值；本发明实施例中，利用哈希函数对数据指纹索引表进行哈希计算，生成数据指纹索引哈希值，例如将数据指纹索引表作为输入，通过哈希函数计算生成一个固定长度的哈希值，作为数据指纹索引哈希值。步骤S62：利用区块链网络将数据指纹索引哈希值进行数据指纹索引表的Merkle树建立，生成Merkle树；本发明实施例中，利用区块链网络将数据指纹索引哈希值进行数据指纹索引表的Merkle树建立，Merkle树是一种哈希树结构，其中每个叶子节点都包含一个数据指纹索引哈希值，而非叶子节点是其子节点的哈希值的哈希值，通过逐层计算哈希值，最终生成Merkle树。步骤S63：利用预设的区块链分块阈值将Merkle树进行分块存储处理，从而生成原始区块存储数据；本发明实施例中，利用预设的区块链分块阈值将Merkle树进行分块存储处理，生成原始区块存储数据，根据设定的分块阈值将Merkle树分成若干块，每块包含一部分Merkle树节点的数据，这样可以将数据分块存储，提高数据存储的效率和安全性。步骤S64：利用云服务数据安全验证共识算法对原始区块存储数据进行数据完整性计算，从而生成原始区块存储数据的完整性验证数据；本发明实施例中，利用云服务数据安全验证共识算法对原始区块存储数据进行数据完整性计算，生成原始区块存储数据的完整性验证数据，数据安全验证共识算法通过对原始区块存储数据的哈希计算和验证过程，确保数据的完整性，根据算法的规则，计算得到原始区块存储数据的完整性验证数据。步骤S65：利用完整性验证阈值对完整性验证数据进行完整性判断，当完整性验证数据不小于完整性验证阈值时，将原始区块存储数据标记为验证区块存储数据，当完整性验证数据小于完整性验证阈值时，将原始区块存储数据剔除。本发明实施例中，利用设定的完整性验证阈值对完整性验证数据进行完整性判断，如果完整性验证数据不小于完整性验证阈值，则将原始区块存储数据标记为验证区块存储数据，表示数据完整性得到验证，如果完整性验证数据小于完整性验证阈值，则将原始区块存储数据剔除，认为数据存在异常或被篡改。优选地，步骤S64中的云服务数据安全验证共识算法如下所示：/＞式中，F表示为完整性验证数据，m表示为原始区块存储数据的节点数量，zj表示为第j个节点的验证数据，ui表示为第j个节点的信任权重，A表示为节点平均大小，y表示为原始区块存储数据的原始数据，o表示为根据初始数据集生成的完整性权重信息，g表示为原始数据的完整性信任阈值，表示为变量y的导数，rj表示为第j个节点生成的哈希值，k表示为数据指纹索引哈希值长度生成的安全权重信息，δ表示为完整性验证数据的异常调整值。本发明利用一种云服务数据安全验证共识算法，该数学公式充分考虑了原始区块存储数据的节点数量m、第j个节点的验证数据zj、第j个节点的信任权重ui、节点平均大小A、原始区块存储数据的原始数据y、根据初始数据集生成的完整性权重信息o、原始数据的完整性信任阈值g、变量y的导数第j个节点生成的哈希值rj、数据指纹索引哈希值长度生成的安全权重信息k以及函数之间的相互作用关系，以形成函数关系式：即，该函数关系式中计算公式将原始区块存储数据的节点验证数据进行加权求和，并应用一系列数学运算，包括对数、指数、三角函数等，以生成完整性验证数据，这个计算过程综合了多个因素，能够综合考虑数据节点的验证结果、信任权重以及数据的完整性特征，从而提供了对数据完整性的综合评估。通过考虑多个节点的验证数据，计算公式可以更准确地评估数据的完整性，每个节点的验证数据被加权平均，其中节点的信任权重用于反映其可信度，通过多节点的参与，可以减少单个节点的潜在错误或恶意行为对数据完整性的影响，提高数据验证的可靠性。计算公式中的根据初始数据集生成的完整性权重信息，用于衡量数据的完整性，这个信息提供了对数据完整性的参考基准，可以与验证数据进行比较，以判断数据的完整性程度。计算公式中的完整性信任阈值是用于判断数据完整性的阈值，当完整性验证数据超过该阈值时，表示数据具有较高的完整性，可以被标记为验证区块存储数据，这个阈值的设定可以根据具体情况进行调整，以满足对数据完整性的要求。计算公式中的哈希值和安全权重信息用于表示数据指纹索引哈希值的安全性，哈希值的引入可以提高数据的抗篡改能力，而安全权重信息则可用于调整数据完整性的计算结果，增强数据完整性验证的可靠性。利用完整性验证数据的异常调整值δ对函数关系式进行调整修正，减少异常数据或误差项带来的误差影响，从而更准确地生成完整性验证数据F，提高了对原始区块存储数据进行数据完整性计算的准确性和可靠性。同时该公式中的权重信息、阈值以及调整值可以根据实际情况进行调整，应用于不同的原始区块存储数据中，提高了算法的灵活性与适用性。在本说明书中，提供了一种云服务数据信息安全管理系统，包括：数据预处理模块，用于获取云服务器的初始数据；利用预设的混淆参数对初始数据集进行混淆加密处理，生成混淆加密数据；数据验证模块，用于获取用户虹膜数据与用户身份信息；根据用户虹膜数据与用户身份信息进行用户验证信息提取，生成用户验证信息；根据用户验证信息对混淆加密数据进行数据验证标记，生成验证加密数据；风险评估模块，利用线性判别分析对验证加密数据进行特征提取处理，生成原始特征集；利用深度学习算法原始特征集进行数据风险预测处理，生成风险评估数据；数据编码模块：根据风险评估数据对原始特征集进行风险筛选处理，生成优化特征集；将优化特征集与风险评估数据进行对应整合，并进行编码处理，生成风险特征向量；数据指纹建立模块：利用哈希函数对风险特征向量进行数据指纹计算，生成风险特征向量的数据指纹；将数据指纹与用户验证信息进行索引关系建立，生成数据指纹索引表；数据存储模块：利用数据指纹索引表进行数据指纹索引表的Merkle树建立，生成Merkle树；对Merkle树进行完整性验证存储处理，从而生成验证区块存储数据。本申请有益效果在于，本发明混淆加密和非对称加密技术，以及其他步骤中的加密处理，保护了数据的隐私和机密性，混淆加密和非对称加密可以有效地对数据进行加密和解密，防止未经授权的访问者获取敏感数据，这种加密方法确保了数据在存储和传输过程中的安全性，使得即使数据被非法获取，也无法解读其中的内容。数据验证标记和完整性验证数据计算，保障了数据的完整性和一致性，通过验证标记和完整性验证，可以检测到数据被篡改或损坏的情况，防止恶意攻击者对数据进行未授权的修改，这样可以确保数据在存储和传输过程中的完整性，使得数据在各个环节都保持一致和可靠。用户身份验证信息提取和关联，以及后续步骤中的用户验证信息使用，确保了数据的安全访问和操作，通过用户身份验证，只有经过验证的用户才能访问和操作数据，避免了未经授权的访问和数据泄露的风险，这种身份验证和权限控制机制可以有效地保护数据免受未授权用户的访问。特征提取、风险评估和风险筛选，对数据进行风险预测和优化处理，通过对数据的特征提取和风险评估，可以识别出潜在的数据安全风险，进一步通过风险筛选，可以剔除高风险的数据或采取相应的措施进行风险降低，从而提高数据的质量和安全性。数据指纹索引和Merkle树的建立，提供了高效的数据索引和存储机制，数据指纹的计算和索引关系的建立，使得数据的检索和验证更加快速和准确，Merkle树的使用可以高效地验证数据的完整性，确保数据在存储和传输过程中不受损坏和篡改。通过区块链技术的应用和哈希计算的使用，提升了数据的安全性和防护能力，区块链技术提供了分布式、不可篡改的数据存储和验证机制，防止数据的篡改和删除，哈希计算提供了数据的唯一标识和摘要，增强了数据的完整性和抗篡改能力，这些技术的应用提升了云服务数据的安全性，保护数据免受恶意攻击和未授权访问的威胁。因此，无论从哪一点来看，均应将实施例看作是示范性的，而且是非限制性的，本发明的范围由所附权利要求而不是上述说明限定，因此旨在将落在申请文件的等同要件的含义和范围内的所有变化涵括在本发明内。以上所述仅是本发明的具体实施方式，使本领域技术人员能够理解或实现本发明。对这些实施例的多种修改对本领域的技术人员来说将是显而易见的，本文中所定义的一般原理可以在不脱离本发明的精神或范围的情况下，在其它实施例中实现。因此，本发明将不会被限制于本文所示的这些实施例，而是要符合与本文所发明的原理和新颖特点相一致的最宽的范围。
