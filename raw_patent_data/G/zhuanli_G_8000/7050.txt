标题title
一种基于单阶人脸定位算法的婴儿窒息或猝死预警方法
摘要abst
本发明涉及一种基于单阶人脸定位算法的婴儿窒息或猝死预警方法，属于计算机视觉领域；它解决了现今通过实时图像对婴儿窒息或猝死进行预防和报警的方法等问题；其技术方案是：基于单阶人脸定位算法的Acc‑Retinaface网络模型，预测出婴儿人脸框、68个人脸关键点以及人脸关键点遮挡信息；监控婴儿人脸及周边情况，实时返回婴儿人脸图像，通过对婴儿脸部被遮挡关键点权重值计算当下婴儿的窒息猝死风险值；将窒息猝死风险值与设定的警报阈值、风险阈值比较判断，并向终端设备返回相应预警信号。本发明实时识别婴儿人脸并检测人脸遮挡情况，对婴儿窒息或猝死情况进行预警，可有效降低婴儿因口鼻遮挡、胃食道反流、婴儿猝死综合症等原因造成的窒息或猝死概率。
权利要求书clms
1.一种基于单阶人脸定位算法的婴儿窒息或猝死预警方法，其特征在于，该方法包括下列步骤：对单阶人脸定位算法的Acc-Retinaface网络模型进行训练与测试；获取婴儿人脸及头部周边图像；使用训练后的网络模型得到婴儿脸部关键点遮挡信息；通过遮挡信息计算出婴儿窒息猝死风险值；根据窒息猝死风险值，返回婴儿窒息或猝死警报。2.根据权利要求1所述的一种基于单阶人脸定位算法的婴儿窒息或猝死预警方法，其特征在于，步骤1）形成单阶人脸定位算法所需的婴儿人脸遮挡网络模型，即Acc-Retinaface网络模型的详细步骤包括：选取网络模型训练数据集，通过merl数据集选取网络模型训练数据集，网络模型训练数据集包括外部遮挡和未遮挡两类数据，在网络模型训练过程中利用1×1卷积层调整特征提取通道数，添加人脸关键点遮挡信息预测通道，并将人脸关键点的预测结果中关键点个数设置为68个，68个关键点分别为口部20个、鼻部9个、眼部12个、眉部10个以及脸部轮廓17个，得到训练集的人脸样本预测结果；得到人脸样本图像预测结果后，基于预测的图像人脸框和真实人脸框对应的交并比，将实验预测出的图像人脸框分为：正人脸框和负人脸框两大类，将人脸样本图像预测结果代入损失函数，若预测结果为正人脸框，则需要对人脸框、人脸关键点以及人脸关键点遮挡进行损失计算，其中对于人脸框的预测损失使用softmax损失函数，对于人脸关键点以及人脸关键点遮挡的预测损失使用smooth-L1损失函数，若预测结果为负人脸框，则只需计算人脸分类损失，使用婴儿人脸遮挡数据集对网络模型进行测试，对收集的婴儿人脸遮挡图像进行人工标记获得其人脸框信息、关键点及遮挡信息，得到小型网络模型测试集，用于对训练完善的网络模型进行测试，得到本方法所需的婴儿人脸遮挡预测网络模型。3.根据权利要求1所述的一种基于单阶人脸定位算法的婴儿窒息或猝死预警方法，其特征在于，步骤2）实时获取婴儿人脸及头部周边图像，在缩小图像存储空间的基础上同步减少图像处理时间；步骤3）使用步骤1）训练的婴儿人脸遮挡预测网络模型得到婴儿脸部关键点遮挡信息，并对遮挡信息结果进行判断，当关键点遮挡信息的相关参数高于阈值时，视为婴儿脸部关键点被遮挡，小于阈值时则视为未被遮挡，阈值设定为0.5；步骤4)根据终端设备的窒息猝死风险值计算方法获得窒息风险情况，将婴儿脸部关键点遮挡情况传回终端设备，根据相关权重计算方法设定口、鼻、眉毛、眼睛以及脸部轮廓区域的关键点相对遮挡权重，再通过窒息猝死风险计算公式得到婴儿人脸窒息猝死风险值，窒息猝死风险计算公式如下：其中C为窒息猝死风险值，Pi第i个关键点的权重值，S为第i个关键点的遮挡信息，设定该关键点未遮挡时S=0，遮挡时S=1，PO为眼睛、眉毛以及人脸轮廓区域的关键点权重值，眼睛、眉毛以及人脸轮廓区域共有关键点39个，设定PO=P，PM为口部区域关键点的权重值，口部区域共有关键点20个，PN为鼻子区域关键点的权重值，鼻子区域共有关键点9个，根据权重计算方法的相对权重关系，当口部区域遮挡个数大于10时N=20，PM=4P，PN=8P，否则设定N=10，PM=2P，PN=4P。4.根据权利要求1所述的一种基于单阶人脸定位算法的婴儿窒息或猝死预警方法，其特征在于，步骤5)根据婴儿人脸窒息猝死风险值Cr_value，通过交叉验证，得到风险阈值R_value和警报阈值W_value，若满足：Cr_value ＜ R_value，终端设备显示安全信号；若满足：R_value ＜ Cr_value ＜ W_value，终端设备发出窒息猝死风险信号；若满足：W_value ＜Cr_value，终端设备发出窒息猝死警报。
说明书desc
技术领域本发明涉及一种基于单阶人脸定位算法的婴儿窒息或猝死预警方法，属于计算机视觉领域。背景技术婴儿是指出生6周-12个月阶段的儿童。由于在1周岁前，各个系统功能不成熟，对外界危险的抵抗力极弱，趴睡、口鼻遮挡、与他人同睡等都很容易造成婴儿窒息。同时，由于婴儿消化功能尚未发育健全造成的胃食管反流也是导致婴儿窒息发生的一个重要因素。根据儿童意外死亡原因统计显示，婴儿意外窒息导致的死亡率极高。婴儿猝死综合症也是导致婴儿意外死亡的重要原因之一。婴儿猝死综合症是指外表看起来完全健康的婴儿突然意外死亡。根据规定：婴儿突然意外死亡，死后虽经尸检亦未能确定其致死原因者称SIDS。SIDS是2周~1岁之间婴儿最常见的死亡原因，占该年龄组死亡率的30%，发病率一般为1‰~2‰。SIDS一般发病时间段为半夜至早晨，这个时间段的婴儿及家长大部分处于睡眠中，很难及时发现问题并做出应急措施，因此SIDS也称为“摇篮猝死”。常见的导致SIDS原因，如婴儿俯卧或侧卧睡眠、放置软的寝具、与他人同床睡眠、束缚过紧/过热等影响婴儿正常呼吸的行为。现有技术中，针对上述婴儿意外窒息及突发猝死情况的检测，市面上大部分采用基于各类传感器的婴儿呼吸检测报警设备，这类设备一般在婴儿发生意外，身体特征出现非正常表现时才被检测出来，即为一种事后报警装置。婴儿期突发性窒息情况可能对身体机能造成极大的不可逆损害甚至威胁生命安全，例如婴儿由于呼吸系统功能不成熟突发呼吸停止，或是由于消化系统未发育完全造成的吐奶导致食道或呼吸道堵塞呛奶引起的突发性窒息。因此在意外发生初期，尽快阻止危险情况变得尤为重要，而事后报警装置反应时间一般较长，不能及时制止这类突发危险状况的发展。通过实时图像对婴儿窒息或猝死进行预防与报警的方法可以提前发现潜在的窒息或猝死危险并反馈风险值，在危险发生前及时制止。本发明中的婴儿窒息或猝死预警的方法中使用到的人脸关键点检测方法属于深度学习方法。传统的人脸检测技术在人脸发生遮挡时，由于部分人脸特征消失，特征提取功能泛化能力差，不同的遮挡位置和人脸方向对结果影响较大，且难以解决大型形状变化问题，对于非正面的婴儿人脸图像遮挡识别能力差，人脸姿势、方向、遮挡物形状等都会来带来极大误差。使用深度学习方法进行人脸检测相对传统方法可改善上述情况，深度学习方法需要大型数据集进行网络模型训练且数据集对人脸遮挡识别效果有较大影响，而在网络模型中加入人脸关键点检测并在关键点信息中加入遮挡信息可帮助网络模型在小型训练数据集的基础上取得更稳定的遮挡检测效果。本发明中采用的遮挡检测方法是一种基于单阶人脸定位的方法，其中使用到的网络模型命名为Acc-Retinaface网络模型，Acc-Retinaface是在人脸检测模型上加入人脸关键点遮挡的单阶人脸检测器，并在网络模型中加上遮挡信息的特征提取通道以及增加关键点输出数量，Acc-Retinaface可以更好地判断实时婴儿图像的脸部遮挡情况。Acc-Retinaface网络模型框架是基于传统的目标检测框架RetinaNet上添加上下文级联检测模块，提升了检测精度使得人脸分类更精确且人脸框预测更准确。Acc-Retinaface人脸检测方法在更准确定位婴儿人脸的基础上，可以返回婴儿脸上的68个关键点的遮挡信息，从而实时判断婴儿的窒息或猝死风险。总体而言，当下技术缺少针对婴儿人脸遮挡检测的相关算法且没有对婴儿窒息或猝死情况进行预警的方法，本方法结合当下针对遮挡数据集有很好的人脸识别效果的单阶人脸定位算法，在小型婴儿脸部遮挡数据集取得了极好的婴儿人脸遮挡检测效果，并通过返回婴儿面部关键点遮挡信息对婴儿窒息或猝死情况进行预警。发明内容本发明要解决的技术问题是：针对使用单阶人脸定位算法对婴儿面部遮挡进行检测，从而对婴儿窒息或猝死情况进行预警的问题。本方法通过实时采集婴儿人脸及头部周边图像，图像数据返回服务器通过单阶人脸定位算法精确定位婴儿人脸并标记婴儿人脸关键点，同时得到婴儿脸部关键点遮挡信息，通过关键点权重计算公式得到相应的婴儿窒息猝死风险值，判断婴儿窒息或猝死风险情况，并向终端返回婴儿窒息或猝死警报。为了解决上述问题，该方法包括下列步骤：1）对单阶人脸定位算法的Acc-Retinaface网络模型进行训练与测试；2）获取婴儿人脸及头部周边图像；3）使用训练后的网络模型得到婴儿脸部关键点遮挡信息；4）通过遮挡信息计算出婴儿窒息猝死风险值；5）根据窒息猝死风险值，返回婴儿窒息或猝死警报。优选地，步骤1）对单阶人脸定位算法的Acc-Retinaface网络模型进行训练与测试。单阶人脸定位算法基于人脸识别的Acc-Retinaface网络模型通过调整网络模型特征提取通道并将人脸关键点的预测结果中关键点个数设置为预测68个关键点，且在每个关键点信息中加入遮挡标签。首先使用Resnet-50网络作为主干特征提取网络，选取部分merl数据集进行婴儿人脸预测网络模型训练，并对Resnet-50最后三层进行FPN结构构建，得到多尺度的映射图，进而利用SSH模块加强特征提取结果，获得人脸样本预测结果。得到预测结果后利用处理后的真实结果与预测结果计算损失函数，使用小型婴儿人脸图像做测试集，最终训练出适用于婴儿人脸遮挡检测的Acc-Retinaface模型。详细步骤包括：1.1）首先选取网络模型训练数据集，数据集选自merl数据集，本方法中网络模型训练使用到外部遮挡和未遮挡两大类数据集。1.2）将1.1）选取的训练集中的人脸样本图像和人脸关键点遮挡信息输入网络模型中，在联合级联框架中结合人脸检测和对齐功能，提取图像人脸形状特征，获得网络模型的有效特征层。对特征提取通道数进行调整，得到图像人脸样本图像的四个预测结果：人脸回归预测结果、人脸框回归预测结果、人脸关键点预测结果以及人脸关键点遮挡信息预测结果。并在人脸图像关键点检测过程中，将人脸关键点的预测结果中关键点个数设定为预测68个关键点，68个关键点分别为口部20个、鼻部9个、眼部12个、眉部10个以及脸部轮廓17个，得到训练集的人脸样本预测结果。1.3）得到人脸样本图像预测结果后，基于预测图像人脸框和真实人脸框对应的交并比，将实验预测出的图像人脸框分为：正人脸框和负人脸框两大类。正人脸框指预测的结果是人脸，负人脸框指预测的结果不是人脸。1.4）将图像人脸框预测结果代入损失函数，对图像人脸遮挡识别进行回归训练。若预测结果为正人脸框，则需要对人脸框、人脸关键点以及人脸关键点遮挡进行损失计算，其中对于人脸框的预测损失使用softmax损失函数，对于人脸关键点以及人脸关键点遮挡的损失使用smooth-L1损失函数；若预测结果为负人脸框，则只需计算人脸分类损失。最终得到训练完善的人脸图像遮挡检测使用的网络模型。1.5）进行网络模型效果测试。为测试训练好的网络模型在婴儿人脸遮挡数据集上的效果，网络收集相关婴儿脸部其他物体遮挡图像或吐奶导致脸部遮挡图像，并对收集图像进行人工标记获得其人脸框信息、关键点及遮挡信息，形成一个小型的婴儿脸部遮挡和吐奶数据集，用于测试训练完善的网络模型，最终得到适用于婴儿人脸遮挡或吐奶预测的Acc-Retinaface网络模型。优选地，步骤2）获取婴儿人脸及头部周边的实时图像，获得原始的婴儿人脸样本图像，可在及时获得婴儿面部及头部周边当下遮挡情况的前提下，减少图像存储所需空间以及图像处理的时间。优选地，步骤3）使用Acc-Retinaface网络模型得到婴儿脸部关键点遮挡信息。将步骤2）中的婴儿人脸图像输入至Acc-Retinaface网络模型中，得到所需检测婴儿人脸图像的人脸框，关键点及遮挡信息。并使用相关参数对遮挡信息的结果进行判断，遮挡信息的结果相关参数大于阈值则视为被遮挡，小于等于阈值则视为未被遮挡，阈值设定为0.5。优选地，步骤4）首先将步骤3）中得到的婴儿脸部关键点遮挡情况传回终端设备，终端设备包含相关权重计算方法和窒息风险计算方法，会根据各个婴儿人脸关键点相对权值计算出遮挡的婴儿人脸关键点权重，并根据关键点权重值计算出当下婴儿的窒息猝死风险值。优选地，步骤5）从步骤4）中得到窒息猝死风险值Cr_value，设定警报阈值W_value和风险阈值R_value，若窒息猝死风险值大于等于警报阈值，即Cr_value ＞ W_value，则终端设备发出窒息猝死警报；若窒息猝死风险值小于警报阈值且大于风险阈值，即R_value ＜Cr_value ＜ W_value，则终端设备发出窒息猝死风险信号；若窒息猝死风险值小于风险阈值，即R_value ＞ Cr_value，则终端设备显示安全信号。与现有技术相比，本发明具有以下有益效果：有效检测婴儿人脸图像被外物或吐奶遮挡区域并得到被遮挡的关键点信息；通过深度学习对婴儿人脸进行识别检测，可在实时检测的同时得到更高的精度；本方法的网络模型包含更多关键点检测及关键点遮挡检测，使用小型婴儿人脸遮挡数据集同样具有高精度的婴儿人脸遮挡检测；本方法是对婴儿的窒息或猝死进行预先警报的一种事前预警方式，可以更有效降低婴儿因口鼻遮挡、胃食道反流、婴儿猝死综合症等原因造成的窒息或猝死风险。附图说明通过阅读参照以下附图所做的详细描述，本申请的其他特征、目的和优点将会变得更加明显：图1是婴儿窒息或猝死预警流程图。图2是单阶人脸定位算法技术路线图。图3是口鼻区域关键点相对权重设定流程图。图4是婴儿面部外物遮挡检测图。图5是婴儿胃食道反流检测图。具体实施方式下面结合附图和实施例对本申请做进一步的详细说明。可以理解的是，此处所描述的具体实施仅仅用于解释相关方法，而非对该方法的使用进行限定。另外还需要说明的是，为了便于描述，附图中仅示出了与该方法相关的部分。下面将参考附图来详细说明本申请。图1是婴儿窒息或猝死预警流程图，可以用于婴儿在无人看护时，对婴儿面部实时情况进行监督，通过面部图像遮挡信息判断婴儿窒息或猝死风险并及时向终端设备发出相应信号，其中包括以下步骤：步骤S100，得到单阶人脸定位算法的Acc-Retinaface网络模型，并使用选取的数据集进行网络模型训练，使用小型婴儿数据集进行网络模型测试。参考图2，其显示基于选取的训练集和小型婴儿人脸测试集，利用单阶人脸定位算法对适用于婴儿人脸遮挡检测的Acc-Retinaface网络模型进行训练及模型测试的技术路线。Acc-Retinaface是在人脸识别网络模型上将人脸关键点的预测结果中关键点个数设定为预测68个关键点，并在每个关键点信息中加入遮挡信息。本方法使用到的Acc-Retinaface网络模型是一种基于像素级的人脸定位方法，它加入一种鲁棒的单级人脸检测器，可同时利用额外监督和自监督结合的多任务学习，对各种尺寸的婴儿人脸图像进行像素级别的定位。本专利使用的单阶人脸定位算法，首先选取部分merl数据集作为婴儿人脸预测网络模型的训练集，并使用Resnet-50网络作为主干特征提取网络，对Resnet-50最后三层进行FPN结构构建，得到多尺度的映射图，利用SSH模块加强特征提取结果，从而获得图像人脸分类预测、人脸框预测、关键点预测以及关键点遮挡预测结果。得到预测结果后利用真实结果与预测结果计算损失函数，使用选取的训练集进行模型训练并使用小型婴儿人脸图像网络模型进行测试，最终训练出适用于婴儿人脸遮挡检测的Acc-Retinaface模型。包括以下步骤：步骤S101，首先选取网络模型训练数据集，数据集选自merl数据集。网络模型训练仅需要使用到外部遮挡和未遮挡两类数据集，用于判断婴儿脸部被外部物体遮挡或吐奶造成的窒息或猝死。步骤S102，将步骤S101选出的训练集的人脸样本图像和图像人脸关键点遮挡信息输入网络模型中。Acc-Retinaface网络模型在实际训练过程中使用Resnet-50作为主干特征提取网，在联合级联框架中结合人脸检测和对齐功能，提取图像人脸形状特征，对Resnet-50最后三层进行FPN结构的构建得到多尺度的映射图，在获得有效特征层后进一步加强特征提取，使用SSH模块加强，调整提取的特征进行通道数，将人脸关键点的预测结果中关键点个数设定为预测68个关键点，68个关键点分别为口部20个、鼻部9个、眼部12个、眉部10个以及脸部轮廓17个，并在每个关键点信息中加入遮挡信息。得到图像人脸样本图像的四个预测结果：人脸回归预测结果、人脸框回归预测结果、人脸关键点预测结果及人脸关键点遮挡信息预测结果。步骤S103，得到图像人脸样本图像的预测结果后，基于预测的图像人脸框和真实人脸框对应的交并比进行图像人脸框分类。交并比指预测出的图像人脸框和真实的图像人脸框面积的重叠范围，交并比值越小，重叠的图像人脸框面积越大，预测的图像人脸框就越接近真实的图像人脸框。将实验预测出的图像人脸框分为：正人脸框和负人脸框两大类。正人脸框指预测的结果是人脸，负人脸框指预测的结果不是人脸。步骤S104利用真实图像和对应的图像预测结果计算相应的损失函数，对于每一个训练模型的最小化多任务损失函数为：图像人脸分类损失Lcls，pi表示预测模型图像人脸的概率，pi*表示真值Lcls是softmax损失，是二分类，判断是否为图像人脸；图像人脸框回归Lbox,ti、ti*分别表示模型对应的预测框位置和真实标注框的位置；图像人脸关键点回归Lpts，li、li*分别表示模型对应的预测关键点坐标和真实关键点坐标；图像人脸关键点遮挡回归Locc，oi、oi*分别表示模型对应的关键点遮挡预测和真实关键点遮挡情况。将图像人脸框预测结果代入损失函数，若预测结果为正人脸框，则需要对人脸框、人脸关键点以及人脸关键点遮挡进行损失计算，其中对于人脸框的预测损失使用softmax损失函数，对于人脸关键点以及人脸关键点遮挡的损失使用smooth-L1损失函数；若预测结果为负人脸框，则只需计算人脸分类损失。最终得到训练完善的图像遮挡检测使用的Acc-Retinaface网络模型。步骤S105，在网络模型训练完善后，本方法使用婴儿人脸遮挡图像进行测试，进而判断本方法对于婴儿人脸框、婴儿人脸关键点及婴儿人脸关键点遮挡检测的精确度。为提高Acc-Retinaface方法对婴儿人脸遮挡检测的效果，采用网络上收集的相关婴儿脸部遮挡或吐奶照片作为测试图像，并对收集图像进行信息标注形成小型测试集，用于婴儿人脸遮挡网络模型测试。数据传入训练完善的Acc-Retinaface方法的网络模型中，检测婴儿原始人脸样本图像人脸框及人脸关键点，获得婴儿人脸框、婴儿人脸关键点以及婴儿人脸关键点遮挡信息，将信息与小型测试集中的真实值作对比，可判断出网络模型对于婴儿人脸遮挡预测有较高精度。最终得到本方法中适用于婴儿人脸遮挡及窒息风险预测的网络模型。步骤S200，继续参考图1，获取婴儿人脸及头部周边的实时图像。本方法选用婴儿的实时图像作为输入，可在及时获得婴儿面部及头部周边当下遮挡情况的前提下，减少图像存储所需空间以及图像处理的时间。步骤S300，使用单阶人脸定位算法的Acc-Retinaface网络模型得到婴儿脸部关键点遮挡信息。将步骤S200中得到的婴儿人脸图像输入至Acc-Retinaface网络模型中，得到所需检测婴儿人脸图像的人脸框，关键点及遮挡信息。并使用相关参数对遮挡信息的结果进行判断，遮挡信息的结果相关参数大于阈值则视为被遮挡，小于等于阈值则视为未被遮挡，阈值设定为0.5。步骤S400，根据终端设备的窒息猝死风险值计算方法获得窒息风险情况。首先将步骤S300中得到的婴儿脸部关键点遮挡情况传回终端设备，终端设备包含相关权重计算方法和窒息风险计算方法，会根据各个婴儿人脸关键点相对权值计算出遮挡的婴儿人脸关键点的权重，并根据被遮挡的关键点权重计算出当下婴儿的窒息猝死风险值。婴儿人脸关键点包括眉毛、眼睛、嘴巴、鼻子、脸部轮廓区域的点。由于婴儿在新生时期呼吸系统还未发育完善，呼吸道不能保证婴儿日常呼吸需求，因此婴儿会使用口部辅助呼吸功能。口鼻的直接遮挡是大部分婴儿窒息情况的决定性因素，所以终端设备在进行婴儿窒息计算时口鼻关键点相对遮挡权重会高于其他部位。设定眉毛、眼睛以及脸部轮廓区域的关键点相对遮挡权重为P。参考图3，根据口部区域关键点遮挡情况得到口、鼻区域关键点相对权重。若口部区域关键点遮挡个数小于等于10，即遮挡个数未过半时，设定口部区域相对权重为2P，鼻子区域关键点遮挡相对权重为4P，若口部区域关键点遮挡个数过半，口部对呼吸功能的辅助效果大打折扣，此时婴儿鼻腔担负主要呼吸功能，鼻子区域关键点遮挡相对权重需要成倍增加，因此设定口部区域相对权重为4P，鼻子区域相对权重为8P。所有关键点的相对权重设定好后，根据窒息风险计算公式得到风险值，窒息风险计算公式如下：其中C为窒息猝死风险值，由于本方法中使用到的方法可以标记人脸的68个关键点，所以设定，Pi第i个关键点的权重值；S为第i个关键点的遮挡信息，设定该关键点未遮挡时S=0，遮挡时S=1；PO为眼睛、眉毛以及人脸轮廓区域的关键点权重值，眼睛、眉毛以及人脸轮廓区域共有关键点39个，设定PO=P；PM为口部区域关键点的权重值，口部区域共有关键点20个，PN为鼻子区域关键点的权重值，鼻子区域共有关键点9个，根据前面描述的相对权重关系，当口部区域遮挡个数大于10时N=20，PM=4P，PN=8P，否则设定N=10，PM=2P，PN=4P。步骤S500，根据步骤S400得到婴儿人脸图像的窒息猝死风险值Cr_value，通过交叉验证，将本方法的风险阈值R_value设定为0.38，警报阈值W_value设定为0.59，可达到最优的窒息猝死风险预警。当满足Cr_value ＜ R_value时，终端设备显示安全信号；当满足R_value ＜ Cr_value ＜ W_value时，终端设备发出窒息风险信号；当满足W_value ＜ Cr_value时，终端设备发出窒息警报。参考图4，当婴儿人脸图像被外物遮挡，且窒息猝死风险值Cr_value = 0.6911，此时图像右下方显示警报标志；参考图5，当婴儿人脸图像由于吐奶脸部被遮挡，且窒息猝死风险值Cr_value = 0.4241，此时图像右下方显示风险预警标志。与现有技术相比，本发明具有以下有益效果：实时高效地识别婴儿的脸；输入婴儿图像即可精确检测婴儿人脸并得到婴儿脸部关键点的遮挡信息，从而辅助判断婴儿呼吸危险；在婴儿无人看护时，通过判断脸部遮挡情况，向家长终端设备发出相应危险预警警报。最后所应说明的是：以上描述仅为本申请的较佳实施方案以及对所运用技术原理的说明。本领域技术人员应当理解，本申请中所涉及的发明范围，并不限于技术特征的特定组合而成的技术方案，而不脱离本发明的精神和范围的任何修改或者局部替换，其均应涵盖在本发明的权利要求范围当中。
