标题title
一种基于时序自适应卷积与注意力机制的目标跟踪方法
摘要abst
本发明公开了一种基于时序自适应卷积与注意力机制的目标跟踪方法，在特征提取方面，该方法提出了一种适用于目标跟踪的时序自适应卷积处理，利用时间信息来辅助空间特征的提取。同时还提出了一种全新的基于注意力的特征融合网络，相较于其他基于注意力的跟踪方法,该网络利用注意力更有效地结合了模板和搜索区域的特征,增强了目标经历干扰时模板信息与搜索区域信息的耦合性。本发明对运动模糊,目标遮挡,目标形变和目标超出视角等极端环境具有较强的鲁棒性。
权利要求书clms
1.一种基于时序自适应卷积与注意力机制的目标跟踪方法，其特征在于，包括如下步骤：步骤1：对于给定的模板图像，利用特征提取骨干网络进行特征提取，得到模板初级特征向量；具体是：将所述模板图像输入骨干网络得到模板初级特征向量fz0，其中Hz0，Wz0为输入模板图像高度与宽度；步骤2：对于给定的搜索图像，利用特征提取骨干网络进行特征提取，得到搜索区域初级特征向量；具体是：将所述搜索图像输入骨干网络得到搜索区域初级特征向量fx0，其中Hx0，Wx0为搜索图像高度与宽度；步骤3：将步骤1提取的模板初级特征向量和步骤2提取的搜索区域初级特征向量进行时序自适应卷积处理，得到模板特征向量与搜索区域特征向量；步骤4：将步骤3得到的搜索区域特征向量和模板特征向量输入基于注意力的特征融合网络，得到搜索区域与模板特征的相似度响应图；步骤5：将响应图输入预测网络，得到跟踪结果；其中：步骤3所述进行时序自适应卷积处理，具体包括：对于输入的模板初级特征向量fz0，使用时序自适应卷积的权重参数Wb和偏置参数bb，对模板初级特征向量进行特征强化，得到模板特征向量fz，模板特征向量fz的计算表示式为：fz＝Wb*fz0+bb；对于搜索区域初级特征向量fx0，首先构造长度为L、元素类型为帧描述符的队列，称为帧描述符队列，其符号为其中帧描述符通过对每一帧的搜索区域初级特征向量fx0进行全局平均池化GAP获得，即帧描述符队列通过下式计算得到：其中Cat表示在空间维度的拼接操作；随后使用帧描述符队列生成权重标定因子和偏置标定因子权重和偏置标定因子的计算表示式为：其中表示卷积运算；进一步的，使用权重标定因子偏置标定因子自适应卷积层权重参数Wb和偏置参数bb计算更新后的自适应卷积的权重参数Wt和偏置参数bt；Wt和bt通过下式计算得到：最后使用更新后自适应卷积层权重参数Wt和偏置参数bt，对搜索区域初级特征向量进行特征强化，得到搜索区域的特征向量fx；搜索区域的特征向量fx的计算表示式为：fx＝Wt*fx0+bt；所述步骤4具体包括：首先对搜索区域特征向量fx和模板特征向量fz在空间维度上进行展平操作，得到展平后的搜索区域特征向量fx1和展平后的模板特征向量fz1；fz1和fx1输入基于注意力的特征融合网络处理，得到搜索区域与模板特征的相似度响应图f；所述基于注意力的特征融合网络由模板分支和搜索分支构成；每个分支，由一个自注意力模块和一个交叉注意力模块组成；首先搜索分支的自注意力模块和模板分支的自注意力模块自适应地聚焦于目标轮廓信息，从而增强搜索区域特征向量fx和模板特征向量fz的表征能力；其中搜索分支的自注意力模块输出为：fx2＝fx1+MultiHead，其中是对fx1的空间位置编码，d为搜索区域特征向量中每个特征的维度，Nx为搜索区域特征向量中特征的数目，MultiHead为多头注意力机制；多头注意力机制的计算式如下：其中与W为学习参数矩阵；Q，K，V为多头注意力机制的输入；模板分支的自注意力模块输出为：fz2＝fz1+MultiHead，其中是对fz1的位置编码，d为模板特征向量中每个特征的维度，Nq为模板特征向量中特征的数目，MultiHead为式表示的多头注意力机制；然后，搜索分支的交叉注意力模块和模板分支的交叉注意力模块同时接收各自分支和另一分支的特征向量，使用模板向量突出搜索区域的目标特征，抑制随机分布的背景噪音；其中搜索分支的自注意力模块输出为：其中是对fz2的位置编码，Pkv是对fx2的位置编码，FFN为前馈网络，由下式计算得到：FFN＝maxW2+b2其中wi和bi分别表示第i层的权重矩阵和偏置向量，MultiHead为式计算的多头注意力机制；模板分支的交叉注意力模块输出为：其中fz3为模板分支的交叉注意力模块的输出，FFN为由式计算的前馈网络，是对fx2的位置编码，Pkv是对fz2的位置编码；最后一个交叉注意力模块用来交汇搜索分支和模板分支的输出，其计算表示为下式：其中f为搜索区域与模板特征的相似度响应图，FFN为由式计算的前馈网络，是对fx3的位置编码，Pkv是对fz3的位置编码。2.如权利要求1所述的一种基于时序自适应卷积与注意力机制的目标跟踪方法，其特征在于：步骤5所述将响应图输入预测网络，得到跟踪结果，具体包括：预测网络由分类分支和回归分支组成，每个分支由一个使用ReLU激活函数、隐藏层维为d的三层感知机组成；对于特征融合网络生成的相似度响应图f,预测网络对每个向量进行预测，以得到前景或背景的分类结果，以及正则化后的坐标；然后为了抑制目标漂移现象,采用余弦窗惩罚对得到的置信度进行后处理；最后,选择置信度得分最高的坐标作为跟踪结果。
说明书desc
技术领域本发明属于计算机视觉技术领域，具体为利用时序自适应卷积进行特征提取与注意力机制进行特征融合的目标跟踪方法。背景技术视觉目标跟踪是计算机视觉中广受研究的课题。由于视觉摄像机的广泛应用，基于视觉跟踪的应用得到了迅速发展，如运动目标分析、地理测量、视觉定位等。尽管基于孪生网络的跟踪方法实现了对简单运动的目跟踪，但在实际应用中由于遮挡、快速运动导致的目标模糊和外观变化等因素，仅基于视觉信息的目标跟踪任是一项具有挑战性的任务。现有方法存在问题1：视频流中丰富的时空信息对准确的视觉目标跟踪至关重要。前者包含用于目标定位的表征信息，后者包含对象在帧间的状态变化。在基于孪生网络的跟踪方法中，先前方法通过特征在空间维度上的拼接、动态模板更新、图神经网络和时空记忆网络引入时间信息。在该方法中一个典型的缺陷在于将视频帧视为独立的个体，仅利用多帧图像对目标表征进行建模，忽略了相邻帧间存在的动态变化信息。现有方法存在问题2：在基于孪生的跟踪方法中，通过构建模板图像和搜索区域图像之间的相似度响应图来对搜索区域中的目标位置进行预测；现有方法通过协相关运算来构建模板图像和搜索区域图像之间的相似性图。然而，协相关运算是一个局部运算，导致其无法聚合在空间上距离较远的特征,对干扰的鲁棒性低。其次协相关运算本质上是一个线性加权操作,导致其丢失了向量在特征空间上丰富的语义信息。发明内容本发明的目的是为了解决现有方法所存在的问题而提出了的一种基于时序自适应卷积与注意力机制的目标跟踪方法，该方法使用时序自适应卷积对模板初级特征向量和搜索区域初级特征向量进行处理，使用视频中的时序信息来增强空间特征的表征能力，从而将孤立的视频帧有机结合。同时提高了时序信息的利用效率；利用一种基于注意力的特征融合网络，使模板与搜索区域在空间上的远距离特征充分聚合,从而获得更具语义信息的相似度响应图。实现本发明目的的具体技术方案是：一种基于时序自适应卷积与注意力机制的目标跟踪方法,包括如下步骤：步骤1,对于给定的模板图像，利用特征提取骨干网络进行特征提取，最终得到模板初级特征向量；步骤2，对于给定的搜索图像，利用特征提取骨干网络进行特征提取，最终得到搜索区域初级特征向量；步骤3，将步骤1提取的模板初级特征向量和步骤2提取的搜索区域初级特征向量输入时序自适应卷积模块，得到模板特征向量与搜索区域特征向量；步骤4，将步骤3得到的搜索区域特征向量和模板特征向量输入基于注意力的特征融合网络，得到搜索区域与模板特征的相似度响应图；步骤5，将响应图输入预测网络，得到跟踪结果。进一步的，步骤1中的模板图像特征提取骨干网络的具体过程如下：特征提取骨干网络使用孪生网络来提取图像特征，该网络由两个分支组成：一个提取目标模板特征的模板分支，一个提取搜索图像特征的搜索分支，并且这两个分支结构相同，共享网络权重.将目标模板图像输入骨干网络得到模板初级特征向量fz0，其中Hz0，Wz0为输入模板图像高度与宽度。进一步的，步骤2中的搜索图像特征提取骨干网络的具体过程如下：特征提取骨干网络使用孪生网络来提取图像特征，该网络由两个分支组成：一个提取目标模板特征的模板分支，一个提取搜索图像特征的搜索分支，并且这两个分支结构相同，共享网络权重.将搜索图像输入骨干网络得到搜索区域初级特征向量fx0，其中Hx0，Wx0为搜索图像高度与宽度。进一步的，步骤3中时序自适应卷积模块的具体描述如下：对于输入的模板初级特征向量fz0，使用自适应卷积层权重参数Wb，和偏置参数bb，对模板的初级特征向量进行特征强化，得到模板的特征向量fz.模板的特征向量fz的计算表示式为：fz＝Wb*fz0+bb.对于搜索区域初级特征向量fx0，首先构造长度为L，元素类型为帧描述符的队列，称为帧描述符队列，其符号为其中帧描述符通过对每一帧的索区域初级特征向量fx0进行全局平均池化获得，即帧描述符队列通过下式计算得到：列其中Cat表示在空间维度的拼接操作；随后使用帧描述符队列生成权重标定因子和偏置标定因子权重和偏置标定因子的计算表示式为：其中表示卷积运算.进一步的，使用权重标定因子偏置标定因子自适应卷积层权重参数Wb和偏置参数bb计算更新后的自适应卷积层权重参数Wt和偏置参数bt.Wt和bt通过下式计算得到最后使用更新后自适应卷积层权重参数Wt和偏置参数bt，对搜索区域初级特征向量进行特征强化，得到搜索区域的特征向量fx.搜索区域的特征向量fx的计算表示式为：fx＝Wt*fx0+bt。进一步的，步骤4中的特征融合网络对特征向量的处理过程如下：首先对搜索区域的特征向量fx和模板的特征向量fz在空间维度上进行展平操作，得到展平后的搜索区域的特征向量fx1和展平后的模板特征向量fz1.所述基于注意力的特征融合网络由模板分支和搜索分支构成；对于每个分支，又由一个自注意力模块和一个交叉注意力模块组成；首先搜索分支的自注意力模块和模板分支的自注意力模块自适应地聚焦于目标轮廓信息，从而增强搜索区域特征向量fx和模板特征向量fz的表征能力；其中搜索分支自注意力模块输出如下fx2＝fx1+MultiHead，其中是对fx1的空间位置编码，d为搜索区域特征向量中每个特征的维度，Nx为搜索区域特征向量中特征的数目，fx2是搜索分支自注意力模块的输出，MultiHead为多头注意力机制.多头注意力机制的计算式如下：其中与W为学习参数矩阵.Q，K，V为多头注意力机制的输入；模板分支自注意力模块输出如下fz2＝fz1+MultiHead，其中fz2是模板分支自注意力模块的输出，是对fz1的位置编码，d为模板特征向量中每个特征的维度，Nq为模板特征向量中特征的数目，MultiHead为式表示的多头注意力机制.然后，搜索分支交叉注意力模块和模板分支交叉注意力模块同时接收各自分支和另一分支的特征向量，使用模板向量突出搜索区域的目标特征，抑制随机分布的背景噪音。其中搜索分支交叉注意力模块输出如下其中是对fz2的位置编码，Pkv是对fx2的位置编码，FFN为前馈网络，可由下式计算得到：FFN＝maxW2+b2其中wi和bi分别表示第i层的权重矩阵和偏置向量，MultiHead为式表示的多头注意力机制；模板分支交叉注意力模块输出如下其中fz3为模板分支交叉注意力模块的输出，FFN为由式计算的前馈网络.最后一个交叉注意力模块用来交汇搜索分支和模板分支的输出，其计算可以表示为下式子：其中f为模板与搜索区域的相似度响应图，FFN为由式计算的前馈网络，是对fx3的位置编码，Pkv是对fz3的位置编码。进一步的，步骤5所述将响应图输入预测网络，得到跟踪结果，具体包括：预测网络由分类分支和回归分支组成。每个分支由一个使用ReLU激活函数,隐藏层维为d的三层感知机组成。对于特征融合网络生成的相似度响应图f,预测网络对每个向量进行预测，以得到前景或背景的分类结果，以及正则化后的坐标。然后为了抑制目标漂移现象,采用余弦窗惩罚对得到的置信度进行后处理.最后,选择置信度得分最高的坐标作为跟踪结果。本发明与现有技术相比，具有以下优点：本发明提出的时序自适应卷积模块利用动态更新的卷积核权重进行特征提取,增强了空间卷积的时序建模能力。与以往引入时间信息的方法相比，时间自适应卷积核的权重由历史特征信息动态生成的，其优点1：它通过使用视频帧之间目标的运动信息来增强空间特征的表征能力，从而将孤立的视频帧有机结合起来；优点2：此外，因为时序自适应卷积在卷积核权重上进行操作，而不是在特征向量上进行操作，相对于其他时序信息引入机制的计算复杂度更低。本发明提出的基于注意力的特征融合网络,通过建立搜索区域与模板特征间长距离的依赖关系，使得跟踪方法能够自适应地提取空间特征间丰富的语义信息；优点3：相较于现有的特征融合方法,该方法提出的特征融合网络在物体经历形变,遮挡等干扰时,仍然可以得到准确的模板图像和搜索区域图像之间的相似度响应图,为后续跟踪结果的生成提供了更加精确的目标信息。附图说明图1是本发明流程图；图2是本发明实施例整体骨干网络结构图；图3是本发明提出的时间自适应卷积处理搜索区域初级特征向量的流程图；图4是本发明提出的时间自适应卷积处理模板初级特征向量的流程图；图5是本发明实施例基于注意力的特征融合网络结构图；图6是本发明提出的基于自注意力的特征融合模块结构图；图7是本发明提出的基于交叉注意力的特征融合模块结构图。具体实施方式为了使本发明的目的、技术方案及优点更加清楚明白，以下结合附图及实施例，对本发明做进一步详细说明，应当理解，此处描述的具体实施例仅用以解释本发明，并不用于限定本发明。本发明提出的时序自适应卷积模块,通过由当前输入的相邻帧特征动态更新卷积核的权重，从而实现使用时间上下文以强化空间特征的表征能力。自适应机制通过对比相邻帧间不同特征的相似度，对提取特征的卷积核权重进行加权。从而突出相邻帧中相似特征，抑制随机分布的背景与干扰。本发明提出的基于注意力的特征融合网络，通过建立搜索区域与模板特征间长距离的依赖关系，使得跟踪方法能够自适应地提取空间特征间丰富的语义信息.与现有方法相比，更精确地得到了模板图像和搜索区域图像之间的相似度响应图，为后续跟踪结果的生成提供了更加精确的目标信息。如图1所示，本发明的整体流程为：步骤1，对于给定的模板图像，利用特征提取骨干网络进行特征提取，最终得到模板初级特征向量；步骤2，对于给定的搜索图像，利用特征提取骨干网络进行特征提取，最终得到搜索区域初级特征向量；步骤3，将步骤1提取的模板初级特征向量和步骤2提取的搜索区域初级特征向量输入时序自适应卷积模块，得到模板特征向量与搜索区域特征向量；步骤4，将步骤3得到的搜索区域特征向量和模板特征向量输入基于注意力的特征融合网络，得到搜索区域与模板特征的相似度响应图；步骤5，将响应图输入预测网络，得到跟踪结果。进一步的，如图2，步骤1和步骤2中的模板图像特征提取骨干网络的具体过程如下：特征提取骨干网络使用孪生网络来提取图像特征，该网络由两个分支组成：一个提取目标模板特征的模板分支，一个提取搜索图像特征的搜索分支，并且这两个分支结构相同，共享网络权重.将目标模板图像输入骨干网络得到模板初级特征向量fz0，其中Hz0，Wz0为输入模板图像高度与宽度.将搜索图像输入骨干网络得到搜索区域初级特征向量fx0，其中Hx0，Wx0为搜索图像高度与宽度。进一步的，如图3，步骤3中搜索区域初级特征向量通过时序自适应卷积模块处理后得到搜索区域的特征向量的具体流程如下：对于搜索区域初级特征向量fx0，首先构造长度为L，元素类型为帧描述符的队列，称为帧描述符队列，其符号为其中帧描述符通过对每一帧的索区域初级特征向量fx0进行全局平均池化获得，即帧描述符队列通过下式计算得到：其中Cat表示在空间维度的拼接操作.随后用帧描述符队列生成权重标定因子和偏置标定因子权重和偏置标定因子的计算表示式为：其中表示1D卷积运算.进一步的，使用权重标定因了偏置标定因子自适应卷积层权重参数Wb，和偏置参数bb计算更新后的自适应卷积层权重参数Wt，和偏置参数bt，Wt，和bt通过下式计算得到最后使用更新后自适应卷积层权重参数Wt，和偏置参数bt，对搜索区域初级特征向量进行特征强化，得到搜索区域的特征向量fx.搜索区域的特征向量fx的计算表示式为：fx＝Wt*fx0+bt。进一步的，如图4，步骤3中模板初级特征向量通过时序自适应卷积处理后得到模板的特征向量的具体流程如下：对于输入的模板初级特征向量fz0，使用自适应卷积层权重参数Wb，和偏置参数bb，对模板的初级特征向量进行特征强化，得到模板的特征向量fz.模板的特征向量fz的计算表示式为：fz＝Wb*fz0+bb。进一步的，如图5，步骤4中的特征融合网络对特征向量的具体过程如下：首先对搜索区域的特征向量fx和模板的特征向量fz在空间维度上进行展平操作，得到展平后的搜索区域的特征向量fx1和展平后的模板特征向量fz1.所述基于注意力的特征融合网络由模板分支和搜索分支构成；对于每个分支，又由一个自注意力模块和一个交叉注意力模块组成；首先搜索分支的自注意力模块和模板分支的自注意力模块自适应地聚焦于目标轮廓信息，从而增强搜索区域特征向量fx和模板特征向量fz的表征能力；其中搜索分支自注意力模块输出如下fx2＝fx1+MultiHead，其中是对fx1的空间位置编码，d为搜索区域特征向量中每个特征的维度，Nx为搜索区域特征向量中特征的数目，fx2是搜索分支自注意力模块的输出，MultiHead为多头注意力机制.类似的，模板分支自注意力模块输出如下fz2＝fz1+MultiHead，其中fz2是模板分支自注意力模块的输出，是对fz1的位置编码，d为模板特征向量中每个特征的维度，Nq为模板特征向量中特征的数目.然后，搜索分支交叉注意力模块和模板分支交叉注意力模块同时接收各自分支和另一分支的特征向量，使用模板向量突出搜索区域的目标特征，抑制随机分布的背景噪音。其中搜索分支交叉注意力模块输出如下其中是对fz2的位置编码，Pkv是对fx2的位置编码，FFN为前馈网络.类似的，模板分支交叉注意力模块输出如下其中fz3为模板分支交叉注意力模块的输出，FFN前馈网络，是对fx2的位置编码，Pkv是对fz2的位置编码.最后一个交叉注意力模块用来交汇搜索分支和模板分支的输出，其计算可以表示为下式子：其中f为模输出的相似度响应图，FFN为前馈网络，是对fx3的位置编码，Pkv是对fz3的位置编码。进一步的，如图6，步骤4中特征融合网络的自注意力模块具体描述如下：本发明提出的自注意力模块采用残差连接的多头自注意力，实现自适应地聚合来自特征向量不同位置的信息.自注意模块可以总结为下式：XEC＝X+MultiHead其中，XEC是自注意模块的输出，X是自注意模块的输入，因为注意力机制没有能力判别不同特征的位置信息，输入加入了由正弦函数生成的空间位置编码Px.MultiHead是本发明使用的多头注意力机制，该机制能够考虑不同特征空间的注意力分布从而使模型关注不同语义空间的信息.MultiHead的计算式如下：其中与W为学习参数矩阵，Q，K，V为多头注意力机制的输入；Attention为该方法使用归一化点积注意力，其中计算如下式所示：其中Q，K，V表示归一化点积注意力的输入.是输入K的维度缩放因子，Softmax为为归一化函数。进一步的，如图7，步骤4中特征融合网络的交叉注意力模块具体描述如下：本发明提出的交叉注意力模块采用残差形式的多头交叉注意对来自两个不同分支输入的特征向量进行融合。CA模块可总结为下面两式：其中Xq是CA模块所在分支的输入，pq是对Xq的位置编码.Xkv是来自另一个分支的输入，Pkv是对Xkv的位置编码，XCF是CA模块的输入，MultiHead为通过式定义的运算，FFN表示前馈网络.前馈网络由两层使用Relu激活函数的全连接层组成。FFN可由下式计算得到：FFN＝maxW2+b2，其中wi和bi分别表示权重矩阵和偏置向量.下标表示权重所在的隐藏层。进一步的，步骤5中由相似度响应图生成跟踪结果的具体处理过程如下：对于特征融合网络生成的预测网络对每个向量进行预测，以得到Hx×Wx个正则化坐标及其置信度分数。然后，为了抑制目标漂移现象，使用用余弦窗惩罚对得到的置信度分数进行重新排序。具体而言，形状为Hx×Wx的汉宁窗被应用于计算最终的置信度分数，汉宁窗对置信度分数的影响因子由参数w决定。最终置信度分数scorew可以定义为scorew＝×score+w×scoreh；其中score是跟踪方法输出的原始置信度分数。scoreh是汉宁窗上对应位置的权值。最后选择置信度分数最高的正则化坐标作为跟踪结果。进一步的，为了验证本发明提出的基于时序自适应卷积的特征强化模块和基于注意力的特征融合网络的效果，本发明在LaSOT数据集下进行了消融实验，并将实验结果与行业前沿水平的跟踪方法指标进行比较。本发明在LaSOT数据集下进行了消融实验，LaSOT数据集是大规模单目标跟踪高质量数据集，这一数据集包含超过352万帧手工标注的图片和1400个视频，被广泛用于单目标跟踪方法的训练与测试。表格中黑色加粗标记的各项数值对应的方法表示本发明在该项指标下表现最好.如表1所示，本发明的名称缩写为LSTT.为了评估本发明提出的时序自适应卷积与特征融合网络的效果，在消融实验中，分别使用卷积核尺寸相同，输入输出维度相同的标准卷积来代替本发明的时序自适应卷积，使用协相关运算来代替本发明的特征融合网络.在表格中使用LSTT-NTAD简称使用特征融合网络，未使用时序自适应卷积.LSTT-NFF简称未使用特征融合网络，使用时序自适应卷积.LSTT-N简称同时未使用特征融合网络和时序自适应卷积.本发明LSTT相较于当前主流的ATOM方法的成功率提高了8.3％，标准化精度提高了11.3％，精度提高了13.5％。本发明提出的基于时序自适应卷积的特征强化模块和基于注意力的特征融合网络在一定程度上提高方法的性能，实验结果验证了本发明提出方法的有效性。表1本发明与其他先进方法成功率，标准化精度与精度的比较方法成功率标准化精度精度LSTT59.868.964.0LSTT-NTAD58.966.762.2LSTT-NFF52.760.455.6LSTT-N35.115.815.1SiamPRN++49.656.949.1ATOM51.557.650.5SiamFC33.642.033.9本发明的保护内容不局限于以上实施例。在不背离发明构思的精神和范围下，本领域技术人员能够想到的变化和优点都被包括在本发明中，并且以所附的权利要求书为保护范围。
