标题title
一种基于数字孪生车间混合数据集的不安全状态检测方法
摘要abst
本发明提出了一种基于数字孪生车间混合数据集的不安全状态检测方法，其步骤如下：对生产制造车间工人不安全状态进行分类，根据实际工人不安全状态类型，在数字孪生的虚拟车间中对这些不安全状态进行仿真，作为深度学习的虚拟数据集，再通过摄像头获取到真实车间工人不安全状态作为真实数据集；将收集到的虚拟数据集和真实数据集进行混合，通过标注工具对真实数据集合标注和自动标注脚本对虚拟数据集标注，再放到目标检测的网络中训练，生成基于虚实混合数据集的权值文件；将训练好的权值文件放入到目标检测网络中对车间不安全状态进行检测；实现在线可视化监控车间工人在车间工作时的安全。本发明利用虚实混合数据集训练模型，实时检测车间工人不安全状态，能够减少车间工人不安全状态的发生，保障了车间生产工人在车间生产过程的安全。
权利要求书clms
1.一种基于数字孪生车间混合数据集的不安全状态检测方法，其特征在于，其步骤如下：S1，对车间生产现场不安全状态进行分类整理，根据物理空间中实际车间生产现场的人员、装备、物料、环境情况，对生产现场不安全状态进行分类，在分类的过程中不存在种类冲突和重复的情况；S2，根据实际工人不安全状态类型，在数字孪生的虚拟车间中对这些不安全状态进行仿真，得到仿真动画；S3，通过车间监控摄像头获取到车间工人不安全状态视频；在制造车间安装支持SDK二次开发的摄像头，通过摄像头自带的录制功能，将真实车间生产过程的场景进行录制，通过Adobe Premiere Pro视频剪辑软件将录制的车间工人不安全状态视频剪辑，在车间现场监控视频剪辑的过程中，根据车间制造工人不安全状态的分类来进行剪辑，根据分类将录制的视频剪辑成一段一段视频，方便以后真实数据集的制作；S4，根据车间现场的实际环境对所建立的仿真动画进行调整，包括光线、背景、遮挡、采样参数、模型参数，以增加仿真动画的逼真度和丰富性；S5，通过建立的仿真动画制作车间现场工人不安全状态的高逼真虚拟数据集；S6，通过车间监控摄像头获取到的视频，制作车间现场工人不安全状态真实数据集；S7，将虚拟数据集和真实数据集合相互结合，生成虚实混合数据集；S8，使用混合数据集对模型进行训练并将迭代训练的模型进行目标检测算法的评估；S9，将训练好的模型应用到物理空间的制造车间真实场景中进行检测。2.如权利要求1所述的一种基于数字孪生车间混合数据集的不安全状态检测方法，其特征在于，步骤S1中，所述分类包括不安全行为类、不规范穿戴类、车间内存在对象闯入类；对于不安全行为类，细分为工人在车间奔跑、工人在车间不小心跌倒、工人在车间内跳跃、工人在车间内长时间聊天、工人在车间内接打电话、工人长时间疲劳工作；对于不规范穿戴类，细分为工人未按规定佩戴安全帽、工人未按规定穿戴工装、工人未按规定佩戴手套等；对于车间内存在对象闯入类，又可以细分为工人进入危险区域、非车间内工人进入车间、非车间内物体进入车间。3.如权利要求1所述的一种基于数字孪生车间混合数据集的不安全状态检测方法，其特征在于，步骤S2具体为：S2.1，首先采用SolidWorks三维软件建立出车间的虚拟模型，包括人物模型，仪器模型、物料模型，并将模型保存为step214格式，便于保存模型的各种材质；S2.2，将导出的Step214文件通过3Dmax软件打开，对模型进行修补，包括一些破面的修改，坐标轴和距离单元的修改，之后将文件保存为后缀名为.FBX的文件，以保证文件在Unity3D中能够顺利打开；S2.3通过脚本控制Unity3D中摄像头获取到仿真动画。4.如权利要求1所述的一种基于数字孪生车间混合数据集的不安全状态检测方法，其特征在于，步骤S5具体为：S5.1，根据车间现场的实际环境，在Unity3D中建立对应的仿真动画，包括工人、物料、机器人等静态模型，在Unity3D中，通过使用C#脚本移动虚拟对象来激活静态场景；S5.2，使用C#脚本控制虚拟摄像机移动和捕获图像；S5.3，使用Unity3D中的C#脚本和着色器计算边界框和语义分段等注释，获取到虚拟数据集的标注。5.如权利要求1所述的一种基于数字孪生车间混合数据集的不安全状态检测方法，其特征在于，步骤S6具体为：S6.1，利用车间监控摄像头拍摄的视频，进行视频取帧，将视频制作成一帧一帧格式统一、像素大小相同的图片；S6.2，对视频取帧产生的图片进行预处理，在采集的数据集中尽量保证目标检测不同类之间样本平衡，同时要保证采集数据的质量，对于过于模糊、遮挡严重等情况的数据集图片进行删除，对于数据集中目标的大小需要根据具体场景来确定最佳大小，在保证上述要求下，还需要保证采集到的数据集的多样性，采集场景中自然状态的图片；S6.3，将需要标注的数据集根据S1中不安全状态进行文件划分，分别作为不同的数据集，放入网络中训练生成不同的预测模型；S6.4，利用LabelImg软件对收集到的数据集进行标注，对于图片中需要检测到的不同目标进行标注，框出图像中目标信息，每标注一张图片会自动生成图片对应的同名XML文件，XML文件内容包括图片中目标物体在整个图片的位置信息和目标物体的类别，即数据集的标注文件。6.如权利要求1所述的一种基于数字孪生车间混合数据集的不安全状态检测方法，其特征在于，步骤S8具体为：S8.1，将数据集划分为训练集、验证集和测试集；S8.2，将划分好的数据集，放入到Pytorch框架下的Yolov4网络中训练；S8.2.1，根据划分好的数据集进行前向传播；S8.2.2，根据前向传播得到当前参数下的损失函数，进行损失计算；S8.2.3，根据计算的损失进行反向传播；S8.3，计算每轮训练的训练损失值和测试损失值，并进行学习率的更新；S8.4，将100次迭代训练的模型进行目标检测算法的评估；S8.5，训练结束得到可以检测不同类别的模型。7.如权利要求1所述的一种基于数字孪生车间混合数据集的不安全状态检测方法，其特征在于，步骤S9具体为：S9.1，利用YoloV4目标检测算法和OpenPose对工人在车间内接打电话进行检测；S9.2，将S8对不同数据集训练好的不同模型放入到物理空间的制造车间真实场景中去，在UI界面根据自身不同需求调用不同的模型；S9.3，将摄像头的视频流中获取帧画面传输到模型中进行预测，根据调用不同的模型，反馈检测结果，当车间工人不存在不安全状态时，制造生产车间正常生产；当车间工人存在不安全状态时，根据安全等级实施多策略安全管控。
说明书desc
技术领域本发明涉及智能制造、不安全状态检测和安全控制的技术领域，尤其涉及一种基于数字孪生车间混合数据集的不安全状态检测方法，特别是基于混合数据集和深度学习实现真实物理车间下的不安全状态检测方法。背景技术车间是生产型企业的基本组成部分，是企业生产任务的执行单元。主要由厂房、机器设备、生产材料和车间工作人员等组成。车间的主要任务是生产，但是生产车间的安全防护装置一般很少，工作环境和生产条件都比较差，生产用的零部件复杂，生产工人的劳动强度较高。同时现在许多企业追求生产效率，而忽略了在生产中的安全问题，这也导致了在车间生产的过程中，比其他行业更容易发生安全隐患。在早期车间的管理和控制的主要形式是：1、在工人进入车间正式上岗前进行安全培训。2、用警示牌、警戒线等形式进行辅助管理。3、管理人员在车间内部巡逻。4、利用监控摄像头对整个车间进行监控等形式来对车间内工人、设备、物料等存在的安全问题进行管理。但是随着时代的发展，车间生产线上的机器人的功能、工作车辆的种类、生产工序等复杂程度比早期车间生产复杂。利用传统的技术去处理车间的安全管理问题有点力不从心。数字孪生车间的出现为解决上述问题提供了途径，包括物理车间、虚拟车间、车间服务系统、车间孪生数据和连接。我们可以通过物理车间与虚拟车间的双向映射与实时交互，实现物理车间、虚拟车间、车间服务系统的集成和融合，实现车间生产要素管理、生产活动计划、生产过程控制等的一种车间运行新模式。针对车间不安全状态的检测问题，基于深度学习的YoloV4目标检测去检测不安全状态是一种高效、方便、漏检率较低的方法，在基于计算机视觉背景下落实安全检测技术处理的方案中，卷积神经网络是最关键的核心技术要求。借助可学习的权重和偏置神经元完成信息的传递，从而提取相应的特征。由于权重是可以学习的，我们只需要针对不同的安全问题去收集不同的数据集，在不同的数据集下放入到卷积神经网络中训练，就可以得到我们想要的检测安全隐患的模型。再通过训练好的安全检测模型和视频监控的视频流结合，去检测和处理车间存在或发生的安全隐患。针对深度学习训练需要用到的数据集问题，由于深度学习的神经网络需要大量的参数拟合，所以需要大量的带有标注的数据集去训练模型。目前数据集的制作大多是通过真实的场景进行数据的采集。而真实数据集的获取存在着许多问题，例如：1.数据集太少，模型就会没有足够多的样例来区分特征，将会导致数据过拟合，从而出现训练时误差低但测试时误差高的情况；2.数据集质量差，在手动标注的时间，会出现标注的标准不统一和标注精度不高的问题，将质量差的数据集放入到网络中训练时，会导致训练结果的质量差。3.分类不平衡，如果每个分类的样例数量与其他类别数量差距太大，则模型可能倾向于数量占主导地位的类，从而导致检测效果差。4.真实数据集收集价格昂贵，需要考虑环境因素，例如：天气、光线、背景、遮挡等，在真实场景中无法随时调整天气、光线等，会导致真实数据集收集的费用变得昂贵。为此，针对上述问题，本发明提出一种基于数字孪生车间混合数据集的不安全状态检测方法，根据物理空间的车间现场，对制造车间生产现场工人不安全状态分类；在此基础上，利用虚拟空间的孪生车间仿真车间现场不安全状态的逼真场景，虚拟数据集可以通过脚本自动生成；为了防止虚拟数据集在训练过程中出现过拟合的情况，需要在真实环境中收集制作数据集，并将虚拟数据集混合作为虚实混合数据集放入网络中训练，生成目标检测模型；最后将训练好的模型应用到物理真实车间中，并针对不同的不安全状态做出不同的响应。基于数字孪生车间混合数据集的不安全状态检测方法弥补基于深度学习的数据集制作成本高的缺点，以及极端生产环境导致安全培训的成本高和风险大的缺点，避免无法挽回的生产安全事故。发明内容针对制造车间工人不安全状态检测效率低、检测效果差和基于深度学习的目标检测技术真实数据集收集困难的问题，本发明提出基于数字孪生车间混合数据集的不安全状态检测方法，基于深度学习和虚实数据集相结合，检测出车间不安全状态，提高了检测的实时性，提高了车间安全系数，提高了车间生产的效率，可实时在线可视化监控制造工人在制造车间生产制造的安全。为了达到上述目的，本发明的技术方案是这样实现的：一种基于数字孪生车间混合数据集的不安全状态检测方法，其步骤如下：S1，对车间生产现场不安全状态进行分类整理，根据物理空间中实际车间生产现场的人员、装备、物料、环境等情况，对生产现场不安全状态进行分类，在分类的过程中不存在种类冲突和重复的情况；S2，根据实际工人不安全状态类型，在数字孪生的虚拟车间中对这些不安全状态进行仿真，得到仿真动画。S3，通过车间监控摄像头获取到车间工人不安全状态视频。在制造车间安装支持SDK二次开发的摄像头。通过摄像头自带的录制功能，将真实车间生产过程的场景进行录制。通过Adobe Premiere Pro视频剪辑软件将录制的车间工人不安全状态视频剪辑。在车间现场监控视频剪辑的过程中，根据车间制造工人不安全状态的分类来进行剪辑，根据分类将录制的视频剪辑成一段一段视频，方便以后真实数据集的制作。S4，根据车间现场的实际环境对所建立的仿真动画进行调整，包括光线、背景、遮挡、采样参数、模型参数，以增加仿真动画的逼真度和丰富性。S5，通过建立的仿真动画制作车间现场工人不安全状态的高逼真虚拟数据集。S6，通过车间监控摄像头获取到的视频，制作车间现场工人不安全状态真实数据集。S7，将虚拟数据集和真实数据集合相互结合，生成虚实混合数据集；S8，使用混合数据集对模型进行训练并将迭代训练的模型进行目标检测算法的评估，S9，将训练好的模型应用到物理空间的制造车间真实场景中进行检测。进一步地，步骤S1中，所述分类包括不安全行为类、不规范穿戴类、车间内存在对象闯入类；对于不安全行为类，细分为工人在车间奔跑、工人在车间不小心跌倒、工人在车间内跳跃、工人在车间内长时间聊天、工人在车间内接打电话、工人长时间疲劳工作；对于不规范穿戴类，细分为工人未按规定佩戴安全帽、工人未按规定穿戴工装、工人未按规定佩戴手套等；对于车间内存在对象闯入类，又可以细分为工人进入危险区域、非车间内工人进入车间、非车间内物体进入车间。进一步地，步骤S2具体为：S2.1，首先采用SolidWorks三维软件建立出车间的虚拟模型，包括人物模型，仪器模型、物料模型等。并将模型保存为step214格式，便于保存模型的各种材质；S2.2，将导出的Step214文件通过3Dmax软件打开，对模型进行修补，包括一些破面的修改，坐标轴和距离单元的修改，之后将文件保存为后缀名为.FBX的文件，以保证文件在Unity3D中能够顺利打开。S2.3通过脚本控制Unity3D中摄像头获取到仿真动画。进一步地，步骤S5具体为：S5.1，根据车间现场的实际环境，在Unity3D中建立对应的仿真动画，包括工人、物料、机器人等静态模型。在Unity3D中，通过使用C#脚本移动虚拟对象来激活静态场景。S5.2，使用C#脚本控制虚拟摄像机移动和捕获图像。S5.3，使用Unity3D中的C#脚本和着色器计算边界框和语义分段等注释，获取到虚拟数据集的标注。进一步地，步骤S6具体为：S6.1，利用车间监控摄像头拍摄的视频，进行视频取帧，将视频制作成一帧一帧格式统一、像素大小相同的图片。S6.2，对视频取帧产生的图片进行预处理，在采集的数据集中尽量保证目标检测不同类之间样本平衡，同时要保证采集数据的质量，对于过于模糊、遮挡严重等情况的数据集图片进行删除。对于数据集中目标的大小需要根据具体场景来确定最佳大小。在保证上述要求下，还需要保证采集到的数据集的多样性，采集场景中自然状态的图片。S6.3，将需要标注的数据集根据S1中不安全状态进行文件划分，分别作为不同的数据集，放入网络中训练生成不同的预测模型。S6.4，利用LabelImg软件对收集到的数据集进行标注，对于图片中需要检测到的不同目标进行标注，框出图像中目标信息。每标注一张图片会自动生成图片对应的同名XML文件，XML文件内容包括图片中目标物体在整个图片的位置信息和目标物体的类别，即数据集的标注文件。进一步地，步骤S8具体为：S8.1，将数据集划分为训练集、验证集和测试集。S8.2，将划分好的数据集，放入到Pytorch框架下的Yolov4网络中训练。S8.2.1，根据划分好的数据集进行前向传播。S8.2.2，根据前向传播得到当前参数下的损失函数，进行损失计算。S8.2.3，根据计算的损失进行反向传播。S8.3，计算每轮训练的训练损失值和测试损失值，并进行学习率的更新。S8.4，将100次迭代训练的模型进行目标检测算法的评估。S8.5，训练结束得到可以检测不同类别的模型。进一步地，步骤S9具体为：S9.1，利用YoloV4目标检测算法和OpenPose对工人在车间内接打电话进行检测。S9.2，将S8对不同数据集训练好的不同模型放入到物理空间的制造车间真实场景中去，在UI界面根据自身不同需求调用不同的模型。S9.3，将摄像头的视频流中获取帧画面传输到模型中进行预测，根据调用不同的模型，反馈检测结果。当车间工人不存在不安全状态时，制造生产车间正常生产；当车间工人存在不安全状态时，根据安全等级实施多策略安全管控。本申请将制造车间存在的工人不安全状态进行分类，使用Unity 3D对孪生车间不安全状态虚拟场景进行仿真，将逼真的仿真动画作为后续目标检测的数据集来源，为了防止在模型训练过程中出现过拟合，需要在虚拟数据集上加入一定比例的真实数据集，将制作的虚实混合数据集放入网络中训练，并将训练好的模型应用的真实的物理车间中，在检测出车间工人存在不安全状态时，根据安全等级实施多策略安全管控。本发明的有益效果：将虚实数据集和深度学习算法结合训练模型，检测车间工人存在的不安全状态。提高了检测的实时性，根据检测到的不同不安全状态类别，给出不同控制方案，实时在线可视化监控制造工人在制造车间生产制造的安全。本发明解决了真实数据集数量少、质量差、分类不平衡、价格昂贵的问题，利用虚拟数据集和真实数据集结合，很大程度上减少了数据集制作的成本和难度。本发明解决了在车间工人不安全状态检测的实时性问题，利用目标检测技术实时的检测车间安全问题，时刻保障车间工人在生产制造过程的安全，提高了工作的效率。附图说明图1为本发明的总体流程图；图2为不同亮度下的示意图；图3为不同视角下的场景示意图；图4为虚拟数据集获取流程图；图5为基于数字孪生车间的目标检测算法训练流程；图6为目标检测算法流程；图7为目标检测和OpenPose结合检测车间工人接电话的示意图；图8为本发明的系统结构图；图9为神经网络结构前向传播过程。具体实施方式下面将结合本发明实施例中的附图，对本发明实施例中的技术方案进行清楚、完整地描述，本实例的应用背景：在制造车间生产现场，存在诸多引起生产事故的不安全状态，不安全状态是导致生产事故发生的潜在因素，需要及时发现其产生原因、涉及人员、带来的危害等，并通知安全管理员进行预警和处理，避免不可挽回的安全生产事故。显然，所描述的实施例仅仅是本发明一部分实施例，而不是全部的实施例。基于本发明中的实施例，本领域普通技术人员在没有付出创造性劳动前提下所获得的所有其他实施例，都属于本发明保护的范围。一种基于数字孪生车间混合数据集的不安全状态检测方法，基于深度学习和虚拟、真实数据集相结合，实现物理场景的车间的不安全状态识别、反馈和控制，其步骤如下：S1，对车间生产现场不安全状态进行分类整理，根据物理空间中实际车间生产现场的人员、装备、物料、环境等情况，对生产现场不安全状态进行分类，在分类的过程中不存在种类冲突和重复的情况；优选地，所述分类包括不安全行为类、不规范穿戴类、车间内存在对象闯入类；对于不安全行为类，细分为工人在车间奔跑、工人在车间不小心跌倒、工人在车间内跳跃、工人在车间内长时间聊天、工人在车间内接打电话、工人长时间疲劳工作；对于不规范穿戴类，细分为工人未按规定佩戴安全帽、工人未按规定穿戴工装、工人未按规定佩戴手套等；对于车间内存在对象闯入类，又可以细分为工人进入危险区域、非车间内工人进入车间、非车间内物体进入车间。S2，根据实际工人不安全状态类型，在数字孪生的虚拟车间中对这些不安全状态进行仿真，得到仿真动画。S2.1，首先采用SolidWorks三维软件建立出车间的虚拟模型，包括人物模型，仪器模型、物料模型等。并将模型保存为step214格式，便于保存模型的各种材质；S2.2，将导出的Step214文件通过3Dmax软件打开，对模型进行修补，包括一些破面的修改，坐标轴和距离单元的修改，之后将文件保存为后缀名为.FBX的文件，以保证文件在Unity3D中能够顺利打开。S2.3通过脚本控制Unity3D中摄像头获取到仿真动画。S3，通过车间监控摄像头获取到车间工人不安全状态视频。为了方便对物理空间的真实制造车间真实场景的检测，在制造车间安装支持SDK二次开发的摄像头。通过摄像头自带的录制功能，将真实车间生产过程的场景进行录制。通过Adobe Premiere Pro视频剪辑软件将录制的车间工人不安全状态视频剪辑。在车间现场监控视频剪辑的过程中，根据车间制造工人不安全状态的分类来进行剪辑，根据分类将录制的视频剪辑成一段一段视频，方便以后真实数据集的制作。S4，根据车间现场的实际环境对所建立的仿真动画进行调整，包括光线、背景、遮挡、采样参数、模型参数，以增加仿真动画的逼真度和丰富性。由于实际车间的情况复杂多样，在Unity3D中对模型进行修改，通过旋转Unity3D软件自带的太阳光，来达到改变模型亮度的效果。如图2所示，为不同亮度下面的场景。在场景中放置戴安全帽和不戴安全帽的人员，并使用Unity3D中的Animation动画功能让这些人员在场景中自由移动；通过脚本控制Unity3D中摄像头的位置，来获取不同的视角，如图3所示，以增加仿真的逼真性。S5，通过建立的仿真动画制作车间现场工人不安全状态的高逼真虚拟数据集，如图4 所示。S5.1，根据车间现场的实际环境，在Unity3D中建立对应的仿真动画，包括工人、物料、机器人等静态模型。在Unity3D中，通过使用C#脚本移动虚拟对象来激活静态场景。S5.2，使用C#脚本控制虚拟摄像机移动和捕获图像。S5.3，使用Unity3D中的C#脚本和着色器计算边界框和语义分段等注释，获取到虚拟数据集的标注。S6，通过车间监控摄像头获取到的视频，制作车间现场工人不安全状态真实数据集。S6.1，利用车间监控摄像头拍摄的视频，进行视频取帧，将视频制作成一帧一帧格式统一、像素大小相同的图片。S6.2，对视频取帧产生的图片进行预处理，在采集的数据集中尽量保证目标检测不同类之间样本平衡，同时要保证采集数据的质量，对于过于模糊、遮挡严重等情况的数据集图片进行删除。对于数据集中目标的大小需要根据具体场景来确定最佳大小。在保证上述要求下，还需要保证采集到的数据集的多样性，采集场景中自然状态的图片，否则会出现过拟合的图片数据。S6.3，将需要标注的数据集根据S1中不安全状态进行文件划分，例如将不安全行为类的小类，分别作为不同的数据集，放入网络中训练生成不同的预测模型。同样的，将不规范穿戴类和车间内存在对象闯入类的子类细分为不同的数据集，分别放入到网络中训练，方便在物理空间的制造车间真实场景中检测的应用。S6.4，利用LabelImg软件对收集到的数据集进行标注，对于图片中需要检测到的不同目标进行标注，框出图像中目标信息。每标注一张图片会自动生成图片对应的同名XML文件，XML文件内容包括图片中目标物体在整个图片的位置信息和目标物体的类别，即数据集的标注文件。S7，将虚拟数据集和真实数据集合相互结合，生成虚实混合数据集；S8，使用混合数据集对模型进行训练并将迭代训练的模型进行目标检测算法的评估，如图5所示。S8.1，将数据集划分为训练集、验证集和测试集。虚拟数据集和真实数据集均匀的分布在各类别的数据集上，不可以出现训练集、验证集和测试集中只出现虚拟数据集或真实数据集一类的情况，而应该即存在虚拟数据集又存在真实数据集。对于不同数量级的数据集，将训练集、验证集、测试集划分成不同比例的集合。对于数据集的量级在万的情况下，把虚实数据集训练集、验证集、测试之间的比例划分为6：2：2。而对于数量级在百万的数据集，将训练集、验证集、测试集比例调整为98：1：1。S8.2，将划分好的数据集，放入到Pytorch框架下的Yolov4网络中训练。利用训练集来训练模型，通过匹配一些参数来建立一个分类器。将训练训练集产生的分类器放入到验证集中，进行调整分类器的参数，使用生成的模型对验证集数据进行预测，记录模型准确率，选出效果最佳的模型所对应的参数。将训练好的模型放入测试集中，测试训练好的模型的分类能力。神经网络的训练过程是前向传播和反向传播交替进行，先通过前向传播训练数据和权重参数计算输出结果，再通过反向传播根据导数链式法则计算损失函数对各参数的梯度，并根据梯度进行参数的更新。利用前向传播算法和反向传播算法不断更新损失函数的值和参数，直到损失函数下降到指定的阈值，即完成神经网络的训练。S8.2.1，根据划分好的数据集进行前向传播。将数据集放入神经网络中，信息从输入层开始，从上一层神经元直接流转到下一层神经元，根据每一个神经元的输入和相应规则可以计算出输出，然后将经过计算的输出作为下一层输入，一直运算到输出层为止，最终得到在当前参数下的损失函数。如图9所示。隐藏层的输出计算：a1＝f11+X2 W21+X3 W31+b1)a2＝f12+X2 W22+X3 W32+b2)a3＝f13+X2 W23+X3 W33+b3)输出层的输出计算：a1＝f1W11+a2W21+a3W31+b1)a2＝f1W12+a2W22+a3W32+b2)其中f函数表示激活函数，常用的激活函数Sigmoid,ReLU,Swish,Mish, GELU等，Yolov4中将激活函数修改成了Mish激活函数，Mish函数的公式如下：Mish＝x×tanh)S8.2.2，根据前向传播得到当前参数下的损失函数，进行损失计算。将图片经过网络预测的预测框和真实图片中真实框对比，计算真实框和预测框的IOU，如果某些预测框和真实框的重合度大于0.5，则忽略。进一步计算CIOU和置信度的loss 值，最后计算预测种类的loss值。S8.2.2.1，计算真实框和预测框的交并比IOU。IOU用来衡量两个边界框重叠的相对大小，预测框和真实框重叠越大，说明算法的预测效果越好，是一种评价预测结果的一种指标。在算法的预测框和真实框之间的交并比IOU≥0.5时，则算法预测结果可以接受，并比IOU的计算公式如下：S8.2.2.2，计算真实框和预测框的CIOU。IOU是比值的概念，对目标物体的尺寸不敏感，CIOU将目标与anchor之间的距离、尺度、惩罚项和重叠率都考虑进去，让目标框的回归趋于稳定。CIOU的计算公式如下：其中，ρ2分别表示预测框和真实框的中心点的欧式距离。c代表的是能够同时包含预测框和真实框的最小闭包区域的对角线距离。对于CIOU的计算公式中α和υ的计算公式如下：S8.2.3，根据计算的损失进行反向传播。将网络中所有权重进行损失函数的梯度计算，这个损失函数的梯度会反馈给最优化方法，用来更新权值进行最小化损失函数。反向传播算法从后往前逐层的求导，并向前传递梯度，得到新计算出来的权重，更新模型参数，实现模型的训练。S8.3，计算每轮训练的训练损失值和测试损失值，并进行学习率的更新。每经过一轮的训练，网络会自动生成训练损失值train loss和测试损失值test loss，当train loss不断下降，test loss不断下降，说明网络仍在学习；当train loss不断下降，但是testloss趋于不变，说明网络出现过拟合；当train loss趋于不变，test loss不断下降，说明数据集存在问题；当train loss趋于不变，test loss趋于不变，说明学习遇到瓶颈，需要减小学习率或批量数目；当train loss不断上升，test loss不断上升，说明网络结构设计不当，参数设置不当等问题。在训练YOLO V 4目标检测模型时，使用Pytorch提供的学习率调整策略StepLR，这种策略是等间隔调整学习率，调整方式如下：lr＝lr×gammastep_size表示调整间隔数，gamma表示调整系数。例如：设置step_size＝50，step_size＝0.1，每隔50个epoch时调整学习率，用当前学习率乘以0.1得到更新后的学习率。在训练过程中，设置迭代次数为100次，在前50次迭代，设置学习率为0.001，在后 50次迭代，设置学习率为0.0001，但如果连续5次迭代train loss值和test loss值没有变化，学习率变为上一次学习率的1/10，以此规律迭代，直到第100次时结束。S8.4，将100次迭代训练的模型进行目标检测算法的评估。通过loss下降曲线和mAP 来评估，先通过loss下降曲线查看网络是否训练完成，当loss 曲线下降趋于平稳，则认为训练完成。再利用mAP来计算目标检测的精确度，mAP的值越高说明训练的结果越好。S8.5，训练结束得到可以检测不同类别的模型。例如：检测工人在车间奔跑、工人在车间不小心跌倒、工人在车间内跳跃的模型，检测工人未按规定佩戴安全帽、工人未按规定穿戴工装、工人未按规定佩戴手套的模型，检测工人在车间内接打电话的模型，检测工人进入危险区域模型，检测非车间内工人进入车间模型。S9，将训练好的模型应用到物理空间的制造车间真实场景中进行检测。目标检测算法 YoloV4检测的步骤，如图6所示。首先读取物理真实车间不安全状态场景的视频，对视频流进行取帧；进一步，对当前帧图片进行预处理，加入灰条，实现不失真的大小调整；进一步，将预处理好的图片放入到主干特征提取网络和特征金字塔中，生成三个有效特征层，并对这三个有效特征层进行解码操作；进一步，获取到预测框，对预测框进行堆叠，非极大抑制操作；进一步，将预测结果的格式进行转化，转化为左上角右下角的格式；进一步，利用置信度进行筛选，获取预测结果中包含的所有类别；进一步，对种类进行遍历，完成非极大抑制；进一步，去除图片预处理时添加的灰条；进一步，将预测结果进行绘制并输出。根据目标检测输出的结果和安全等级实施多策略安全管控。S9.1，利用YoloV4目标检测算法和OpenPose对工人在车间内接打电话进行检测。车间工人在车间内接打电话的检测模型，如图7所示。直接利用目标检测算法检测效果较差，可利用YoloV4目标检测算法和OpenPose结合的办法进行检测。但是Open Pose在无人背景下检测效果并不好，可能出现误检。所以，先通过YoloV4目标检测算法先检测出人，然后将除人以外的背景全部设置为黑色，生成只存在人的图片。然后，将这张图片放入到 OpenPose中进行关键点检测，得到关键点的信息。当检测到的手臂关键点弯曲程度达到一定值时，利用目标检算法检测手部关键点内容，如果通过目标检测算法检测到手机时，则说明车间工人在车间内接打电话。S9.1，对于车间工人在车间内接打电话的检测模型，如图7所示，由于直接利用目标检测算法检测效果较差，可利用YoloV4目标检测算法和OpenPose结合的办法进行检测，同时由于Open Pose在无人背景下检测效果并不好，可能出现误检。所以，先通过YoloV4 目标检测算法先检测出人，然后将除人以外的背景全部设置为黑色，生成只存在人的图片。然后，将这张图片放入到Open Pose中进行关键点检测，得到关键点的信息。当检测到的手臂关键点弯曲程度达到一定值时，利用目标检算法检测手部关键点内容，如果通过目标检测算法检测到手机时，则说明车间工人在车间内接打电话。S9.2，将S8对不同数据集训练好的不同模型放入到物理空间的制造车间真实场景中去，在UI界面根据自身不同需求调用不同的模型。例如：只需检测工人在车间奔跑、工人在车间不小心跌倒、工人在车间内跳跃，我们只需在UI界面上进行选择，在选择的同时会自动调用检测工人在车间奔跑、工人在车间不小心跌倒、工人在车间内跳跃的模型。S9.3，将摄像头的视频流中获取帧画面传输到模型中进行预测，根据调用不同的模型，反馈检测结果。当车间工人不存在不安全状态时，制造生产车间正常生产；当车间工人存在不安全状态时，根据安全等级实施多策略安全管控。图8所示的一种基于数字孪生车间混合数据集的不安全状态检测方法的系统结构图，主要包括物理空间的车间生产现场、虚拟空间的数字孪生车间、基于深度学习的目标检测。针对不同产品的不同车间生产现场会存在不同类型的不安全状态，建立对应的车间生产现场不安全状态分类。根据车间生产现场不安全状态分别对物理空间的车间生产现场和虚拟空间的数字孪生车间进行数据集的采集，将采集到的数据集放入网络中训练，并将训练好的模型放入到物理空间的车间生产现场进行检测。随着工业4.0不断推进发展，制造车间中工人的安全备受关注，本发明的思想主要解决车间工人不安全状态的数据集制作问题和车间工人在生产制作的安全问题。基于数字孪生技术搭建一套具备实时响应、动态反馈、在线可视化的检测系统。将孪生车间不安全状态虚拟场景进行仿真获取到的虚拟数据集和物理车间不安全状态的真实数据集混合，制作成混合虚实数据集，节省了深度学习算法收集数据集的成本。将训练好的模型应用到真实物理车间中，可以有效的检测出车间工人不安全状态，保证了工作人员的安全，同时提高车间工人的工作效率。以上所述仅为本发明的较佳实施例而已，并不用以限制本发明，凡在本发明的精神和原则之内，所作的任何修改、等同替换、改进等，均应包含在本发明的保护范围之内。
