标题title
面向API序列恶意软件检测模型的黑盒攻击与防御方法
摘要abst
本发明公开了一种面向API序列恶意软件检测模型的黑盒攻击与防御方法，包括：面向黑盒的代理模型构建；基于扰动的生成模型构建：通过训练生成模型，在恶意软件的API序列中添加噪声API来对其进行扰动；对抗训练：通过对抗训练，使得代理模型能够更好地模拟被攻击模型，使得生成模型生成的恶意软件API序列能够更不容易被代理模拟检测出来；模型的防御性训练：通过加入生成模型生成的恶意样本来对检测模型进行再训练，使得其对对抗样本具有更强的鲁棒性。本发明通过模拟攻击者来生成对抗样本，并基于对抗样本来对恶意软件检测模型进行再训练，可大大提高恶意软件检测模型对恶意对抗攻击的防御能力。
权利要求书clms
1.一种面向API序列恶意软件检测模型的黑盒攻击与防御方法，其特征在于，包括以下步骤：1） API序列抽取；2）构建面向黑盒的代理模型：3）构建生成模型，具体包括：将长度为N的API序列进行分割生成N个API子序列，子序列经过框架后得到N个噪声API序列，再将N个噪声API序列插入到步骤1）获得长度为N的API序列中，获得对抗样本API序列；4）从恶意软件集中获取对抗训练的恶意样本，从良性软件集中获取良性样本，将对抗训练的恶意样本输入到步骤3）中生成模型中，得到对抗样本API序列，将对抗样本API序列和良性样本混合，作为训练集，输入到黑盒模型中，得到训练标签，利用训练集和训练标签训练步骤2）中的面向黑盒的代理模型中，根据代理模型损失函数更新面向黑盒的代理模型中的参数，采用面向黑盒的代理模型更新后的参数以及根据生成模型的损失函数更新生成模型中的参数，迭代更新，得到最终的生成模型；5）步骤4）最终的生成模型生成对抗样本，输入到黑盒模型中，将黑盒模型未能正确分类的样本作为防御性训练的恶意样本，输入到黑盒模型中进行防御性训练，将训练后的黑盒模型对基于API序列恶意软件检测模型的黑盒攻击的黑盒攻击进行防御。2.根据权利要求1所述的面向API序列恶意软件检测模型的黑盒攻击与防御方法，其特征在于，步骤1）中，API序列抽取具体包括：采用沙箱对软件样本进行模拟运行，抽取得到API序列。3.根据权利要求1所述的面向API序列恶意软件检测模型的黑盒攻击与防御方法，其特征在于，步骤2）中，所述的面向黑盒的代理模型依次包括：输入层、嵌入层、循环层以及输出分类层。4.根据权利要求3所述的面向API序列恶意软件检测模型的黑盒攻击与防御方法，其特征在于，步骤2）中，所述的输出分类层依次包括：表征向量输出层、全连接层和sigmoid层。5.根据权利要求1所述的面向API序列恶意软件检测模型的黑盒攻击与防御方法，其特征在于，步骤3）中，所述的框架采用seq2seq框架。
说明书desc
技术领域本发明涉及机器学习与信息安全技术领域，具体涉及一种面向API序列恶意软件检测模型的黑盒攻击与防御方法。背景技术恶意软件指任何用于损害计算机、服务器或计算机网络的软件。恶意软件包括病毒、蠕虫、木马、勒索软件等多种形式。恶意软件是威胁个人、企业、国家信息安全的一个严重问题。与传统的网络威胁相比，恶意软件具有变种多、更新快、隐蔽性高等特点。因此，如何有效地检测恶意软件，是信息安全领域的一个重要的研究主题。恶意软件的静态检测已经十分成熟，静态检测的优势在于不需要实际运行软件，因此检测的代价较小。但已经出现了很多方法对静态检测进行绕过，例如软件打包、代码混淆等技术。而API调用是软件动态运行过程中最重要的行为，因此分析API调用序列是实现恶意软件动态检测的重要手段。在黑盒攻击方面，已经有人提出了基于GAN的恶意软件攻击算法。GAN即生成式对抗网络，是一种利用博弈的思想进行对抗从而提升模型性能的方法。GAN同时训练一个生成器和一个判别器，其中生成器通过学习将噪声的分布映射为逼近于真实样本的对抗样本的分布，而判别器需要从混有真实样本和对抗样本的数据中将对抗样本鉴别出来。整个生成对抗网络的训练过程就是生成器不断模仿真实样本学习如何生成对抗样本，同时判别器不断从样本中找出对抗样本，直到生成器找到了能够迷惑判别器的方法。基于GAN的恶意软件攻击算法基于替代检测器拟合黑盒分类器以逼近其决策边界的思路，能够绕过基于机器学习的黑盒检测模型，生成对抗样本。然而，上述方法存在许多不足： 假设的黑盒模型只检测API是否被调用，过于简单和理想化，不满足实际情况； 未能考虑到对API调用特征向量修改后，软件是否还存在恶意功能。发明内容本发明提出了一种面向API序列恶意软件检测模型的黑盒攻击与防御方法，通过生成式对抗方法，对恶意API序列进行加噪，使黑盒模型无法对其正确分类，再用生成的对抗样本训练黑盒模型，提高黑盒模型的对该攻击的防御能力。一种面向API序列恶意软件检测模型的黑盒攻击与防御方法，具体方法如下： 面向黑盒的代理模型构建：由于被攻击模型是黑盒的，无法得知其具体模型结构和参数，因此通过构建泛化能力强的模型来模拟被攻击黑盒模型； 基于扰动的生成模型构建：通过训练生成模型，在恶意软件的API序列中添加噪声API来对其进行扰动； 对抗训练：通过对抗训练，使得代理模型能够更好地模拟被攻击模型，使得生成模型生成的恶意软件API序列能够更不容易被代理模拟检测出来； 模型的防御性训练：通过加入生成模型生成的恶意样本来对检测模型进行再训练，使得其对对抗样本具有更强的鲁棒性。一种面向API序列恶意软件检测模型的黑盒攻击与防御方法，包括以下步骤：1） API序列抽取；2）构建面向黑盒的代理模型：3）构建生成模型，具体包括：将长度为N的API序列进行分割，将长度为N的API序列进行分割生成N个API子序列，子序列经过seq2seq框架后得到N个噪声API序列，再将N个噪声API序列插入到步骤1）获得长度为N的API序列中，获得对抗样本API序列；4）从恶意软件集中获取对抗训练的恶意样本，从良性软件集中获取良性样本，将对抗训练的恶意样本输入到步骤3）中生成模型中，得到对抗样本API序列，将对抗样本API序列和良性样本混合，作为训练集，输入到黑盒模型中，得到训练标签，利用训练集和训练标签训练步骤2）中的面向黑盒的代理模型中，根据代理模型损失函数更新面向黑盒的代理模型中的参数，采用面向黑盒的代理模型更新后的参数以及根据生成模型的损失函数更新生成模型中的参数，迭代更新，得到最终的生成模型；由于无法获得黑盒模型中的参数，所以采用代理模型学习黑盒模型分类后数据的方式，而生成模型在对抗训练的过程中，不断精确噪声插入的位置和数量，最终使黑盒模型的分辨准确率有显著的下降。5）模型的防御性训练：步骤4）最终的生成模型生成对抗样本，输入到黑盒模型中，将黑盒模型未能正确分类的样本作为防御性训练的恶意样本，输入到黑盒模型中进行防御性训练，将训练后的黑盒模型对基于API序列恶意软件检测模型的黑盒攻击进行防御。经防御性训练后的黑盒模型增强了对对抗样本的识别能力，能够对此类攻击有良好的防御效能。步骤中，API序列抽取具体包括：采用沙箱对软件样本进行模拟运行，抽取得到该软件样本的API序列。步骤2）中，所述的面向黑盒的代理模型依次包括：输入层、嵌入层、循环层以及输出分类层，所述的输出分类层依次包括：表征向量输出层、全连接层和sigmoid层。全连接层将输出的表征向量映射到样本标记空间，sigmoid最终进行二分类，输出序列为恶意的概率。步骤3）中，所述的生成模型采用seq2seq框架。将长度为N的API序列进行分割，将长度为N的API序列进行分割生成N个API子序列，子序列经过seq2seq框架后得到N个噪声API序列，再将N个噪声API序列插入到步骤1）获得长度为N的API序列中，获得对抗样本API序列，具体包括：长度为N的API序列为s = ，a1为API序列中的第1个API，a2为API序列中的第2个API，ak为API序列中的第k个API，aN为API序列中的第N个API；将s进行分割，得到N个子序列SS = {, , , …, , }，SS中的每个子序列ssk经过seq2seq框架得到生成噪声API序列gsk = ；N个噪声API序列为gs1, gs2, …gsk, …, gsN，其中，gsk = ，gs1为N个噪声API序列中第1个噪声API序列，gs2为N个噪声API序列中第2个噪声API序列，gsk为N个噪声API序列中第k个噪声API序列，gsN为N个噪声API序列中第N个噪声API序列，bk1为第k个噪声API序列中的第1个噪声API，bk2为第k个噪声API序列中的第2个噪声API，bkL为第k个噪声API序列中的第L个噪声API；将N个噪声API序列插入到长度为N的API序列中，将gsk插入到长度为N的API序列的ak后面，获得对抗样本API序列g = 。插入噪声API序列不能改变原始的API序列顺序，否则可能破坏原有的恶意软件功能。而无法明确知道插入的噪声API的位置和数量，因此将原始的API序列在每个位置上分割成N个子序列，将每个子序列输入生成模型，学习其特征，增强输出的噪声API序列的扰动效果。与现有技术相比，本发明具有如下优点：本发明通过模拟攻击者来生成对抗样本，并基于对抗样本来对恶意软件检测模型进行再训练，可大大提高恶意软件检测模型对恶意对抗攻击的防御能力。附图说明图1为一种面向API序列恶意软件检测模型的黑盒攻击与防御方法流程图。图2为代理模型网络结构图。图3为生成模型网络结构图。具体实施方式为了使本技术领域的人员更好地理解本申请方案，下面结合附图和具体实施方式。如图1所示，一种面向API序列恶意软件检测模型的黑盒攻击与防御方法，包括如下步骤：  API序列抽取，面向黑盒的代理模型构建：由于被攻击模型是黑盒的，无法得知其具体模型结构和参数，因此通过构建泛化能力强的模型来模拟被攻击黑盒模型。 基于扰动的生成模型构建：通过训练生成模型，在恶意软件的API序列中添加噪声API来对其进行扰动。 对抗训练：通过对抗训练，使得代理模型能够更好地模拟被攻击模型，使得生成模型生成的恶意软件API序列能够更不容易被代理模拟检测出来。 模型的防御性训练：通过加入生成模型生成的恶意样本来对检测模型进行再训练，使得其对对抗样本具有更强的鲁棒性。步骤中，API序列抽取，面向黑盒的代理模型构建的详细步骤如下： API序列抽取：基于API序列的动态检测是当前恶意软件检测的主流方法。给定一个软件样本，采用沙箱对软件样本进行模拟运行，得到该软件样本的API序列。 代理模型网络结构定义：由于被攻击的基于API序列的恶意软件检测模型是一个黑盒，因此采用泛化能力较强的LSTM作为代理模型。基于LSTM的代理模型的网络结构如图2所示，面向黑盒的代理模型依次包括：输入层、嵌入层、循环层以及输出分类层，所述的输出分类层依次包括：表征向量输出层、全连接层和sigmoid层。具体描述如下：输入层：首先，给定一个软件样本s，获得s的完整API序列。然后，由于每个软件样本的API调用数量不一致，而模型要求输入样本具有相同的形状，因此通过在过短的API序列后面拼接空API、以及对过长的API序列进行末尾删除的方式，得到固定长度的API序列。其中，N为固定的API序列长度，ak为第k个API调用。嵌入层：首先，采用词嵌入技术对大量API序列进行学习，得到每个API的低维稠密表征向量。然后，将软件样本API序列转换为一个表征向量序列。其中，ak的表征向量为ek。循环层：将嵌入层的输出输入一个LSTM，每个API表征向量ek输入一个LSTM单元，则每个LSTM单元根据公式输出一个隐状态向量hk，最后得到一个隐状态向量序列。输出分类层：取hN作为s的最终表征向量，并在hN上叠加一个全连接层和一个sigmoid层，得到最终是否为恶意软件的概率。步骤中，基于扰动的生成模型构建的详细步骤如下： 生成模型网络结构定义：采用seq2seq框架定义生成模型，输入为一段API序列，输出为添加了扰动的新的API序列。该生成模型的网络结构如图3所示，具体描述如下：输入层：模型的输入为一个API序列as = 。这里的API序列的长度可以不固定。编码层：首先，采用一个嵌入层将as转换为API表征向量序列es= 。然后，采用一个LSTM处理es，输出为一个隐状态向量序列hs = ；最后，采用注意力机制对hs进行加权平均，得到编码层的输出，记为C。解码层：采用一个LSTM处理C，每个LSTM单元根据公式和输出一个隐状态向量gk和一个结果状态向量yk。结果状态向量除了对应每个API的表征向量之外，还包括一个结束状态向量，只要出现了结束状态向量，则立刻结束当前的生成过程，W、V、b、c为模型内参数。输出层：根据API表征向量查询表将解码层的输出转换为对应的API序列。 基于扰动的API序列生成：对恶意软件的API序列进行扰动需要满足一个前提条件，就是该恶意软件的恶意功能不能失效。因此，添加扰动的主要思路为：不删除恶意软件原有的API，也不改变恶意软件原有API的相对位置，而是在恶意软件原有API序列中的每个API之后插入不定长度的其它API。给定一个恶意软件的API序列s = ，基于扰动的API序列生成的具体步骤如下： 将s在每个位置上进行分割，得到N个子序列SS = {, ,, …, , }； 对SS中的每个子序列ssk，将ssk输入训练好的生成模型，得到生成子序列gsk = ； 将每个生成的子序列gsk拼接在输入子序列ssk在原始API序列s对应的位置之后，得到最终的生成API序列g = 。步骤中，对抗训练的详细步骤如下： 采样：采样一个正常样本的mini-batch，采样一个恶意样本的mini-batch。 生成对抗样本：将M中的每个样本ms输入步骤训练好的生成器，得到一个生成样本gs，所有生成样本构成生成样本集M΄。 标注：将B和M΄作为训练集S，并输入被攻击的黑盒模型，得到S的训练标签。 训练代理模型：利用训练标签、根据公式所示的损失函数更新代理模型的参数。其中，v为样本s的训练标签，Dθ为代理模型将s识别为恶意软件的概率。 训练生成模型：利用训练标签、根据公式所示的损失函数更新生成模型的参数。 迭代：返回步骤，反复迭代，直到算法收敛，或达到指定训练轮数。步骤中，模型的防御性训练的详细步骤如下： 样本增强：收集由生成模型生成的能够绕过检测模型的样本，加入训练样本集。 检测模型再训练：采用增强后的训练样本集对检测模型进行再次训练，增强其对对抗攻击的鲁棒性。
