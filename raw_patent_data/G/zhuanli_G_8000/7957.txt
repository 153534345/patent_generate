标题title
一种实时GPU服务中的批处理规模方法
摘要abst
本发明属于批处理领域，公开了一种实时GPU服务中的批处理规模方法。步骤1：客户端发送待处理的图像数据到消息队列；步骤2：服务端从队列中接收图像数据，合成批处理图像数据；步骤3：服务端GPU对数据进行处理；步骤4：服务端根据对应的线程id返回处理结果到客户端。本发明用于解决实时GPU服务中由于批处理规模选择不当，导致的服务端处理时间过长和客户端访问延迟的问题。
权利要求书clms
1.一种实时GPU服务中的批处理规模方法，其特征在于，所述选择方法包括以下步骤：步骤1：客户端发送待处理的图像数据到消息队列；步骤2：服务端从队列中接收图像数据，合成批处理图像数据；步骤3：服务端GPU对数据进行处理；步骤4：服务端根据对应的线程id返回处理结果到客户端。2.根据权利要求1所述一种实时GPU服务中的批处理规模方法，其特征在于，所述步骤1中的处理的图像数据可替换为语音数据和/或文本数据；所述步骤1中每个客户端均通过一个单独的线程进行图像数据、语音数据和/或文本数据的发送。3.根据权利要求1所述一种实时GPU服务中的批处理规模方法，其特征在于，所述步骤2中合成批处理图像数据的批处理规模选择为2，即一次处理2幅图像；批处理规模为2的选取依据为：客户端中每条数据的产生视为随机并独立分布的事件，则一段时间内待处理的数据量服从泊松分布。4.根据权利要求3所述一种实时GPU服务中的批处理规模方法，其特征在于，在理想情况下，即服务端GPU数量足够多，且GPU的批处理规模无穷大的条件下，τ时间段内处理数据所需时间的数学期望是：其中，ζ表示数据从CPU传送到GPU所需时间，ξ表示GPU处理单条数据所需时间，λ表示单位时间内随机事件的平均发生概率。5.根据权利要求3所述一种实时GPU服务中的批处理规模方法，其特征在于，在GPU批处理规模有限，定义规模为M，同时GPU数量足够多的条件下，τ时间段内处理数据所需时间的数学期望是：其中，k表示总数据量对批处理规模的整除结果，m表示总数据量对批处理规模的取余结果。6.根据权利要求3所述一种实时GPU服务中的批处理规模方法，其特征在于，在GPU批处理规模有限，且GPU数量有限的实际条件下，τ时间段内处理数据所需时间的数学期望是：为了使等待时间最短，应达到最小，经计算可得当M＝2时，此项达到最小。7.根据权利要求1或2所述一种实时GPU服务中的批处理规模方法，其特征在于，对于语音数据进行语音转文字或/和语音翻译处理；对文本数据进行文本段落关键字提取或/和文本翻译处理；对图像数据进行OCR识别、图像分类或/和目标检测处理。8.根据权利要求2所述一种实时GPU服务中的批处理规模方法，其特征在于，所述步骤4具体为，批处理图像数据结果的返回：根据线程id对不同客户端通过不同线程发送的图像数据进行返回；其中系统中设置一个单独的线程用于记录全部的线程id以及后续的处理结果分发。9.一种电子设备，其特征在于，包括处理器、通信接口、存储器和通信总线，其中，处理器，通信接口，存储器通过通信总线完成相互间的通信；存储器，用于存放计算机程序；处理器，用于执行存储器上所存放的程序时，实现权利要求1-8任一所述的方法步骤。10.一种计算机可读存储介质，其特征在于，所述计算机可读存储介质内存储有计算机程序，所述计算机程序被处理器执行时实现权利要求1-8任一所述的方法步骤。
说明书desc
技术领域本发明属于批处理领域，具体涉及一种实时GPU服务中的批处理规模方法。背景技术随着深度学习技术的发展，越来越多的行业应用深度学习技术以实现智能化的信息处理。对于需要实时服务的任务，需要考虑通过GPU来提高处理高并发的服务。一种简单的方式是直接将待处理的数据发送给GPU，每次访问单独进行GPU处理，但会导致重复的GPU资源消耗。因此，需将并发访问合并为批处理的批次，然后GPU一次处理整个批次，从而降低数据传输成本。因此，批处理规模的选择是影响每次并发访问处理时间的关键因素，如果规模过大，前面的访问会等待足够的访问到达形成一个批次，再由GPU进行处理。批处理规模越大，GPU处理的时间也越长，并且需要更多的内存开销，因此访问将等待更长的时间。批处理规模是神经网络模型训练过程中的一项重要参数，选择合适的规模有利于模型的收敛。如果规模选择太小，每一个批次训练出来的梯度校正方向会不准确，从而导致训练出现明显的波动；另一方面，如果规模选择较大，会使一些数据的误分类梯度信息不能有效地反向传播。在模型训练完成后，模型的参数被固定，成为一个只进行前向传播的神经网络，用于根据给定的输入前向推理计算输出，然后进行预测。为了提供实时在线服务，简单的直接将访问数据作为网络输入进行处理是可行的，但是每次前向操作都需要GPU复制和分配内存，将多个访问合并为一个批次再进行处理，能够有效减少处理时间和访问延迟。发明内容本发明提供一种实时GPU服务中的批处理规模方法，用于解决实时GPU服务中由于批处理规模选择不当，导致的服务端处理时间过长和客户端访问延迟的问题。本发明通过以下技术方案实现：一种实时GPU服务中的批处理规模方法，所述选择方法包括以下步骤：步骤1：客户端发送待处理的图像数据到消息队列；步骤2：服务端从队列中接收图像数据，合成批处理图像数据；步骤3：服务端GPU对图像数据进行处理；步骤4：服务端根据对应的线程id返回处理结果到客户端。一种实时GPU服务中的批处理规模方法，所述步骤1中的处理的图像数据可替换为语音和/或文本；所述步骤1中每个客户端均通过一个单独的线程进行图像数据、语音数据和/或文本数据的发送。一种实时GPU服务中的批处理规模方法，所述步骤2中合成批处理图像数据的批处理规模选择为2，即一次处理2幅图像；批处理规模为2的选取依据为：客户端中每条数据的产生视为随机并独立分布的事件，则一段时间内待处理的数据量服从泊松分布。一种实时GPU服务中的批处理规模方法，在理想情况下，即服务端GPU数量足够多，且GPU的批处理规模无穷大的条件下，τ时间段内处理数据所需时间的数学期望是：其中，ζ表示数据从CPU传送到GPU所需时间，ξ表示GPU处理单条数据所需时间，λ表示单位时间内随机事件的平均发生概率。一种实时GPU服务中的批处理规模方法，在GPU批处理规模有限，定义规模为M，同时GPU数量足够多的条件下，τ时间段内处理数据所需时间的数学期望是：其中，k表示总数据量对批处理规模的整除结果，m表示总数据量对批处理规模的取余结果。一种实时GPU服务中的批处理规模方法，在GPU批处理规模有限，且GPU数量有限的实际条件下，τ时间段内处理数据所需时间的数学期望是：为了使等待时间最短，应达到最小，经计算可得当M＝2时，此项达到最小。一种实时GPU服务中的批处理规模方法，对于语音数据进行语音转文字或/和语音翻译处理；对文本数据进行文本段落关键字提取或/和文本翻译处理；对图像数据进行OCR识别、图像分类或/和目标检测处理。一种实时GPU服务中的批处理规模方法，所述步骤4具体为，批处理图像数据结果的返回：根据线程id对不同客户端通过不同线程发送的图像数据进行返回；其中系统中设置一个单独的线程用于记录全部的线程id以及后续的处理结果分发。一种电子设备，包括处理器、通信接口、存储器和通信总线，其中，处理器，通信接口，存储器通过通信总线完成相互间的通信；存储器，用于存放计算机程序；处理器，用于执行存储器上所存放的程序时，实现上述所述的方法步骤。一种计算机可读存储介质，所述计算机可读存储介质内存储有计算机程序，所述计算机程序被处理器执行时实现上述所述的方法步骤。本发明的有益效果是：本发明的设置合理的批处理规模，能够在资源有限的前提下，最大化的减少客户端等待结果返回的时间。本发明规模选择的适用范围较广，适用于语音、文本、图像等多种通过GPU提供实时处理的数据场景。附图说明图1是本发明的方法流程图。具体实施方式下面将结合本发明实施例中的附图对本发明实施例中的技术方案进行清楚、完整地描述，显然，所描述的实施例仅仅是本发明一部分实施例，而不是全部的实施例。基于本发明中的实施例，本领域普通技术人员在没有做出创造性劳动前提下所获得的所有其他实施例，都属于本发明保护的范围。一种实时GPU服务中的批处理规模方法，所述选择方法包括以下步骤：步骤1：客户端发送待处理的图像数据到消息队列；消息队列协议：包括生产者、队列、消费者，生产者首先发送消息到队列中，再由消费者从队列中接收消息并进行处理；消息队列协议中的生产者、消息、消费者，分别对应专利所述方法中的客户端、待处理数据、服务端；步骤2：服务端从队列中接收图像数据，合成批处理图像数据；步骤3：服务端GPU对数据进行处理；步骤4：服务端根据对应的线程id返回处理结果到客户端。一种实时GPU服务中的批处理规模方法，所述步骤1中的处理的图像数据可替换为语音数据和/或文本数据；所述步骤1中每个客户端均通过一个单独的线程进行图像数据、语音数据和/或文本数据的发送。一种实时GPU服务中的批处理规模方法，所述步骤2中合成批处理数据的批处理规模选择为2，即一次处理2幅图像；批处理规模为2的选取依据为：客户端中每条数据的产生可以视为随机并独立分布的事件，则一段时间内待处理的数据量服从泊松分布。一种实时GPU服务中的批处理规模方法，在理想情况下，即服务端GPU数量足够多，且GPU的批处理规模无穷大的条件下，τ时间段内处理数据所需时间的数学期望是：其中，ζ表示数据从CPU传送到GPU所需时间，ξ表示GPU处理单条数据所需时间，λ表示单位时间内随机事件的平均发生概率。一种实时GPU服务中的批处理规模方法，在GPU批处理规模有限，定义规模为M，同时GPU数量足够多的条件下，τ时间段内处理数据所需时间的数学期望是：其中，k表示总数据量对批处理规模的整除结果，m表示总数据量对批处理规模的取余结果。一种实时GPU服务中的批处理规模方法，在GPU批处理规模有限，且GPU数量有限的实际条件下，τ时间段内处理数据所需时间的数学期望是：为了使等待时间最短，应达到最小，经计算可得当M＝2时，此项达到最小。一种实时GPU服务中的批处理规模方法，对于语音数据进行语音转文字或/和语音翻译处理；对文本数据进行文本段落关键字提取或/和文本翻译处理；对图像数据进行OCR识别、图像分类或/和目标检测处理。一种实时GPU服务中的批处理规模方法，所述步骤4具体为，批处理图像数据结果的返回：根据线程id对不同客户端通过不同线程发送的图像数据进行返回；其中系统中设置一个单独的线程用于记录全部的线程id以及后续的处理结果分发。一种电子设备，包括处理器、通信接口、存储器和通信总线，其中，处理器，通信接口，存储器通过通信总线完成相互间的通信；存储器，用于存放计算机程序；处理器，用于执行存储器上所存放的程序时，实现上述所述的方法步骤。一种计算机可读存储介质，所述计算机可读存储介质内存储有计算机程序，所述计算机程序被处理器执行时实现上述所述的方法步骤。以身份证照片识别为例，客户端将身份证图像发送给服务端，服务端进行识别，再返回识别结果给客户端。首先多个不同的用户通过手机采集身份证图像；之后发送到服务端，服务端将每2幅图像合成一个批次图像数据，同时记录发送图像对应的设备id；最后由GPU对批次图像数据进行识别。识别的过程是首先通过预先训练完成的身份证目标检测模型定位身份证在图像中的位置，得到位置信息后从原始图像中截取身份证区域；然后通过霍夫变换检测身份证边缘后进行倾斜矫正，得到摆正的身份证区域图像；最后通过OCR工具识别图像中的文字，按照设定规则对识别结果进行拆分，以字典的数据结构存储识别结果，形如{“姓名”：“张三”，“性别”：“男”，“民族”：“汉”，...}。识别后根据对应的id将识别结果发送给对应的客户端，再进行下一个批次图像数据的识别。
