标题title
一种基于特征增强的复杂场景下小目标检测方法
摘要abst
本发明属于计算机视觉和目标检测领域，具体涉及一种基于特征增强的复杂场景下小目标检测方法。本发明的技术方案是：首先提出Cutout‑DA数据增强方法，生成新的遮挡数据扩充至VisDrone2021数据集中，然后设计多尺度融合的特征增强路径聚合网络MSFE‑PANet，通过集成注意机制、特征融合以及针对小目标的网络预测尺度策略，获取到更丰富、细致的语义信息特征和空间信息特征，设计预测框排斥损失函数RB_Loss，最后训练模型。本发明可以增强深层特征图的强定位信息与浅层特征图的强语义信息相互融合，帮助网络在复杂场景中找到感兴趣区域，提高对小目标的敏感度。并设计RB_Loss排斥损失函数、网络预测尺度解决复杂背景下重叠、遮挡小目标的漏检、误检的问题。
权利要求书clms
1.一种基于特征增强的复杂场景下小目标检测方法,包括以下步骤步骤1、数据准备：数据集来源于航拍图像；步骤2、数据增强：提出Cutout-DA数据增强方法，该方法首先在数据集中任意选取部分数据图像，然后通过对这些图像中的可见部分目标和全部目标，随机地按照目标大小比例的0.2、0.4、0.6、0.8进行部分位置的遮挡，生成新的遮挡数据扩充至VisDrone2021数据集中；步骤3、设计多尺度融合的特征增强路径聚合网络MSFE-PANet；步骤3.1：改进网络预测尺度在YOLOv4中移除针对检测大目标预测头YOLO head3，但保留其所对应的13*13的特征图；同时，在预测网络中增加了由浅层高分辨率的特征图104*104生成的针对检测小尺度目标的预测头YOLO head0,生成新的网络预测尺度结构；步骤3.2：特征层融合在新的网络预测尺度结构上将每一层特征网络提取的特征图进行相应倍数上采样分别与第一层特征图相加融合得到新的特征图；步骤3.3：引入注意力模块；步骤4：设计预测框排斥损失函数RB_Loss；步骤5：训练模型。2.根据权利要求1所述的一种基于特征增强的复杂场景下小目标检测方法,其特征在于：所述步骤3.3具体包括步骤3.3.1：添加CBAM注意力模块，如公式所示；通道注意力的计算公式为：其中σ为Sigmoid激活函数，MLP权重W0和W1是共享的空间注意力的计算公式为：其中σ为Sigmoid激活函数，f7*7表示7*7的滤波器；步骤3.3.2：改进CBAM的通道注意力模块；步骤3.3.3：引入SE-attention注意力模块；步骤3.3.4：改进SPP模块；步骤3.3.5：优化SE-attention注意力模块。3.根据权利要求2所述的一种基于特征增强的复杂场景下小目标检测方法,其特征在于：所述步骤3.3.2，计算公式定义为4.根据权利要求3所述的一种基于特征增强的复杂场景下小目标检测方法,其特征在于：所述步骤3.3.3，给定一个输入X,通道数为C1,经过Ftr的一系列卷积、池化操作得到通道数为C2的特征U；Fsq为特征压缩操作，顺着空间维度进行特征压缩，并将每个二维的特征通道变成一个像素；接着进行Fex激励操作，然后通过乘法加权到之前的特征上计算公式：其中：UC表示特征图中的第C个通道；ZC为压缩操作的输出，计算公式:σ为Sigmoid激活函数；W1,W2均为全连接操作；δ为ReLU激活函数，计算公式:SC为步长S中的第C个权重；S＝Fex＝σ)＝σ)Fscale＝＝SC·UC。5.根据权利要求4所述的一种基于特征增强的复杂场景下小目标检测方法,其特征在于：所述步骤3.3.4具体为将SPP中的1*1，5*5，9*9和13*13尺寸内核的池化层改为1*1卷积和3*3空洞卷积，改进的SPP模块不会改变特征图的尺寸，输出特征图尺寸计算公式为6.根据权利要求5所述的一种基于特征增强的复杂场景下小目标检测方法,其特征在于：所述步骤3.3.5具体为在SE-attention中加入改进的SPP模块，得到SSE-attention注意力模块。7.根据权利要求2-6任意一个权利要求所述的一种基于特征增强的复杂场景下小目标检测方法,其特征在于：所述步骤4具体为把两个重叠目标的先验预测框之间的重叠度IOU作为损失的值，反向传播网络会按照梯度方向进行优化，将两个目标的重叠先验预测框分离，定义为公式中和表示不同目标框匹配的先验预测框
说明书desc
技术领域本发明属于计算机视觉和目标检测领域，具体涉及一种基于特征增强的复杂场景下小目标检测方法。背景技术近年来，深度学习技术的快速发展，促使计算机视觉取得了显著的突破，将其推向了前所未有的研究热点。计算机视觉的主要任务是对图像进行解析，包括对图像的分类、检测和分割。目标检测作为计算机视觉领域的核心研究方向之一，利用相关算法，通过精确的定位找到特定的目标类。小目标检测作为目标检测的难点，有着同样重要的应用价值，在自动驾驶、智慧医疗、缺陷检测和航拍图像分析等诸多领域发挥着重要作用。在汽车的高分辨率场景照片中检测小的、遥远的物体是安全部署自动驾驶汽车的必要条件；同时在医学影像学中，如果能对大小只有几个像素的肿块和肿瘤早期发现对于准确、早期诊断至关重要；自动工业检测也可以受益于小目标检测，通过定位可以在材料表面上可见的小缺陷。综上所述，小目标检测具有广泛的应用价值和重要的研究意义。尽管目标检测算法已经取得了重大突破，但由于检测小目标和大目标之间的性能上存在显著的差距，所以对于小目标的研究仍然不够理想。现有方法下的小目标检测还不能很好的满足在实际复杂场景应用，主要有以下几个问题。一、可视化特征不明显问题：小目标检测的难点在于目标特征不明显，可利用信息较少，若图像本身的分辨率比较低，则小目标可能只能用几个像素来表示，在可视化特征不明显的情况下，精准地检测小目标是现在面临的一大挑战；二、特征提取问题：在目标检测中，特征提取的好坏直接影响最终检测的性能，与大尺度目标相比，小目标的特征更难提取。大多数计算机视觉架构都会使用池化层，池化后小目标的某些特性也会被删除。在深度神经网络中提取有效的小目标特征也是当前面临的问题；三、背景干扰问题。复杂环境下的小目标检测会受到光照、复杂地理元素、遮挡、聚集等因素的干扰，因此难以将它们与背景或相似的目标区分开来，有效地改善复杂背景干扰也是当前面临的挑战。发明内容本发明针对现有技术不能精确检测小目标、特征难以提取和检测不能很好的满足实际复杂场景的问题，本发明提供一种基于特征增强的复杂场景下小目标检测方法。为实现上述目的，本发明的技术方案如下：一种基于特征增强的复杂场景下小目标检测方法,包括以下步骤步骤1、数据准备：数据集来源于航拍图像；步骤2、数据增强：提出Cutout-DA数据增强方法，该方法首先在数据集中任意选取部分数据图像，然后通过对这些图像中的可见部分目标和全部目标，随机地按照目标大小比例的0.2、0.4、0.6、0.8进行部分位置的遮挡，生成新的遮挡数据扩充至Vi sDrone2021数据集中；步骤3、设计多尺度融合的特征增强路径聚合网络MSFE-PANet；步骤3.1：改进网络预测尺度在YOLOv4中移除针对检测大目标预测头YOLO head3，但保留其所对应的13*13的特征图；同时，在预测网络中增加了由浅层高分辨率的特征图104*104生成的针对检测小尺度目标的预测头YOLO head0,生成新的网络预测尺度结构。步骤3.2：特征层融合在新的网络预测尺度结构上将每一层特征网络提取的特征图进行相应倍数上采样分别与第一层特征图相加融合得到新的特征图；步骤3.3：引入注意力模块；步骤4：设计预测框排斥损失函数RB_Loss。步骤5：训练模型。上述步骤3.3：在PANet中集成注意力机制步骤3.3.1：添加CBAM注意力模块，如公式所示。通道注意力的计算公式为：其中σ为Sigmoid激活函数，MLP权重W0和W1是共享的空间注意力的计算公式为：其中σ为Sigmoid激活函数，f7*7表示7*7的滤波器。步骤3.3.2：改进CBAM的通道注意力模块；步骤3.3.3：引入SE-attention注意力模块；步骤3.3.4：改进SPP模块；步骤3.3.5：优化SE-attention注意力模块。上述步骤3.3.2，计算公式定义为：上述步骤3.3.3，给定一个输入X,通道数为C1,经过Ftr的一系列卷积、池化操作得到通道数为C2的特征U；Fsq为特征压缩操作，顺着空间维度进行特征压缩，并将每个二维的特征通道变成一个像素；接着是Fex激励操作，然后通过乘法加权到之前的特征上计算公式：中：UC表示特征图中的第C个通道；ZC为压缩操作的输出。计算公式:σ为Sigmoid激活函数；W1,W2均为全连接操作；δ为ReLU激活函数。计算公式:SC为步长S中的第C个权重。S＝Fex＝σ)＝σ) Fscale＝＝SC·UC 上述步骤3.3.4，具体为：将SPP中的1*1，5*5，9*9和13*13尺寸内核的池化层改为1*1卷积和3*3空洞卷积，改进的SPP模块不会改变特征图的尺寸，输出特征图尺寸计算公式为：上述步骤3.3.5，具体为：在SE-attention中加入改进的SPP模块，得到SSE-attention注意力模块。上述步骤4，具体为：把两个重叠目标的先验预测框之间的重叠度IOU作为损失的值，反向传播网络会按照梯度方向进行优化，将两个目标的重叠先验预测框分离，定义为公式中和表示不同目标框匹配的先验预测框与现有技术相比，本发明的有益效果：1、本发明设计了RB_Loss排斥损失函数和Cutout-DA数据增强策略来改进网络训练方案，相较于基准网络YOLOv4的Mosaic和CutMix数据增强方法，采用本发明所设计的Cutout-DA数据增强策略，在数据集VisDrone2021上的mAP提升了3.57个精度。这结果充分表明了检测算法针对小目标采用Cutout-DA策略的有效性；在YOLOv4预测网络中，由于输出的先验预测框需要通过NMS的判断处理，相互遮挡、重叠目标会影响目标框匹配，导致大量漏检和误检的情况。本发明提出的RB_Loss损失通过IOU进一步减少遮挡目标检测互相影响，mAP提升了2.8个精度。2、本发明提出了一种多尺度融合的特征增强路径聚合网络MSFE-PANet，在通过针对小目标的网络预测尺度策略和多尺度特征融合可以得到更丰富、细致的语义信息特征和空间信息特征，mAP在Cutout-DA和RB_Loss两个策略上提高了9.47个精度，大幅度提升小目标检测的准确性；再添加LW-CBAM和SSE-Attention注意力机制，进一步提取注意力区域，帮助网络更专注于有用的小目标对象，mAP提升了6.63个精度，解决了复杂背景下重叠、遮挡小目标的漏检、误检问题。3、本发明可以精确检测小目标，特征提取容易，可以满足各种实际复杂场景。应用范围广，适应性强。附图说明图1为本发明中多尺度融合的特征增强路径聚合网络MSFE-PANet结构；图2为本发明中MSFE-PANet细节结构图；图3为本发明中预测尺度改进结构；图4为本发明中CBAM的通道注意力结构；图5为本发明中CBAM的空间注意力结构；图6为本发明中不同模块结果图像对比；图7为本发明中注意力模块的不同种嵌入方式；图8为本发明实施例中MSFE-PANet的细节结果图像；图9为本发明实施例中MSFE-PANet的可视化结果图像；具体实施方式下面结合附图对本发明作进一步描述。以下实施例仅用于更加清楚地说明本发明的技术方案，而不能以此来限制本发明的保护范围。本发明了一种多尺度融合的特征增强路径聚合网络MSFE-PANet，可以增强深层特征图的强定位信息与浅层特征图的强语义信息相互融合，帮助网络在复杂场景中找到感兴趣区域，提高对小目标的敏感度。并设计RB_Loss排斥损失函数、网络预测尺度解决复杂背景下重叠、遮挡小目标的漏检、误检问题。参见图1，本发明提供的一种基于特征增强的复杂场景下小目标检测方法，包括以下步骤：步骤1：数据准备。具体为：采用大型航拍数据集VisDrone2021，该数据集的图像尺寸约为2000*1500，其中包含从乡村到城市多种场景，以及包含各种气候变化，明暗变化和拍摄角度变换等,同时包括行人、汽车、自行车和三轮车等10个类别，数据集中6471张图像用于训练，548张图像用作验证，1610张图像用于测试。步骤2：数据增强。具体为：提出Cutout-DA数据增强方法，该方法首先在数据集中任意选取部分数据图像，然后通过对这些图像中的可见部分目标和全部目标，随机地按照目标大小比例的0.2、0.4、0.6、0.8进行部分位置的遮挡，生成新的遮挡数据扩充至数据集中，增强模型对遮挡目标的鲁棒性，有利于提升对遮挡目标判断的准确性。步骤3：：算法设计。具体为：设计多尺度融合的特征增强路径聚合网络FEMF-PANet。步骤3.1：改进网络预测尺度，参照图3。在YOLOv4中移除针对检测大目标预测头YOLO head3，但保留其所对应的13*13的特征图；同时，在预测网络中增加了由浅层高分辨率的特征图104*104生成的针对检测小尺度目标的预测头YOLO head0，得到新的网络预测尺度结构。步骤3.2：参照图3，特征层融合，具体为：在新的网络预测尺度结构上将每一层特征网络提取的特征图进行相应倍数上采样分别与第一层特征图相加融合得到新的特征图，使特征预测网络更加细致，改善对小目标的检测精度；步骤3.3：引入注意力模块。具体为：在PANet中集成注意力机制。步骤3.3.1：添加CBAM注意力模块。CBAM可以集成到大部分的CNN网络框架中，实现端到端的训练方式。给定一个中间特征图作为输入，CBAM沿着通道和空间的两个独立维度依次推断出注意图，如公式所示。参照图4，引入改进CBAM注意力模块，其中通道注意力的计算公式为：σ为Sigmoid激活函数，MLP权重W0和W1是共享的参照图5，在空间注意模块，利用特征的空间间关系来生成一个空间注意图。空间注意力的计算公式为：σ为Sigmoid激活函数，f7*7表示7*7的滤波器。步骤3.3.2：改进CBAM的通道注意力模块。本发明使用1*1的卷积代替通道注意力模块中的全连接层，得到更轻量级的卷积注意力模块LW-CBAM。其计算公式可定义为：步骤3.3.3：引入SE-attention注意力模块。具体为：首先给定一个输入X,通道数为C1,经过Ftr的一系列卷积、池化操作得到通道数为C2的特征U；Fsq为特征压缩操作，顺着空间维度进行特征压缩，并将每个二维的特征通道变成一个像素，该像素具有全局的感受野，并且输出的维度和输入的特征通道数相匹配；接着是Fex激励操作，基于特征通道间相关性，每个特征通道生成一个权重，来代表每个特征通道的重要程度，然后通过乘法加权到之前的特征上，完成重要特征的标定。计算公式：UC表示特征图中的第C个通道；ZC为压缩操作的输出。计算公式:σ为Sigmoid激活函数；W1,W2均为全连接操作；δ为ReLU激活函数。计算公式:SC为步长S中的第C个权重。S＝Fex＝σ)＝σ) Fscale＝＝SC·UC 步骤3.3.4：参照图2，改进SPP模块。具体为：将SPP中的1*1，5*5，9*9和13*13尺寸内核的池化层改为1*1卷积和3*3空洞卷积，但改进的SPP模块仍不会改变特征图的尺寸。输出特征图尺寸计算公式为：步骤3.3.5：参照图2，集成优化的SE-attention注意力模块，在SE-attention中加入改进的SPP模块，以增强输入至SE-attention中的特征图特征信息的表达能力，从而达到更好的分类效果。参照图7，本发明根据新的网络预测尺度结构，在网络的颈部和检测头两个不同区域分别嵌入LW-CBAM和SSE-Attention注意力机制模块，对重要通道和空间特征进行增强。采用四种嵌入方式进行实验验证，得到最优MSFE-PANet网络模型，提高小目标检测的性能。参照图8，本发明方法在嵌入最优注意力模块后，在复杂背景下对重叠小目标、聚集小目标、遮挡小目标检测的细节效果。步骤4：在模型训练方案中，设计预测框排斥损失函数RB_Loss具体为：把两个重叠目标的先验预测框之间的重叠度IOU作为损失的值。重叠度越大，损失函数的值就越大，在训练阶段中，反向传播网络会按照梯度方向进行优化，将两个目标的重叠先验预测框分离。将该排斥损失函数与YOLOv4模型结合起来，使其符合复杂应用场景下的小目标检测，有效解决图像中目标相互遮挡、重叠的问题。定义为公式中和表示不同目标框匹配的先验预测框。使其符合复杂应用场景下的小目标检测，有效解决图像中目标相互遮挡、重叠的问题；步骤5：训练模型，在VisDrone2021数据集上以200epochs对网络进行了训练，实验设置输入图片大小尺寸为416*416，前100epoch将Batch_Size设置为4，后100epoch将Batch_Size设置为8。参照图6，本发明方法在VisDrone2021数据集进行验证，并与基准网络YOLOv4的检测性能比较。通过逐步添加Cutout-DA数据增强方法、注意力模块和RB_Loss损失等相应模块，验证本发明方法针对复杂场景中小目标检测的有效性。参照图9，本发明方法与其他方法比较结果，对于小目标所存在的漏检、误检的情况，本发明可以将其准确检测出来，并能适应复杂场景中的小目标检测任务。
