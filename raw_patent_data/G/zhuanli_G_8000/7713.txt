标题title
面向芯粒的神经网络推理开销估计方法及装置、电子设备
摘要abst
本发明公开了面向芯粒的神经网络推理开销估计方法及装置、电子设备，其中面向芯粒的神经网络推理开销估计方法包括神经网络参数和芯粒拓扑结构获取、并行组内开销估计、并行组间网络传输开销估计及神经网络推理开销估计四个步骤。使得推理开销估计适用于神经网络在芯粒上并行调度的实际场景，神经网络推理开销估计能够适用于芯粒这样的拓扑结构，充分考虑芯粒上小芯片单元内外的带宽、小芯片单元内路由转发延迟和小芯片单元外路由转发延迟，使得神经网络在芯粒上的推理开销估计达到较高的精度，从而为神经网络在芯粒上加速推理所需的高性能调度策略奠定良好基础。
权利要求书clms
1.面向芯粒的神经网络推理开销估计方法，其特征在于，包括：神经网络参数和芯粒拓扑结构获取：获取神经网络计算图、其中的算子及其划分后的并行组，获取芯粒拓扑结构及其划分后的子芯粒拓扑结构，获取神经网络计算图中每个算子的划分策略和映射策略；并行组内开销估计：计算单算子v的计算开销dv和算子v内网络传输开销cv，根据所述dv和cv得到并行组pi内每个算子v的开销，从所述并行组pi内选择最大的单个算子的开销，作为该并行组pi的并行组内开销Ti，其中i≥0；并行组间网络传输开销估计：计算并行组pi及其相邻后序并行组pj间所有具有数据依赖的算子对之间的网络传输开销，加总得到并行组pi的并行组间网络传输开销cpi，其中v属于并行组pi的算子集合Vi，u属于并行组pj的算子集合Vj；神经网络推理开销估计：获取并行组数量P，加总所有P个并行组内开销和P-1个并行组间网络传输开销，得到整个神经网络计算图的推理开销T*。2.根据权利要求1所述的方法，其特征在于，获取神经网络计算图、其中的算子及其划分后的并行组，包括：获取神经网络推理过程的有向无环计算图G，G由结点集合V和有向边集合E组成，G中每个结点v代表一个算子，每条有向边e代表结点间的数据依赖关系；获取划分后的并行组集合P，P由划分计算图G后的若干并行组pi组成，并行组pi内的所有算子完全并行执行，算子集合记为Vi，Vi包含于结点集合V，所有并行组的算子集合之间无交集且其并集为计算图G的结点集合V。3.根据权利要求1所述的方法，其特征在于，获取芯粒拓扑结构及其划分后的子芯粒拓扑结构，包括：获取芯粒中小芯片单元阵列尺寸M1*N1、小芯片单元内的嵌入式神经网络处理器阵列尺寸M2*N2、芯粒的坐标表示；获取子芯粒拓扑结构集合S，集合S由若干子芯粒拓扑结构submeshi组成，其中每种子芯粒拓扑结构submeshi由表示,m1*n1为子芯粒的小芯片单元阵列尺寸，m2*n2为子芯粒小芯片单元阵列中坐标最大的小芯片单元内的嵌入式神经网络处理器阵列尺寸，若m1*n1＞1，则其余小芯片单元内的嵌入式神经网络处理器阵列尺寸均为M2*N2。4.根据权利要求1所述的方法，其特征在于，获取神经网络计算图中每个算子的划分策略和映射策略，包括：获取每个算子v的划分策略的独热编码sv以及算子v所分配到的子芯粒拓扑结构submeshv；获取每个算子v的映射策略mv，mv由表示，submeshv算子v所分配到的子芯粒拓扑结构，mbeg为算子v在芯粒上分配到的芯粒起始坐标,mend为算子v在芯粒上分配到的芯粒上限坐标，和分别为小芯片单元阵列中小芯片单元的坐标，和分别为相应小芯片单元内嵌入式神经网络处理器阵列中嵌入式神经网络处理器的坐标。5.根据权利要求1所述的方法，其特征在于，计算单算子v的计算开销dv，包括：输入算子v分配到每个嵌入式神经网络处理器上的计算量m*k*n、嵌入式神经网络处理器上脉冲阵列的大小w*w，其中m*k*n为当前处理的张量的尺寸；若m＞w或n＞w，则通过加总分配到每个嵌入式神经网络处理器上的计算量m*k*n与脉冲阵列尺寸w*w的比例和2倍的一维脉冲拍数w-1，得到单算子v的计算开销dv；若m＜w且n＜w，则通过加总每一维的计算量再减去1，得到单算子v的计算开销dv。6.根据权利要求1所述的方法，其特征在于，计算算子v内网络传输开销cv，包括：输入算子v的划分策略的独热编码sv、算子内通信延迟矩阵Rv、小芯片单元内带宽b1、小芯片单元间带宽b2和映射策略mv；通过计算转置的算子v的划分策略的独热编码sv与算子内通信延迟矩阵Rv之积，得到算子v内的通信延迟；根据划分策略的独热编码sv和映射策略mv，分别计算小芯片单元内路由转发平均跳数h1与路由转发周期数r1之积、小芯片单元间路由转发平均跳数h2与路由转发周期数r2之积，加总得到算子v内的路由转发延迟；加总算子v内的通信延迟和算子v内的路由转发延迟，得到算子v内的网络传输开销cv。7.根据权利要求1所述的方法，其特征在于，计算具有数据依赖的算子对之间的网络传输开销，包括：输入并行组pi和其相邻后序并行组pj具有数据依赖的算子对及其划分策略的独热编码sv和su、算子间通信延迟矩阵R、映射策略mv和mu；通过计算转置的算子v的划分策略的独热编码sv、算子对间的通信延迟矩阵R及算子u的划分策略的独热编码su之积，得到算子对间通信延迟；根据划分策略的独热编码sv和su、映射策略mv和mu，分别计算小芯片单元内路由转发平均跳数h1与路由转发周期数r1之积、小芯片单元间路由转发平均跳数h2与路由转发周期数r2之积，加总得到算子对间路由转发延迟；加总算子对间通信延迟和算子对间路由转发延迟，得到算子对之间的网络传输开销。8.一种面向芯粒的神经网络推理开销估计装置，其特征在于，包括：神经网络参数和芯粒拓扑结构获取模块，用于获取神经网络计算图及其划分后的并行组，获取芯粒拓扑结构及其划分后的子芯粒拓扑结构，获取神经网络计算图中每个算子的划分策略和映射策略；并行组内开销估计模块，用于计算单算子v的计算开销dv和算子v内网络传输开销cv，根据所述dv和cv得到并行组pi内每个算子v的开销，从所述并行组pi内选择最大的单个算子的开销，作为该并行组pi的并行组内开销Ti，其中i≥0；并行组间网络传输开销估计模块，用于计算并行组pi及其相邻后序并行组pj间所有具有数据依赖的算子对之间的网络传输开销，加总得到并行组pi的并行组间网络传输开销cpi，其中v属于并行组pi的算子集合Vi，u属于并行组pj的算子集合Vj；神经网络推理开销估计模块，用于获取并行组数量P，加总所有P个并行组内开销和P-1个并行组间网络传输开销，得到整个神经网络计算图的推理开销T*。9.一种电子设备，其特征在于，包括：一个或多个处理器；存储器，用于存储一个或多个程序；当所述一个或多个程序被所述一个或多个处理器执行，使得所述一个或多个处理器实现如权利要求1-7任一项所述的面向芯粒的神经网络推理开销估计方法。10.一种计算机可读存储介质，其上存储有计算机指令，其特征在于，该指令被处理器执行时实现如权利要求1-7任一项所述的面向芯粒的神经网络推理开销估计方法的步骤。
说明书desc
技术领域本发明属于深度学习、性能评估、高性能计算交叉技术领域，尤其涉及面向芯粒的神经网络推理开销估计方法及装置、电子设备。背景技术对于分类、识别、预测等具有挑战性的问题，神经网络是目前最有效的解决方案之一，并应用于许多实际应用中。但是，面对日益复杂的问题以及更高精度的需求，大规模神经网络成为研究热点和发展趋势，其处理的数据量急剧增大，这给神经网络加速器的计算和存储性能带来了极大的挑战。近年来，随着芯粒技术的发展，神经网络加速器正在从芯片升级至芯粒。芯粒将小芯片单元集成封装为满足特定功能的模块芯片，相比于原来的普通芯片具有更高的灵活度和性能以及更低的成本，对神经网络加速器这种专用领域架构的发展十分有利。因此，对于芯粒这种集成度高的更复杂的结构，为了充分利用芯粒资源，以加速神经网络在芯粒上的推理，通常需要设计神经网络计算图的算子内并行划分策略、算子间并行划分策略和计算图到芯粒的映射策略，即神经网络推理调度策略，那么，在研究高性能调度策略的过程中，为了找到使得神经网络在芯粒上进行推理的开销最小的高性能调度策略，如何精确估计推理所需总开销则是至关重要的。推理总开销估计包括计算开销和通信开销的估计。对于计算开销的估算，在现有技术中，计算开销通常不影响调度策略的选择。现有技术通常采取用模拟器进行模拟的方法，分析神经网络推理的总运行时间；或者，在影响调度策略决策的总开销估算中忽略计算开销。对于通信开销的估算，现有技术通常采用2种方式。其一，考虑神经网络在运行过程中的数据传输量；其二，考虑神经网络在运行过程中的数据传输距离。但是，现有技术在估算通信开销时都不考虑带宽和路由转发延迟，这会使得通信开销的估算值与实际值之间具有较大误差。一方面，在芯粒结构中，片内和片外带宽差异较大，会对实际通信开销产生较大影响。另一方面，在实际的神经网络推理中由路由转发带来的拥塞延迟的影响是不容忽视的。因此，在推理开销建模不够精确的情况下进行调度策略搜索算法优化所能够带来的神经网络推理芯粒的性能提升将会面临瓶颈。发明内容针对现有技术的不足，本申请实施例的目的是提供面向芯粒的神经网络推理开销估计方法及装置、电子设备。根据本申请实施例的第一方面，提供面向芯粒的神经网络推理开销估计方法，包括：神经网络参数和芯粒拓扑结构获取：获取神经网络计算图、其中的算子及其划分后的并行组，获取芯粒拓扑结构及其划分后的子芯粒拓扑结构，获取神经网络计算图中每个算子的划分策略和映射策略；并行组内开销估计：计算单算子v的计算开销dv和算子v内网络传输开销cv，根据所述dv和cv得到并行组pi内每个算子v的开销，从所述并行组pi内选择最大的单个算子的开销，作为该并行组pi的并行组内开销Ti，其中i≥0；并行组间网络传输开销估计：计算并行组pi及其相邻后序并行组pj间所有具有数据依赖的算子对之间的网络传输开销，加总得到并行组pi的并行组间网络传输开销cpi，其中v属于并行组pi的算子集合Vi，u属于并行组pj的算子集合Vj；神经网络推理开销估计：获取并行组数量P，加总所有P个并行组内开销和P-1个并行组间网络传输开销，得到整个神经网络计算图的推理开销T*。进一步地，获取神经网络计算图、其中的算子及其划分后的并行组，包括：获取神经网络推理过程的有向无环计算图G，G由结点集合V和有向边集合E组成，G中每个结点v代表一个算子，每条有向边e代表结点间的数据依赖关系；获取划分后的并行组集合P，P由划分计算图G后的若干并行组pi组成，并行组pi内的所有算子完全并行执行，算子集合记为Vi，Vi包含于结点集合V，所有并行组的算子集合之间无交集且其并集为计算图G的结点集合V。进一步地，获取芯粒拓扑结构及其划分后的子芯粒拓扑结构，包括：获取芯粒中小芯片单元阵列尺寸M1*N1、小芯片单元内的嵌入式神经网络处理器阵列尺寸M2*N2、芯粒的坐标表示；获取子芯粒拓扑结构集合S，集合S由若干子芯粒拓扑结构submeshi组成，其中每种子芯粒拓扑结构submeshi由表示,m1*n1为子芯粒的小芯片单元阵列尺寸，m2*n2为子芯粒小芯片单元阵列中坐标最大的小芯片单元内的嵌入式神经网络处理器阵列尺寸，若m1*n1＞1，则其余小芯片单元内的嵌入式神经网络处理器阵列尺寸均为M2*N2。进一步地，获取神经网络计算图中每个算子的划分策略和映射策略，包括：获取每个算子v的划分策略的独热编码sv以及算子v所分配到的子芯粒拓扑结构submeshv；获取每个算子v的映射策略mv，mv由表示，submeshv算子v所分配到的子芯粒拓扑结构，mbeg为算子v在芯粒上分配到的芯粒起始坐标,mend为算子v在芯粒上分配到的芯粒上限坐标，和分别为小芯片单元阵列中小芯片单元的坐标，和分别为相应小芯片单元内嵌入式神经网络处理器阵列中嵌入式神经网络处理器的坐标。进一步地，计算单算子v的计算开销dv，包括：输入算子v分配到每个嵌入式神经网络处理器上的计算量m*k*n、嵌入式神经网络处理器上脉冲阵列的大小w*w，其中m*k*n为当前处理的张量的尺寸；若m＞w或n＞w，则通过加总分配到每个嵌入式神经网络处理器上的计算量m*k*n与脉冲阵列尺寸w*w的比例和2倍的一维脉冲拍数w-1，得到单算子v的计算开销dv；若m＜w且n＜w，则通过加总每一维的计算量再减去1，得到单算子v的计算开销dv。进一步地，计算算子v内网络传输开销cv，包括：输入算子v的划分策略的独热编码sv、算子内通信延迟矩阵Rv、小芯片单元内带宽b1、小芯片单元间带宽b2和映射策略mv；通过计算转置的算子v的划分策略的独热编码sv与算子内通信延迟矩阵Rv之积，得到算子v内的通信延迟；根据划分策略的独热编码sv和映射策略mv，分别计算小芯片单元内路由转发平均跳数h1与路由转发周期数r1之积、小芯片单元间路由转发平均跳数h2与路由转发周期数r2之积，加总得到算子v内的路由转发延迟；加总算子v内的通信延迟和算子v内的路由转发延迟，得到算子v内的网络传输开销cv。进一步地，计算具有数据依赖的算子对之间的网络传输开销，包括：输入并行组pi和其相邻后序并行组pj具有数据依赖的算子对及其划分策略的独热编码sv和su、算子间通信延迟矩阵R、映射策略mv和mu；通过计算转置的算子v的划分策略的独热编码sv、算子对间的通信延迟矩阵R及算子u的划分策略的独热编码su之积，得到算子对间通信延迟；根据划分策略的独热编码sv和su、映射策略mv和mu，分别计算小芯片单元内路由转发平均跳数h1与路由转发周期数r1之积、小芯片单元间路由转发平均跳数h2与路由转发周期数r2之积，加总得到算子对间路由转发延迟；加总算子对间通信延迟和算子对间路由转发延迟，得到算子对之间的网络传输开销。根据本申请实施例的第二方面，提供一种面向芯粒的神经网络推理开销估计装置，包括：神经网络参数和芯粒拓扑结构获取模块，用于获取神经网络计算图及其划分后的并行组，获取芯粒拓扑结构及其划分后的子芯粒拓扑结构，获取神经网络计算图中每个算子的划分策略和映射策略；并行组内开销估计模块，用于计算单算子v的计算开销dv和算子v内网络传输开销cv，根据所述dv和cv得到并行组pi内每个算子v的开销，从所述并行组pi内选择最大的单个算子的开销，作为该并行组pi的并行组内开销Ti，其中i≥0；并行组间网络传输开销估计模块，用于计算并行组pi及其相邻后序并行组pj间所有具有数据依赖的算子对之间的网络传输开销，加总得到并行组pi的并行组间网络传输开销cpi，其中v属于并行组pi的算子集合Vi，u属于并行组pj的算子集合Vj；神经网络推理开销估计模块，用于获取并行组数量P，加总所有P个并行组内开销和P-1个并行组间网络传输开销，得到整个神经网络计算图的推理开销T*。根据本申请实施例的第三方面，提供一种电子设备，包括：一个或多个处理器；存储器，用于存储一个或多个程序；当所述一个或多个程序被所述一个或多个处理器执行，使得所述一个或多个处理器实现如第一方面所述的面向芯粒的神经网络推理开销估计方法。根据本申请实施例的第四方面，提供一种计算机可读存储介质，其上存储有计算机指令，该指令被处理器执行时实现如第一方面所述的面向芯粒的神经网络推理开销估计方法的步骤。本申请的实施例提供的技术方案可以包括以下有益效果：由上述实施例可知，本申请采取面向芯粒的神经网络推理开销估计方法，使得推理开销估计适用于神经网络在芯粒上并行调度的实际场景。将计算开销纳入推理开销估计，并通过比较计算量和嵌入式神经网络处理器上脉冲阵列的大小采用不同的计算开销估计方式，使得推理的计算开销估计更加准确；采取算子内网络传输开销估计和算子对间网络传输开销估计方法，使得神经网络推理开销估计能够适用于芯粒这样的拓扑结构，充分考虑芯粒上小芯片单元内外的带宽、小芯片单元内路由转发延迟和小芯片单元外路由转发延迟，使得神经网络在芯粒上的推理开销估计达到较高的精度，从而为神经网络在芯粒上加速推理所需的高性能调度策略奠定良好基础。应当理解的是，以上的一般描述和后文的细节描述仅是示例性和解释性的，并不能限制本申请。附图说明此处的附图被并入说明书中并构成本说明书的一部分，示出了符合本申请的实施例，并与说明书一起用于解释本申请的原理。图1是根据一示例性实施例示出的一种面向芯粒的神经网络推理开销估计方法的流程图。图2是根据一示例性实施例示出的一种芯粒拓扑结构的示意图。图3是根据一示例性实施例示出的一种面向芯粒的神经网络推理开销估计装置的框图。图4是根据一示例性实施例示出的一种电子设备的示意图。具体实施方式这里将详细地对示例性实施例进行说明，其示例表示在附图中。下面的描述涉及附图时，除非另有表示，不同附图中的相同数字表示相同或相似的要素。以下示例性实施例中所描述的实施方式并不代表与本申请相一致的所有实施方式。在本申请使用的术语是仅仅出于描述特定实施例的目的，而非旨在限制本申请。在本申请和所附权利要求书中所使用的单数形式的“一种”、“所述”和“该”也旨在包括多数形式，除非上下文清楚地表示其他含义。还应当理解，本文中使用的术语“和/或”是指并包含一个或多个相关联的列出项目的任何或所有可能组合。应当理解，尽管在本申请可能采用术语第一、第二、第三等来描述各种信息，但这些信息不应限于这些术语。这些术语仅用来将同一类型的信息彼此区分开。例如，在不脱离本申请范围的情况下，第一信息也可以被称为第二信息，类似地，第二信息也可以被称为第一信息。取决于语境，如在此所使用的词语“如果”可以被解释成为“在……时”或“当……时”或“响应于确定”。图1是根据一示例性实施例示出的面向芯粒的神经网络推理开销估计方法的流程图，如图1所示，该方法应用于终端中，可以包括以下步骤：步骤神经网络参数和芯粒拓扑结构获取：获取神经网络计算图及其划分后的并行组，获取芯粒拓扑结构及其划分后的子芯粒拓扑结构，获取神经网络计算图中每个算子的划分策略和映射策略；步骤并行组内开销估计：计算单算子v的计算开销dv和算子v内网络传输开销cv，根据所述dv和cv得到并行组pi内每个算子v的开销，从所述并行组pi内选择最大的单个算子的开销，作为该并行组pi的并行组内开销Ti，其中i≥0；步骤并行组间网络传输开销估计：计算并行组pi及其相邻后序并行组pj间所有具有数据依赖的算子对之间的网络传输开销，加总得到并行组pi的并行组间网络传输开销cpi，其中v属于并行组pi的算子集合Vi，u属于并行组pj的算子集合Vj；步骤神经网络推理开销估计：获取并行组数量P，加总所有P个并行组内开销和P-1个并行组间网络传输开销，得到整个神经网络计算图的推理开销T*。由上述实施例可知，本申请采取并行组内开销估计方法，使得推理开销估计适用于神经网络在芯粒上并行调度的实际场景。采取算子内网络传输开销估计和算子对间网络传输开销估计方法，使得神经网络推理开销估计能够适用于芯粒这样的拓扑结构，充分考虑芯粒上小芯片单元内外的带宽、小芯片单元内路由转发延迟和小芯片单元外路由转发延迟，使得神经网络在芯粒上的推理开销估计达到较高的精度，从而为神经网络在芯粒上加速推理所需的高性能调度策略奠定良好基础。本申请所公开的面向芯粒的神经网络推理开销估计方法适用于基于芯粒拓扑结构的所有神经网络，本申请中以ResNeXt为例进行说明。需要说明的是，以下以ResNeXt为例进行说明的内容并不限制本申请的范围。假设为神经网络推理设计了一款基于芯粒的神经网络加速器，并在该芯粒上使用预训练过的神经网络ResNeXt执行大量的虚假图像识别任务，则需要设计一种ResNeXt计算图调度策略，以充分利用芯粒的计算和存储资源，使得ResNeXt完成虚假图像识别任务的总推理开销尽可能小，因此，需要估计ResNeXt在各种调度策略下的推理开销，从而找到使得推理开销最小的调度策略，从而确定ResNeXt计算图调度策略。为了实现以上要求，可以使用下面展示的面向芯粒的神经网络推理开销估计方法。在步骤的具体实施中：获取神经网络计算图及其划分后的并行组，包括：获取神经网络推理过程的有向无环计算图G，G由结点集合V和有向边集合E组成，G中每个结点v代表一个算子，每条有向边e代表结点间的数据依赖关系；具体地，获取ResNeXt模块的有向无环计算图G，G中的结点集合V={v0, v1, …,v98},每个结点与该模块的算子一一对应，如结点v1表示CONV；G中的有向边集合E={e0, e1, …, e129}，每条有向边与该模块算子间的每个数据依赖关系一一对应，如有向边e32=表示v1的输出结果是v33的输入数据，也即CONV的输出结果是CONV的输入数据。该步骤是估计整个网络推理开销的基础。获取划分后的并行组集合P，P由划分计算图G后的若干并行组pi组成，并行组pi内的所有算子完全并行执行，算子集合记为Vi，Vi包含于结点集合V，所有并行组的算子集合之间无交集且其并集为计算图G的结点集合V。具体地，获取划分图G后的并行组集合P，如P由6个并行组组成，并行组p0由一个SPLIT组成，并行组p1由32个CONV组成，并行组p2由32个CONV组成，并行组p3由32个CONV组成，并行组p4、p5分别由ADD、ADD组成。该步骤获取了在芯粒上推理ResNeXt的调度策略中的计算图并行划分策略，使得推理开销估计方法能够估计不同计算图并行划分方法下的推理开销。获取芯粒拓扑结构及其划分后的子芯粒拓扑结构，包括：获取芯粒中小芯片单元阵列尺寸M1*N1、小芯片单元内的NPU阵列尺寸M2*N2、芯粒的坐标表示；在本实施例中，如图2所示，其中的NOP和NOC分别为小芯片单元间路由部件和小芯片单元内路由部件，获取的芯粒中小芯片单元阵列尺寸为2*2，小芯片单元内的NPU阵列尺寸为4*4，若从0开始编号，则芯粒坐标表示的是位于小芯片单元阵列中第二行第二列那个小芯片单元上第一行第三列的NPU。该步骤是将算子置于芯粒上执行的通信开销估计的基础。获取子芯粒拓扑结构集合S，集合S由若干子芯粒拓扑结构submeshi组成，其中每种拓扑结构submeshi由表示,m1*n1为子芯粒的小芯片单元阵列尺寸，m2*n2为子芯粒小芯片单元阵列中坐标最大的小芯片单元内的NPU阵列尺寸，若m1*n1＞1，则其余小芯片单元内的NPU阵列尺寸均为M2*N2。在本实施例中，获取子芯粒拓扑结构结合S={submesh0, submesh1}，其中，submesh0表示给算子分配1个小芯片单元中1*4大小的NPU阵列，submesh1表示给算子分配的小芯片单元阵列尺寸为1*2，其中第1个小芯片单元完全分配给算子，第2个小芯片单元分配其中2*4大小的NPU阵列给算子。该步骤用于获取每个算子可能分配到的芯粒计算资源的大小，是将算子置于芯粒上执行的通信开销估计的基础。获取神经网络计算图中每个算子的划分策略和映射策略，包括：获取每个算子v的划分策略的独热编码sv以及算子v所分配到的子芯粒拓扑结构submeshv；在本实施例中，获取sv1=、sv33=，则表示算子v1和v33的划分策略的独热编码均为，获取submeshv1= submesh0、submeshv33= submesh0，则表示算子v1和v33所分配到的子芯粒拓扑结构均为submesh0。 该步骤获取了当前采取的每个算子的划分策略和分配到的计算资源大小，是计算在某种调度策略下整个神经网络计算图在芯粒上推理的开销的关键。获取每个算子v的映射策略mv，mv由表示，submeshv算子v所分配到的子芯粒拓扑结构，mbeg为算子v在芯粒上分配到的芯粒起始坐标,mend为算子v在芯粒上分配到的芯粒上限坐标，和分别为小芯片单元阵列中小芯片单元的坐标，和分别为相应小芯片单元内NPU阵列中NPU的坐标。在本实施例中，获取mv1=, )，表示算子v1在芯粒上分配到的芯粒起始坐标为，在芯粒上分配到的芯粒上限坐标为；获取mv33=, )，表示算子mv33在芯粒上分配到的芯粒起始坐标为，在芯粒上分配到的芯粒上限坐标为，其余算子的映射策略mvi同理，此处被不做赘述。该步骤获取了当前采取的每个算子的映射策略，是计算在某种调度策略下整个神经网络计算图在芯粒上推理的开销的关键。在步骤的具体实施中，以矩阵乘为例，计算单算子计算开销dv，包括：输入算子v分配到每个NPU上的计算量m*k*n、NPU上脉冲阵列的大小w*w，其中m*k*n为当前处理的张量的尺寸；若m＞w或n＞w，则通过加总分配到每个嵌入式神经网络处理器上的计算量m*k*n与脉冲阵列尺寸w*w的比例和2倍的一维脉冲拍数w-1，得到单算子v的计算开销dv；若m＜w且n＜w，则通过加总每一维的计算量再减去1，得到单算子v的计算开销dv。在本实施例中，以算子v33为例，输入算子v33分配到每个NPU上的计算量为3*3*3，NPU上脉冲阵列的大小为4*4，则通过加总每一维的计算量再减去1，得到算子v33的计算开销dv33=8，算子v1的计算开销的计算方式同理，此处不作赘述。该步骤将计算量与NPU上脉冲阵列的大小作比较，进而采取不同的计算方式，能够得到较精准的每个算子在分配到的每个NPU上的计算开销。计算算子内网络传输开销cv，包括：输入算子v的划分策略的独热编码sv、算子内通信延迟矩阵Rv、小芯片单元内带宽b1、小芯片单元间带宽b2和映射策略mv；在本实施例中，如输入算子v33的划分策略的独热编码sv33=、算子内通信延迟矩阵Rv33=、小芯片单元内带宽b1=50、小芯片单元间带宽b2=20和映射策略mv33=, )。通过计算转置的算子v的划分策略的独热编码sv与算子内通信延迟矩阵Rv之积，得到算子v内的通信延迟；本实施例中，以算子v33内的通信延迟计算为例，通过计算转置的算子v33的划分策略的独热编码sv33与算子内通信延迟矩阵Rv33之积，得到算子v33内的通信延迟为0*10+1*25=25。该步骤能够计算得到算子在某划分策略下的算子内通信延迟。根据划分策略的独热编码sv和映射策略mv，分别计算小芯片单元内路由转发平均跳数h1与路由转发周期数r1之积、小芯片单元间路由转发平均跳数h2与路由转发周期数r2之积，加总得到算子v内的路由转发延迟；具体地，如划分策略的独热编码sv33=代表的划分方式需要参与计算的每个NPU的结果都归约到坐标最大的那个NPU对应的存储单元上，由映射策略mv33=, ) 知算子v33只在号小芯片单元的、、、号NPU上计算，且每个NPU上的计算结果都需要搬运到号NPU对应的存储单元上，那么，在号小芯片单元上，号NPU传输计算结果到号NPU对应的存储单元的路由转发跳数为3，号NPU传输计算结果到号NPU对应的存储单元的路由转发跳数为2，号NPU传输计算结果到号NPU对应的存储单元的路由转发跳数为1，号NPU的计算结果不需要数据搬运，如共有100次这样的数据搬运，则可计算出小芯片单元内路由转发平均跳数h1=100*/3=200，小芯片单元内路由转发周期数由小芯片单元内采用的路由部件决定，如小芯片单元内路由转发周期数r1=1，则小芯片单元内路由转发平均跳数h1与路由转发周期数r1之积为2，而当前策略下不存在跨小芯片单元间的数据传输，小芯片单元间路由转发平均跳数h2=0，因此，小芯片单元间路由转发平均跳数h2与路由转发周期数r2之积为0，加总得到算子v33内的路由转发延迟为200。该步骤能够计算得到某调度策略下的算子内路由转发延迟。加总算子v内的通信延迟和算子v内的路由转发延迟，得到算子v内的网络传输开销cv；具体地，加总算子v33内的通信延迟25和算子v33内的路由转发延迟200，得到算子v33内的网络传输开销cv33=225。该步骤将由路由转发导致的拥塞延迟加入算子内通信开销的计算，提高了推理开销估计的精确度。在步骤的具体实施中，计算具有数据依赖的算子对之间的网络传输开销，包括：输入并行组pi和其相邻后序并行组pj具有数据依赖的算子对及其划分策略的独热编码sv和su、算子间通信延迟矩阵R、映射策略mv和mu；具体地，如输入并行组p1和其相邻后序并行组p2具有数据依赖的算子对为、算子v1的划分策略的独热编码sv1=、算子v33的划分策略的独热编码sv33=、算子间通信延迟矩阵R=、映射策略mv1=,)和mv33=, )。通过计算转置的算子v的划分策略的独热编码sv、算子对间的通信延迟矩阵R及算子u的划分策略的独热编码su之积，得到算子对间通信延迟；具体地，通过计算转置的算子v1的划分策略的独热编码sv1、算子对间的通信延迟矩阵R及算子v33的划分策略的独热编码sv33之积，得到算子对间通信延迟为T===60*0+75*1=75。该步骤能够计算得到具有数据依赖的算子对在某划分策略下的算子间通信延迟。根据划分策略的独热编码sv和su、映射策略mv和mu，分别计算小芯片单元内路由转发平均跳数h1与路由转发周期数r1之积、小芯片单元间路由转发平均跳数h2与路由转发周期数r2之积，加总得到算子对间路由转发延迟；具体地，如划分策略的独热编码sv1和sv33、映射策略mv1和mv33表示的算子间数据传输方式为号NPU的计算结果需要搬运到号NPU对应的存储单元上，小芯片单元间路由转发跳数为1，小芯片单元内路由转发跳数为2，号NPU的计算结果需要搬运到号NPU对应的存储单元上，小芯片单元间路由转发跳数为1，小芯片单元内路由转发跳数为3， 号NPU的计算结果需要搬运到号NPU对应的存储单元上，小芯片单元间路由转发跳数为1，小芯片单元内路由转发跳数为4，号NPU的计算结果需要搬运到号NPU对应的存储单元上，小芯片单元间路由转发跳数为1，小芯片单元内路由转发跳数为5，如共有100次这样的数据搬运，则小芯片单元内路由转发平均跳数h1=100*/4=350，小芯片单元间路由转发平均跳数h2=100*/4=100，而小芯片单元内路由转发周期数由小芯片单元内采用的路由部件决定，小芯片单元间路由转发周期数由小芯片单元间采用的路由部件决定，如小芯片单元内路由转发周期数r1=1，小芯片单元间路由转发周期数r2=5，则小芯片单元内路由转发平均跳数h1与路由转发周期数r1之积为350、小芯片单元间路由转发平均跳数h2与路由转发周期数r2之积为500，加总得到算子对间路由转发延迟为850。该步骤能够计算得到某调度策略下的算子间路由转发延迟。加总算子对间通信延迟和算子对间路由转发延迟，得到算子对之间的网络传输开销；具体地，加总算子对间通信延迟75和算子对间路由转发延迟850，得到算子对之间的网络传输开销为925。该步骤将由路由转发导致的拥塞延迟加入算子间通信开销的计算，提高了推理开销估计的精确度。在步骤的具体实施中，获取并行组数量P=6，如6个并行组内开销之和为114、其间网络传输开销之和为3375，则得到整个神经网络计算图的推理开销T*=114+3375=3489。与前述的面向芯粒的神经网络推理开销估计方法的实施例相对应，本申请还提供了面向芯粒的神经网络推理开销估计装置的实施例。图3是根据一示例性实施例示出的一种面向芯粒的神经网络推理开销估计装置框图。参照图3，该装置可以包括：神经网络参数和芯粒拓扑结构获取模块21，用于获取神经网络计算图及其划分后的并行组，获取芯粒拓扑结构及其划分后的子芯粒拓扑结构，获取神经网络计算图中每个算子的划分策略和映射策略；并行组内开销估计模块22，用于计算单算子v的开销dv和算子v内网络传输开销cv，根据所述dv和cv得到并行组pi内每个算子v的开销，从所述并行组pi内选择最大的单个算子的开销，作为该并行组pi的并行组内开销Ti，其中i≥0；并行组间网络传输开销估计模块23，用于计算并行组pi及其相邻后序并行组pj间所有具有数据依赖的算子对之间的网络传输开销，加总得到并行组pi的并行组间网络传输开销cpi，其中v属于并行组pi的算子集合Vi，u属于并行组pj的算子集合Vj；神经网络推理开销估计模块24，用于获取并行组数量P，加总所有P个并行组内开销和P-1个并行组间网络传输开销，得到整个神经网络计算图的推理开销T*。关于上述实施例中的装置，其中各个模块执行操作的具体方式已经在有关该方法的实施例中进行了详细描述，此处将不做详细阐述说明。对于装置实施例而言，由于其基本对应于方法实施例，所以相关之处参见方法实施例的部分说明即可。以上所描述的装置实施例仅仅是示意性的，其中所述作为分离部件说明的单元可以是或者也可以不是物理上分开的，作为单元显示的部件可以是或者也可以不是物理单元，即可以位于一个地方，或者也可以分布到多个网络单元上。可以根据实际的需要选择其中的部分或者全部模块来实现本申请方案的目的。本领域普通技术人员在不付出创造性劳动的情况下，即可以理解并实施。相应的，本申请还提供一种电子设备，包括：一个或多个处理器；存储器，用于存储一个或多个程序；当所述一个或多个程序被所述一个或多个处理器执行，使得所述一个或多个处理器实现如上述的面向芯粒的神经网络推理开销估计方法。如图4所示，为本发明实施例提供的一种面向芯粒的神经网络推理开销估计方法所在任意具备数据处理能力的设备的一种硬件结构图，除了图4所示的处理器、内存以及网络接口之外，实施例中装置所在的任意具备数据处理能力的设备通常根据该任意具备数据处理能力的设备的实际功能，还可以包括其他硬件，对此不再赘述。相应的，本申请还提供一种计算机可读存储介质，其上存储有计算机指令，该指令被处理器执行时实现如上述的面向芯粒的神经网络推理开销估计方法。所述计算机可读存储介质可以是前述任一实施例所述的任意具备数据处理能力的设备的内部存储单元，例如硬盘或内存。所述计算机可读存储介质也可以是风力发电机的外部存储设备，例如所述设备上配备的插接式硬盘、智能存储卡、SD卡、闪存卡等。进一步的，所述计算机可读存储介还可以既包括任意具备数据处理能力的设备的内部存储单元也包括外部存储设备。所述计算机可读存储介质用于存储所述计算机程序以及所述任意具备数据处理能力的设备所需的其他程序和数据，还可以用于暂时地存储已经输出或者将要输出的数据。本领域技术人员在考虑说明书及实践这里公开的内容后，将容易想到本申请的其它实施方案。本申请旨在涵盖本申请的任何变型、用途或者适应性变化，这些变型、用途或者适应性变化遵循本申请的一般性原理并包括本申请未公开的本技术领域中的公知常识或惯用技术手段。应当理解的是，本申请并不局限于上面已经描述并在附图中示出的精确结构，并且可以在不脱离其范围进行各种修改和改变。
