标题title
一种基于路端单目相机的交通流要素感知与定位方法及其应用
摘要abst
本发明公开了一种基于路端单目相机的交通流要素感知与定位方法及其应用，属于自动驾驶交通环境感知技术领域。该方法及其应用中，均充分利用道路单目相机的位姿固定的优势，在道路局部坐标系中确定一个透视变换转换矩阵，然后根据透视变换转换矩阵计算出交通流要素局部坐标定位。整个处理过程仅依靠纯图像处理技术完成。与现有的利用在智能车端部署多目相机或相机融合激光雷达的感知方式相比，本发明仅依靠路端单目相机与交通流要素的几何信息便可完成对交通流要素的轨迹和姿态等信息感知，具有成本低、实时性强等优点。
权利要求书clms
1.一种基于路端单目相机的交通流要素感知与定位方法，其特征在于：包括以下步骤：步骤1、建立当前道路局部坐标系：以道路长度方向为Y轴、宽度方向为X轴，建立道路局部坐标系，利用高精定位记录该坐标系原点的经纬度坐标；步骤2、确定透视变换转换矩阵：在当前道路范围内，确定出一个四边形的定位范围，并将该范围作为识别跟踪和定位的目标区域，然后采集目标区域各角点的像素坐标及其对应的物理坐标，求取像素坐标到物理坐标变换的透视变换矩阵；提取交通流要素像素信息：对目标进行识别，根据实际范围对目标识别结果进行掩模处理，并将处理的结果作为多目标跟踪的输入，完成道路范围内多目标跟踪，以得到目标跟踪框底部中间点像素信息；步骤3、基于透视变换的交通流要素局部坐标定位：根据步骤2得到的目标跟踪框底部中间点像素信息和透视变换矩阵，计算出交通流要素的局部物理坐标；根据步骤1的原点经纬度坐标，计算出当前局部物理坐标对应的交通流要素对应的经纬度坐标。2.根据权利要求1所述的一种基于路端单目相机的交通流要素感知与定位方法，其特征在于：为获得最优精确度，所述四边形为矩形，角点为矩形的四个顶点。3.根据权利要求1所述的基于路端单目相机的交通流要素感知与定位方法的应用，其特征在于：步骤S1、车辆长度、宽度关系建模：选取多种常见的小型车辆长度和宽度，建模为车辆长度和宽度的函数；步骤S2、目标车辆长度和宽度估计：利用图像坐标与物理坐标的对应关系，根据上述基于路端单目相机的交通流要素感知与定位方法，分别计算出目标车辆跟踪框底部A点、B点局部物理坐标；根据A、B点的局部物理坐标完成目标车辆的宽度估计，利用步骤S1得到的车辆长度和宽度的函数估算出目标车辆长度；步骤S3、目标车辆高度估计：根据相机光轴与道路面平行关系，确定出相机与目标车辆的几何位置关系；将目标车辆模型近似处理为长方体，结合步骤S2计算所得到的目标车辆长度，以及相机与目标车辆的几何位置关系，根据相机成像原理计算出目标车辆实际的成像物体高度，通过相似三角形计算出目标车辆实际高度；步骤S4、目标车辆偏航角信息估计：基于车辆成像整体宽度与车辆偏航角的对应关系利用步骤S2计算得到的A点、B点的局部物理坐标，对车辆整体成像宽度进行估计，反推得到偏航角信息；步骤S5、基于步骤S4得到的偏航角信息对目标车辆中心位置进行定位修正，即可得到精确的目标车辆定位信息。进一步的，所述步骤S5还可以根据目标车辆与道路之间的几何位置关系实现目标车辆定位估计；具体为：步骤S5.1、从提取的车辆信息中找出目标车辆跟踪框的十字中心点，利用目标车辆跟踪框的十字中心点像素对应透视变换后的局部物理坐标估计目标车辆的实际位置；步骤S5.2根据目标车辆跟踪框十字中心点对应的局部物理坐标和目标车辆实际的中心点坐标之间的几何关系完成对车辆的定位估计修正。
说明书desc
技术领域本发明涉及自动驾驶交通环境感知技术领域，具体涉及一种基于路端单目相机的交通流要素感知与定位方法及其应用。背景技术交通环境感知作为自动驾驶发展的关键技术之一，是未来保障智能网联汽车安全高效通行的重要支撑。目前常采用的交通环境感知方式主要是智能车通过激光雷达数据与视觉数据融合处理来完成对交通流目标的精准定位。但激光雷达成本高、实时性相对单独相机感知而言更差，对于道路场景交通流要素的感知范围受限，导致智能网联汽车不能及时获取道路实时全要素交通流数据，难以保障实时路径规划和安全通行需求。因此，利用图像处理实现一种高精度、高效率的交通流要素目标位姿感知技术对于智能网联汽车安全通行的现实需求至关重要。发明内容本发明的目的在于提供一种基于路端单目相机的交通流要素感知与定位方法，在满足精度需求的前提下，克服了激光雷达与视觉融合实现定位带来的成本高、实时性差等问题。为实现上述目的，本发明采用如下技术方案：一种基于路端单目相机的交通流要素感知与定位方法，包括以下步骤：步骤1、建立当前道路局部坐标系：以道路长度方向为Y轴、宽度方向为X轴，建立道路局部坐标系，利用高精定位记录该坐标系原点的经纬度坐标；步骤2、确定透视变换转换矩阵：在当前道路范围内，确定出一个四边形的定位范围，并将该范围作为识别跟踪和定位的目标区域，然后采集目标区域各角点的像素坐标及其对应的物理坐标，求取像素坐标到物理坐标变换的透视变换矩阵；提取交通流要素像素信息：对目标进行识别，根据实际范围对目标识别结果进行掩模处理，并将处理的结果作为多目标跟踪的输入，完成道路范围内多目标跟踪，以得到目标跟踪框底部中间点像素信息；步骤3、基于透视变换的交通流要素局部坐标定位：根据步骤2得到的目标跟踪框底部中间点像素信息和透视变换矩阵，计算出交通流要素的局部物理坐标；根据步骤1的原点经纬度坐标，计算出当前局部物理坐标对应的交通流要素对应的经纬度坐标。进一步的，为获得最优精确度，所述四边形为矩形，角点为矩形的四个顶点。一种基于路端单目相机的交通流要素感知与定位方法，其在车辆跟踪定位中的应用过程如下：步骤S1、车辆长度、宽度关系建模：选取多种常见的小型车辆长度和宽度，建模为车辆长度和宽度的函数；步骤S2、目标车辆长度和宽度估计：利用图像坐标与物理坐标的对应关系，根据上述基于路端单目相机的交通流要素感知与定位方法，分别计算出目标车辆跟踪框底部A点、B点局部物理坐标；根据A、B点的局部物理坐标完成目标车辆的宽度估计，利用步骤S1得到的车辆长度和宽度的函数估算出目标车辆长度；步骤S3、目标车辆高度估计：根据相机光轴与道路面平行关系，确定出相机与目标车辆的几何位置关系；将目标车辆模型近似处理为长方体，结合步骤S2计算所得到的目标车辆长度，以及相机与目标车辆的几何位置关系，根据相机成像原理计算出目标车辆实际的成像物体高度，通过相似三角形计算出目标车辆实际高度；步骤S4、目标车辆偏航角信息估计：基于车辆成像整体宽度与车辆偏航角的对应关系利用步骤S2计算得到的A点、B点的局部物理坐标，对车辆整体成像宽度进行估计，反推得到偏航角信息；步骤S5、基于步骤S4得到的偏航角信息对目标车辆中心位置进行定位修正，即可得到精确的目标车辆定位信息。进一步的，所述步骤S5还可以根据目标车辆与道路之间的几何位置关系实现目标车辆定位估计修正；具体为：步骤S5.1、从提取的车辆信息中找出目标车辆跟踪框的十字中心点，利用目标车辆跟踪框的十字中心点像素对应透视变换后的局部物理坐标估计目标车辆的实际位置；步骤S5.2根据目标车辆跟踪框十字中心点对应的局部物理坐标和目标车辆实际的中心点坐标之间的几何关系完成对车辆的定位估计修正。本发明提供的一种基于路端单目相机的交通流要素感知与定位方法，充分利用道路单目相机的位姿固定的优势，在道路局部坐标系中根据像素位置和局部坐标的对应关系确定一个透视变换转换矩阵，然后根据透视变换转换矩阵计算出交通流要素局部坐标定位，整个处理过程仅依靠纯图像处理技术完成。与现有的利用在智能车端部署多目相机或相机融合激光雷达的感知方式相比，本发明仅依靠路端单目相机与交通流要素的几何信息便可完成对交通流要素的轨迹和姿态等信息感知，具有成本低、实时性强等优点。附图说明图1为路侧定位区域选取；图2为本发明基于路端单目相机的交通流要素感知与定位方法的框图；图3为实施例车辆长宽关系建模；图4为实施例车辆宽度估计示意图；图5为实施例相机与车辆之间几何关系图；图6为实施例车辆整体宽度估计；图7为实施例实际成像宽度与车辆的偏航角关系；图8为实施例基于宽度的定位修正方法示意图；图9为实施例基于高度修正的方法示意图。具体实施方式下面结合附图和实施例对本发明作进一步说明。如图2所示，本发明提供的一种基于路端单目相机的交通流要素感知与定位方法，包括以下步骤：步骤1、建立当前道路局部坐标系：以道路长度方向为Y轴，宽度方向为X轴建立道路局部坐标系，利用高精定位记录该坐标系原点的经纬度坐标。步骤2、确定透视变换转换矩阵：如图所示，在当前道路范围内，先确定出一个四边形的定位范围，并将该范围作为识别跟踪和定位的目标区域，然后采集目标区域各角点的像素坐标以及其对应的物理坐标，求取像素坐标到物理坐标变换的透视变换矩阵。同时，通过深度学习Yolov5图像识别技术对道路交通流要素进行分类提取，然后根据道路实际范围对目标识别结果进行掩模处理，并将处理的结果作为DeepSort多目标跟踪的输入，完成道路范围内多目标跟踪，以得到该区域内目标跟踪框底部中间点像素信息。步骤3、基于透视变换的交通流要素局部坐标定位：根据步骤2得到的目标跟踪框底部中间点像素信息和透视变换矩阵计算出交通流要素的局部物理坐标；再根据步骤1的原点经纬度坐标计算出当前局部物理坐标对应的交通流要素对应的经纬度坐标。从上述描述中不难发现，本实施基于路端单目相机的交通流要素感知与定位方法充分利用了单目相机的位姿固定的优势，仅依靠纯图像处理技术就能完成交通流要素的感知与定位，具有成本低、实时性强等优势。针对上述方法，本实施还提供了其在车辆跟踪定位中的应用，具体应用过程如下：步骤S1、车辆长度宽度关系建模：由于单目相机的跟踪信息很难单独获得车辆的宽度和高度，所以需要对车辆的尺寸信息和状态信息分别进行估计。本实施例选取国内销量前20以及常见的小型车辆长度和宽度，建模为车辆长度和宽度函数。如图3所示，通过对选取的所有车辆长宽数据的关系进行线性拟合，得到k＝0.2071，b＝836.34，回归方程整体的拟合度R2＝0.9392；拟合度较好，可用于表示多数车辆的长宽关系，即得到表示车辆长度和宽度的关系函数公式,，其中W为车辆宽度，L为车辆长度，单位为毫米。W＝0.2071L+836.34 步骤S2、利用步骤S1得到的车辆长度和宽度的关系函数，完成待定位目标车辆长度和宽度估计：本实施例中，路端部署的单目相机的光轴平行于道路的方向。设定目标车辆是以平行于光轴方向进入定位区域。如图4所示，识别框的A点和B点像素坐标对应的物理坐标可以通过上述基于路端单目相机的交通流要素感知与定位方法计算得到。再根据A、B两点的物理坐标计算出A、B两点的物理距离来估计目标车辆初始宽度。然后根据步骤S1得到的长宽关系函数估算出车辆长度。步骤S3、目标车辆高度估计：如图5所示，相机光轴与道路面平行，相机物距Z为成像物体沿相机光轴到相机的距离、F为相机焦距、Y为像素高度，过相机成像原理计算出实际成像物理高度。为方便计算，将目标车辆模型近似处理为长方体。根据给定车辆长度L以及单目像机与车辆的几何位置关系，通过相似三角形即可计算出目标车辆的实际高度，推导过程见表达式。步骤S4、目标车辆偏航角信息估计：如图6所示，根据步骤S2得到的目标车辆长度和宽度、以及光轴与道路面平行这一特定条件，确定出目标车辆识别框底部对应的实际车辆成像宽度W'与车辆的偏角存在一一对应关系。在实际使用中，车身相对于道路方向的偏移有左偏或者右偏两种情况，根据这两种情况建立偏移角度与车辆成像宽度之间的关系式L sinθ+W cosθ＝W′ 几何关系如图7所示，利用步骤S2计算得到的A点和B点的像素坐标对应的物理坐标，根据关系式推导出偏航角的公式，从而计算出目标车辆的偏航角信息。式中，L为车辆长度，W为车辆宽度，W′为车辆实际成像宽度，θ为相对于道路方向的偏角。步骤S5、基于步骤步骤S4得到的偏航角信息对目标车辆中心位置进行定位修正，即可得到精确的目标车辆定位信息。具体如图8所示：由几何关系可得车辆中心位置X坐标始终位于成像宽度W′的中间；根据相机光轴与道路平行关系，得出识别跟踪框底部对应的实际线段AB垂直于道路方向；根据图像框左下点和右下点的像素点经过透视变换得到的物理坐标X1和X2，再根据X1和X2的物理坐标，求得目标车辆真正的中心点X坐标。通过求C点和D点的物理坐标得到中心点的Y坐标；从而得到目标车辆中心点X值、Y值。中心点X、Y的表达式为：X＝/2Y＝/2+/2 最后取连续多帧，根据连续多帧之间的中心坐标的变换情况，求取车辆的速度信息，并且可以判断当前车辆相对于道路的偏航角方向。在实际使用中，如果直接使用车辆跟踪框的十字中心点像素对应透视变换后的物理坐标来估计车辆的实际定位，根据识别跟踪框中心对应的物理坐标和车辆实际的中心坐标的几何关系，车辆高度一定的情况下，两者之间误差会随着车辆与相机距离的增加而增大。为减小误差，本实施例增加了定位的修正过程，修正过程中，仍将目标车辆视为长方体来计算修正量。如图9所示，车辆识别框的中心对应目标车辆长方体的几何中心，通过计算跟踪框中心点像素的物理坐标判断该中心点位于车辆实际位置的左前方或右前方；依据判断结果结合相机高度、目标车辆高度计算出X和Y值需要修正的参数Δx和Δy，在之前得到的目标车辆中心点基础上进行修正。Δy/y＝h/2HΔx＝Δy*tanβ X＝X+/-Δx Y＝Y-Δy 增加修正过程后，本实施例使用基于宽度几何属性的定位修正方法，最终实现了接近厘米级的定位经度，实现了基于路端单目相机的车辆位姿估计，解决了单目相机感知信息不完整问题。综上可见，本发现提供的一种基于路端单目相机的交通流要素感知与定位方法能够有效获取交通流的局部坐标，并根据得到的局部坐标结合目标车辆与道路方向、单目相机之间的几何关系即可得到精确的定位。整个处理过程仅依靠纯图像处理技术完成，成本更低。
