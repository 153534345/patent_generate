标题title
一种蒙语视频智能分析方法
摘要abst
本申请涉及一种蒙语视频智能分析方法，包括：数据处理、语音信息处理，图像信息处理，蒙汉文本翻译，要素提取，意图识别，内容分析预警，通用模型研判识别，自建分析研判模型。本申请利用当前先进的人工智能、大数据和蒙古文信息处理技术，针对蒙语的视频数据进行识别、翻译、检索、监测及管理，大大提升了蒙语视频自动分析能力，降低了人工分析成本，提高了分析效率和实时率。
权利要求书clms
1.一种蒙语视频智能分析方法，其特征在于，包括以下步骤：步骤S1，数据处理，判断接收数据是否为视频数据，若是，转至步骤S2，若不是，则进行格式转换提取音频数据、蒙语文本信息，提取的音频数据通过音频的转写提取蒙语文本信息，之后将蒙语文本信息翻译成对应的中文文本信息，转至步骤S5；步骤S2，语音信息处理，提取视频数据中的语音信息作出处理；步骤S3，图像信息处理，提取视频数据中的图像信息作出处理；步骤S4，蒙汉文本翻译，通过图像的OCR识别从图像信息提取出蒙语文本信息，通过音频的转写从语音信息提取出蒙语文本信息，将蒙语文本信息翻译成对应的中文文本信息；步骤S5，要素提取，识别中文文本信息所包含的要素信息，包含人名、地名、事务、组织信息，并且根据提取出来的人名、地名、事务得到对应的要素组织信息；步骤S6，意图识别，根据中文文本信息的主题、内容和属性，将中文文本信息归到一个或多个类别，识别文本信息中所表达的意图；步骤S7，内容分析预警，系统通过基础库，结合人工经验战法模型，从原声、MD5、声纹、关键词对视频进行打分预警，按照分值高低排序；步骤S8，通用模型研判识别，利用通用模型对视频数据进行研判识别；步骤S9，自建分析研判模型，通过对大数据的事件发生、发展趋势的分析、学习，形成具有针对性的事件分析研判模型，进行进一步研判。2.根据权利要求1所述的一种蒙语视频智能分析方法,其特征在于：所述步骤S2包括：步骤S21，语音信息预处理，对视频数据中的音频进行场景分割，划分为音乐、噪音、语音；步骤S22，语音信息语种识别，通过对蒙语语种进行声学模型训练和语言模型训练，对需要处理的视频数据进行语种识别比对，自动识别判断视频数据所属的语种，确认视频数据中的蒙语语种的视频数据片段；步骤S23，语音信息转写，对语音信息预处理得到的音乐、噪音、语音，进行端点检测、降噪，提取声学特征；将提取到的声学特征和对语音信息语种识别中识别到的蒙语语种的视频数据，在训练好的声学模型和语言模型训练中，使用解码器进行解码，进行音频文本转换得到蒙语文本信息。3.根据权利要求2所述的一种蒙语视频智能分析方法,其特征在于：所述步骤S21中，语音信息预处理还包括：S211，能量四门限算法，设置“静寂状态”、“语音起始状态”、“语音稳定状态”及“语音衰减状态”四个状态，并分别设置状态间跳转所需的四个能量门限值，根据视频数据中的音频中每一帧的能量信息，实现四个状态之间的跳转，最终实现音频中能量较高的语音片段的检测；S212，基于规则的噪声判断算法，利用音频的频段能量，对通过了能量四门限算法的信号片段，进行音乐、噪音场景的初判；S213，模型分类器判决，根据实际系统的应用环境，训练出与实际应用场景中所出现各种场景相匹配的模型；在训练过程中，引入区分性训练，并使用最小分类误差准则。4.根据权利要求1所述的一种蒙语视频智能分析方法,其特征在于：所述步骤S3包括：步骤S31，图像信息预处理，筛选是否满足图片的有效性检测，清晰度检测，以及图像的MD5去重功能；筛选是否满足图像增强、图像二值化、图像透视变换、图像边界检测、图像倾斜检测、图像外部块检测、图像内容区域检测；并针对满足检测的图像信息进行二值化、噪声去除、倾斜校正；所述二值化用于使图像信息只包含黑色的前景信息和白色的背景信息；所述噪声去除根据噪声的特征对待识别的图像信息进行去噪处理；所述倾斜校正用于校正图像方向；步骤S32，图像信息识别，结合OCR识别服务，利用各种模式识别算法分析文字形态特征，判断出蒙文的标准编码，提取出图片中包含的蒙古文文本信息，并按通用字符格式存储在文本文档中。5.根据权利要求1所述的一种蒙语视频智能分析方法,其特征在于：所述步骤S4包括：步骤S41，分词，将汉字序列切分成词序列；步骤S42，词性标注，给句子中每个词一个词性类别，包括数字和人名；步骤S43，解码器解码，包括基于层次短语的解码器PSMT和基于神经网络的解码器NMT；所述基于层次短语的解码器PSMT包括翻译模型、语言模型、调序模型、搜索空间和数线性模型打分，基于层次短语的解码器PSMT用于将句子按照短语进行切分，每个短句分别进行翻译，然后再进行调序；所述搜索空间包括所有切分的短语，并获得所有的翻译假设，所述数线性模型打分对翻译假设打分，并选择得分最高的翻译假设作为翻译结果。6.根据权利要求1所述的一种蒙语视频智能分析方法,其特征在于：所述步骤S5中，要素提取通过大数据的行业领域数据，进行人工领域专家标注，所述的人工领域专家标注包括：词法、句法和语义；基于标注数据训练词法、句法、语义分析的统计模型；所述词法分析采用条件随机场模型，并结合规则文法；所述句法采用概率上下文无关文法建立统计句法分析模型，并基于动态规划思想设计句法分析算法，并进行分析算法的裁剪策略效率优化；所述语义基于句法结构树进行语义特征提取，根据带语义标注的数据训练语义消歧模型，结合语义解析规则文法，实现对要素的语义理解。7.根据权利要求1所述的一种蒙语视频智能分析方法,其特征在于：所述步骤S6中，意图识别支持多类别的组合关键词匹配KWS策略，基于上访的实验原型，能够自定义不同类别的正负组合关键词，能够实现基于规则的关键词匹配；意图识别同时支持KWS、KWP、NB、LDA+SVM和NN五种策略；意图识别完成多类别文本分类下的多策略得分融合,每个策略都支持多分类判别，最后进行综合多策略得分融合，配置各个策略的权重，根据权重进行得分融合；意图识别支持多策略输入输出统一格式,完成不同策略下面统一的输入输出格式定义；意图识别基于NN策略，实现同时加载多个nn模型，支持配置各个nn模型的的权重和阈值，使用NN策略后计算各个nn模型的得分进行融合结果输出；意图识别基于NN策略能够动态切换使用的nn模型。8.根据权利要求1所述的一种蒙语视频智能分析方法,其特征在于：所述步骤S7包括：步骤S71，人声分离，对视频数据和音频数据中的语音内容进行活动语音监测，识别视频数据和音频数据片段中各部分的噪音，噪音包括静音、白噪音、彩铃，根据监测结果对噪音进行抑制，对有效语音进行增强，然后根据不同说话人的声纹特点进行聚类，最终实现说话人的人声分离；声纹预警，人声分离之后进行视频数据和音频数据的声纹提取和注册，然后将视频数据和音频数据中的声纹信息注册到声纹库中，结合声纹库的预警发现模块，发现跨应用的特定人员；步骤S72，图像预警，基于场景识别和图像语种识别，将获取的图像数据标签化、场景化，对其中涉枪、涉蒙语、涉特定人像的数据进行推送预警；图像预警包括人像预警、蒙文图片的识别预警和涉枪类图片的发现预警；所述人像预警能够建立重点人像的知识库，通过知识库和当前人脸相似度识别引擎实现重点人像的预警；所述蒙文图片的识别预警调用图像OCR和语种识别引擎；所述涉枪类图片的发现预警调用图像类的物体监测引擎；所述图像预警的预警内容包括：人物、人群、游行、枪支、旗帜 、色情、血腥、自焚、烧伤的图片；步骤S73，文本内容预警，通过图像的OCR识别和音频数据的转写，建立关键词的知识库，结合关键词，发现图像中的有害文本信息，在接入视频数据时，对其中的中文、蒙文内容进行识别和提取，并且和关键词的知识库进行比对，所述文本内容预警还采取并行处理。9.根据权利要求1所述的一种蒙语视频智能分析方法,其特征在于：所述步骤S8包括：步骤S81，色情内容、场景识别，分成色情、性感、正常三类，通过训练多个网络模型、对特定的用户采用多模型级连判定，对于视频鉴黄，先采用截帧鉴黄，对于疑似的图片，再采用视频片段算法和光流算法；步骤S82，暴恐内容智能识别，通过暴恐图片和视频数据源，依托分布式深度学习平台，对图片、视频进行暴恐分类，并对暴恐场景和暴恐物品，所述暴恐场景的识别包括游行、旗帜、台标，所述暴恐物品的识别包括枪支、面具、胡须脸；步骤S83，政治敏感人物智能识别，自动对视频中出现的政治人物进行智能识别，通过对比政治人物人脸的特征，识别出视频图像中是否存在政治人物，如果存在，识别出是谁；政治敏感人物智能识别模型建立政治敏感人像的知识库，通过知识库和当前人脸相似度识别引擎实现政治人像的预警。10.根据权利要求1所述的一种蒙语视频智能分析方法,其特征在于：所述步骤S9中，所述自建分析研判模型，基于民警进行各自创建，与各民警关联，打上相应业务属性，说明应用的案件方向；所述自建分析研判模型基于不同的数据源，包括两群数据、互联网数据，各自使用不同的技战法进行分析，在呈现时，基于不同的数据类型进行归类展示；所述自建分析研判模型包括公共模型和私有模型，所有自建分析研判模型能够根据当前使用的成效，发布成文公共模型或者是指定共享至其他民警；所述自建分析研判模型的最终应用通过设置启用时间和应用数据范围与比对任务、预警分析挂钩，用于主动告警、提醒用户。
说明书desc
技术领域本申请涉及蒙语视频分析的领域，尤其是涉及一种蒙语视频智能分析方法。背景技术随着信息化和互联网技术的迅速发展，蒙古文网站和公众号的数目越来越多，互联网数据中也包含大量的蒙古文视频资源，网民通过视频方式进行沟通联系的平台和技术迅速发展成熟。网民利用蒙古语在通讯工具中进行便捷的沟通交流的同时，也为公共安全机关的正常管理带来极大难题，对警务人员的需求量巨大，且很难保证时效性。因此亟需能够自动实现蒙古文网络视频异常信息的检索与监测，来完成互联网视频信息的分析工作。发明内容为了解决蒙语视频信息人为分析工作难开展、效率低、无法保证时效性的问题，本申请提供一种蒙语视频智能分析方法。本申请提供一种蒙语视频智能分析方法，包括以下步骤：步骤S1，数据处理，判断接收数据是否为视频数据，若是，转至步骤S2，若不是，则进行格式转换提取音频数据、蒙语文本信息，提取的音频数据通过音频的转写提取蒙语文本信息，之后将蒙语文本信息翻译成对应的中文文本信息，转至步骤S5；步骤S2，语音信息处理，提取视频数据中的语音信息作出处理；步骤S3，图像信息处理，提取视频数据中的图像信息作出处理；步骤S4，蒙汉文本翻译，通过图像的OCR识别从图像信息提取出蒙语文本信息，通过音频的转写从语音信息提取出蒙语文本信息，将蒙语文本信息翻译成对应的中文文本信息；步骤S5，要素提取，识别中文文本信息所包含的要素信息，包含人名、地名、事务、组织信息，并且根据提取出来的人名、地名、事务得到对应的要素组织信息；步骤S6，意图识别，根据中文文本信息的主题、内容和属性，将中文文本信息归到一个或多个类别，识别文本信息中所表达的意图；步骤S7，内容分析预警，系统通过基础库，结合人工经验战法模型，从原声、MD5、声纹、关键词对视频进行打分预警，按照分值高低排序；步骤S8，通用模型研判识别，利用通用模型对视频数据进行研判识别；步骤S9，自建分析研判模型，通过对大数据的事件发生、发展趋势的分析、学习，形成具有针对性的事件分析研判模型，进行进一步研判。通过上述方法，针对蒙语的视频数据进行识别、翻译、检索、监测及管理，大大提升了蒙语视频自动分析能力，降低了人工分析成本，提高了分析效率和实时率。进一步的，所述步骤S2包括：步骤S21,语音信息预处理，对视频中的音频进行场景分割，判断为音乐、噪音、语音等，方便后续的语音识别处理；步骤S22，语音信息语种识别，通过对蒙语语种进行声学模型训练和语言模型训练，对需要处理的视频数据进行语种识别比对，自动识别判断视频数据所属的语种，确认视频数据中的蒙语语种的视频数据片段，能够提高对蒙语的语种识别效率；步骤S23，语音信息转写，对语音信息预处理得到的音乐、噪音、语音，进行端点检测、降噪，提取声学特征；将提取到的声学特征和对语音信息语种识别中识别到的蒙语语种的视频数据，在训练好的声学模型和语言模型训练中，使用解码器进行解码，进行音频文本转换得到蒙语文本信息，能够快速得到蒙语文本信息。进一步的，所述步骤S21中，语音信息预处理还包括：S211，能量四门限算法，设置“静寂状态”、“语音起始状态”、“语音稳定状态”及“语音衰减状态”四个状态，并分别设置状态间跳转所需的四个能量门限值，根据视频数据中的音频中每一帧的能量信息，实现四个状态之间的跳转，最终实现音频中能量较高的语音片段的检测；S212，基于规则的噪声判断算法，利用音频的频段能量，对通过了能量四门限算法的信号片段，进行音乐、噪音场景的初判；通过基于规则的初步检测，可以将多数的场景检测出来，但是考虑到具体环境的需求，每一套系统的特定应用环境下，场景情况均不同。S213，模型分类器判决，根据实际系统的应用环境，训练出与实际应用场景中所出现各种场景相匹配的模型；在训练过程中，引入区分性训练，并使用最小分类误差准则，从而提高各种场景的匹配精度。进一步地，所述步骤S3包括：步骤S31，图像信息预处理，筛选是否满足图片的有效性检测，清晰度检测，以及图像的MD5去重功能；筛选是否满足图像增强、图像二值化、图像透视变换、图像边界检测、图像倾斜检测、图像外部块检测、图像内容区域检测；并针对满足检测的图像信息进行二值化、噪声去除、倾斜校正；所述二值化用于使图像信息只包含黑色的前景信息和白色的背景信息，从而提升图像信息预处理的效率和精确度；所述噪声去除根据噪声的特征对待识别的图像信息进行去噪处理，从而提升图像信息预处理的精确度；所述倾斜校正用于校正图像方向；步骤S32，图像信息识别，结合OCR识别服务，利用各种模式识别算法分析文字形态特征，判断出蒙文的标准编码，可以快速提取出图片中包含的蒙古文文本信息，并按通用字符格式存储在文本文档中，并为后续的业务分析提供更多的数据支撑。进一步的，所述步骤S4包括：步骤S41，分词，将汉字序列切分成词序列。因为在汉语中，词是承载语义的最基本的单元，分词是信息检索、文本分类、情感分析等多项中文自然语言处理任务的基础；步骤S42，词性标注，给句子中每个词一个词性类别，包括数字和人名，防止数字和人名对翻译产生误导。步骤S43，解码器解码，包括基于层次短语的解码器PSMT和基于神经网络的解码器NMT；所述基于层次短语的解码器PSMT包括翻译模型、语言模型、调序模型、搜索空间和数线性模型打分，基于层次短语的解码器PSMT用于将句子按照短语进行切分，每个短句分别进行翻译，然后再进行调序；所述搜索空间包括所有切分的短语，并获得所有的翻译假设，所述数线性模型打分对翻译假设打分，并选择得分最高的翻译假设作为翻译结果，从而提高翻译准确度。进一步的，所述步骤S5中，要素提取通过大数据中行业领域数据，进行人工领域专家标注，所述的人工领域专家标注包括：词法、句法和语义；基于标注数据训练词法、句法、语义分析的统计模型；所述词法分析采用条件随机场模型，并结合规则文法；所述句法采用概率上下文无关文法建立统计句法分析模型，并基于动态规划思想设计句法分析算法，并进行分析算法的裁剪策略效率优化；所述语义基于句法结构树进行语义特征提取，根据带语义标注的数据训练语义消歧模型，结合语义解析规则文法，实现对要素的语义理解。通过上述技术方案，能够最大程度提取视频数据中的有效要素。所述步骤S6中，意图识别支持多类别的组合关键词匹配KWS策略，基于上访的实验原型，能够自定义不同类别的正负组合关键词，能够实现基于规则的关键词匹配；意图识别同时支持KWS、KWP、NB、LDA+SVM和NN五种策略；在进行多策略分类时，意图识别支持支持上述五种策略的配置使用，从而提高意图识别的准确度；意图识别完成多类别文本分类下的多策略得分融合,每个策略都支持多分类判别，最后进行综合多策略得分融合，配置各个策略的权重，根据权重进行得分融合，从而提高意图识别的准确度；意图识别支持多策略输入输出统一格式,完成不同策略下面统一的输入输出格式定义；意图识别基于NN策略，实现同时加载多个nn模型，支持配置各个nn模型的的权重和阈值，使用NN策略后计算各个nn模型的得分进行融合结果输出；意图识别基于NN策略能够动态切换使用的nn模型，使用灵活、方便。进一步的，所述步骤S7包括：步骤S71，人声分离，对视频数据和音频数据中的语音内容进行活动语音监测，识别视频数据和音频数据片段中各部分的噪音，噪音包括静音、白噪音、彩铃，根据监测结果对噪音进行抑制，对有效语音进行增强，然后根据不同说话人的声纹特点进行聚类，最终实现说话人的人声分离；声纹预警，人声分离之后进行视频数据和音频数据的声纹提取和注册，然后将视频数据和音频数据中的声纹信息注册到声纹库中，结合声纹库的预警发现模块，发现跨应用的特定人员，能够提高声纹预警的准确度和效率；步骤S72，图像预警，基于场景识别和图像语种识别，将获取的图像数据标签化、场景化，对其中涉枪、涉蒙语、涉特定人像的数据进行推送预警；图像预警包括人像预警、蒙文图片的识别预警和涉枪类图片的发现预警；所述人像预警能够建立重点人像的知识库，通过知识库和当前人脸相似度识别引擎实现重点人像的预警；所述蒙文图片的识别预警调用图像OCR和语种识别引擎；所述涉枪类图片的发现预警调用图像类的物体监测引擎；所述图像预警的预警内容包括：人物、人群、游行、枪支、旗帜 、色情、血腥、自焚、烧伤的图片；步骤S73，文本内容预警，通过图像的OCR识别和音频数据的转写，建立关键词的知识库，结合关键词，发现图像中的有害文本信息，在接入视频数据时，对其中的中文、蒙文内容进行识别和提取，并且和关键词的知识库进行比对，所述文本内容预警还采取并行处理，并行处理用于提高文本内容预警的使用效率。进一步的，所述步骤S8包括：步骤S81，色情内容、场景识别，分成色情、性感、正常三类，通过训练多个网络模型、对特定的用户采用多模型级连判定，对于视频鉴黄，先采用截帧鉴黄，对于疑似的图片，再采用视频片段算法和光流算法，从而提高色情内容、场景识别的效率。步骤S82，暴恐内容智能识别，通过暴恐图片和视频数据源，依托分布式深度学习平台，对图片、视频进行暴恐分类，并对暴恐场景和暴恐物品，所述暴恐场景的识别包括游行、旗帜、台标，所述暴恐物品的识别包括枪支、面具、胡须脸；步骤S83，政治敏感人物智能识别，自动对视频中出现的政治人物进行智能识别，通过对比政治人物人脸的特征，识别出视频图像中是否存在政治人物，如果存在，识别出是谁；政治敏感人物智能识别模型建立政治敏感人像的知识库，通过知识库和当前人脸相似度识别引擎实现政治人像的预警。进一步的，所述步骤S9中，所述自建分析研判模型，基于民警进行各自创建，与各民警关联，打上相应业务属性，说明应用的案件方向，方便自建分析研判模型的精确使用；所述自建分析研判模型基于不同的数据源，包括两群数据、互联网数据，各自使用不同的技战法进行分析，在呈现时，基于不同的数据类型进行归类展示；所述自建分析研判模型包括公共模型和私有模型，所有自建分析研判模型能够根据当前使用的成效，发布成文公共模型或者是指定共享至其他民警，既满足各民警的独立使用需求，也将自建分析研判模型共享；自建分析研判模型的最终应用通过设置启用时间和应用数据范围与比对任务、预警分析挂钩，用于主动告警、提醒用户。综上所述，本申请包括以下有益技术效果：1.利用当前先进的人工智能、大数据和蒙古文信息处理技术，实现对各种渠道获取的蒙语视频信息的识别、翻译、检索、监测及管理，大大提升了蒙语视频自动分析能力，降低了人工分析成本，提高了分析效率和实时率；2.对视频数据信息进行治理，对公共安全业务中各类蒙古文视频信息处理、组织、治理等实施服务，有利于营造清朗的网络空间，维护社会稳定。附图说明图1是本申请一种蒙语视频智能分析方法的总体步骤图；图2是本申请一种蒙语视频智能分析方法的语音信息处理的详细步骤图；图3是本申请一种蒙语视频智能分析方法的图像信息处理的详细步骤图；图4是本申请一种蒙语视频智能分析方法的蒙汉文本翻译的详细步骤图；图5是本申请一种蒙语视频智能分析方法的内容分析预警的详细步骤图；图6是本申请一种蒙语视频智能分析方法的通用模型研判识别的详细步骤图。具体实施方式下面对照附图1-6，通过对实施例的描述，本申请的具体实施方式如所涉及的各构件的形状、构造、各部分之间的相互位置及连接关系、各部分的作用及工作原理、制造工艺及操作使用方法等，作进一步详细的说明，以帮助本领域技术人员对本发明的发明构思、技术方案有更完整、准确和深入的理解。为方便说明，本申请提及方向以附图所示方向为准。一种蒙语视频智能分析方法，包括以下步骤：步骤S1，数据处理，判断接收数据是否为视频数据，若是，转至步骤S2，若不是，则进行格式转换提取音频数据、蒙语文本信息，提取的音频数据通过音频的转写提取蒙语文本信息，之后将蒙语文本信息翻译成对应的中文文本信息，转至步骤S5；步骤S2，语音信息处理，提取视频数据中的语音信息作出处理；步骤S3，图像信息处理，提取视频数据中的图像信息作出处理；步骤S4，蒙汉文本翻译，通过图像的OCR识别从图像信息提取出蒙语文本信息，通过音频的转写从语音信息提取出蒙语文本信息，将蒙语文本信息翻译成对应的中文文本信息；步骤S5，要素提取，识别中文文本信息所包含的要素信息，包含人名、地名、事务、组织信息，并且根据提取出来的人名、地名、事务进行三元组组合正编出对应的要素组织信息；步骤S6，意图识别，根据中文文本信息的主题、内容和属性，将中文文本信息归到一个或多个类别，识别文本信息中所表达的意图；步骤S7，内容分析预警，系统通过基础库，结合人工经验战法模型，从原声、MD5、声纹、关键词对视频进行打分预警，按照分值高低排序；步骤S8，通用模型研判识别，利用通用模型对视频数据进行研判识别；步骤S9，自建分析研判模型，通过对大数据的事件发生、发展趋势的分析、学习，形成具有针对性的事件分析研判模型，进行进一步研判。通过上述方法，针对蒙语的视频数据进行识别、翻译、检索、监测及管理，大大提升了蒙语视频自动分析能力，降低了人工分析成本，提高了分析效率和实时率。所述步骤S2包括：步骤S21,语音信息预处理，对视频中的音频进行场景分割，判断为音乐、噪音、语音等，抽取其中的语音，方便后续的语音识别处理；语音信息预处理还包括：S211，能量四门限算法，设置“静寂状态”、“语音起始状态”、“语音稳定状态”及“语音衰减状态”四个状态，根据需要可以自行定义范围，并分别设置状态间跳转所需的四个能量门限值，根据视频数据中的音频中每一帧的能量信息，实现四个状态之间的跳转，最终实现音频中能量较高的语音片段的检测；S212，基于规则的噪声判断算法，利用音频的频段能量，对通过了能量四门限算法的信号片段，进行音乐、噪音场景的初判；通过基于规则的初步检测，可以将多数的场景检测出来，但是考虑到具体环境的需求，每一套系统的特定应用环境下，场景情况均不同，所以还需要进行模型分类器判决。S213，模型分类器判决，根据实际系统的应用环境，训练出与实际应用场景中所出现各种场景相匹配的模型；在训练过程中，引入区分性训练，并使用最小分类误差准则，提高场景分辨的效果，从而提高各种场景的匹配精度，得到最终的有效语音。这三个步骤的复杂度依次提升，分别针对不同的场景类型进行检出，最终实现不同的场景分割和检测出其中的语音片段。步骤S22，语音信息语种识别，通过对蒙语语种进行声学模型训练和语言模型训练，对需要处理的视频数据进行语种识别比对，自动识别判断视频数据所属的语种，确认视频数据中的蒙语语种的视频数据片段，能够提高对蒙语的语种识别效率；声学模型训练用于建立蒙语语种语音信息的数据库，包括数据筛选、数据标注、质量复核和抽样复查。声学模型训练具备3000小时的有效数据量。数据筛选的筛选语音为12000小时，折损率按75%计算。数据标注的标注语音为3890小时，折损率按23%计算。质量复核对数据标注后的3890小时数据进行100%全检。抽样复查将质量复核后的数据，抽取20%进行再次检查，检查的数据有600小时，最终形成3000小时有效数据。语言模型训练用于建立蒙语语种文本信息的数据库，与声学模型训练类似，这里不再具体阐述。步骤S23，语音信息转写，对语音信息预处理得到的音乐、噪音、语音，进行端点检测、降噪，提取声学特征；将提取到的声学特征和对语音信息语种识别中识别到的蒙语语种的视频数据，在训练好的声学模型和语言模型训练中，使用解码器进行解码，进行音频文本转换得到蒙语文本信息，能够快速得到蒙语文本信息。所述步骤S3包括：步骤S31，图像信息预处理，筛选是否满足图片的有效性检测，清晰度检测，以及图像的MD5去重功能；筛选是否满足图像增强、图像二值化、图像透视变换、图像边界检测、图像倾斜检测、图像外部块检测、图像内容区域检测；并针对满足检测的图像信息进行二值化、噪声去除、倾斜校正；其中，图像边界检测为黑边检测，用于检测图像边界是否存在黑色区域，图像外部块检测为非本页图像块，用于检测图像是否为同一页。所述二值化用于使图像信息只包含黑色的前景信息和白色的背景信息，从而提升图像信息预处理的效率和精确度；所述噪声去除根据噪声的特征对待识别的图像信息进行去噪处理，从而提升图像信息预处理的精确度；所述倾斜校正用于校正图像方向；由于彩色图像所含信息量过于巨大，在对图像中印刷体字符进行识别处理前，对图像进行二值化处理，使图像只包含黑色的前景信息和白色的背景信息，提升识别处理的效率和精确度。由于待识别图像的品质受限于输入设备、环境、以及文档的印刷质量，在对图像中印刷体字符进行识别处理前，根据噪声的特征对待识别图像进行去噪处理，提升识别处理的精确度。由于扫描和拍摄过程涉及人工操作，输入计算机的待识别图像或多或少都会存在一些倾斜，在对图像中印刷体字符进行识别处理前，进行图像方向检测，并校正图像方向。图像信息预处理的实时率保障一小时处理一百万张图片。步骤S32，图像信息识别，结合具有检测暗、亮的模式确定图像形状，然后用字符识别方法将形状翻译成计算机文字功能的光学字符识别OCR识别服务，利用各种模式识别算法分析文字形态特征，判断出蒙文的标准编码，可以快速提取出图片中包含的蒙古文文本信息，并按通用字符格式存储在文本文档中，并为后续的业务分析提供更多的数据支撑。所述步骤S4包括：步骤S41，分词，将汉字序列切分成词序列。步骤S42，词性标注，给句子中每个词一个词性类别，包括数字和人名，防止数字和人名对翻译产生误导。词性作为对词的一种泛化，在语言识别、句法分析、信息抽取等任务中有重要作用。在翻译中也会利用词性信息，例如对于数字和人名等的翻译，如果仅仅依靠解码器是很难正确翻译的，如果在前处理过程中识别出数字和人名，在翻译时仅仅使用一个占位符，例如数字用$number、人名用$human_name代替，在后处理时再将原词还原就能比较好的处理数字和人名等的翻译。步骤S43，解码器解码，包括传统的基于层次短语的解码器PSMT和基于神经网络的解码器NMT。基于层次短语的解码器PSMT包括翻译模型、语言模型、扭曲模型、调序模型、搜索空间和数线性模型打分，基于层次短语的解码器PSMT用于将句子按照短语进行切分，每个短句分别进行翻译，然后再进行调序；所述搜索空间包括所有切分的短语，并获得所有的翻译假设，所述数线性模型打分对翻译假设打分，并选择得分最高的翻译假设作为翻译结果，从而提高翻译准确度。所述步骤S5中，要素提取通过大数据中的行业领域数据，进行人工领域专家标注，所述的人工领域专家标注包括：词法、句法和语义；基于标注数据训练词法、句法、语义分析的统计模型。词法分析采用条件随机场模型，并结合规则文法，能达到较好的分词效果。句法采用概率上下文无关文法建立统计句法分析模型，并基于动态规划思想设计句法分析算法，并进行分析算法的裁剪策略效率优化。语义基于句法结构树进行语义特征提取，根据带语义标注的数据训练语义消歧模型，结合语义解析规则文法，实现对要素的语义理解。通过上述技术方案，能够最大程度提取视频数据中的有效要素。所述步骤S6中，意图识别支持多类别的组合关键词匹配KWS策略，基于上访的实验原型，能够自定义不同类别的正负组合关键词，能够实现基于规则的关键词匹配；意图识别同时支持KWS、KWP、NB、LDA+SVM和NN五种策略；在进行多策略分类时，意图识别支持上述五种策略的配置使用，每个策略都支持多分类判别，从而提高意图识别的准确度。意图识别的配置方法为先通过多类别文本分类下的多策略得分融合,之后进行综合多策略得分融合，最后配置各个策略的权重，根据权重进行得分融合，从而提高意图识别的准确度。意图识别支持多策略输入输出统一格式,完成不同策略下面统一的输入输出格式定义，特别是输出，定义json格式，输出格式统一；意图识别基于NN策略，实现同时加载多个nn模型，支持配置各个nn模型的的权重和阈值，使用NN策略后计算各个nn模型的得分进行融合结果输出；意图识别基于NN策略能够动态切换使用的nn模型，使用灵活、方便。所述步骤S7包括：步骤S71，人声分离，对视频数据和音频数据中的语音内容进行活动语音监测，识别视频数据和音频数据片段中各部分的噪音，噪音包括静音、白噪音、彩铃，根据监测结果对噪音进行抑制，对有效语音进行增强，然后根据不同说话人的声纹特点进行聚类，最终实现说话人的人声分离，针对互联网音视频说话人数量不确定的特点，这里实现盲分，实现只上传语音，自动识别说话人片段信息；声纹预警，人声分离之后进行视频数据和音频数据的声纹提取和注册，然后将视频数据和音频数据中的声纹信息注册到声纹库中，结合声纹库的预警发现模块，发现跨应用的特定人员，能够提高声纹预警的准确度和效率；由于互联网语音片段一般都比较短，达不到声纹提取的时长要求，这时将多个短音频进行拼接，拼接后才能进行声纹提取。步骤S72，图像预警，基于场景识别和图像语种识别，将获取的图像数据标签化、场景化，对其中涉枪、涉蒙语、涉特定人像的数据进行推送预警；图像预警包括人像预警、蒙文图片的识别预警和涉枪类图片的发现预警；所述人像预警能够建立重点人像的知识库，通过知识库和当前人脸相似度识别引擎实现重点人像的预警；所述蒙文图片的识别预警调用图像OCR和语种识别引擎；所述涉枪类图片的发现预警调用图像类的物体监测引擎；所述图像预警的预警内容包括：人物、人群、游行、枪支、旗帜 、色情、血腥、自焚、烧伤的图片；步骤S73，文本内容预警，通过图像的OCR识别和音频数据的转写，建立关键词的知识库，结合关键词，发现图像中的有害文本信息，在接入视频数据时，对其中的中文、蒙文内容进行识别和提取，并且和关键词的知识库进行比对，所述文本内容预警还采取并行处理，并行处理用于提高文本内容预警的使用效率。所述步骤S8包括：步骤S81，色情内容、场景识别，分成色情、性感、正常三类，通过训练多个网络模型、对特定的用户采用多模型级连判定，对于视频鉴黄，先采用截帧鉴黄，对于疑似的图片，再采用视频片段算法和光流算法，视频片段算法和光流算法用于确认图片内容是否属于色情内容、场景识别，从而提高色情内容、场景识别的效率。步骤S82，暴恐内容智能识别，通过暴恐图片和视频数据源，依托分布式深度学习平台，对图片、视频进行暴恐分类，并对暴恐场景和暴恐物品，所述暴恐场景的识别包括游行、旗帜、台标，所述暴恐物品的识别包括枪支、面具、胡须脸；对于视频数据的处理还提前进行切帧。步骤S83，政治敏感人物智能识别，自动对视频中出现的政治人物进行智能识别，通过对比政治人物人脸的特征，识别出视频图像中是否存在政治人物，如果存在，识别出是谁；政治敏感人物智能识别模型建立政治敏感人像的知识库，通过知识库和当前人脸相似度识别引擎实现政治人像的预警。知识库可以预存入各种重点人物的素材，便于快速进行对比识别。所述步骤S9中，所述自建分析研判模型，基于民警进行各自创建，因为每个民警在分析时使用的技战法是不同的，且各自挖掘方向并不相同，所以自建分析研判模型与各民警关联，打上相应业务属性，说明应用的案件方向，方便自建分析研判模型的精确使用。自建分析研判模型基于不同的数据源，包括两群数据、互联网数据，各自使用不同的技战法进行分析，在呈现时，基于不同的数据类型进行归类展示。自建分析研判模型包括公共模型和私有模型，所有自建分析研判模型能够根据当前使用的成效，发布成文公共模型或者是指定共享至其他民警，既满足各民警的独立使用需求，也将自建分析研判模型共享，便于数据挖掘与分析。自建分析研判模型的最终应用通过设置启用时间和应用数据范围与比对任务、预警分析挂钩，用于主动告警、提醒用户。以上示意性地对本发明及其实施方式进行了描述，该描述没有限制性，附图所示的也只是本发明的实施方式之一，实际的结构并不局限与此。所以，如果本领域的普通技术人员受其启示，在不脱离本发明创造宗旨的情况下，不创造性地设计出与该技术方案相似的结构方式及实施例，均应属于本发明的保护范围。
