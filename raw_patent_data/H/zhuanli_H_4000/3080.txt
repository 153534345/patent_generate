标题title
一种基于深度学习的无人机可见光相机通信方法及其系统
摘要abst
本发明公开了一种基于深度学习的无人机可见光相机通信方法及其系统，包括：发送端使用LED阵列以预先设计的数据帧格式发送数据信息；接收端利用相机捕获LED阵列图像；采用YOLOv5s深度学习算法快速检测出图像中LED阵列位置；结合数据帧格式特点和透视变换算法实现LED的精确定位和状态识别，恢复数据信息；系统包括：发送端、接收端、初步定位模块、精确定位模块、矫正模块和信息获取模块；本发明将深度学习和传统图像处理方法相结合，能够提高无人机可见光相机通信的可靠性，减少系统时延，并且硬件总体造价低，适用于移动设备，易推广。
权利要求书clms
1.一种基于深度学习的无人机可见光相机通信方法，其特征在于，包括以下步骤：S1.至少一个发送端LED阵列以预设的数据帧格式发送光信号；S2.至少一个接收端相机捕获LED阵列发送的光信号，并获取相应的图像；S3.采用YOLOv5s深度学习算法检测图像中LED阵列的位置，并且将得到的预测框按照比例扩大，使预测框完全包含LED阵列；S4.将放大后的预测框区域进行二值化处理，结合数据帧格式特点实现LED阵列的精确定位；S5.使用透视变换算法对精确定位后的LED阵列进行位置矫正；S6.计算LED阵列上的LED灯数量，并且识别每个LED灯的状态，获取光信号对应的数据信息。2.根据权利要求1所述的一种基于深度学习的无人机可见光相机通信方法，其特征在于，S1中，预设的数据帧格式具体包括：定位图形、分割图形和数据位；定位图形，用于接收端在任意方向扫描对LED阵列进行快速精确定位；分隔图形，用于将定位图形与数据位隔开；数据位为LED阵列上除定位图形和分割图形的剩余位置，用于表示发送的数据。3.根据权利要求1所述的一种基于深度学习的无人机可见光相机通信方法，其特征在于，S3中，YOLOv5s深度学习算法的具体内容包括：S31.建立YOLOv5s深度学习模型，输入待检测的图像；S32.提取输入图像的底层特征，获取不同阶段的特征图；S33.融合不同阶段的特征图上不同层次的特征信息，得到融合后的特征图；S34.预测融合后的特征图上LED阵列的类别信息和位置信息；其中类别信息为LED阵列上的LED灯亮或灭的状态信息；S35.通过损失函数LDIoU优化YOLOv5s深度学习模型，其中，损失函数LDIoU为：其中，IoU表示两个预测框交集与并集之比，Bp＝表示预测框，xp,yp,wp,hp分别表示预测框的中心点横坐标、纵坐标、宽度和高度，Bgt＝表示真实框，xgt,ygt,wgt,hgt分别表示真实框的中心点横坐标、纵坐标、宽度和高度，bp＝表示预测框的中心点，bgt＝表示真实框的中心点，ρ表示欧式距离，c表示覆盖两个框的最小外接矩形的对角线长度。4.根据权利要求1所述的一种基于深度学习的无人机可见光相机通信方法，其特征在于，S4中的结合数据帧格式特点实现LED阵列的精确定位的具体内容包括：在包含LED阵列的二值图像的x轴方向上逐行扫描图像边缘点；当扫描到的点连续2个以上为相同像素点时对相同像素点个数进行计数，直至扫描到不同的像素点停止计数，记录相同像素点的个数后继续进行扫描；其中，灰度值小于阈值的像素为黑色像素，灰度值大于阈值的像素为白色像素；根据中的方法依次进行扫描并记录黑色像素个数m1、白色像素个数m2和黑色像素个数m3；当m1:m2:m3满足1:2:1的关系时，记录m2对应的白色像素行的中心点像素坐标y1值，继续扫描下一行，依次得到y2,y3,...,ym；沿图像y轴进行扫描，根据中方法依次记录黑色像素个数n1、白色像素个数n2和黑色像素个数n3，当n1:n2:n3满足1:2:1关系时，依次记录对应的白色像素列的中心点像素坐标x1,x2,x3,...,xn值；计算得到定位图形中心点像素坐标其中，n表示满足条件的像素列数，m表示满足条件的像素行数；再将所获得的定位图形中心点中的任意三个组合成三角形，选取构成等腰直角三角形的组合，作为同属于一个LED阵列上的三个定位图形，以及LED阵列三个角点的像素坐标为：和采用最小二乘法，得到LED阵列上剩余一个角点的像素坐标，完成LED阵列精确定位。5.根据权利要求1所述的一种基于深度学习的无人机可见光相机通信方法，其特征在于，S5的具体内容包括：S51.根据LED阵列4个角点的像素坐标和矫正后角点的像素坐标，计算出透视变换矩阵M：其中w’为变换系数；S52.利用透视变换矩阵M对LED阵列图像进行透视变换，变换后的LED阵列上的像素点坐标：其中a33＝1。6.根据权利要求1所述的一种基于深度学习的无人机可见光相机通信方法，其特征在于，S6的具体内容包括：S61.根据矫正后LED阵列定位图形的中心点之间的水平距离d，角点与定位图形中心点的水平距离r，计算出LED阵列中的LED灯个数N：S62.连接LED阵列的4个角点构成四边形，将四边形进行平均分割，分割后包括N个分格，用每个分格的平均灰度值p表示二进制数据S：7.一种基于深度学习的无人机可见光相机通信系统，基于权利要求1-6任意一项所述的一种基于深度学习的无人机可见光相机通信方法，其特征在于，至少包括一个以上的发送端和接收端，并且还包括初步定位模块、精确定位模块、矫正模块和信息获取模块；其中，发送端为LED阵列，用于以预设的数据帧格式发送光信号；接收端为相机，用于捕获LED阵列发送的光信号，并获取相应的图像；所述初步定位模块，用于通过YOLOv5s深度学习算法检测图像中LED阵列的位置，并且将得到的预测框按照比例扩大，使预测框完全包含LED阵列；精确定位模块，用于将放大后的预测框区域进行二值化处理，结合数据帧格式特点实现LED阵列的精确定位；矫正模块，用于使用透视变换算法对精确定位后的LED阵列进行位置矫正；信息获取模块，用于计算LED阵列上的LED灯数量，并且识别每个LED灯的状态，获取光信号对应的数据信息。8.根据权利要求7所述的一种基于深度学习的无人机可见光相机通信方法，其特征在于，发射端为设置于地面的LED阵列或主无人机上的LED阵列。
说明书desc
技术领域本发明涉及无人机技术领域，更具体的说是涉及一种基于深度学习的无人机可见光相机通信方法及其系统。背景技术无人机是无人驾驶飞行器的统称，已经被广泛应用于环境监测、农业浇灌、快递运输、灾难救援、遥感测绘等领域。无人机与地面、主无人机与辅助无人机之间的高效通信是保证无人机安全飞行的前提，当前主要使用射频通信技术，但该技术存在频谱资源紧缺、易受电磁辐射干扰等问题，并且随着射频通信干扰技术的不断发展，使用单一的射频通信技术已经无法保证通信的可靠性。可见光相机通信是一种以相机作为接收端的光无线通信技术，具有频谱范围广、无射频干扰、视距通信保密性高等特点，能够在一定程度上弥补射频通信技术的缺陷。采用可见光相机通信技术可以使无人机有效的克服射频干扰，在电磁敏感的环境中仍然能正常使用。研究无人机可见光相机通信方法具有一定的现实意义。公开号为CN113726431A的中国专利申请公开了一种基于摄像头辅助的无人机可见光通信装置和方法，该方法中的发送端无人机通过预先存储无人机的形状参数来定位接收端无人机的位置，然后相应的调整LED角度和直径，再向接收端无人机发送信号，而接收端无人机通过接收主控单元来判断信号的状态，获得数据信息。该方案虽然公开了无人机可见光通信的装置和方法，但是并未公开发送端采用的数据帧格式，以及接收端从图像中获得信号的具体方法。公开号为CN1074511A的中国专利申请公开了一种基于可见光视觉通信的无人机协同SLAM方法，该方法通过主无人机携带的LED信号源的高频闪烁来传输协同信息，而辅助无人机利用CMOS摄像头捕获LED发出的光信号，再将得到的条纹图像经过灰度转换、二阶多项式拟合、索贝尔滤波等操作后还原出协同信息，恢复发送的数据。该方案虽然利用可见光同时实现了照明功能和通信功能，并解决了高频闪烁摄像过程中像素饱和溢出造成的明暗条纹区分不清的问题，但是当外界环境较为复杂或通信距离较远时，无法保证通信的可靠性。当可见光相机通信应用于实际场景时，发送端的LED相对于接收端会呈现不同的方向或视角，并且相机捕获的图像中往往包含大量的噪声，这给LED 状态的识别带来了极大的挑战。目前的可见光相机通信一般采用传统图像处理方法或者深度学习方法来检测识别LED。基于传统图像处理的LED检测识别方法设计简单，但抗干扰能力较差，容易受到环境噪声的影响，无法应用于复杂的环境中。而基于深度学习的LED检测识别方法具有较强的鲁棒性，但算法的复杂度一般较高，处理时延较大，无法满足无人机通信的实时性要求。因此，如何提供一种将深度学习和传统图像处理方法相结合的无人机可见光相机通信方法及其系统是本领域技术人员亟需解决的问题。发明内容有鉴于此，本发明提供了一种基于深度学习的无人机可见光相机通信方法及其系统，本发明充分发挥YOLOv5s深度学习算法的速度和精度优势，结合预先设计的数据帧格式进一步快速准确的检测识别LED，实现了高精度、低时延、低成本的无人机可见光相机通信。为了实现上述目的，本发明采用如下技术方案：一种基于深度学习的无人机可见光相机通信方法，包括以下步骤：S1.至少一个发送端LED阵列以预设的数据帧格式发送光信号；S2.至少一个接收端相机捕获LED阵列发送的光信号，并获取相应的图像；S3.采用YOLOv5s深度学习算法检测图像中LED阵列的位置，并且将得到的预测框按照比例扩大，使预测框完全包含LED阵列；S4.将放大后的预测框区域进行二值化处理，结合数据帧格式特点实现 LED阵列的精确定位；S5.使用透视变换算法对精确定位后的LED阵列进行位置矫正；S6.计算LED阵列上的LED灯数量，并且识别每个LED灯的状态，获取光信号对应的数据信息。优选的，S1中，预设的数据帧格式具体包括：定位图形、分割图形和数据位；定位图形，用于接收端在任意方向扫描对LED阵列进行快速精确定位；分隔图形，用于将定位图形与数据位隔开；数据位为LED阵列上除定位图形和分割图形的剩余位置，用于表示发送的数据。优选的，S3中，YOLOv5s深度学习算法的具体内容包括：S31.建立YOLOv5s深度学习模型，输入待检测的图像；S32.提取输入图像的底层特征，获取不同阶段的特征图；S33.融合不同阶段的特征图上不同层次的特征信息，得到融合后的特征图；S34.预测融合后的特征图上LED阵列的类别信息和位置信息；其中类别信息为LED阵列上的LED灯亮或灭的状态信息；S35.通过损失函数LDIoU优化YOLOv5s深度学习模型，其中，损失函数LDIoU为：其中，IoU表示两个预测框交集与并集之比，Bp＝表示预测框，xp,yp,wp,hp分别表示预测框的中心点横坐标、纵坐标、宽度和高度，Bgt＝表示真实框，xgt,ygt,wgt,hgt分别表示真实框的中心点横坐标、纵坐标、宽度和高度，bp＝表示预测框的中心点，bgt＝表示真实框的中心点，ρ表示欧式距离，c表示覆盖两个框的最小外接矩形的对角线长度。优选的，S4中的结合数据帧格式特点实现LED阵列的精确定位的具体内容包括：在包含LED阵列的二值图像的x轴方向上逐行扫描图像边缘点；当扫描到的点连续2个以上为相同像素点时对相同像素点个数进行计数，直至扫描到不同的像素点停止计数，记录相同像素点的个数后继续进行扫描；其中，灰度值小于阈值的像素为黑色像素，灰度值大于阈值的像素为白色像素；根据中的方法依次进行扫描并记录黑色像素个数m1、白色像素个数m2和黑色像素个数m3；当m1:m2:m3满足1:2:1的关系时，记录m2对应的白色像素行的中心点像素坐标y1值，继续扫描下一行，依次得到 y2,y3,...,ym；沿图像y轴进行扫描，根据中方法依次记录黑色像素个数n1、白色像素个数n2和黑色像素个数n3，当n1:n2:n3满足1:2:1关系时，依次记录对应的白色像素列的中心点像素坐标x1,x2,x3,...,xn值；计算得到定位图形中心点像素坐标其中，n表示满足条件的像素列数，m表示满足条件的像素行数；再将所获得的定位图形中心点中的任意三个组合成三角形，选取构成等腰直角三角形的组合，作为同属于一个LED阵列上的三个定位图形，以及LED阵列三个角点的像素坐标为：和采用最小二乘法，得到LED阵列上剩余一个角点的像素坐标，完成LED阵列精确定位。优选的，S5的具体内容包括：S51.根据LED阵列4个角点的像素坐标和矫正后角点的像素坐标 ，计算出透视变换矩阵M：其中w’为变换系数；S52.利用透视变换矩阵M对LED阵列图像进行透视变换，变换后的LED 阵列上的像素点坐标：其中a33＝1。优选的，S6的具体内容包括：S61.根据矫正后LED阵列定位图形的中心点之间的水平距离d，角点与定位图形中心点的水平距离r，计算出LED阵列中的LED灯个数N：S62.连接LED阵列的4个角点构成四边形，将四边形进行平均分割，分割后包括N个分格，用每个分格的平均灰度值p表示二进制数据S：一种基于深度学习的无人机可见光相机通信系统，包括：发送端、接收端、初步定位模块、精确定位模块、矫正模块和信息获取模块；发送端为LED阵列，用于以预设的数据帧格式发送光信号；接收端为相机，用于捕获LED阵列发送的光信号，并获取相应的图像；所述初步定位模块，用于通过YOLOv5s深度学习算法检测图像中LED 阵列的位置，并且将得到的预测框按照比例扩大，使预测框完全包含LED阵列；精确定位模块，用于将放大后的预测框区域进行二值化处理，结合数据帧格式特点实现LED阵列的精确定位；矫正模块，用于使用透视变换算法对精确定位后的LED阵列进行位置矫正；信息获取模块，用于计算LED阵列上的LED灯数量，并且识别每个LED 灯的状态，获取光信号对应的数据信息。优选的，发射端为设置于地面的LED阵列或主无人机上的LED阵列。经由上述的技术方案可知，与现有技术相比，本发明公开提供了一种基于深度学习的无人机可见光相机通信方法及其系统，有益效果如下：本发明将当前性能优越的YOLOv5s深度学习算法和传统图像处理算法相结合，有效的提升了无人机可见光相机通信中LED的定位和识别精度，降低了通信的误码率，减小了系统时延。并且提供的方法占用内存小，适用于移动嵌入式设备，不依赖于价格高昂的显卡设备，硬件总体造价低，便于操作，易于大规模推广；本发明设计的数据帧格式便于高效的检测具有不同LED数量的LED 阵列，能够增强无人机可见光相机通信系统的鲁棒性，即使当LED阵列呈现不同的方向或视角时，仍然能快速准确的获取数据；本发明在无人机通信中采用可见光相机通信技术，不仅可以保证数据信息的安全性，还能使无人机免受射频干扰，在电磁敏感的环境中仍然能正常使用。附图说明为了更清楚地说明本发明实施例或现有技术中的技术方案，下面将对实施例或现有技术描述中所需要使用的附图作简单地介绍，显而易见地，下面描述中的附图仅仅是本发明的实施例，对于本领域普通技术人员来讲，在不付出创造性劳动的前提下，还可以根据提供的附图获得其他的附图。图1为本发明实施例提供的无人机与地面、主无人机与辅助无人机之间的可见光相机通信场景示意图；图2为本发明实施例提供的一种基于深度学习的无人机可见光相机通信方法流程图；图3为本发明实施例提供的数据帧格式示意图：1、2、3为定位图形，4、 5、6为分隔图形，7为数据位；图4为本发明实施例提供的采用透视变换算法矫正LED阵列示意图；图5为本发明实施例提供的LED阵列上每个LED灯的平均灰度值示意图；图6为本发明实施例提供的LED阵列恢复的数据位信息示意图。具体实施方式下面将结合本发明实施例中的附图，对本发明实施例中的技术方案进行清楚、完整地描述，显然，所描述的实施例仅仅是本发明一部分实施例，而不是全部的实施例。基于本发明中的实施例，本领域普通技术人员在没有做出创造性劳动前提下所获得的所有其他实施例，都属于本发明保护的范围。本发明实施例公开了一种基于深度学习的无人机可见光相机通信方法及其系统。在本实施例中，图1无人机与地面、主无人机与辅助无人机之间的可见光相机通信场景示意图。地面或者主无人机为发送端，通过LED阵列闪烁发送数据信息，光信号在可见光信道中传输，接收端无人机使用相机捕获带有 LED阵列的图像，实现无人机的可见光相机通信。本实施例的流程如图2所示，具体步骤如下：步骤一：在发送端的LED阵列上将待发送的数据信息映射成预先设计的数据帧格式，通过LED阵列闪烁发送数据信息。预先设计的数据帧格式如图3所示，图中采用的是16×16的LED阵列，具体包括：定位图形。在LED阵列上的三个角分别放置三个类似于“回”字的图形，如图3中的1、2、3所示。该图形由16个LED灯组成，其中外侧的12 个LED灯为全亮状态，内侧的4个LED灯为全灭状态。使用定位图形后，从任意方向扫描都能快速精确的定位出LED阵列的具体位置；分隔图形。在LED阵列上定位图形的内侧放置类似于“L”型的图形，如图3中的4、5、6所示。该图形由9个LED灯组成且为全灭状态，用于将定位图形与数据位隔开；数据位。LED阵列上的剩余位置用来表示发送的数据，如图3中的 7所示。步骤二：接收端无人机采用相机捕获发送端LED阵列发出的光信号，并在图像传感器上得到相应的图像；步骤三：采用YOLOv5s目标检测算法检测图像中LED阵列的位置，并且将得到的预测框扩大到原来的1.2倍，使其完全包含LED阵列。YOLOv5s目标检测算法的网络具体包括：输入端。将待检测的图像尺寸统一为608×608×3大小，以batch形式输入到网络中；主干网络。由于CSPDarkNet能够有效解决大型网络中梯度重复的问题，减少计算量，本发明将其作为主干网络来提取输入图像的底层特征，并且输出了三个不同阶段的特征图B0、B1和B2；检测颈部。主干网络输出的浅层特征图一般包含目标的局部信息，深层特征图一般包含目标的全局语义信息。本发明采用PANet高效融合不同层次的特征信息；目标检测头。将检测颈部融合后的特征图输入到目标检测头能够得到三种不同尺度的特征图：Out0：76×76×21用于检测小尺寸的LED阵列、 Out1：38×38×21用于检测中等尺寸的LED阵列和Out2：19×19×21用于检测大尺寸的LED阵列；不同于原始的YOLOv5s目标检测算法，本发明采用更加简单，收敛速度更快的DIoU损失函数来优化网络性能。该损失函数通过最小化预测框中心点与真实框中心点的归一化距离实现了比GIoU更快的收敛速度，即使预测框和真实框相互包含也能实现快速精确的回归。DIoU损失函数LDIoU的计算公式如下：其中，IoU表示两个框交集与并集之比，Bp＝表示预测框，xp,yp,wp,hp分别表示预测框的中心点横坐标、纵坐标、宽度和高度，Bgt＝表示真实框，xgt,ygt,wgt,hgt分别表示真实框的中心点横坐标、纵坐标、宽度和高度，bp＝表示预测框的中心点，bgt＝表示真实框的中心点，ρ表示欧式距离，c表示覆盖两个框的最小外接矩形的对角线长度。步骤四：将扩大后的预测框区域进行二值化处理，结合数据帧格式特点实现LED阵列的精确定位，具体包括：在包含LED阵列的二值图像的x轴方向上逐行扫描图像边缘点，当扫描到连续2个以上黑色像素时，记录黑色像素个数，当扫描到白色像素时停止记数，将此时黑色像素个数记为m1，以同样方法依次记录白色像素个数m2和黑色像素个数m3。当 m1:m2:m3满足1:2:1的关系时，记录m2对应的白色像素行的中心点像素坐标y1值，继续扫描下一行，依次得到y2,y3,...,ym；沿图像y轴扫描，当黑色像素个数n1，白色像素个数n2，黑色像素个数n3满足1:2:1关系时，依次记录对应的白色像素列的中心点像素坐标 x1,x2,x3,...,xn值。可以计算出定位图形的中心点像素坐标其中，n表示满足条件的像素列数，m表示满足条件的像素行数；将得到的定位图形中心点的任意三个组合成三角形，找到能够构成等腰直角三角形的组合，即得到了同属于一个LED阵列上的三个定位图形，以及图3中LED阵列左上、左下和右上三个角点的像素坐标：和采用最小二乘法，得到LED阵列右下角点D4的像素坐标，完成 LED阵列的精确定位。步骤五：使用透视变换算法对定位后的LED阵列进行位置矫正，如图4 所示。该过程具体包括：根据LED阵列4个角点的像素坐标和矫正后角点的像素坐标 ，计算出透视变换矩阵M：利用透视变换矩阵M对LED阵列图像进行透视变换，变换后的LED 阵列上的像素点坐标：其中a33＝1。步骤六：计算LED阵列上的LED灯数量，并且识别每个LED状态，得到发送端所发送的数据信息。该过程具体包括：根据透视变换后的LED阵列定位图形间中心点的水平距离d，角点与定位图形中心点的水平距离r，如图3所示，计算出LED阵列中的LED灯个数N：连接LED阵列的4个角点构成四边形，将四边形平均分割为数目为N的网格，用每个格子的平均灰度值p表示二进制数据S：将图3中的数据帧格式以OOK调制方式映射到LED阵列上，得到每个 LED灯的平均灰度值如图5所示，再利用式恢复出数据位的比特信息如 图6所示。一种基于深度学习的无人机可见光相机通信系统，包括：发送端、接收端、初步定位模块、精确定位模块、矫正模块和信息获取模块；发送端为LED阵列，用于以预设的数据帧格式发送光信号；接收端为相机，用于捕获LED阵列发送的光信号，并获取相应的图像；所述初步定位模块，用于通过YOLOv5s深度学习算法检测图像中LED 阵列的位置，并且将得到的预测框按照比例扩大，使预测框完全包含LED阵列；精确定位模块，用于将放大后的预测框区域进行二值化处理，结合数据帧格式特点实现LED阵列的精确定位；矫正模块，用于使用透视变换算法对精确定位后的LED阵列进行位置矫正；信息获取模块，用于计算LED阵列上的LED灯数量，并且识别每个LED 灯的状态，获取光信号对应的数据信息。为了进一步实施上述技术方案，发射端为设置于地面的LED阵列或主无人机上的LED阵列。本说明书中各个实施例采用递进的方式描述，每个实施例重点说明的都是与其他实施例的不同之处，各个实施例之间相同相似部分互相参见即可。对于实施例公开的装置而言，由于其与实施例公开的方法相对应，所以描述的比较简单，相关之处参见方法部分说明即可。对所公开的实施例的上述说明，使本领域专业技术人员能够实现或使用本发明。对这些实施例的多种修改对本领域的专业技术人员来说将是显而易见的，本文中所定义的一般原理可以在不脱离本发明的精神或范围的情况下，在其它实施例中实现。因此，本发明将不会被限制于本文所示的这些实施例，而是要符合与本文所公开的原理和新颖特点相一致的最宽的范围。
