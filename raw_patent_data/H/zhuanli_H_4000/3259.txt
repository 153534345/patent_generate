标题title
一种便携式智能设备裸眼3D图片效果处理方法
摘要abst
本发明公开了一种便携式智能设备裸眼3D图片效果处理方法，包括如下步骤：步骤一：通过所述智能设备采集当前现实场景的2D图片和视频；步骤二：中央处理器将获取的图片进行标准点阵规划，将获取的视频进行解码和视点分割；步骤三：将点阵图形与分割视点进行拼接，获取每个视点的像素参数差、深度参数差、阴影参数差和光亮参数差；步骤四：将每个视点的像素参数差、深度参数差、阴影参数差和光亮参数差补入每个源视点中，计算平均值，生成目标视点；步骤五：将目标视点进行合成，生成3D目标图像视点数据；步骤六：将3D目标图像视点数据导入裸眼3D显示屏的显示界面进行图像显示。本发明可以提高了智能设备裸眼3D图片的成片效果，增加图片的真实感。
权利要求书clms
1.一种便携式智能设备裸眼3D图片效果处理方法，其特征在于，包括如下步骤：步骤一：通过所述智能设备的摄像模块采集当前现实场景的2D图片和视频，并将采集的2D图片和视频发送给智能设备中内置的中央处理器；步骤二：中央处理器将获取的2D图片进行标准点阵规划并生成点阵图形，将获取的视频进行解码，并对解码的图像进行视点分割；步骤三：将生成的2D图片点阵图形与视频的图像分割视点进行拼接，获取图片与图像每个视点的像素参数差、深度参数差、阴影参数差和光亮参数差；步骤四：将每个视点生成的像素参数差、深度参数差、阴影参数差和光亮参数差分别补入图片的每个源视点以及图像的每个源视点中，分别计算图片和图像每个源视点与像素参数差值、深度参数差值和阴影参数差值之间的平均值，生成图片的目标视点和图像的目标视点；步骤五：将生成的图片的目标视点和图像的目标视点进行合成，生成3D目标图像视点数据；步骤六：将3D目标图像视点数据导入智能设备中内置的裸眼3D显示屏的显示界面，根据光栅排列格式对3D目标图像视点数据进行排列分割，得到裸眼3D显示屏每个像素点的显示信号，并通过裸眼3D显示屏进行图像显示。2.如权利要求1所述的一种便携式智能设备裸眼3D图片效果处理方法，其特征在于：所述智能设备为具有摄像功能的手机、平板、电脑、手表、手环中的一种。3.如权利要求2所述的一种便携式智能设备裸眼3D图片效果处理方法，其特征在于：所述摄像模块的摄像头个数不少于2个。4.如权利要求3所述的一种便携式智能设备裸眼3D图片效果处理方法，其特征在于：所述摄像模块采集的视频时长为2s-6s。5.权利要求1-4任一项所述的一种便携式智能设备裸眼3D图片效果处理方法，其特征在于：所述智能设备中还内置有视频解码模块和存储模块；所述视频解码模块用于视频图像的解码；所述存储模块用于存储摄像模块采集的2D图片、视频以及3D目标图像视点数据。6.权利要求5所述的一种便携式智能设备裸眼3D图片效果处理方法，其特征在于：所述视频解码模块对摄像模块采集的视频进行解码后，获得的图像为RGB图像数据。7.如权利要求6所述的一种便携式智能设备裸眼3D图片效果处理方法，其特征在于：所述视频图像解码成RGB图像数据后，以每0.2s-0.5s为间隔进行图像定格，生成多个定格图像数据，并将生成的定格图像数据与获取的2D图片进行对比，取图像重合度最高的定格图像为目标图像进行视点分割。8.如权利要求1-4任一项所述的一种便携式智能设备裸眼3D图片效果处理方法，其特征在于：所述2D图片和视频在进行点阵规划和视点分割后的分辨率与裸眼3D显示屏显示界面的分辨率相同。
说明书desc
技术领域本发明涉及裸眼3D技术领域，特别涉及一种便携式智能设备裸眼3D图片效果处理方法。背景技术随着科技的不断发展，3D显示技术也得到了不断的升级。相对于2D画面，3D画面所显示的图像可以更加立体，图像也不再局限于屏幕的平面上，而是能走出屏幕，让观众拥有身临其境的感觉，因此，3D显示技术也越来越受到人们的欢迎。而随着智能设备的普及，如何将3D显示技术投入到便携式智能设备中使用，使设备显示的图片更加立体生动，已经成为了人们所关注的方向。传统的智能设备为了实现裸眼3D的观看效果，都需要采用特殊的3D显示屏进行使用。但这类智能设备在读取传统的图片时，却不能很好地将普通的2D图片转换为3D图片进行立体展示，图片细节易受到虚化，因此显示的3D图片效果也无法达到精确显示，立体真实感较差。发明内容本发明的目的在于提供一种便携式智能设备裸眼3D图片效果处理方法，以解决上述背景技术中提到的问题。为了达成上述目的，本发明的解决方案为：一种便携式智能设备裸眼3D图片效果处理方法，包括如下步骤：步骤一：通过所述智能设备的摄像模块采集当前现实场景的2D图片和视频，并将采集的2D图片和视频发送给智能设备中内置的中央处理器；步骤二：中央处理器将获取的2D图片进行标准点阵规划并生成点阵图形，将获取的视频进行解码，并对解码的图像进行视点分割；步骤三：将生成的2D图片点阵图形与视频的图像分割视点进行拼接，获取图片与图像每个视点的像素参数差、深度参数差、阴影参数差和光亮参数差；步骤四：将每个视点生成的像素参数差、深度参数差、阴影参数差和光亮参数差分别补入图片的每个源视点以及图像的每个源视点中，分别计算图片和图像每个源视点与像素参数差值、深度参数差值和阴影参数差值之间的平均值，生成图片的目标视点和图像的目标视点；步骤五：将生成的图片的目标视点和图像的目标视点进行合成，生成3D目标图像视点数据；步骤六：将3D目标图像视点数据导入智能设备中内置的裸眼3D显示屏的显示界面，根据光栅排列格式对3D目标图像视点数据进行排列分割，得到裸眼3D显示屏每个像素点的显示信号，并通过裸眼3D显示屏进行图像显示。进一步地，所述智能设备为具有摄像功能的手机、平板、电脑、手表、手环中的一种。更进一步地，所述摄像模块的摄像头个数不少于2个。进一步地，所述摄像模块采集的视频时长为2s-6s。进一步地，所述智能设备中还内置有视频解码模块和存储模块；所述视频解码模块用于视频图像的解码；所述存储模块用于存储摄像模块采集的2D图片、视频以及3D目标图像视点数据。更进一步地，所述视频解码模块对摄像模块采集的视频进行解码后，获得的图像为RGB图像数据。进一步地，所述视频图像解码成RGB图像数据后，以每0.2s-0.5s为间隔进行图像定格，生成多个定格图像数据，并将生成的定格图像数据与获取的2D图片进行对比，取图像重合度最高的定格图像为目标图像进行视点分割。进一步地，所述2D图片和视频在进行点阵规划和视点分割后的分辨率与裸眼3D显示屏显示界面的分辨率相同。本发明对照现有技术的有益效果是：本发明通过获取当前现实场景2D图片和视频，并对获取的图片和视频进行视点分割和对比，提取每个视点的像素参数差、深度参数差、阴影参数差和光亮参数差，并视点生成的像素参数差、深度参数差、阴影参数差和光亮参数差进行补入，使得生成图片的目标视点和图像的目标视点可以更加真实、精确，有效减少数据误差，再通过图片的目标视点和图像的目标视点的合成形成3D目标图像视点数据，最终通过裸眼3D显示屏的显示界面进行显示，可以提高了智能设备裸眼3D图片的成片效果，增加了图片的真实感。附图说明图1为本发明的方法流程图。具体实施方式下面详细描述本发明的实施例，所述实施例的示例在附图中示出，其中自始至终相同或类似的标号表示相同或类似的元件或具有相同或类似功能的元件。下面通过参考附图描述的实施例是示例性的，旨在用于解释本发明，而不能理解为对本发明的限制。实施例一：如图1所示，一种便携式智能设备裸眼3D图片效果处理方法，包括如下步骤：步骤一：通过所述智能设备的摄像模块采集当前现实场景的2D图片和视频，并将采集的2D图片和视频发送给智能设备中内置的中央处理器；本实施例中，所述智能设备为具有摄像功能的手机、平板、电脑、手表、手环中的一种；本实施例中，所述摄像模块的摄像头个数不少于2个；本实施例中，所述摄像模块采集的视频时长为2s-6s；其中，智能设备优选为手机；摄像模块的摄像头个数优选为2个；摄像模块采集的视频时长优选为2s；当智能设备通过摄像模块进行图片和视频的采集后，可以作为基础数据进行分析对比，为后续图片的3D效果呈现提供了足够的数据支撑基础；步骤二：中央处理器将获取的2D图片进行标准点阵规划并生成点阵图形，将获取的视频进行解码，并对解码的图像进行视点分割；步骤三：将生成的2D图片点阵图形与视频的图像分割视点进行拼接，获取图片与图像每个视点的像素参数差、深度参数差、阴影参数差和光亮参数差；步骤四：将每个视点生成的像素参数差、深度参数差、阴影参数差和光亮参数差分别补入图片的每个源视点以及图像的每个源视点中，分别计算图片和图像每个源视点与像素参数差值、深度参数差值和阴影参数差值之间的平均值，生成图片的目标视点和图像的目标视点；步骤五：将生成的图片的目标视点和图像的目标视点进行合成，生成3D目标图像视点数据；本实施例中，所述智能设备中还内置有视频解码模块和存储模块；所述视频解码模块用于视频图像的解码；所述存储模块用于存储摄像模块采集的2D图片、视频以及3D目标图像视点数据；本实施例中，所述视频解码模块对摄像模块采集的视频进行解码后，获得的图像为RGB图像数据；本实施例中，所述视频图像解码成RGB图像数据后，以每0.2s-0.5s为间隔进行图像定格，生成多个定格图像数据，并将生成的定格图像数据与获取的2D图片进行对比，取图像重合度最高的定格图像为目标图像进行视点分割；其中，视频解码模块将视频图像解码成RGB彩色数据，并以每0.2s为间隔进行图像定格，生成多个定格图像数据，使重合度最高的定格图像作为视点分割对象进行视点分割，再对图片点阵图形与视频的图像分割视点进行拼接提取，可以有效减少每个视点的像素参数差、深度参数差、阴影参数差和光亮参数差，进而使得每个视点的像素参数差、深度参数差、阴影参数差和光亮参数差补入图片的每个源视点以及图像的每个源视点中后，有效减少数据误差，并使得计算的平均值可以更为准确，保证生成图片的目标视点和图像的目标视点合成后，获得的3D目标图像视点数据可以拥有良好的画面真实度，减少画面虚化区域；而存储摄像的设置可以用于存储采集的2D图片、视频以及3D目标图像视点数据，保证各项数据的记录需求；步骤六：将3D目标图像视点数据导入智能设备中内置的裸眼3D显示屏的显示界面，根据光栅排列格式对3D目标图像视点数据进行排列分割，得到裸眼3D显示屏每个像素点的显示信号，并通过裸眼3D显示屏进行图像显示；本实施例中，所述2D图片和视频在进行点阵规划和视点分割后的分辨率与裸眼3D显示屏显示界面的分辨率相同；其中，当相同分辨率的3D目标图像视点数据导入裸眼3D显示屏的显示界面后，可以使每个3D目标图像视点与裸眼3D显示屏显示界面的视点一一对应，确保每个3D目标图像视点都可以精准通过裸眼3D显示屏的显示界面进行显示，从而提高了智能设备裸眼3D图片的成片效果，增加了图片的真实感；综上，本发明所提供的一种便携式智能设备裸眼3D图片效果处理方法，通过获取当前现实场景2D图片和视频，并对获取的图片和视频进行视点分割和对比，提取每个视点的像素参数差、深度参数差、阴影参数差和光亮参数差，并视点生成的像素参数差、深度参数差、阴影参数差和光亮参数差进行补入，使得生成图片的目标视点和图像的目标视点可以更加真实、精确，有效减少数据误差，再通过图片的目标视点和图像的目标视点的合成形成3D目标图像视点数据，最终通过裸眼3D显示屏的显示界面进行显示，可以提高了智能设备裸眼3D图片的成片效果，增加了图片的真实感。在本说明书的描述中，参考术语“一个实施例”、“一些实施例”、“示例”、“具体示例”、或“一些示例”等的描述意指结合该实施例或示例描述的具体特征、结构、材料或者特点包含于本发明的至少一个实施例或示例中。在本说明书中，对上述术语的示意性表述不应理解为必须针对的是相同的实施例或示例。而且，描述的具体特征、结构、材料或者特点可以在任何的一个或多个实施例或示例中以合适的方式结合。此外，本领域的技术人员可以将本说明书中描述的不同实施例或示例进行接合和组合。尽管上面已经示出和描述了本发明的实施例，可以理解的是，上述实施例是示例性的，不能理解为对本发明的限制，本领域的普通技术人员在本发明的范围内可以对上述实施例进行变化、修改、替换和变型。
