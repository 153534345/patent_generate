标题title
基于视频图像识别的并行信号处理方法及系统
摘要abst
本发明涉及信号处理领域技术领域，尤其涉及一种基于视频图像识别的并行信号处理方法和系统。该方法包括接收视频图像信息；对所述视频图像的图像信息和声音信息进行识别；对识别之后的声音信息转化为文本信息；在显示屏上目标显示区域显示所述文本信息，该系统包括接收模块、识别模块、转化模块和显示模块。通过对接收视频图像信息的字幕信息和声音信息进行识别，并将声音信息根据语音识别算法转化为文本信息并在显示屏目标显示区域进行显示，实现了电视无字幕视频播放的字幕显示，解决了电视视频播放实时字幕显示存在局限性的问题。
权利要求书clms
1.一种基于视频图像识别的并行信号处理方法，其特征在于，包括：接收视频图像信息；对所述视频图像在目标显示区域的字幕信息和视频图像的声音信息进行识别，若在目标显示区域未能识别出文本信息，则判定所述视频图像不含字幕信息；对识别之后的声音信息转化为文本信息，若在目标显示区域识别出文本信息，则将所述文本信息与所述声音信息识别之后的文本字符进行对比，当所述文本信息与所述声音信息识别之后的文本字符匹配度≥80％时，判定所述文本信息为字幕信息，当所述文本信息与所述声音信息识别之后的文本字符匹配度＜80％时，判定所述文本信息不为字幕信息；在显示屏上目标显示区域显示所述文本信息。2.根据权利要求1所述的基于视频图像识别的并行信号处理方法，其特征在于，在对所述视频图像的声音信息进行识别时，通过深度学习神经网络、声学模型和语言模型对所述声音信息进行识别转化，所述深度学习神经网络用以对声音信息进行编码，得到编码信息，所述声学模型用以对所述编码信息进行解码，得到解码信息，所述语言模型用以对所述解码信息进行识别并输出为文本信息，所述语言模型不仅能够将所述解码信息输出，还能够记录输出文本信息的文本字符间的时间间隔，在所述深度学习神经网络对声音信息进行编码时，对所述声音信息的声音特征进行提取，并将所述声音特征与第一目标声音特征库进行匹配度对比，若所述声音特征与第一目标声音特征库的匹配度≥80％，则判定所述声音特征为人声特征。3.根据权利要求2所述的基于视频图像识别的并行信号处理方法，其特征在于，若所述声音特征与第一目标声音特征库的匹配度＜80％，则判定所述声音特征为非人声特征，所述深度学习神经网络对人声信息正常解码，对非人声特征进一步根据与第二目标声音特征库、第三目标声音特征库和第四目标声音特征库的匹配度进行对比，若所述非人声特征与第二目标声音特征库的匹配度≥80％，则判定所述声音特征为音乐声音特征，若所述非人声特征与第三目标声音特征库的匹配度≥80％，则判定所述声音特征为动物声音特征，若所述非人声特征与第四目标声音特征库的匹配度≥80％，则判定所述声音特征为自然声音特征。4.根据权利要求3所述的基于视频图像识别的并行信号处理方法，其特征在于，在显示屏上目标显示区域显示所述文本信息时，所述目标显示区域设置有最大文本字符数值Nm和文本信息的显示时间，所述最大文本字符数值Nm用以对目标显示区域的文本信息的字符数值进行限制，所述显示时间用以对目标显示区域的文本信息进行时间限制。5.根据权利要求4所述的基于视频图像识别的并行信号处理方法，其特征在于，在对所述文本信息进行显示时，所述文本信息只在目标显示区域进行显示，若所述文本信息的字符数量N≤Nm，则目标显示区域正常显示所述文本信息，若所述文本信息的字符数量N＞Nm，则将所述文本信息进行分段，第一段文本信息的字符数量为Nm，第二段文本信息的字符数量为N-Nm，若所述第二段文本信息字符数量N-Nm＞Nm，则继续对所述第二段文本信息字符进行分段，第三段文本信息字符数量为N-2ⅹNm。6.根据权利要求5所述的基于视频图像识别的并行信号处理方法，其特征在于，在对所述文本信息进行显示时，在文本信息的结尾字符之后的目标显示区域不再显示下一段文本信息，对某一文本信息字符为所述文本信息开始字符或者结尾字符的判定为，所述文本信息中某一文本字符P0与下一个文本字符P1之间的时间间隔为T0，所述文本字符P1与下一个文本字符P2之间的时间间隔为T1，当N≤Nm时，目标显示区域只显示该段文本信息，当N＞Nm时，目标显示区域根据开始字符和结束字符对文本信息进行分段，开始字符和结束字符的判定为，若T1/T0≥2，则文本字符P1为所述文本信息的一个结尾字符，P2为所述文本信息的一个开始字符，若T1/T0＜2，则文本字符P1和文本字符P2均不是开始字符或结尾字符。7.根据权利要求6所述的基于视频图像识别的并行信号处理方法，其特征在于，在对所述文本信息进行显示时，所述文本信息在目标显示区域的显示时间为，若所述文本信息的字符数量N1≤Nm，则所述显示时间为所述文本信息的开始字符和结尾字符之间的时间间隔T2，若所述文本信息的字符数量N2满足Nm＜N2≤2ⅹNm，则将该段文本信息分为两次显示，第一次显示的文本信息字符数量为Nm，第二次显示的文本信息字符数量为N2-Nm，第一次文本信息在所述目标显示区域的显示时间为T3ⅹNm/N2，第二次文本信息在所述目标显示区域的显示时间为T3ⅹ/N2，T3为所述文本信息的开始字符和结尾字符之间的时间间隔，若所述文本信息的字符数量N3满足2ⅹNm＜N3≤3ⅹNm，则将该段文本信息分为三次显示，则第一次显示的文本信息字符数量为Nm，第二次显示的文本信息字符数量为Nm，第三次显示的文本信息字符数量为N3-2ⅹNm，第一次显示的文本信息和第二次显示的文本信息在所述目标显示区域的显示时间相同，均为T4ⅹNm/N3，第三次显示的文本信息在所述目标显示区域的显示时间为T4ⅹ/N3，T4为该段文本信息的开始字符和结尾字符之间的时间间隔，在显示屏上目标显示区域显示非人声特征转化来的文本信息时，目标显示区域直接对非人声特征的种类信息进行显示，所述种类信息包括音乐声、动物叫声和自然声，在显示屏上目标显示区域显示文本信息时，对目标显示区域的视频图像颜色进行识别判定，若目标显示区域的视频图像颜色为白色，则将所述显示文本信息颜色设置为蓝色，若目标显示区域的视频图像颜色不为白色，则将所述显示文本信息颜色设置为白色。8.一种应用于权利要求1-7任一所述的基于视频图像识别的并行信号处理方法的基于视频图像识别的并行信号处理系统，其特征在于，包括：接收模块，用以接收视频图像信息；识别模块，用以对所述视频图像的图像信息和声音信息进行识别；转化模块，用以对识别之后的声音信息转化为文本信息；显示模块，用以对所述文本信息进行显示。9.根据权利要求8所述的基于视频图像识别的并行信号处理系统，其特征在于，所述识别模块包括第一识别单元和第二识别单元，所述第一识别单元用以对所述视频图像目标显示区域的字幕信息进行识别，所述第二识别单元用以对所述视频图像的声音信息进行识别，所述第二识别单元包括深度学习神经网络和声学模型，所述深度学习神经网络用以对声音信息进行编码，得到编码信息，所述声学模型用以对所述编码信息进行解码，得到解码信息。10.根据权利要求9所述的基于视频图像识别的并行信号处理系统，其特征在于，所述转化模块中含有语言模型，用以对所述解码信息进行输出为文本信息，所述显示模块设置有最大文本字符数值Nm和文本信息的显示时间，用以对文本信息的显示数量和显示时间进行限制。
说明书desc
技术领域本发明涉及信号处理领域，尤其涉及一种基于视频图像识别的并行信号处理方法及系统。背景技术电视作为娱乐方式的一种，丰富着人们的生活。但由于并不是所有的电视节目都有字幕，字幕的缺乏严重影响听障人群的观看体验。申请号为CN201811367918.4的专利文献公开了一种字幕添加方法、装置、电子设备及计算机可读存储介质，其中该方法包括：提取待添加字幕的视频文件中的音频信息，并对音频信息进行语音识别，得到音频信息对应的文本信息及语音环境特征，然后依据得到的文本信息及语音环境特征，生成相应的字幕信息，继而将字幕信息添加至视频文件中，以使得视频文件在播放时携带字幕信息。现有技术通过对视频的音频信息进行提取并识别，然后添加到视频文件中，使视频文件播放时携带字幕信息，该方法需要预先对视频进行处理，因此在电视视频播放实时字幕显示中存在局限性。发明内容为此，本发明提供一种基于视频图像识别的并行信号处理方法及系统，可以解决电视视频播放实时字幕显示存在局限性的问题。为实现上述目的，本发明提供一种基于视频图像识别的并行信号处理方法，该方法包括：接收视频图像信息；对所述视频图像在目标显示区域的字幕信息和视频图像的声音信息进行识别，若在目标显示区域未能识别出文本信息，则判定所述视频图像不含字幕信息；对识别之后的声音信息转化为文本信息，若在目标显示区域识别出文本信息，则将所述文本信息与所述声音信息识别之后的文本字符进行对比，当所述文本信息与所述声音信息识别之后的文本字符匹配度≥80％时，判定所述文本信息为字幕信息，当所述文本信息与所述声音信息识别之后的文本字符匹配度＜80％时，判定所述文本信息不为字幕信息；在显示屏上目标显示区域显示所述文本信息。进一步地，在对所述视频图像的声音信息进行识别时，通过深度学习神经网络、声学模型和语言模型对所述声音信息进行识别转化，所述深度学习神经网络用以对声音信息进行编码，得到编码信息，所述声学模型用以对所述编码信息进行解码，得到解码信息，所述语言模型用以对所述解码信息进行识别并输出为文本信息，所述语言模型不仅能够将所述解码信息输出，还能够记录输出文本信息的文本字符间的时间间隔，在所述深度学习神经网络对声音信息进行编码时，对所述声音信息的声音特征进行提取，并将所述声音特征与第一目标声音特征库进行匹配度对比，若所述声音特征与第一目标声音特征库的匹配度≥80％，则判定所述声音特征为人声特征。进一步地，若所述声音特征与第一目标声音特征库的匹配度＜80％，则判定所述声音特征为非人声特征。所述深度学习神经网络对人声信息正常解码，对非人声特征进一步根据与第二目标声音特征库、第三目标声音特征库和第四目标声音特征库的匹配度进行对比，若所述非人声特征与第二目标声音特征库的匹配度≥80％，则判定所述声音特征为音乐声音特征，若所述非人声特征与第三目标声音特征库的匹配度≥80％，则判定所述声音特征为动物声音特征，若所述非人声特征与第四目标声音特征库的匹配度≥80％，则判定所述声音特征为自然声音特征。进一步地，在显示屏上目标显示区域显示所述文本信息时，所述目标显示区域设置有最大文本字符数值Nm和文本信息的显示时间，所述最大文本字符数值Nm用以对目标显示区域的文本信息的字符数值进行限制，所述显示时间用以对目标显示区域的文本信息进行时间限制。进一步地，在对所述文本信息进行显示时，所述文本信息只在目标显示区域进行显示，若所述文本信息的字符数量N≤Nm，则目标显示区域正常显示所述文本信息，若所述文本信息的字符数量N＞Nm，则将所述文本信息进行分段，第一段文本信息的字符数量为Nm，第二段文本信息的字符数量为N-Nm，若所述第二段文本信息字符数量N-Nm＞Nm，则继续对所述第二段文本信息字符进行分段，第三段文本信息字符数量为N-2ⅹNm。进一步地，在对所述文本信息进行显示时，在文本信息的结尾字符之后的目标显示区域不再显示下一段文本信息，对某一文本信息字符为所述文本信息开始字符或者结尾字符的判定为，当N≤Nm时，目标显示区域只显示该段文本信息，当N＞Nm时，目标显示区域根据开始字符和结束字符对文本信息进行分段，开始字符和结束字符的判定为，所述文本信息中某一文本字符P0与下一个文本字符P1之间的时间间隔为T0，所述文本字符P1与下一个文本字符P2之间的时间间隔为T1，若T1/T0≥2，则文本字符P1为所述文本信息的一个结尾字符，P2为所述文本信息的一个开始字符，若T1/T0＜2，则文本字符P1和文本字符P2均不是开始字符或结尾字符。进一步地，在对所述文本信息进行显示时，所述文本信息在目标显示区域的显示时间为，若所述文本信息的字符数量N1≤Nm，则所述显示时间为所述文本信息的开始字符和结尾字符之间的时间间隔T2，若所述文本信息的字符数量N2满足Nm＜N2≤2ⅹNm，则将该段文本信息分为两次显示，第一次显示的文本信息字符数量为Nm，第二次显示的文本信息字符数量为N2-Nm，第一次文本信息在所述目标显示区域的显示时间为T3ⅹNm/N2，第二次文本信息在所述目标显示区域的显示时间为T3ⅹ/N2，T3为所述文本信息的开始字符和结尾字符之间的时间间隔，若所述文本信息的字符数量N3满足2ⅹNm＜N3≤3ⅹNm，则将该段文本信息分为三次显示，则第一次显示的文本信息字符数量为Nm，第二次显示的文本信息字符数量为Nm，第三次显示的文本信息字符数量为N3-2ⅹNm，第一次显示的文本信息和第二次显示的文本信息在所述目标显示区域的显示时间相同，均为T4ⅹNm/N3，第三次显示的文本信息在所述目标显示区域的显示时间为T4ⅹ/N3，T4为该段文本信息的开始字符和结尾字符之间的时间间隔，在显示屏上目标显示区域显示非人声信息转化来的文本信息时，目标显示区域直接对非人声特征的种类信息进行显示，所述种类信息包括音乐声、动物叫声和自然声，在显示屏上目标显示区域显示文本信息时，对目标显示区域的视频图像颜色进行识别判定，若目标显示区域的视频图像颜色为白色，则将所述显示文本信息颜色设置为蓝色，若目标显示区域的视频图像颜色不为白色，则将所述显示文本信息颜色设置为白色。进一步地，本发明还提供了基于视频图像识别的并行信号处理方法的基于视频图像识别的并行信号处理系统，该系统包括：接收模块，用以接收视频图像信息；识别模块，用以对所述视频图像的图像信息和声音信息进行识别；转化模块，用以对识别之后的声音信息转化为文本信息；显示模块，用以对所述文本信息进行显示。进一步地，所述识别模块包括第一识别单元和第二识别单元，所述第一识别单元用以对所述视频图像目标显示区域的字幕信息进行识别，所述第二识别单元用以对所述视频图像的声音信息进行识别，所述第二识别单元包括深度学习神经网络和声学模型，所述深度学习神经网络用以对声音信息进行编码，得到编码信息，所述声学模型用以对所述编码信息进行解码，得到解码信息。进一步地，所述转化模块中含有语言模型，用以对所述解码信息进行输出为文本信息，所述显示模块设置有最大文本字符数值Nm和文本信息的显示时间，用以对文本信息的显示数量和显示时间进行限制。与现有技术相比，本发明的有益效果在于，通过接收视频图像信息，并对所述视频图像的字幕信息和声音信息进行识别，将声音信息根据语音识别算法转化为文本信息并在显示屏目标显示区域进行显示，实现了电视无字幕视频播放的字幕显示，解决了电视视频播放实时字幕显示存在局限性的问题。尤其，通过对视频图像的识别，判定视频图像是否含字幕信息，通过将在目标显示区域的文本信息与声音信息识别之后的文本字符进行对比，实现了对文本信息是否为字幕信息的快速判断，提高了视频图像处理的效率。尤其，通过深度学习神经网络、声学模型和语言模型的综合应用，对视频图像的声音信息进行转化，得到文本信息，在视频播放过程中即可对所述声音信息进行实时的识别转化，提高了信息数据的处理效率。尤其，通过设置最大文本字符数值Nm和文本信息的显示时间来对文本信息的显示进行限制，在满足观看体验的同时缩短显示时间，提高了信息数据的处理效率。尤其，通过对比文本字符间的时间间隔与下一时间间隔的比例关系确定文本字符属性，即是否为开始字符或者结尾字符，而不是直接采用固定的时间间隔来确定文本字符属性，固定的时间间隔会受到不同的声音语境和声音语速的影响，而造成文本字符属性的判断不准确，采用对比文本字符间的时间间隔与下一时间间隔的比例关系来确定文本字符属性提高了确定文本字符属性的准确性，提高了电视机的观看体验。尤其，通过对目标显示区域内字幕信息的显示时间进行控制，不同的声音识别后生成的文本信息具有不同的显示时间，不同的时间显示由声音信息决定，使得文本信息在目标显示区域显示更加贴合语境，提高了观看体验。附图说明图1为本发明实施例提供的基于视频图像识别的并行信号处理方法的流程意图；图2为本发明实施例提供的基于视频图像识别的并行信号处理系统的结构示意图；图3为本发明实施例提供的基于视频图像识别的并行信号处理系统目标显示区域在显示屏上位置的示意图。具体实施方式为了使本发明的目的和优点更加清楚明白，下面结合实施例对本发明作进一步描述；应当理解，此处所描述的具体实施例仅仅用于解释本发明，并不用于限定本发明。下面参照附图来描述本发明的优选实施方式。本领域技术人员应当理解的是，这些实施方式仅仅用于解释本发明的技术原理，并非在限制本发明的保护范围。需要说明的是，在本发明的描述中，术语“上”、“下”、“左”、“右”、“内”、“外”等指示的方向或位置关系的术语是基于附图所示的方向或位置关系，这仅仅是为了便于描述，而不是指示或暗示所述装置或元件必须具有特定的方位、以特定的方位构造和操作，因此不能理解为对本发明的限制。此外，还需要说明的是，在本发明的描述中，除非另有明确的规定和限定，术语“安装”、“相连”、“连接”应做广义理解，例如，可以是固定连接，也可以是可拆卸连接，或一体地连接；可以是机械连接，也可以是电连接；可以是直接相连，也可以通过中间媒介间接相连，可以是两个元件内部的连通。对于本领域技术人员而言，可根据具体情况理解上述术语在本发明中的具体含义。请参阅图1所示，本发明实施例提供一种基于视频图像识别的并行信号处理方法，该方法包括：步骤S110，接收视频图像信息；步骤S120，对所述视频图像在目标显示区域的字幕信息和视频图像的声音信息进行识别，若在目标显示区域未能识别出文本信息，则判定所述视频图像不含字幕信息；步骤S130，对识别之后的声音信息转化为文本信息，若在目标显示区域识别出文本信息，则将所述文本信息与所述声音信息识别之后的文本字符进行对比，当所述文本信息与所述声音信息识别之后的文本字符匹配度≥80％时，判定所述文本信息为字幕信息，当所述文本信息与所述声音信息识别之后的文本字符匹配度＜80％时，判定所述文本信息不为字幕信息；步骤S140，在显示屏上目标显示区域显示所述文本信息。具体而言，本发明实施例接收模块接收视频图像信息，并对所述视频图像的字幕信息和声音信息进行识别，将声音信息根据语音识别算法转化为文本信息并在显示屏目标显示区域进行显示，实现了电视无字幕视频播放的字幕显示，提高了听障人群的观看体验。具体而言，本发明实施例通过对视频图像的识别，判定视频图像是否含字幕信息，通过将在目标显示区域的文本信息与声音信息识别之后的文本字符进行对比，实现了对文本信息是否为字幕信息的快速判断，提高了视频图像处理的效率。具体而言，在对所述视频图像的声音信息进行识别时，通过深度学习神经网络、声学模型和语言模型对所述声音信息进行识别转化，所述深度学习神经网络用以对声音信息进行编码，得到编码信息，所述声学模型用以对所述编码信息进行解码，得到解码信息，所述语言模型用以对所述解码信息进行识别并输出为文本信息，所述语言模型不仅能够将所述解码信息输出，还能够记录输出文本信息的文本字符间的时间间隔。具体而言，本发明实施例通过深度学习神经网络、声学模型和语言模型的综合应用，对视频图像的声音信息进行转化，得到文本信息，在视频播放过程中即可对所述声音信息进行实时的识别转化，提高了信息数据的处理效率。具体而言，在所述深度学习神经网络对声音信息进行编码时，对所述声音信息的声音特征进行提取，并将所述声音特征与第一目标声音特征库进行匹配度对比，若所述声音特征与第一目标声音特征库的匹配度≥80％，则判定所述声音信息为人声信息。具体而言，若所述声音特征与第一目标声音特征库的匹配度＜80％，则判定所述声音信息为非人声信息，所述深度学习神经网络对人声信息正常解码，对非人声信息进一步根据与第二目标声音特征库、第三目标声音特征库和第四目标声音特征库的匹配度进行对比，若所述非人声特征与第二目标声音特征库的匹配度≥80％，则判定所述声音信息为音乐声音信息，若所述非人声特征与第三目标声音特征库的匹配度≥80％，则判定所述声音信息为动物声音信息，若所述非人声特征与第四目标声音特征库的匹配度≥80％，则判定所述声音信息为自然声音信息。具体而言，在显示屏上目标显示区域显示人声信息转化来的文本信息时，所述目标显示区域设置有最大文本字符数值Nm和文本信息的显示时间，所述最大文本字符数值Nm用以对目标显示区域的文本信息的字符数值进行限制，所述显示时间用以对目标显示区域的文本信息进行时间限制。具体而言，本发明实施例通过设置最大文本字符数值Nm和文本信息的显示时间来对文本信息的显示进行限制，在满足观看体验的同时缩短显示时间，提高了信息数据的处理效率。具体而言，在对所述文本信息进行显示时，所述文本信息只在目标显示区域进行显示，若所述文本信息的字符数量N≤Nm，则目标显示区域正常显示所述文本信息，若所述文本信息的字符数量N＞Nm，则将所述文本信息进行分段，第一段文本信息的字符数量为Nm，第二段文本信息的字符数量为N-Nm，若所述第二段文本信息字符数量N-Nm＞Nm，则继续对所述第二段文本信息字符进行分段，第三段文本信息字符数量为N-2ⅹNm。具体而言，在对所述文本信息进行显示时，在文本信息的结尾字符之后的目标显示区域不再显示下一段文本信息，对某一文本信息字符为所述文本信息开始字符或者结尾字符的判定为，所述文本信息中某一文本字符P0与下一个文本字符P1之间的时间间隔为T0，所述文本字符P1与下一个文本字符P2之间的时间间隔为T1，当N≤Nm时，目标显示区域只显示该段文本信息，当N＞Nm时，目标显示区域根据开始字符和结束字符对文本信息进行分段，开始字符和结束字符的判定为，所述文本信息中某一文本字符P0与下一个文本字符P1之间的时间间隔为T0，所述文本字符P1与下一个文本字符P2之间的时间间隔为T1，若T1/T0≥2，则文本字符P1为所述文本信息的一个结尾字符，P2为所述文本信息的一个开始字符，若T1/T0＜2，则文本字符P1和文本字符P2均不是开始字符或结尾字符。具体而言，本发明实施例通过对比文本字符间的时间间隔与下一时间间隔的比例关系确定文本字符属性，即是否为开始字符或者结尾字符，而不是直接采用固定的时间间隔来确定文本字符属性，固定的时间间隔会受到不同的声音语境和声音语速的影响，而造成文本字符属性的判断不准确，采用对比文本字符间的时间间隔与下一时间间隔的比例关系来确定文本字符属性提高了确定文本字符属性的准确性，提高了电视机的观看体验。具体而言，在对所述文本信息进行显示时，所述文本信息在目标显示区域的显示时间为，若所述文本信息的字符数量N1≤Nm，则所述显示时间为所述文本信息的开始字符和结尾字符之间的时间间隔T2，若所述文本信息的字符数量N2满足Nm＜N2≤2ⅹNm，则将该段文本信息分为两次显示，第一次显示的文本信息字符数量为Nm，第二次显示的文本信息字符数量为N2-Nm，第一次文本信息在所述目标显示区域的显示时间为T3ⅹNm/N2，第二次文本信息在所述目标显示区域的显示时间为T3ⅹ/N2，T3为所述文本信息的开始字符和结尾字符之间的时间间隔，若所述文本信息的字符数量N3满足2ⅹNm＜N3≤3ⅹNm，则将该段文本信息分为三次显示，则第一次显示的文本信息字符数量为Nm，第二次显示的文本信息字符数量为Nm，第三次显示的文本信息字符数量为N3-2ⅹNm，第一次显示的文本信息和第二次显示的文本信息在所述目标显示区域的显示时间相同，均为T4ⅹNm/N3，第三次显示的文本信息在所述目标显示区域的显示时间为T4ⅹ/N3，T4为该段文本信息的开始字符和结尾字符之间的时间间隔。具体而言，本发明实施例通过对目标显示区域内字幕信息的显示时间进行控制，不同的声音识别后生成的文本信息具有不同的显示时间，不同的时间显示由声音信息决定，使得文本信息在目标显示区域显示更加贴合语境，提高了观看体验。具体而言，在显示屏上目标显示区域显示非人声信息转化来的文本信息时，目标显示区域直接对非人声信息的种类信息进行显示，所述种类信息包括音乐声、动物叫声和自然声。具体而言，在显示屏上目标显示区域显示文本信息时，对目标显示区域的视频图像颜色进行识别判定，若目标显示区域的视频图像颜色为白色，则将所述显示文本信息颜色设置为蓝色，若目标显示区域的视频图像颜色不为白色，则将所述显示文本信息颜色设置为白色。请参阅图2所示，本发明实施例还提供应用于基于视频图像识别的并行信号处理方法的基于视频图像识别的并行信号处理系统，该系统包括：接收模块210，用以接收视频图像信息；识别模块220，用以对所述视频图像的图像信息和声音信息进行识别；转化模块230，用以对识别之后的声音信息转化为文本信息；显示模块230，用以对所述文本信息进行显示。具体而言，所述识别模块包括第一识别单元和第二识别单元，所述第一识别单元用以对所述视频图像目标显示区域的字幕信息进行识别，所述第二识别单元用以对所述视频图像的声音信息进行识别。具体而言，所述第二识别单元包括深度学习神经网络和声学模型，所述深度学习神经网络用以对声音信息进行编码，得到编码信息，所述声学模型用以对所述编码信息进行解码，得到解码信息。具体而言，所述转化模块中含有语言模型，用以对所述解码信息进行输出为文本信息。具体而言，所述显示模块设置有最大文本字符数值Nm和文本信息的显示时间，用以对文本信息的显示数量和显示时间进行限制。请参阅图3所示，本发明实施例提供的基于视频图像识别的并行信号处理系统的目标显示区域的位置在显示屏310的底部位置区域320，所述显示屏310的长度为L，宽度为W，所述目标显示区域320的长度为0.8ⅹL，宽度为0.125ⅹW，所述目标显示区域320的底边距显示屏310的底边的距离为0.07ⅹW，所述目标显示区域320在长度方向上位于显示屏310长度方向的居中位置。至此，已经结合附图所示的优选实施方式描述了本发明的技术方案，但是，本领域技术人员容易理解的是，本发明的保护范围显然不局限于这些具体实施方式。在不偏离本发明的原理的前提下，本领域技术人员可以对相关技术特征做出等同的更改或替换，这些更改或替换之后的技术方案都将落入本发明的保护范围之内。以上所述仅为本发明的优选实施例，并不用于限制本发明；对于本领域的技术人员来说，本发明可以有各种更改和变化。凡在本发明的精神和原则之内，所作的任何修改、等同替换、改进等，均应包含在本发明的保护范围之内。
