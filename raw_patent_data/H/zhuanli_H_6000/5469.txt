标题title
视频防抖拼接方法、装置、设备及存储介质
摘要abst
本申请涉及深度学习技术领域，公开了一种视频防抖拼接方法、装置、设备及存储介质。所述方法包括：通过手持设备进行视频拍摄，得到第一视频数据并采集得到手持部位压力分布数据以及多轴加速度信号数据；计算多个像素位移数据；进行分布强度和特征提取，得到压力分布特征集并进行运动特征提取，得到加速度运动特征集；进行特征融合，得到目标融合特征集；进行时序关联分析和矩阵转换，得到位移特征关系矩阵；通过视频防抖补偿模型进行视频防抖补偿参数分析，得到目标视频防抖补偿参数并进行防抖处理和视频拼接，得到第二视频数据，本申请实现了智能化的视频防抖拼接并提高了视频的防抖显示效果。
权利要求书clms
1.一种视频防抖拼接方法，其特征在于，所述视频防抖拼接方法包括：通过预置的手持设备进行视频拍摄，得到第一视频数据，并对所述手持设备进行手持部位压力分布采集和多轴加速度信号采集，得到手持部位压力分布数据以及多轴加速度信号数据；对所述第一视频数据进行视频帧分割，得到多个初始视频帧，并计算所述多个初始视频帧中相邻两帧之间的像素位移，得到多个像素位移数据；对所述手持部位压力分布数据进行分布强度和特征提取，得到压力分布特征集，并对所述多轴加速度信号数据进行运动特征提取，得到加速度运动特征集；对所述压力分布特征集以及所述加速度运动特征集进行相关系数计算，得到目标相关系数，并根据所述目标相关系数对所述压力分布特征集以及所述加速度运动特征集进行特征融合，得到目标融合特征集；对所述多个像素位移数据和所述目标融合特征集进行时序关联分析和矩阵转换，得到位移特征关系矩阵；将所述位移特征关系矩阵输入预置的视频防抖补偿模型进行视频防抖补偿参数分析，得到目标视频防抖补偿参数，并根据所述目标视频防抖补偿参数对所述多个初始视频帧进行防抖处理和视频拼接，得到第二视频数据。2.根据权利要求1所述的视频防抖拼接方法，其特征在于，所述通过预置的手持设备进行视频拍摄，得到第一视频数据，并对所述手持设备进行手持部位压力分布采集和多轴加速度信号采集，得到手持部位压力分布数据以及多轴加速度信号数据，包括：通过预置的手持设备进行视频拍摄，得到原始视频流数据，并对所述原始视频流数据进行颜色校正，得到第一视频数据；对所述手持设备进行手持部位压力分布采集，得到多个初始压力分布数据，并对所述多个初始压力分布数据进行平均压力计算，得到手持部位压力分布数据；对所述手持设备进行多轴加速度信号采集，得到x轴的第一加速度数据、y轴的第二加速度数据以及z轴的第三加速度数据；通过预置的多轴加速度计算函数对所述x轴的第一加速度数据、所述y轴的第二加速度数据以及z轴的所述第三加速度数据进行多轴加速度计算，得到初始多轴加速度数据，所述多轴加速度计算函数为：，a表示初始多轴加速度数据，ax表示x轴的第一加速度数据，ay表示y轴的第二加速度数据，az表示z轴的第三加速度数据，对所述初始多轴加速度数据进行傅里叶信号变换，得到多轴加速度信号数据。3.根据权利要求1所述的视频防抖拼接方法，其特征在于，所述对所述第一视频数据进行视频帧分割，得到多个初始视频帧，并计算所述多个初始视频帧中相邻两帧之间的像素位移，得到多个像素位移数据，包括：对所述第一视频数据进行图像变化率计算，得到图像变化率数据；根据所述图像变化率数据对所述第一视频数据进行平滑过渡处理，得到标准视频数据；对所述标准视频数据进行视频帧分割，得到多个初始视频帧；对所述多个初始视频帧进行画面中心识别，得到每个初始视频帧的画面中心像素点，并根据所述画面中心像素点构建每个初始视频帧的初始像素云图；基于K次近邻算法对每个初始像素云图中的画面中心像素点进行临近点识别，得到每个初始视频帧的K个最近邻点；分别计算所述K个最近邻点与每个初始视频帧的画面中心像素点之间的距离，得到多个第一点距，并对所述多个第一点距进行均值运算，得到每个初始视频帧的第二点距；根据所述第二点距对所述多个初始视频帧中的相邻两帧进行像素位移计算，得到多个像素位移数据。4.根据权利要求1所述的视频防抖拼接方法，其特征在于，所述对所述手持部位压力分布数据进行分布强度和特征提取，得到压力分布特征集，并对所述多轴加速度信号数据进行运动特征提取，得到加速度运动特征集，包括：通过预置的压力积分函数，对所述手持部位压力分布数据进行压力积分，得到累积压力分布强度，所述压力积分函数为：，/＞表示累积压力分布强度，表示手持部位压力分布数据，/＞表示时间；对所述累积压力分布强度进行曲线拟合，得到压力分布强度曲线，并对所述压力分布强度曲线进行曲线特征识别，得到多个第一压力分布特征；对所述多个第一压力分布特征进行特征标准化处理，得到多个第二压力分布特征，并对所述多个第二压力分布特征进行集合转换，得到压力分布特征集；对所述多轴加速度信号数据进行曲线拟合，得到加速度变化曲线，并对所述加速度变化曲线进行曲线特征识别，得到多个第一加速度运动特征；对所述多个第一加速度运动特征进行特征标准化处理，得到多个第二加速度运动特征，并对所述多个第二加速度运动特征进行集合转换，得到加速度运动特征集。5.根据权利要求1所述的视频防抖拼接方法，其特征在于，所述对所述压力分布特征集以及所述加速度运动特征集进行相关系数计算，得到目标相关系数，并根据所述目标相关系数对所述压力分布特征集以及所述加速度运动特征集进行特征融合，得到目标融合特征集，包括：对所述压力分布特征集进行均值计算，得到压力分布特征均值，并对所述压力分布特征集进行标准差计算，得到压力分布特征标准差；对所述加速度运动特征集进行均值计算，得到加速度运动特征均值，并对所述加速度运动特征集进行标准差计算，得到加速度运动特征标准差；根据所述压力分布特征均值、所述压力分布特征标准差、所述加速度运动特征均值以及所述加速度运动特征标准差，对所述压力分布特征集以及所述加速度运动特征集进行相关系数计算，得到目标相关系数；根据所述目标相关系数对所述压力分布特征集以及所述加速度运动特征集进行特征转换，得到多个目标压力分布特征以及多个目标加速度运动特征；对所述多个目标压力分布特征以及所述多个目标加速度运动特征进行特征集合融合，得到目标融合特征集。6.根据权利要求5所述的视频防抖拼接方法，其特征在于，所述对所述多个像素位移数据和所述目标融合特征集进行时序关联分析和矩阵转换，得到位移特征关系矩阵，包括：获取所述多个像素位移数据的第一时间戳数据，并获取所述目标融合特征集的第二时间戳数据；根据所述第一时间戳数据和所述第二时间戳数据对所述多个像素位移数据和所述目标融合特征集进行时序关联分析和对应匹配，得到每个像素位移数据与目标融合特征集的对应关系；根据所述对应关系，对所述多个像素位移数据和所述目标融合特征集进行矩阵转换，得到位移特征关系矩阵，所述位移特征关系矩阵包括多个三维列向量，每个三维列向量依次包括像素位移数据、目标压力分布特征以及目标加速度运动特征。7.根据权利要求6所述的视频防抖拼接方法，其特征在于，所述将所述位移特征关系矩阵输入预置的视频防抖补偿模型进行视频防抖补偿参数分析，得到目标视频防抖补偿参数，并根据所述目标视频防抖补偿参数对所述多个初始视频帧进行防抖处理和视频拼接，得到第二视频数据，包括：将所述位移特征关系矩阵输入预置的视频防抖补偿模型，所述视频防抖补偿模型包括卷积长短时记忆网络、单层长短时记忆网络以及全连接层；通过所述卷积长短时记忆网络对所述位移特征关系矩阵进行深层次特征运算，得到深层次特征关系矩阵；通过所述单层长短时记忆网络对所述深层次特征关系矩阵进行隐藏特征分析，得到目标特征关系矩阵；通过所述全连接层中的ReLU函数对所述目标特征关系矩阵进行视频防抖补偿参数计算，得到目标视频防抖补偿参数；根据所述目标视频防抖补偿参数对所述多个初始视频帧进行防抖处理，得到多个目标视频帧；对所述多个目标视频帧进行视频拼接，得到第二视频数据。8.一种视频防抖拼接装置，其特征在于，所述视频防抖拼接装置包括：采集模块，用于通过预置的手持设备进行视频拍摄，得到第一视频数据，并对所述手持设备进行手持部位压力分布采集和多轴加速度信号采集，得到手持部位压力分布数据以及多轴加速度信号数据；计算模块，用于对所述第一视频数据进行视频帧分割，得到多个初始视频帧，并计算所述多个初始视频帧中相邻两帧之间的像素位移，得到多个像素位移数据；特征提取模块，用于对所述手持部位压力分布数据进行分布强度和特征提取，得到压力分布特征集，并对所述多轴加速度信号数据进行运动特征提取，得到加速度运动特征集；特征融合模块，用于对所述压力分布特征集以及所述加速度运动特征集进行相关系数计算，得到目标相关系数，并根据所述目标相关系数对所述压力分布特征集以及所述加速度运动特征集进行特征融合，得到目标融合特征集；转换模块，用于对所述多个像素位移数据和所述目标融合特征集进行时序关联分析和矩阵转换，得到位移特征关系矩阵；处理模块，用于将所述位移特征关系矩阵输入预置的视频防抖补偿模型进行视频防抖补偿参数分析，得到目标视频防抖补偿参数，并根据所述目标视频防抖补偿参数对所述多个初始视频帧进行防抖处理和视频拼接，得到第二视频数据。9.一种视频防抖拼接设备，其特征在于，所述视频防抖拼接设备包括：存储器和至少一个处理器，所述存储器中存储有指令；所述至少一个处理器调用所述存储器中的所述指令，以使得所述视频防抖拼接设备执行如权利要求1-7中任一项所述的视频防抖拼接方法。10.一种计算机可读存储介质，所述计算机可读存储介质上存储有指令，其特征在于，所述指令被处理器执行时实现如权利要求1-7中任一项所述的视频防抖拼接方法。
说明书desc
技术领域本申请涉及深度学习技术领域，尤其涉及一种视频防抖拼接方法、装置、设备及存储介质。背景技术手持设备拍摄的视频常常面临晃动和抖动问题，导致观看体验不佳，降低了视频质量。此外，要在不同场景和拍摄条件下实现稳定的视频拼接也是一个挑战。因此，研究视频防抖和拼接方法变得至关重要，以提高视频质量并增强用户体验。然而，当前视频防抖和拼接技术仍然存在一些问题。现有的防抖方法往往依赖于软件后期处理，需要额外的计算资源和时间，不够实时和高效。其次，对于视频拼接，不同场景和条件下的手持拍摄导致视频之间的不连贯性，难以实现自然的切换和过渡。发明内容本申请提供了一种视频防抖拼接方法、装置、设备及存储介质，用于实现了智能化的视频防抖拼接并提高了视频的防抖显示效果。第一方面，本申请提供了一种视频防抖拼接方法，所述视频防抖拼接方法包括：通过预置的手持设备进行视频拍摄，得到第一视频数据，并对所述手持设备进行手持部位压力分布采集和多轴加速度信号采集，得到手持部位压力分布数据以及多轴加速度信号数据；对所述第一视频数据进行视频帧分割，得到多个初始视频帧，并计算所述多个初始视频帧中相邻两帧之间的像素位移，得到多个像素位移数据；对所述手持部位压力分布数据进行分布强度和特征提取，得到压力分布特征集，并对所述多轴加速度信号数据进行运动特征提取，得到加速度运动特征集；对所述压力分布特征集以及所述加速度运动特征集进行相关系数计算，得到目标相关系数，并根据所述目标相关系数对所述压力分布特征集以及所述加速度运动特征集进行特征融合，得到目标融合特征集；对所述多个像素位移数据和所述目标融合特征集进行时序关联分析和矩阵转换，得到位移特征关系矩阵；将所述位移特征关系矩阵输入预置的视频防抖补偿模型进行视频防抖补偿参数分析，得到目标视频防抖补偿参数，并根据所述目标视频防抖补偿参数对所述多个初始视频帧进行防抖处理和视频拼接，得到第二视频数据。第二方面，本申请提供了一种视频防抖拼接装置，所述视频防抖拼接装置包括：采集模块，用于通过预置的手持设备进行视频拍摄，得到第一视频数据，并对所述手持设备进行手持部位压力分布采集和多轴加速度信号采集，得到手持部位压力分布数据以及多轴加速度信号数据；计算模块，用于对所述第一视频数据进行视频帧分割，得到多个初始视频帧，并计算所述多个初始视频帧中相邻两帧之间的像素位移，得到多个像素位移数据；特征提取模块，用于对所述手持部位压力分布数据进行分布强度和特征提取，得到压力分布特征集，并对所述多轴加速度信号数据进行运动特征提取，得到加速度运动特征集；特征融合模块，用于对所述压力分布特征集以及所述加速度运动特征集进行相关系数计算，得到目标相关系数，并根据所述目标相关系数对所述压力分布特征集以及所述加速度运动特征集进行特征融合，得到目标融合特征集；转换模块，用于对所述多个像素位移数据和所述目标融合特征集进行时序关联分析和矩阵转换，得到位移特征关系矩阵；处理模块，用于将所述位移特征关系矩阵输入预置的视频防抖补偿模型进行视频防抖补偿参数分析，得到目标视频防抖补偿参数，并根据所述目标视频防抖补偿参数对所述多个初始视频帧进行防抖处理和视频拼接，得到第二视频数据。本申请第三方面提供了一种视频防抖拼接设备，包括：存储器和至少一个处理器，所述存储器中存储有指令；所述至少一个处理器调用所述存储器中的所述指令，以使得所述视频防抖拼接设备执行上述的视频防抖拼接方法。本申请的第四方面提供了一种计算机可读存储介质，所述计算机可读存储介质中存储有指令，当其在计算机上运行时，使得计算机执行上述的视频防抖拼接方法。本申请提供的技术方案中，通过采集手持设备的多轴加速度信号数据和压力分布数据，能够更准确地分析和补偿相机运动，从而实现高效的视频防抖。这有助于减少视频中的晃动和抖动，提高视频的稳定性和观赏性。利用相关系数计算和特征融合，可以根据不同情况自适应地调整视频拼接过程。可以根据拍摄场景和条件来优化视频拼接，以获得更自然和连贯的视频流。通过对像素位移数据和目标特征之间的时序关联分析，可以更好地理解视频帧之间的关系。这有助于确保视频拼接的连贯性和流畅性，减少不连贯的过渡。通过综合利用多种数据源，包括加速度数据、压力分布数据和像素位移数据，能够提高视频的质量。这包括减少模糊、抖动、颜色偏差等问题，提供更清晰、稳定和自然的视频输出。采用卷积长短时记忆网络等深度神经网络技术进行深层次的特征提取和分析，从而能够更精确地理解视觉和感知数据之间的关联性。不仅能够减少晃动，还能够处理更复杂的场景和动态条件。通过使用先进的深度学习技术，能够自动分析、编辑和优化视频内容。用户不再需要手动编辑和调整视频，而是能够获得高度自动化和智能化的视频后期处理，进而实现了智能化的视频防抖拼接并提高了视频的防抖显示效果。附图说明为了更清楚地说明本发明实施例的技术方案，下面将对实施例描述中所需要使用的附图作简单地介绍，显而易见地，下面描述中的附图是本发明的一些实施例，对于本领域普通技术人员来讲，在不付出创造性劳动的前提下，还可以基于这些附图获得其他的附图。图1为本申请实施例中视频防抖拼接方法的一个实施例示意图；图2为本申请实施例中视频防抖拼接装置的一个实施例示意图。具体实施方式本申请实施例提供了一种视频防抖拼接方法、装置、设备及存储介质。本申请的说明书和权利要求书及上述附图中的术语“第一”、“第二”、“第三”、“第四”等是用于区别类似的对象，而不必用于描述特定的顺序或先后次序。应该理解这样使用的数据在适当情况下可以互换，以便这里描述的实施例能够以除了在这里图示或描述的内容以外的顺序实施。此外，术语“包括”或“具有”及其任何变形，意图在于覆盖不排他的包含，例如，包含了一系列步骤或单元的过程、方法、系统、产品或设备不必限于清楚地列出的那些步骤或单元，而是可包括没有清楚地列出的或对于这些过程、方法、产品或设备固有的其它步骤或单元。为便于理解，下面对本申请实施例的具体流程进行描述，请参阅图1，本申请实施例中视频防抖拼接方法的一个实施例包括：步骤S101、通过预置的手持设备进行视频拍摄，得到第一视频数据，并对手持设备进行手持部位压力分布采集和多轴加速度信号采集，得到手持部位压力分布数据以及多轴加速度信号数据；可以理解的是，本申请的执行主体可以为视频防抖拼接装置，还可以是终端或者服务器，具体此处不做限定。本申请实施例以服务器为执行主体为例进行说明。具体的，通过预置的手持设备进行视频拍摄，得到原始视频流数据。为了提高视频质量并确保色彩的准确性和一致性，对这些原始视频流数据进行颜色校正，从而得到更为准确和稳定的第一视频数据。颜色校正可以通过各种算法实现，例如白平衡调整和色彩空间转换，以适应不同的光照条件和设备特性。对手持部位压力分布进行采集。通过在设备的手持部位集成压力传感器，连续记录在使用过程中的压力变化。采集到的多个初始压力分布数据通过平均压力计算进行处理，从而得到更为稳定和可靠的手持部位压力分布数据。这个数据不仅反映了用户握持设备的方式，而且还可以用来推断视频拍摄过程中的稳定性和用户的移动模式。对设备进行多轴加速度信号采集。这包括收集x轴的第一加速度数据、y轴的第二加速度数据以及z轴的第三加速度数据。这些数据提供了关于设备在三维空间中移动方向和速度的重要信息。通过预置的多轴加速度计算函数，综合三个方向上的加速度数据，形成初始多轴加速度数据。多轴加速度计算函数是基于物理模型的算法，能够准确计算出设备在空间中的综合加速度矢量。对初始多轴加速度数据进行傅里叶信号变换，将时间域信号转换为频域信号，揭示出信号的频率成分。获得的多轴加速度信号数据不仅提供了设备在空间中运动的详细描述，还包括了频率信息。步骤S102、对第一视频数据进行视频帧分割，得到多个初始视频帧，并计算多个初始视频帧中相邻两帧之间的像素位移，得到多个像素位移数据；具体的，对第一视频数据进行图像变化率计算，评估视频中每一帧图像与前一帧图像变化程度，得到图像变化率数据。这些数据反映了视频中图像变化的快慢和幅度。对第一视频数据进行平滑过渡处理，以减少视频拍摄中的突然或剧烈变化，这有助于稳定视频内容，使其更加适合分析和处理，进而得到标准视频数据。将标准视频数据进行视频帧分割，将视频分解成多个初始视频帧，这些帧是防抖和拼接处理的基础。分割后，对每个初始视频帧进行画面中心识别，确定每一帧的画面中心像素点。基于画面中心像素点，构建每个初始视频帧的初始像素云图，这些像素云图详细描述了每一帧的像素分布情况。通过K次近邻算法对每个初始像素云图中的画面中心像素点进行临近点识别，识别出每个初始视频帧的K个最近邻点。分别计算这K个最近邻点与每个初始视频帧的画面中心像素点之间的距离，即第一点距，并对这些第一点距进行均值运算，得到每个初始视频帧的第二点距。这个第二点距是衡量画面中心附近像素点分布稳定性和一致性的重要指标。基于得到的第二点距数据，对多个初始视频帧中相邻两帧进行像素位移计算，以确定一帧与下一帧之间的相对移动情况。这些像素位移数据提供了必要的信息来调整每一帧的位置和方向，以减少或消除视频抖动，进而获得更加平稳和连贯的视频效果。步骤S103、对手持部位压力分布数据进行分布强度和特征提取，得到压力分布特征集，并对多轴加速度信号数据进行运动特征提取，得到加速度运动特征集；具体的，通过预置的压力积分函数对手持部位压力分布数据进行压力积分，该函数通过积分过程计算出一段时间内的累积压力分布强度。这一过程基于压力随时间变化的积分模型，反映了用户手持设备时的压力变化情况。得到的累积压力分布强度不仅提供了压力变化的总体情况，还能够揭示拍摄过程中手持稳定性的变化趋势。对累积压力分布强度进行曲线拟合，以生成更为平滑且易于分析的压力分布强度曲线。这一曲线反映了压力变化的趋势和模式。通过对压力分布强度曲线进一步的曲线特征识别，可以得到多个第一压力分布特征，这些特征包括峰值、波动频率和变化趋势等。为了确保这些特征具有普遍的比较和分析价值，对它们进行特征标准化处理，将不同量级或单位的特征转换成统一的标准形式，然后进行集合转换，整合成为一个综合的压力分布特征集。同样，对多轴加速度信号数据进行分析。通过曲线拟合得到反映设备运动变化的加速度变化曲线。这些曲线描绘了设备在各个方向上加速度的变化情况。对加速度变化曲线进行曲线特征识别，从中提取出多个第一加速度运动特征。这些特征包括加速度的极值、变化率和周期性等。接着，对第一加速度运动特征进行特征标准化处理，以确保不同的特征可以在同一标准下进行比较和分析。将这些第二加速度运动特征进行集合转换，整合成一个全面的加速度运动特征集。这个特征集不仅反映了设备在三维空间中的运动特性，还能够与压力分布特征集相结合，提供一个全方位的视角来理解和分析手持拍摄过程中的稳定性问题。步骤S104、对压力分布特征集以及加速度运动特征集进行相关系数计算，得到目标相关系数，并根据目标相关系数对压力分布特征集以及加速度运动特征集进行特征融合，得到目标融合特征集；具体的，计算压力分布特征集的均值，这一均值反映了用户手持设备时压力分布的平均水平。同时，进行标准差计算，得到压力分布特征标准差，这一标准差揭示了压力分布特征在均值周围的波动程度，反映了压力分布的稳定性和一致性。同样，通过计算加速度运动特征的均值和标准差，可以得到反映设备运动状态的基本统计量。加速度运动特征均值提供了设备运动强度的平均水平，而加速度运动特征标准差则反映了这些运动特征的波动程度。根据所得到的压力分布特征均值、压力分布特征标准差、加速度运动特征均值以及加速度运动特征标准差进行相关系数计算。相关系数是衡量两组数据间线性相关程度的统计量，能够揭示压力分布特征和加速度运动特征之间的关系强度和方向。通过这一计算，可以得到目标相关系数，这一系数直接影响后续的特征融合过程。根据所得的目标相关系数，对压力分布特征集和加速度运动特征集进行特征转换，从而得到多个目标压力分布特征和多个目标加速度运动特征。通过调整特征的比重、合并相似特征或排除噪声特征等操作，提炼和优化特征集，使其更适合于后续的融合和分析。将多个目标压力分布特征和多个目标加速度运动特征进行特征集合融合。通过综合考虑压力分布和加速度运动的相关性，整合两者的信息，形成一个全面反映手持稳定性和设备运动状态的目标融合特征集。步骤S105、对多个像素位移数据和目标融合特征集进行时序关联分析和矩阵转换，得到位移特征关系矩阵；具体的，获取多个像素位移数据的第一时间戳数据以及获取目标融合特征集的第二时间戳数据。时间戳数据确保了后续处理步骤能够在正确的时间点上同步并关联不同类型的数据。根据这些时间戳对多个像素位移数据和目标融合特征集进行时序关联分析和对应匹配，形成一个清晰的对应关系，将时间序列数据转换为有用信息。接着，对多个像素位移数据和目标融合特征集进行矩阵转换。将时序关联的数据组织成位移特征关系矩阵的形式。位移特征关系矩阵不仅能够将多维数据整合在一起，还能够为后续的计算和分析提供方便的数学表达形式。在这个矩阵中，每个三维列向量都依次包含了相应的像素位移数据、目标压力分布特征以及目标加速度运动特征。步骤S106、将位移特征关系矩阵输入预置的视频防抖补偿模型进行视频防抖补偿参数分析，得到目标视频防抖补偿参数，并根据目标视频防抖补偿参数对多个初始视频帧进行防抖处理和视频拼接，得到第二视频数据。具体的，将位移特征关系矩阵输入预置的视频防抖补偿模型。这个模型是一个由多个层次组成的深度学习框架，包括卷积长短时记忆网络、单层长短时记忆网络以及全连接层。通过卷积长短时记忆网络对位移特征关系矩阵进行深层次特征运算，提取出视频数据中复杂且深层的时空特征，得到一个更加精细化的深层次特征关系矩阵。通过单层长短时记忆网络对深层次特征关系矩阵进行进一步的分析，通过其独特的记忆能力，能够有效处理和分析时间序列数据，揭示出隐藏在深层次特征关系矩阵中的时序特征和模式。通过这一分析，得到目标特征关系矩阵，这个矩阵更加准确地捕捉到了视频帧之间的动态关联和变化趋势。通过全连接层中的ReLU激活函数对目标特征关系矩阵进行处理，计算出视频防抖补偿参数。ReLU函数以其非线性和稀疏激活特性，在深度学习中被广泛用于增加模型的复杂性和非线性能力。通过这一层的计算，可以得到一组既精确又实用的目标视频防抖补偿参数，这些参数是接下来进行实际防抖处理的关键。对多个初始视频帧进行防抖处理。根据目标视频防抖补偿参数，通过相应的算法调整每一帧的位置和姿态，以减少或消除抖动带来的影响，得到多个目标视频帧。这些经过防抖处理的视频帧将具有更高的稳定性和连贯性。将多个目标视频帧进行视频拼接，通过特定的拼接技术和算法，将这些稳定的视频帧组合成一个连续流畅的第二视频数据。这个视频数据不仅在视觉上更加稳定和流畅，而且保留了原始视频内容的完整性和连贯性。本申请实施例中，通过采集手持设备的多轴加速度信号数据和压力分布数据，能够更准确地分析和补偿相机运动，从而实现高效的视频防抖。这有助于减少视频中的晃动和抖动，提高视频的稳定性和观赏性。利用相关系数计算和特征融合，可以根据不同情况自适应地调整视频拼接过程。可以根据拍摄场景和条件来优化视频拼接，以获得更自然和连贯的视频流。通过对像素位移数据和目标特征之间的时序关联分析，可以更好地理解视频帧之间的关系。这有助于确保视频拼接的连贯性和流畅性，减少不连贯的过渡。通过综合利用多种数据源，包括加速度数据、压力分布数据和像素位移数据，能够提高视频的质量。这包括减少模糊、抖动、颜色偏差等问题，提供更清晰、稳定和自然的视频输出。采用卷积长短时记忆网络等深度神经网络技术进行深层次的特征提取和分析，从而能够更精确地理解视觉和感知数据之间的关联性。不仅能够减少晃动，还能够处理更复杂的场景和动态条件。通过使用先进的深度学习技术，能够自动分析、编辑和优化视频内容。用户不再需要手动编辑和调整视频，而是能够获得高度自动化和智能化的视频后期处理，进而实现了智能化的视频防抖拼接并提高了视频的防抖显示效果。在一具体实施例中，执行步骤S101的过程可以具体包括如下步骤：通过预置的手持设备进行视频拍摄，得到原始视频流数据，并对原始视频流数据进行颜色校正，得到第一视频数据；对手持设备进行手持部位压力分布采集，得到多个初始压力分布数据，并对多个初始压力分布数据进行平均压力计算，得到手持部位压力分布数据；对手持设备进行多轴加速度信号采集，得到x轴的第一加速度数据、y轴的第二加速度数据以及z轴的第三加速度数据；通过预置的多轴加速度计算函数对x轴的第一加速度数据、y轴的第二加速度数据以及z轴的第三加速度数据进行多轴加速度计算，得到初始多轴加速度数据，多轴加速度计算函数为：，a表示初始多轴加速度数据，ax表示x轴的第一加速度数据，ay表示y轴的第二加速度数据，az表示z轴的第三加速度数据，对初始多轴加速度数据进行傅里叶信号变换，得到多轴加速度信号数据。具体的，通过预置的手持设备进行视频拍摄，得到原始视频流数据，这些数据是未经处理的，包含由于光线条件、设备限制等因素造成的色彩偏差。对原始视频流数据进行颜色校正，通过调整色彩平衡、对比度和亮度等参数来优化视频质量。对手持设备的手持部位进行压力分布采集。在设备的手持部位集成压力传感器，这些传感器能够实时监测和记录用户握持设备时的压力变化。通过收集多个初始压力分布数据，能够了解用户握持的稳定性以及分析握持方式对视频稳定性的影响。对初始压力分布数据进行平均压力计算，得到更加准确和全面的手持部位压力分布数据。对手持设备进行多轴加速度信号采集，这包括在x、y和z轴上测量设备的加速度。通过测量x轴的第一加速度数据、y轴的第二加速度数据以及z轴的第三加速度数据，全面捕捉设备在三维空间中的运动情况。接着，通过预置的多轴加速度计算函数进行加工处理。这个函数通过计算加速度向量的大小来综合x、y、z三轴的加速度信息，从而得到一个代表整体运动强度的初始多轴加速度数据。对初始多轴加速度数据进行傅里叶信号变换，将时域信号转换为频域信号，揭示出信号的频率成分。通过这种变换识别出视频中的震动频率和强度。例如，如果用户在拍摄时手部发抖，这种震动会在加速度信号的频域中产生特定的模式。通过分析这些模式，系统能够精确地调整视频以补偿这些抖动，从而实现更平稳的视频效果。在一具体实施例中，执行步骤S102的过程可以具体包括如下步骤：对第一视频数据进行图像变化率计算，得到图像变化率数据；根据图像变化率数据对第一视频数据进行平滑过渡处理，得到标准视频数据；对标准视频数据进行视频帧分割，得到多个初始视频帧；对多个初始视频帧进行画面中心识别，得到每个初始视频帧的画面中心像素点，并根据画面中心像素点构建每个初始视频帧的初始像素云图；基于K次近邻算法对每个初始像素云图中的画面中心像素点进行临近点识别，得到每个初始视频帧的K个最近邻点；分别计算K个最近邻点与每个初始视频帧的画面中心像素点之间的距离，得到多个第一点距，并对多个第一点距进行均值运算，得到每个初始视频帧的第二点距；根据第二点距对多个初始视频帧中的相邻两帧进行像素位移计算，得到多个像素位移数据。具体的，通过分析视频帧之间的差异，采用如像素差异、光流法或其他图像处理技术，对第一视频数据进行图像变化率计算。图像变化率数据反映了视频中的运动和变化速度，是后续平滑过渡处理和帧分割的重要依据。例如，如果一个视频片段中的场景从静止突然切换到快速移动，那么图像变化率会在这一点上出现显著的峰值。根据图像变化率数据对第一视频数据进行平滑过渡处理，减少视频中的突兀变化和噪声，使视频内容变得更加平滑和连贯。平滑过程可以通过各种滤波器如高斯模糊、均值滤波或中值滤波来实现，目的是降低图像变化率中的尖峰和波动，从而得到标准视频数据。例如，如果原始视频在某一帧中出现了快速移动导致的模糊，通过平滑过渡处理可以在一定程度上减少这种模糊，使场景变得更加清晰。对标准视频数据进行视频帧分割，将连续的视频流分解成一系列独立的初始视频帧。每个视频帧都是一个静态的图像，代表了视频在特定时间点的视觉内容。视频帧分割通常涉及到解码视频数据流，并按照特定的帧率提取单独的帧。通过图像处理技术如边缘检测、区域分割或图像矩计算，对初始视频帧进行画面中心识别。画面中心像素点是每个视频帧的视觉中心，是后续分析的重要参考点。并根据画面中心像素点构建初始像素云图。像素云图是一个二维的点集，代表了视频帧中的像素分布情况，可以用来分析帧内的结构和运动。为了进一步分析这些像素云图，采用K次近邻算法对每个初始像素云图中的画面中心像素点进行临近点识别。K次近邻算法是一种基于距离的算法，它可以识别出与画面中心像素点最接近的K个像素点。这些最近邻点提供了关于画面中心周围像素分布的重要信息，有助于理解视频帧的内容和结构。分别计算K个最近邻点与每个初始视频帧的画面中心像素点之间的距离，得到多个第一点距。这些第一点距反映了画面中心周围像素点的分布情况。为了得到更加稳定和可靠的分析结果，对多个第一点距进行均值运算，从而得到每个初始视频帧的第二点距。这个第二点距是一个综合指标，它平均了画面中心周围像素点的分布情况，可以更准确地反映视频帧的稳定性和运动特征。根据第二点距对多个初始视频帧中的相邻两帧进行像素位移计算，以此得到多个像素位移数据。像素位移数据是衡量视频帧之间运动变化的关键指标，它们反映了相邻帧之间的运动速度和方向。通过这些数据，可以精确地识别出视频中的运动模式和趋势，这有助于后续的视频防抖处理和拼接。在一具体实施例中，执行步骤S103的过程可以具体包括如下步骤：通过预置的压力积分函数，对手持部位压力分布数据进行压力积分，得到累积压力分布强度，压力积分函数为：，/＞表示累积压力分布强度，/＞表示手持部位压力分布数据，/＞表示时间；对累积压力分布强度进行曲线拟合，得到压力分布强度曲线，并对压力分布强度曲线进行曲线特征识别，得到多个第一压力分布特征；对多个第一压力分布特征进行特征标准化处理，得到多个第二压力分布特征，并对多个第二压力分布特征进行集合转换，得到压力分布特征集；对多轴加速度信号数据进行曲线拟合，得到加速度变化曲线，并对加速度变化曲线进行曲线特征识别，得到多个第一加速度运动特征；对多个第一加速度运动特征进行特征标准化处理，得到多个第二加速度运动特征，并对多个第二加速度运动特征进行集合转换，得到加速度运动特征集。具体的，通过预置的压力积分函数对手持部位压力分布数据进行积分计算。将连续的压力数据转换成累积压力分布强度，提供一个全面的压力变化视图。具体地，这个积分函数通过对压力分布数据进行时间积分，从而得到表示总压力负荷的值。例如，如果用户在使用设备时不断加大握持力度，积分值会随着时间的增加而增大，反映出压力的累积效果。对累积压力分布强度进行曲线拟合。通过数学模型如多项式拟合、指数平滑或其他曲线拟合技术，将离散的数据点转换成一个连续的压力分布强度曲线。这条曲线更直观地显示了压力如何随时间变化。例如，如果用户在拍摄视频时手部稳定，则压力分布强度曲线将相对平坦；反之，如果用户手部颤抖，曲线将显示出更多的波动。对压力分布强度曲线进行曲线特征识别，提取描述压力变化的关键信息。这些第一压力分布特征包括曲线的峰值、均值、波动范围和频率等，它们共同描绘了压力分布的综合特性。为了使这些特征更具有比较性和一致性，进行特征标准化处理，将不同量级或单位的特征转换到同一标准下，然后进行集合转换，整合成为一个综合的压力分布特征集。同时，对多轴加速度信号数据进行分析，将离散的加速度数据点转换成连续的加速度变化曲线。这些曲线提供了设备运动状态的直观描述，显示了加速度如何随时间变化。对加速度变化曲线进行曲线特征识别，提取描述运动状态的关键信息。这些第一加速度运动特征包括加速度曲线的极值、变化速率和周期性等，它们共同反映了设备的运动特性和稳定性。对这些特征进行特征标准化处理和集合转换，形成一个全面的加速度运动特征集。在一具体实施例中，执行步骤S104的过程可以具体包括如下步骤：对压力分布特征集进行均值计算，得到压力分布特征均值，并对压力分布特征集进行标准差计算，得到压力分布特征标准差；对加速度运动特征集进行均值计算，得到加速度运动特征均值，并对加速度运动特征集进行标准差计算，得到加速度运动特征标准差；根据压力分布特征均值、压力分布特征标准差、加速度运动特征均值以及加速度运动特征标准差，对压力分布特征集以及加速度运动特征集进行相关系数计算，得到目标相关系数；根据目标相关系数对压力分布特征集以及加速度运动特征集进行特征转换，得到多个目标压力分布特征以及多个目标加速度运动特征；对多个目标压力分布特征以及多个目标加速度运动特征进行特征集合融合，得到目标融合特征集。具体的，对压力分布特征集进行统计分析，包括均值和标准差的计算。均值计算提供了压力分布特征的平均水平，是衡量整体压力趋势的一个重要指标。标准差计算提供了压力分布特征的波动程度，反映了各数据点相对于均值的分散情况。高标准差意味着压力分布特征点间的差异较大，反之则较小。同样，对加速度运动特征集进行统计分析，包括均值和标准差的计算。加速度运动特征均值反映了设备运动状态的平均强度，而加速度运动特征标准差则显示了运动强度的变化范围和不确定性。例如，一个在平稳环境中静止拍摄的设备其加速度运动特征均值将接近于零，标准差也很小；而在剧烈移动或抖动的情况下，均值和标准差都会相应增大。进行相关系数计算。相关系数是衡量两组数据间线性关系强度和方向的统计指标，通过计算压力分布特征均值、标准差、加速度运动特征均值以及标准差之间的相关性，可以得到反映这两组特征集之间关联度的目标相关系数。根据计算得到的目标相关系数，对压力分布特征集和加速度运动特征集进行特征转换，以便更好地反映它们之间的关联性。这个转换过程包括调整特征权重、合并相似特征或排除噪声特征等操作，旨在提炼和优化特征集，使其更适合于后续的分析和应用。例如，如果某个压力分布特征与加速度运动特征之间存在很强的相关性，则这两个特征可以合并为一个综合特征，以简化模型并提高分析效率。将目标压力分布特征和目标加速度运动特征进行特征集合融合，形成一个综合的目标融合特征集。这个融合过程整合了压力分布和加速度运动的相关信息，提供了一个全方位的视角来理解和分析手持设备的稳定性和运动状态。通过这个综合特征集，可以更准确地识别和预测视频中的抖动现象，为视频防抖处理和拼接提供支持。例如，如果目标融合特征集显示某段视频中的压力和加速度特征突然变化，系统可以据此判断视频出现抖动，并相应调整防抖算法以消除这些抖动效果。在一具体实施例中，执行步骤S105的过程可以具体包括如下步骤：获取多个像素位移数据的第一时间戳数据，并获取目标融合特征集的第二时间戳数据；根据第一时间戳数据和第二时间戳数据对多个像素位移数据和目标融合特征集进行时序关联分析和对应匹配，得到每个像素位移数据与目标融合特征集的对应关系；根据对应关系，对多个像素位移数据和目标融合特征集进行矩阵转换，得到位移特征关系矩阵，位移特征关系矩阵包括多个三维列向量，每个三维列向量依次包括像素位移数据、目标压力分布特征以及目标加速度运动特征。具体的，获取多个像素位移数据的第一时间戳数据，并获取目标融合特征集的第二时间戳数据。时间戳数据确保了数据可以被准确地同步和对齐。根据第一时间戳数据和第二时间戳数据对多个像素位移数据和目标融合特征集进行时序关联分析和对应匹配。通过比较和对齐不同数据源的时间戳，以确保视频帧中的像素位移数据和传感器记录的压力分布特征、加速度运动特征能够准确匹配。通过时序关联分析，构建出每个像素位移数据与目标融合特征集之间的对应关系。根据对应关系，对多个像素位移数据和目标融合特征集进行矩阵转换。将时序对应的数据组织成位移特征关系矩阵的形式，以便于进行进一步的分析和处理。位移特征关系矩阵是一个复杂的数据结构，它包含多个三维列向量，每个列向量依次包括相应的像素位移数据、目标压力分布特征以及目标加速度运动特征。在一具体实施例中，执行步骤S106的过程可以具体包括如下步骤：将位移特征关系矩阵输入预置的视频防抖补偿模型，视频防抖补偿模型包括卷积长短时记忆网络、单层长短时记忆网络以及全连接层；通过卷积长短时记忆网络对位移特征关系矩阵进行深层次特征运算，得到深层次特征关系矩阵；通过单层长短时记忆网络对深层次特征关系矩阵进行隐藏特征分析，得到目标特征关系矩阵；通过全连接层中的ReLU函数对目标特征关系矩阵进行视频防抖补偿参数计算，得到目标视频防抖补偿参数；根据目标视频防抖补偿参数对多个初始视频帧进行防抖处理，得到多个目标视频帧；对多个目标视频帧进行视频拼接，得到第二视频数据。具体的，将位移特征关系矩阵输入预置的视频防抖补偿模型中。该模型是一个深度学习网络，它由卷积长短时记忆网络、单层长短时记忆网络以及全连接层组成。这些组件共同工作，通过深度学习的方法从位移特征关系矩阵中提取出有用的信息，并计算出用于视频防抖的补偿参数。通过在卷积神经网络的基础上引入LSTM结构，ConvLSTM能够有效地捕捉时间序列数据中的空间特征和时间依赖性。当位移特征关系矩阵被输入到ConvLSTM时，网络会对其进行深层次的特征运算，提取出描述视频帧之间运动和变化的复杂特征。这些特征被组织成一个深层次特征关系矩阵。将深层次特征关系矩阵输入单层长短时记忆网络。LSTM是一种特殊的循环神经网络，能够学习长期依赖信息，适合处理和预测时间序列数据中的重要事件。LSTM对深层次特征关系矩阵进行进一步的隐藏特征分析，挖掘出更深层次的时间关联和模式，这些信息被编码成目标特征关系矩阵。通过全连接层中的ReLU函数对目标特征关系矩阵进行视频防抖补偿参数计算。ReLU函数是一个非线性函数，它可以增加网络的非线性特性而不影响神经元之间的相对排序，从而帮助网络学习复杂的特征。在这一层，对目标特征关系矩阵进行视频防抖补偿参数计算，输出一组用于后续防抖处理的参数。对多个初始视频帧进行防抖处理。调整视频帧的位置和方向，以补偿由于手部抖动或其他因素导致的不期望的运动。通过应用计算得到的补偿参数，每个视频帧都会被调整到一个更稳定的状态，从而得到一系列经过防抖处理的目标视频帧。对多个目标视频帧进行视频拼接，创建出一个连续流畅的第二视频数据。视频拼接过程需要精确地对齐和融合各个视频帧，确保转换过程中的连贯性和视觉效果。通过这一过程，将抖动而不稳定的视频转换成一个更加平稳和高质量的视频流。上面对本申请实施例中视频防抖拼接方法进行了描述，下面对本申请实施例中视频防抖拼接装置进行描述，请参阅图2，本申请实施例中视频防抖拼接装置一个实施例包括：采集模块201，用于通过预置的手持设备进行视频拍摄，得到第一视频数据，并对所述手持设备进行手持部位压力分布采集和多轴加速度信号采集，得到手持部位压力分布数据以及多轴加速度信号数据；计算模块202，用于对所述第一视频数据进行视频帧分割，得到多个初始视频帧，并计算所述多个初始视频帧中相邻两帧之间的像素位移，得到多个像素位移数据；特征提取模块203，用于对所述手持部位压力分布数据进行分布强度和特征提取，得到压力分布特征集，并对所述多轴加速度信号数据进行运动特征提取，得到加速度运动特征集；特征融合模块204，用于对所述压力分布特征集以及所述加速度运动特征集进行相关系数计算，得到目标相关系数，并根据所述目标相关系数对所述压力分布特征集以及所述加速度运动特征集进行特征融合，得到目标融合特征集；转换模块205，用于对所述多个像素位移数据和所述目标融合特征集进行时序关联分析和矩阵转换，得到位移特征关系矩阵；处理模块206，用于将所述位移特征关系矩阵输入预置的视频防抖补偿模型进行视频防抖补偿参数分析，得到目标视频防抖补偿参数，并根据所述目标视频防抖补偿参数对所述多个初始视频帧进行防抖处理和视频拼接，得到第二视频数据。通过上述各个组成部分的协同合作，通过采集手持设备的多轴加速度信号数据和压力分布数据，能够更准确地分析和补偿相机运动，从而实现高效的视频防抖。这有助于减少视频中的晃动和抖动，提高视频的稳定性和观赏性。利用相关系数计算和特征融合，可以根据不同情况自适应地调整视频拼接过程。可以根据拍摄场景和条件来优化视频拼接，以获得更自然和连贯的视频流。通过对像素位移数据和目标特征之间的时序关联分析，可以更好地理解视频帧之间的关系。这有助于确保视频拼接的连贯性和流畅性，减少不连贯的过渡。通过综合利用多种数据源，包括加速度数据、压力分布数据和像素位移数据，能够提高视频的质量。这包括减少模糊、抖动、颜色偏差等问题，提供更清晰、稳定和自然的视频输出。采用卷积长短时记忆网络等深度神经网络技术进行深层次的特征提取和分析，从而能够更精确地理解视觉和感知数据之间的关联性。不仅能够减少晃动，还能够处理更复杂的场景和动态条件。通过使用先进的深度学习技术，能够自动分析、编辑和优化视频内容。用户不再需要手动编辑和调整视频，而是能够获得高度自动化和智能化的视频后期处理，进而实现了智能化的视频防抖拼接并提高了视频的防抖显示效果。本申请还提供一种视频防抖拼接设备，所述视频防抖拼接设备包括存储器和处理器，存储器中存储有计算机可读指令，计算机可读指令被处理器执行时，使得处理器执行上述各实施例中的所述视频防抖拼接方法的步骤。本申请还提供一种计算机可读存储介质，该计算机可读存储介质可以为非易失性计算机可读存储介质，该计算机可读存储介质也可以为易失性计算机可读存储介质，所述计算机可读存储介质中存储有指令，当所述指令在计算机上运行时，使得计算机执行所述视频防抖拼接方法的步骤。所属领域的技术人员可以清楚地了解到，为描述的方便和简洁，上述描述的系统，系统和单元的具体工作过程，可以参考前述方法实施例中的对应过程，在此不再赘述。所述集成的单元如果以软件功能单元的形式实现并作为独立的产品销售或使用时，可以存储在一个计算机可读取存储介质中。基于这样的理解，本申请的技术方案本质上或者说对现有技术做出贡献的部分或者该技术方案的全部或部分可以以软件产品的形式体现出来，该计算机软件产品存储在一个存储介质中，包括若干指令用以使得一台计算机设备执行本申请各个实施例所述方法的全部或部分步骤。而前述的存储介质包括：U盘、移动硬盘、只读存储器、随机存取存储器、磁碟或者光盘等各种可以存储程序代码的介质。以上所述，以上实施例仅用以说明本申请的技术方案，而非对其限制；尽管参照前述实施例对本申请进行了详细的说明，本领域的普通技术人员应当理解：其依然可以对前述各实施例所记载的技术方案进行修改，或者对其中部分技术特征进行等同替换；而这些修改或者替换，并不使相应技术方案的本质脱离本申请各实施例技术方案的精神和范围。
