标题title
一种智能布控球及其布控方法
摘要abst
本申请涉及布控球技术领域，提供一种智能布控球及其布控方法，智能布控球包括热成像装置、拍摄装置、KA200类脑芯片和布控监测装置；拍摄装置和布控监测装置分别与KA200类脑芯片连接，KA200类脑芯片用于控制拍摄装置和布控监测装置；布控监测装置包括高空作业人员行为识别单元、终端浏览行为识别单元、车辆异常停放识别单元、垃圾混扔行为识别单元、第一环境真伪识别单元、第二环境真伪识别单元和目标跟踪单元。本申请提供的智能布控球实现当通过内置的异常识别模块识别到异常情况时，可通过水平旋转或俯仰旋转调整拍摄装置，再对拍摄装置进行变焦镜头调节焦距，实现对异常情况的精准拍摄。
权利要求书clms
1.一种智能布控球，其特征在于，包括热成像装置、拍摄装置、KA200类脑芯片和布控监测装置；所述拍摄装置和所述布控监测装置分别与所述所述KA200类脑芯片连接，所述KA200类脑芯片用于控制所述拍摄装置和所述布控监测装置；所述布控监测装置包括高空作业人员行为识别单元、终端浏览行为识别单元、车辆异常停放识别单元、垃圾混扔行为识别单元、第一环境真伪识别单元、第二环境真伪识别单元和目标跟踪单元；所述拍摄装置用于：采集视频流数据；所述热成像装置用于：采集点云数据；所述高空作业人员行为识别单元用于：获取所述拍摄装置的当前时刻位置信息、当前时刻镜头姿态信息和镜头参数信息，以及所述视频流数据中指定高空区域的当前时刻影像；基于所述当前时刻位置信息、所述当前时刻镜头姿态信息、所述镜头参数信息以及所述指定高空区域中监控目标所在区域的地理位置信息和数字高程模型数据，在所述当前时刻影像中标记所述监控目标所在区域；对所述监控目标所在区域进行高空作业人员行为识别，在确定所述监控目标所在区域内存在高空作业人员，则采集所述高空作业人员的人体框、人脸框和安全帽框，并将人体框、人脸框和安全帽框显示在监控界面；所述终端浏览行为识别单元用于：对所述视频流数据中的每一帧视频图像进行终端浏览行为识别布控，得到每一帧视频图像的头部位置区域和手部位置区域，并根据所述头部位置区域和所述手部位置区域，识别出用户是否存在浏览终端设备行为；所述车辆异常停放识别单元用于：对所述视频流数据中的每一帧视频图像进行车辆异常停放识别布控，得到每一帧视频图像的车辆停放检测框和停车区域检测框，并根据所述车辆停放检测框和所述停车区域检测框，识别出是否存在车辆异常停放行为；所述垃圾混扔行为识别单元用于：从所述视频流数据中实时抽取出至少两帧图像，识别出各帧所述图像中的目标主体，所述目标主体包括待扔垃圾、扔垃圾对象以及存放待扔垃圾的垃圾容器中的至少一种；对至少两帧所述图像中的所述扔垃圾对象以及所述待扔垃圾进行分析，以筛选出各所述扔垃圾对象的扔垃圾事件所关联的目标图像；根据所述目标图像中所记录的所述扔垃圾对象所携带的待扔垃圾一次减少的数量或各所述垃圾容器的垃圾合并数量，识别出垃圾混扔的目标垃圾事件；所述第一环境真伪识别单元用于：确定所述视频流数据对应的第一判别特征向量和第二判别特征向量；所述第一判别特征向量表示所述视频流数据中每帧人脸图像之间的时域特征信息；所述第二判别特征向量表示所述视频流数据中每帧所述人脸图像之间的频域特征信息；基于所述第一判别特征向量和所述第二判别特征向量，确定所述视频流数据对应的目标特征向量；所述目标特征向量表示融合所述时域特征信息和所述频域特征信息的特征信息；基于所述目标特征向量，确定所述视频流数据的检测结果；所述检测结果用于指示所述视频流数据中的环境是否为伪造环境；所述第二环境真伪识别单元用于：将所述视频流数据进行预处理，得到多个视频片段；所述视频流数据包括音频，每个所述视频片段包括所述音频；针对每个所述视频片段，分别提取所述视频片段的视频特征向量和所述视频片段中的所述音频的音频特征向量；基于各所述视频特征向量和各所述音频特征向量，确定所述视频流数据对应的总视频特征向量和总音频特征向量；基于各所述视频特征向量、各所述音频特征向量、所述总视频特征向量和所述总音频特征向量，确定所述视频流数据的目标检测结果；所述目标检测结果表示所述视频流数据中的环境是否为伪造环境；所述目标跟踪单元用于：获取视频流数据的目标图像和热成像装置采集的所述目标图像对应的第一点云数据；基于所述目标图像和所述第一点云数据，确定所述待跟踪目标的第二点云数据；基于所述第二点云数据，确定所述待跟踪目标在下一时刻的位姿信息；基于所述待跟踪目标在下一时刻的位姿信息，对所述待跟踪目标进行跟踪。2.根据权利要求1所述的智能布控球，其特征在于，所述高空作业人员行为识别单元还用于：基于所述当前时刻位置信息，或者基于所述当前时刻位置信息和所述当前时刻镜头姿态信息，在所述指定高空区域中监控目标所在区域的地理位置信息和数字高程模型数据，确定所述指定高空区域的当前当前时刻影像对应的目标地理位置信息和目标数字高程模型数据；基于所述目标数字高程模型数据、所述目标地理位置信息、所述当前时刻镜头姿态信息和所述镜头参数信息，获取所述目标地理位置信息对应的像素坐标值；基于所述目标地理位置信息对应的像素坐标值，在所述指定高空区域的当前时刻影像中标记所述监控目标所在区域；所述高空作业人员行为识别单元还用于：基于所述目标数字高程模型数据和所述目标地理位置信息，获取所述目标地理位置信息对应的大地坐标值；通过高斯正算对所述目标地理位置信息对应的大地坐标值进行坐标系转换，获取所述目标地理位置信息对应的物方坐标值；基于所述当前时刻位置信息、所述当前时刻镜头姿态信息、所述镜头参数信息和所述目标地理位置信息对应的物方坐标值，通过共线方程，获取所述目标地理位置信息对应的像方坐标值；基于所述镜头参数信息，对所述目标地理位置信息对应的像方坐标值进行坐标系转换，获取所述目标地理位置信息对应的像素坐标值。3.根据权利要求2所述的智能布控球，其特征在于，所述高空作业人员行为识别单元还用于：基于所述当前时刻位置信息，获取所述指定高空区域中所述拍摄装置的垂直投影点；将以所述垂直投影点为圆心，以预设距离为半径的圆形区域，确定为所述拍摄装置的关联区域；在所述指定高空区域中监控目标所在区域的地理位置信息和数字高程模型数据中，筛选所述拍摄装置的关联区域的地理位置信息和数字高程模型数据，作为所述目标地理位置信息和所述目标数字高程模型数据；所述高空作业人员行为识别单元还用于：基于所述目标地理位置信息对应的像素坐标值，在空白影像中生成图斑，获得当前时刻拍摄装置对应的图斑影像；在所述当前时刻拍摄装置对应的图斑影像中裁剪出所述指定高空区域的当前时刻影像对应的目标图斑影像；将所述目标图斑影像与所述指定高空区域的当前时刻影像进行逐帧叠加，获得标记有所述监控目标所在区域的所述指定高空区域的当前时刻影像。4.根据权利要求1所述的智能布控球，其特征在于，所述终端浏览行为识别单元还用于：获取所述头部位置区域中的鼻子部位位置坐标和所述头部位置区域的第一中心位置坐标，并基于所述鼻子部位位置坐标和所述第一中心位置坐标，确定第一位置坐标；获取所述手部位置区域中光源亮度最大的光源位置坐标和所述手部位置区域的第二中心位置坐标，并根据所述光源位置坐标和所述第二中心位置坐标，确定第二位置坐标；基于所述第一位置坐标计算所述头部位置区域的第一区域面积，并基于所述第二位置坐标，计算所述手部位置区域的第二区域面积；基于所述第一位置坐标和所述第二位置坐标的差值，确定目标位置坐标，并基于所述目标位置坐标计算第一目标区域面积；基于所述第一区域面积、所述第二区域面积和所述第一目标区域面积，计算第二目标区域面积；基于所述第一目标区域面积和所述第二目标区域面积，计算所述头部位置区域和所述手部位置区域的区域面积比值；若所述区域面积比值大于第一预设比值，则确定用户存在浏览终端设备行为；或，若所述区域面积比值小于或者等于所述第一预设比值，则确定用户不存在浏览终端设备行为。5.根据权利要求1所述的智能布控球，其特征在于，所述车辆异常停放识别单元还用于：根据所述车辆停放检测框的左上角点坐标和右下角点坐标，计算所述车辆停放检测框的第一检测框面积；根据所述停车区域检测框的左上角点坐标和右下角点坐标，计算所述停车区域检测框的第二检测框面积；基于所述车辆停放检测框和所述停车区域检测框中的左上角点横坐标最大值、左上角点纵坐标最小值、右下角点横坐标最小值和右下角点纵坐标最大值，计算所述车辆停放检测框和所述停车区域检测框的交集检测框面积；根据所述第一检测框面积、所述第二检测框面积和所述交集检测框面积，计算所述车辆停放检测框和所述停车区域检测框的并集检测框面积；将所述交集检测框面积除以所述并集检测框面积，得到所述车辆停放检测框和所述停车区域检测框的交并检测框面积比；若所述交并检测框面积比大于预设阈值，则确定存在车辆异常停放行为；或，若所述交并检测框面积比小于或者等于所述预设阈值，则确定不存在车辆异常停放行为。6.根据权利要求1所述的智能布控球，其特征在于，所述垃圾混扔行为识别单元还用于：确定所述图像中的待扔垃圾，其中，所述图像之前的缓存图像中不存在所述待扔垃圾或所述待扔垃圾与所述缓存图像中出现的历史垃圾之间的重叠度小于预设重叠度；若所述图像中包括至少两个待识别对象，则确定与所述待扔垃圾之间的第一距离最小，且所述第一距离小于第一预设距离的所述待识别对象为扔垃圾对象；若所述图像中包括至少两个垃圾容器，则确定与所述扔垃圾对象之间的第二距离最小的所述垃圾容器为存放待扔垃圾的垃圾容器；若所述图像之前的缓存图像中不存在所述扔垃圾对象，则确定所述图像中的所述扔垃圾对象所携带的待扔垃圾的第一数量；若所述第一数量大于预设数量，则确定所述图像为所述扔垃圾对象的扔垃圾事件所关联的目标图像。7.根据权利要求1所述的智能布控球，其特征在于，所述第一环境真伪识别单元还用于：基于所述视频流数据中的每帧所述人脸图像，确定所述人脸图像的人脸区域和非人脸区域；所述人脸区域包括人眼以下包括左右两侧脸颊的区域；所述非人脸区域包括所述人眼以上除了额头以外的左右两侧区域；基于各所述人脸区域和各所述非人脸区域，分别提取各所述人脸区域对应的第一时域特征和各所述非人脸区域对应的第二时域特征；基于所述第一时域特征和所述第二时域特征，确定所述视频流数据对应的第一判别特征向量；基于所述第一时域特征，确定所述视频流数据对应的第二判别特征向量；所述第一环境真伪识别单元还用于：将所述第一判别特征向量和所述第二判别特征向量进行归一化，得到归一化之后的第一判别特征向量和归一化之后的第二判别特征向量；将所述归一化之后的第一判别特征向量和所述归一化之后的第二判别特征向量进行拼接，得到所述视频流数据对应的目标特征向量；将所述目标特征向量输入分类判别网络模型，得到所述分类判别网络模型输出的检测结果；分类判别网络模型是基于样本检测视频对应的样本特征向量和标签数据进行训练得到的，所述分类判别网络模型用于对所述视频流数据中的环境是否为伪造环境进行分类判别。8.根据权利要求1所述的智能布控球，其特征在于，所述第二环境真伪识别单元还用于：基于所述总视频特征向量和所述总音频特征向量，确定所述视频流数据对应的融合特征向量；基于各所述视频特征向量、各所述音频特征向量和所述融合特征向量，分别确定各所述视频特征向量对应的第一检测结果、各所述音频特征向量对应的第二检测结果和所述融合特征向量对应的第三检测结果；基于所述第一检测结果、所述第二检测结果和所述第三检测结果，确定所述视频流数据的目标检测结果；所述第二环境真伪识别单元还用于：针对每个所述视频片段，将所述视频片段对应的所述视频特征向量和所述音频特征向量进行归一化，分别得到归一化之后的视频特征向量和归一化之后的音频特征向量；分别将各所述归一化之后的视频特征向量和各所述归一化之后的音频特征向量进行拼接，得到所述视频流数据对应的总视频特征向量和总音频特征向量。9.根据权利要求1所述的智能布控球，其特征在于，所述目标跟踪单元还用于：将所述目标图像输入至目标检测网络模型，得到所述目标检测网络模型输出的所述待跟踪目标在当前时刻位置信息；所述目标检测网络模型是基于样本目标图像和标签数数据进行训练得到，用于对所述目标图像中的所述待跟踪目标进行检测；将所述第一点云数据和所述位置信息对应的待跟踪目标图像进行对齐，确定所述待跟踪目标在所述第一点云数据对应的位置和范围；基于所述位置和范围，确定所述待跟踪目标的第二点云数据。10.一种智能布控球的布控方法，其特征在于，应用于如权利要求1至9任一项所述的智能布控球，包括：采集视频流数据和点云数据；基于所述视频流数据进行高空作业人员行为识别，具体为：获取所述拍摄装置的当前时刻位置信息、当前时刻镜头姿态信息和镜头参数信息，以及所述视频流数据中指定高空区域的当前时刻影像；基于所述当前时刻位置信息、所述当前时刻镜头姿态信息、所述镜头参数信息以及所述指定高空区域中监控目标所在区域的地理位置信息和数字高程模型数据，在所述当前时刻影像中标记所述监控目标所在区域；对所述监控目标所在区域进行高空作业人员行为识别，在确定所述监控目标所在区域内存在高空作业人员，则采集所述高空作业人员的人体框、人脸框和安全帽框，并将人体框、人脸框和安全帽框显示在监控界面；或，基于所述视频流数据进行进行终端浏览行为识别布控，具体为：对所述视频流数据中的每一帧视频图像进行终端浏览行为识别布控，得到每一帧视频图像的头部位置区域和手部位置区域，并根据所述头部位置区域和所述手部位置区域，识别出用户是否存在浏览终端设备行为；或，基于所述视频流数据车辆异常停放识别，具体为：对所述视频流数据中的每一帧视频图像进行车辆异常停放识别布控，得到每一帧视频图像的车辆停放检测框和停车区域检测框，并根据所述车辆停放检测框和所述停车区域检测框，识别出是否存在车辆异常停放行为；或，基于所述视频流数据进行垃圾混扔行为识别，具体为：从所述视频流数据中实时抽取出至少两帧图像，识别出各帧所述图像中的目标主体，所述目标主体包括待扔垃圾、扔垃圾对象以及存放待扔垃圾的垃圾容器中的至少一种；对至少两帧所述图像中的所述扔垃圾对象以及所述待扔垃圾进行分析，以筛选出各所述扔垃圾对象的扔垃圾事件所关联的目标图像；根据所述目标图像中所记录的所述扔垃圾对象所携带的待扔垃圾一次减少的数量或各所述垃圾容器的垃圾合并数量，识别出垃圾混扔的目标垃圾事件；或，基于所述视频流数据进行环境真伪识别，具体为：确定所述视频流数据对应的第一判别特征向量和第二判别特征向量；所述第一判别特征向量表示所述视频流数据中每帧人脸图像之间的时域特征信息；所述第二判别特征向量表示所述视频流数据中每帧所述人脸图像之间的频域特征信息；基于所述第一判别特征向量和所述第二判别特征向量，确定所述视频流数据对应的目标特征向量；所述目标特征向量表示融合所述时域特征信息和所述频域特征信息的特征信息；基于所述目标特征向量，确定所述视频流数据的检测结果；所述检测结果用于指示所述视频流数据中的环境是否为伪造环境；或，基于所述视频流数据进行环境真伪识别，具体为：将所述视频流数据进行预处理，得到多个视频片段；所述视频流数据包括音频，每个所述视频片段包括所述音频；针对每个所述视频片段，分别提取所述视频片段的视频特征向量和所述视频片段中的所述音频的音频特征向量；基于各所述视频特征向量和各所述音频特征向量，确定所述视频流数据对应的总视频特征向量和总音频特征向量；基于各所述视频特征向量、各所述音频特征向量、所述总视频特征向量和所述总音频特征向量，确定所述视频流数据的目标检测结果；所述目标检测结果表示所述视频流数据中的环境是否为伪造环境；或，基于所述视频流数据和所述点云数据进行目标跟踪，具体为：获取视频流数据的目标图像和热成像装置采集的所述目标图像对应的第一点云数据；基于所述目标图像和所述第一点云数据，确定所述待跟踪目标的第二点云数据；基于所述第二点云数据，确定所述待跟踪目标在下一时刻的位姿信息；基于所述待跟踪目标在下一时刻的位姿信息，对所述待跟踪目标进行跟踪。
说明书desc
技术领域本申请涉及布控球技术领域，具体涉及一种智能布控球及其布控方法。背景技术视频监控在现有生活的很多情况下均不可或缺，尤其是在相对重要场所，往往需要对其进行持续、有效的监控，现有技术中的视频监控设备的功能单一，即单种视频监控设备只能实现单一的功能，对于单种视频监控设备之外的功能场景并不能识别，因此，现有技术中的视频监控设备不能实现对异常情况的精准拍摄。发明内容本申请实施例提供一种智能布控球及其布控方法，旨在实现对异常情况的精准拍摄。第一方面，本申请实施例提供一种智能布控球，包括热成像装置、拍摄装置、KA200类脑芯片和布控监测装置；所述拍摄装置和所述布控监测装置分别与所述所述KA200类脑芯片连接，所述KA200类脑芯片用于控制所述拍摄装置和所述布控监测装置；所述布控监测装置包括高空作业人员行为识别单元、终端浏览行为识别单元、车辆异常停放识别单元、垃圾混扔行为识别单元、第一环境真伪识别单元、第二环境真伪识别单元和目标跟踪单元；所述拍摄装置用于：采集视频流数据；所述热成像装置用于：采集点云数据；所述高空作业人员行为识别单元用于：获取所述拍摄装置的当前时刻位置信息、当前时刻镜头姿态信息和镜头参数信息，以及所述视频流数据中指定高空区域的当前时刻影像；基于所述当前时刻位置信息、所述当前时刻镜头姿态信息、所述镜头参数信息以及所述指定高空区域中监控目标所在区域的地理位置信息和数字高程模型数据，在所述当前时刻影像中标记所述监控目标所在区域；对所述监控目标所在区域进行高空作业人员行为识别，在确定所述监控目标所在区域内存在高空作业人员，则采集所述高空作业人员的人体框、人脸框和安全帽框，并将人体框、人脸框和安全帽框显示在监控界面；所述终端浏览行为识别单元用于：对所述视频流数据中的每一帧视频图像进行终端浏览行为识别布控，得到每一帧视频图像的头部位置区域和手部位置区域，并根据所述头部位置区域和所述手部位置区域，识别出用户是否存在浏览终端设备行为；所述车辆异常停放识别单元用于：对所述视频流数据中的每一帧视频图像进行车辆异常停放识别布控，得到每一帧视频图像的车辆停放检测框和停车区域检测框，并根据所述车辆停放检测框和所述停车区域检测框，识别出是否存在车辆异常停放行为；所述垃圾混扔行为识别单元用于：从所述视频流数据中实时抽取出至少两帧图像，识别出各帧所述图像中的目标主体，所述目标主体包括待扔垃圾、扔垃圾对象以及存放待扔垃圾的垃圾容器中的至少一种；对至少两帧所述图像中的所述扔垃圾对象以及所述待扔垃圾进行分析，以筛选出各所述扔垃圾对象的扔垃圾事件所关联的目标图像；根据所述目标图像中所记录的所述扔垃圾对象所携带的待扔垃圾一次减少的数量或各所述垃圾容器的垃圾合并数量，识别出垃圾混扔的目标垃圾事件；所述第一环境真伪识别单元用于：确定所述视频流数据对应的第一判别特征向量和第二判别特征向量；所述第一判别特征向量表示所述视频流数据中每帧人脸图像之间的时域特征信息；所述第二判别特征向量表示所述视频流数据中每帧所述人脸图像之间的频域特征信息；基于所述第一判别特征向量和所述第二判别特征向量，确定所述视频流数据对应的目标特征向量；所述目标特征向量表示融合所述时域特征信息和所述频域特征信息的特征信息；基于所述目标特征向量，确定所述视频流数据的检测结果；所述检测结果用于指示所述视频流数据中的环境是否为伪造环境；所述第二环境真伪识别单元用于：将所述视频流数据进行预处理，得到多个视频片段；所述视频流数据包括音频，每个所述视频片段包括所述音频；针对每个所述视频片段，分别提取所述视频片段的视频特征向量和所述视频片段中的所述音频的音频特征向量；基于各所述视频特征向量和各所述音频特征向量，确定所述视频流数据对应的总视频特征向量和总音频特征向量；基于各所述视频特征向量、各所述音频特征向量、所述总视频特征向量和所述总音频特征向量，确定所述视频流数据的目标检测结果；所述目标检测结果表示所述视频流数据中的环境是否为伪造环境；所述目标跟踪单元用于：获取视频流数据的目标图像和热成像装置采集的所述目标图像对应的第一点云数据；基于所述目标图像和所述第一点云数据，确定所述待跟踪目标的第二点云数据；基于所述第二点云数据，确定所述待跟踪目标在下一时刻的位姿信息；基于所述待跟踪目标在下一时刻的位姿信息，对所述待跟踪目标进行跟踪。第二方面，本申请实施例提供一种智能布控球的布控方法，应用于第一方面所述的智能布控球，包括：采集视频流数据和点云数据；基于所述视频流数据进行高空作业人员行为识别，具体为：获取所述拍摄装置的当前时刻位置信息、当前时刻镜头姿态信息和镜头参数信息，以及所述视频流数据中指定高空区域的当前时刻影像；基于所述当前时刻位置信息、所述当前时刻镜头姿态信息、所述镜头参数信息以及所述指定高空区域中监控目标所在区域的地理位置信息和数字高程模型数据，在所述当前时刻影像中标记所述监控目标所在区域；对所述监控目标所在区域进行高空作业人员行为识别，在确定所述监控目标所在区域内存在高空作业人员，则采集所述高空作业人员的人体框、人脸框和安全帽框，并将人体框、人脸框和安全帽框显示在监控界面；或，基于所述视频流数据进行进行终端浏览行为识别布控，具体为：对所述视频流数据中的每一帧视频图像进行终端浏览行为识别布控，得到每一帧视频图像的头部位置区域和手部位置区域，并根据所述头部位置区域和所述手部位置区域，识别出用户是否存在浏览终端设备行为；或，基于所述视频流数据车辆异常停放识别，具体为：对所述视频流数据中的每一帧视频图像进行车辆异常停放识别布控，得到每一帧视频图像的车辆停放检测框和停车区域检测框，并根据所述车辆停放检测框和所述停车区域检测框，识别出是否存在车辆异常停放行为；或，基于所述视频流数据进行垃圾混扔行为识别，具体为：从所述视频流数据中实时抽取出至少两帧图像，识别出各帧所述图像中的目标主体，所述目标主体包括待扔垃圾、扔垃圾对象以及存放待扔垃圾的垃圾容器中的至少一种；对至少两帧所述图像中的所述扔垃圾对象以及所述待扔垃圾进行分析，以筛选出各所述扔垃圾对象的扔垃圾事件所关联的目标图像；根据所述目标图像中所记录的所述扔垃圾对象所携带的待扔垃圾一次减少的数量或各所述垃圾容器的垃圾合并数量，识别出垃圾混扔的目标垃圾事件；或，基于所述视频流数据进行环境真伪识别，具体为：确定所述视频流数据对应的第一判别特征向量和第二判别特征向量；所述第一判别特征向量表示所述视频流数据中每帧人脸图像之间的时域特征信息；所述第二判别特征向量表示所述视频流数据中每帧所述人脸图像之间的频域特征信息；基于所述第一判别特征向量和所述第二判别特征向量，确定所述视频流数据对应的目标特征向量；所述目标特征向量表示融合所述时域特征信息和所述频域特征信息的特征信息；基于所述目标特征向量，确定所述视频流数据的检测结果；所述检测结果用于指示所述视频流数据中的环境是否为伪造环境；或，基于所述视频流数据进行环境真伪识别，具体为：将所述视频流数据进行预处理，得到多个视频片段；所述视频流数据包括音频，每个所述视频片段包括所述音频；针对每个所述视频片段，分别提取所述视频片段的视频特征向量和所述视频片段中的所述音频的音频特征向量；基于各所述视频特征向量和各所述音频特征向量，确定所述视频流数据对应的总视频特征向量和总音频特征向量；基于各所述视频特征向量、各所述音频特征向量、所述总视频特征向量和所述总音频特征向量，确定所述视频流数据的目标检测结果；所述目标检测结果表示所述视频流数据中的环境是否为伪造环境；或，基于所述视频流数据和所述点云数据进行目标跟踪，具体为：获取视频流数据的目标图像和热成像装置采集的所述目标图像对应的第一点云数据；基于所述目标图像和所述第一点云数据，确定所述待跟踪目标的第二点云数据；基于所述第二点云数据，确定所述待跟踪目标在下一时刻的位姿信息；基于所述待跟踪目标在下一时刻的位姿信息，对所述待跟踪目标进行跟踪。第三方面，本申请实施例提供一种计算机设备，所述计算机设备包括存储器、处理器及存储在所述存储器上并可在所述处理器上运行的计算机程序，所述处理器执行所述计算机程序时实现第二方面所述的智能布控球的布控方法。第四方面，本申请实施例提供一种非暂态计算机可读存储介质，非暂态计算机可读存储介质包括计算机程序，所述计算机程序被处理器执行时实现第二方面所述的智能布控球的布控方法。本申请实施例提供的智能布控球及其布控方法，智能布控球包括热成像装置、拍摄装置、KA200类脑芯片和布控监测装置；拍摄装置和布控监测装置分别与KA200类脑芯片连接，KA200类脑芯片用于控制拍摄装置和布控监测装置；布控监测装置包括高空作业人员行为识别单元、终端浏览行为识别单元、车辆异常停放识别单元、垃圾混扔行为识别单元、第一环境真伪识别单元、第二环境真伪识别单元和目标跟踪单元。在智能布控球进行布控的过程中，智能布控球实现当通过内置的异常识别模块识别到异常情况时，可通过水平旋转或俯仰旋转调整拍摄装置，再对拍摄装置进行变焦镜头调节焦距，实现对异常情况的精准拍摄。附图说明为了更清楚地说明本申请或现有技术中的技术方案，下面将对实施例或现有技术描述中所需要使用的附图作一简单地介绍，显而易见地，下面描述中的附图是本申请的一些实施例，对于本领域普通技术人员来讲，在不付出创造性劳动的前提下，还可以根据这些附图获得其他的附图。图1是本申请实施例提供的智能布控球的结构示意图之一；图2是本申请实施例提供的智能布控球的结构示意图之二。具体实施方式为使本申请的目的、技术方案和优点更加清楚，下面将结合本申请实施例中的附图，对本申请中的技术方案进行清楚、完整地描述，显然，所描述的实施例是本申请一部分实施例，而不是全部的实施例。基于本申请中的实施例，本领域普通技术人员在没有作出创造性劳动前提下所获得的所有其他实施例，都属于本申请保护的范围。参照图1，图1是本申请实施例提供的智能布控球的结构示意图之一。本申请实施例提供一种智能布控球包括热成像装置、拍摄装置、KA200类脑芯片和布控监测装置；拍摄装置和布控监测装置分别与KA200类脑芯片连接，KA200类脑芯片用于控制拍摄装置和布控监测装置；布控监测装置包括高空作业人员行为识别单元、终端浏览行为识别单元、车辆异常停放识别单元、垃圾混扔行为识别单元、第一环境真伪识别单元、第二环境真伪识别单元和目标跟踪单元。可选的，拍摄装置采集视频流数据。可选的，高空作业人员行为识别单元获取拍摄装置的当前时刻位置信息、当前时刻镜头姿态信息和镜头参数信息，以及视频流数据中指定高空区域的当前时刻影像。可以理解的是，对于一个大面积区域，可以仅对上述大面积区域中的部分区域进行区域监控，例如：平面区域、高楼层高空区域、高空作业区域等等，因此，本申请实施例中所要监控的区域为指定高空区域，也即高空作业区域。可以理解的是，由于摄像头的拍摄范围有限，因此本申请实施例中拍摄装置的数量为多个，每一拍摄装置可以获取指定高空区域中部分区域的影像，将所有的拍摄装置在某一时刻获取的影像进行拼接，可以获取指定高空区域的完整影像。可选地，本申请实施例中还可以将智能布控球设置在一个无人机的底部，无人机带动智能布控球中的拍摄装置在指定高空区域内飞行的过程中，拍摄装置可以获取指定高空区域的影像。需要说明的是，本申请实施例中的拍摄装置，可以泛指任一拍摄摄像头；指定高空区域的当前时刻影像，可以泛指上述拍摄装置当前时刻对指定高空区域进行拍摄获得的影像。需要说明的是，本申请实施例中的智能布控球内置有全球导航卫星系统和接收器与惯性导航系统。拍摄装置的镜头可以沿水平方向和垂直方向转动。智能布控球还搭载有通信设备。作为一个可选地实施例，获取指定高空区域的当前时刻影像、拍摄装置的当前时刻位置信息以及拍摄装置的的镜头当前时刻姿态信息之前，方法还包括：控制拍摄装置的镜头按照预设规则在水平方向和/或竖直方向转动。可选地，本申请实施例中可以控制拍摄装置的镜头在水平方向和/或垂直方向的转动角度每隔预设时长就改变一次，并在拍摄装置的镜头的转动角度发生改变的情况下，控制拍摄装置采集一张指定高空区域的影像。相应地，本申请实施例中上一时刻与当前时刻之间间隔的时长，即为上述预设时长。可选地，本申请实施例中还可以控制拍摄装置的镜头在水平方向和/或垂直方向的均速转动，并可以控制拍摄装置采集指定高空区域的视频影像。相应地，本申请实施例中当前时刻与下一时刻之间间隔的时长，可以根据拍摄装置采集的指定高空区域的视频影像数据中任意两帧影像之间间隔的时长确定，即指定高空区域上一时刻的影像，为拍摄装置拍摄的视频影像中上一帧的影像，指定高空区域的当前时刻影像，为拍摄装置拍摄的视频影像中当前帧的影像。拍摄装置拍摄到指定高空区域的当前时刻影像之后，可以通过数据通信的方式，将指定高空区域的当前时刻影像发送至区域监控装置，进而可以基于机器视觉视觉技术算法，对拍摄装置拍摄到指定高空区域的视频影像数据进行读取，并提取当前帧的影像，作为指定高空区域的当前时刻影像。其中，OpenCV是一个基于C++语言编写的跨平台计算机视觉和机器学习软件库，可运行在多种系统上，具有很好的移植性，并且提供了Python、MATLAB、Java、C#等多种编程语言接口，可以实现图像处理、目标检测、运动跟踪、物体识别等多项功能。OpenCV在计算机视觉领域具有独特的优势，因为其致力于对真实世界影像的实时处理，通过代码优化将其的执行速度带来了极大的提升。应用OpenCV视觉库处理视频影像这样的每秒多帧画面，可以将其的速度优势体现的淋漓尽致。本申请实施例中可以基于OpenCV影像处理算法，对拍摄装置拍摄到指定高空区域的视频影像数据进行读取，并提取当前帧的影像，作为指定高空区域的当前时刻影像。本申请实施例中可以用拍摄装置的当前时刻位置与姿态系统数据，描述拍摄装置的当前时刻位置信息以及拍摄装置的的镜头当前时刻姿态信息。其中，拍摄装置的POS数据可以包括纬度、经度、高程、航向角、俯仰角及翻滚角等信息。基于智能布控球内置的GNSS接收器和INS系统当前时刻采集到的运行数据，可以获取拍摄装置当前时刻的POS数据。拍摄装置可以通过数据通信的方式，将智能布控球内置的GNSS接收器和INS系统当前时刻采集到的运行数据发送至区域监控装置。需要说明的是，拍摄装置的当前时刻位置信息可以包括拍摄装置当前时刻的纬度、经度以及高程。基于智能布控球内置的GNSS接收器当前时刻采集到的运行数据，可以获取拍摄装置的当前时刻位置信息。需要说明的是，拍摄装置的镜头当前时刻姿态信息可以包括拍摄装置的镜头当前时刻的欧拉角。由于拍摄装置的镜头只能在水平方向和垂直方向转动，因此，本申请实施中可以以拍摄装置的镜头旋转点为原点，水平方向为X轴，以竖直方向为Z轴，建立空间直角坐标系，进而可以将目标摄像机的镜头的旋转看作先绕X轴旋转h角度，再绕Y轴旋转p角度，最后绕Z轴旋转r角度的欧拉角hpr。其中，p角度为0°。基于智能布控球内置的INS系统当前时刻采集到的运行数据，可以计算得到拍摄装置的镜头当前时刻的欧拉角可选的，高空作业人员行为识别单元基于当前时刻位置信息、当前时刻镜头姿态信息、镜头参数信息以及指定高空区域中监控目标所在区域的地理位置信息和数字高程模型数据，在当前时刻影像中标记监控目标所在区域，具体为：需要说明的是，指定高空区域中监控目标所在区域的地理位置信息，可以包括指定高空区域中监控目标所在区域的边界上每一地面点的地理位置信息；指定高空区域中监控目标所在区域的地理位置信息，还可可以包括指定高空区域中监控目标所在区域中每一地面点的地理位置信息等。其中，本申请实施例中的地理位置信息可以包括经度和纬度。可选地，本申请实施例中可以通过图斑的方式，在指定高空区域的遥感影像中标记指定高空区域中监控目标所在区域，获得指定高空区域的图斑遥感影像。指定高空区域的遥感影像中监控目标所在区域的图斑，可以是通过人工勾画以及地块分割等方式生成的。获取指定高空区域的图斑遥感影像之后，可以基于指定高空区域的图斑遥感影像，获取指定高空区域中监控目标所在区域的地理位置信息。需要说明的是，指定高空区域中监控目标所在区域的地理位置信息中设置有主关键字，用于对指定高空区域中监控目标所在区域的地理位置信息进行检索。本申请实施例中可以通过数据查询、用户输入等方式，获取指定高空区域中监控目标所在区域的地理位置信息。可以理解的是，由于指定高空区域中监控目标所在区域的地理位置信息包含的是平面信息，但指定高空区域的当前时刻影像是拍摄装置从空中获取的，因此还需要通过指定高空区域中监控目标所在区域的数字高程模型数据，表达指定高空区域在竖直方向上的特征。其中，数字高程模型，是通过有限的地形高程数据实现对地面地形的数字化模拟。本申请实施例中从地理空间数据云等网络开源地理数据库中下载获取指定高空区域中监控目标所在区域的数字高程模型数据，还可以基于用户的输入或接收其他电子设备发送的指定高空区域中监控目标所在区域的数字高程模型数据。需要说明的是，为了提高对指定高空区域中监控目标所在区域的区域监控准确率，应选取空间分辨率较高的指定高空区域中监控目标所在区域的数字高程模型数据。本申请实施例中拍摄装置的镜头参数信息可以包括焦距、分辨率以及CMOS成像尺寸。拍摄装置的出厂信息中可以包括拍摄装置的镜头参数信息。本申请实施例中可以通过信息查询、用户输入等方式，获取拍摄装置的镜头参数信息。获取指定高空区域中监控目标所在区域的地理位置信息和数字高程模型数据、拍摄装置的当前时刻位置信息、拍摄装置的镜头当前时刻姿态信息以及拍摄装置的镜头参数信息之后，可以通过数值计算、深度学习以及模型设计等方式，在指定高空区域的当前时刻影像中标记监控目标所在的区域。作为一个可选地实施例，基于指定高空区域中监控目标所在区域的地理位置信息和数字高程模型数据、拍摄装置的当前时刻位置信息、拍摄装置的镜头当前时刻姿态信息以及拍摄装置的镜头参数信息，在指定高空区域的当前时刻影像中标记监控目标所在区域，包括：基于拍摄装置的当前时刻位置信息，或者基于拍摄装置的当前时刻位置信息和拍摄装置的镜头当前时刻姿态信息，在指定高空区域中监控目标所在区域的地理位置信息和数字高程模型数据中确定指定高空区域的当前时刻影像对应的目标地理位置信息和目标数字高程模型数据。具体地，获取指定高空区域中监控目标所在区域的地理位置信息和数字高程模型数据、拍摄装置的当前时刻位置信息、拍摄装置的镜头当前时刻姿态信息以及拍摄装置的镜头参数信息之后，可以通过数值计算和数据筛选的方式，确定指定高空区域的当前时刻影像对应的目标地理位置信息和目标数据高程模型数据。作为一个可选地实施例，基于拍摄装置的当前时刻位置信息，在指定高空区域中监控目标所在区域的地理位置信息和数字高程模型数据中确定指定高空区域的当前时刻影像对应的目标地理位置信息和目标数字高程模型数据，包括：基于拍摄装置的当前时刻位置信息，在指定高空区域中拍摄装置的垂直投影点；将以垂直投影点为圆心，以预设距离为半径的圆形区域，确定为拍摄装置的关联区域；在指定高空区域中监控目标所在区域的地理位置信息和数字高程模型数据中，筛选拍摄装置的关联区域的地理位置信息和数字高程模型数据，作为目标地理位置信息和目标数字高程模型数据。具体地，获取指定高空区域中监控目标所在区域的地理位置信息和数字高程模型数据、拍摄装置的当前时刻位置信息、拍摄装置的镜头当前时刻姿态信息以及拍摄装置的镜头参数信息之后，可以基于拍摄装置的当前时刻位置信息，确定拍摄装置在指定高空区域的投影点，进而可以将以上述投影点为圆心，以预设距离为半径的圆形区域，确定为拍摄装置对应的关联区域。需要说明的是，预设距离可以是根据先验知识和/或实际情况确定的。本申请实施例中对预设距离的具体取值不作限定。可选地，预设距离的取值范围可以在400米至600米之间，例如预设距离可以为400米、500米或600米。优选地，预设距离可以为500米。确定拍摄装置对应的关联区域之后，可以基于指定高空区域中监控目标所在区域的地理位置信息，确定拍摄装置对应的关联区域中监控目标所在的区域，进而可以在指定高空区域中监控目标所在区域的地理位置信息中筛选拍摄装置对应的关联区域中监控目标所在区域的地理位置信息，作为指定高空区域的当前时刻影像对应的目标地理位置信息。可以理解的是，上述目标地理位置信息包括拍摄装置对应的关联区域中每一地面点的地理位置信息。确定拍摄装置对应的关联区域中监控目标所在的区域之后，还可以在指定高空区域中监控目标所在区域的数字高程模型数据中筛选拍摄装置对应的关联区域中监控目标所在区域的数字高程模型数据，作为指定高空区域的当前时刻影像对应的目标数字高程模型数据。可以理解的是，上述目标数字高程模型数据包括拍摄装置对应的关联区域中每一地面点的数字高程模型数据。基于目标数字高程模型数据、目标地理位置信息、拍摄装置的镜头当前时刻姿态信息以及拍摄装置的镜头参数信息，获取目标地理位置信息对应的像素坐标值。具体地，获取指定高空区域的当前时刻影像对应的目标地理位置信息和目标数字高程模型数据、拍摄装置的镜头当前时刻姿态信息以及拍摄装置的镜头参数信息之后，可以通过数值计算的方式，在指定高空区域的当前时刻影像中标记监控目标所在的区域。作为一个可选地实施例，基于目标数字高程模型数据、目标地理位置信息、拍摄装置的镜头当前时刻姿态信息以及拍摄装置的镜头参数信息，获取目标地理位置信息对应的像素坐标值，包括：基于目标数字高程模型数据和目标地理位置信息，获取目标地理位置信息对应的大地坐标值。获取指定高空区域的当前时刻影像对应的目标地理位置信息和目标数字高程模型数据之后，可以基于指定高空区域的当前时刻影像对应的目标地理位置信息和目标数字高程模型数据，确定指定高空区域中监控目标所在区域中的每一地面点在大地坐标系中的坐标值，作为目标地理位置信息对应的大地坐标值。其中，大地坐标值可以用于描述地球上任意一点的经度L、纬度B和高程H。通过高斯正算对目标地理位置信息对应的大地坐标值进行坐标系转换，获取目标地理位置信息对应的物方坐标值。需要说明的是，通过高斯正算可以实现大地坐标系和物方坐标系之间的坐标系转换。因此，本申请实施例中可以采用高斯正算，对目标地理位置信息对应的大地坐标值进行物方坐标系转换，获取上述目标地理位置信息对应的物方坐标值。其中，物方坐标系用于描述地面点在物方空间的位置。具体地，高斯正反算实质描述的是大地坐标系与高斯-克吕格投影坐标系之间的映射关系。将经度、纬度进行高斯-克吕格投影，就产生了高斯-克吕格投影坐标系。高斯-克吕格投影坐标系中的Y轴沿着赤道指向正东，高斯-克吕格投影坐标系中的X轴沿着中央子午线指向正北。需要说明的是，本申请实施例中可以将高斯-克吕格投影坐标系确定为物方坐标系。对于指定高空区域中监控目标所在区域的任意一个地面点i，基于上述地面点i的大地坐标值，可以通过高斯正算计算得到上述地面点i的高斯投影坐标值具体计算公式如下：其中，上述高斯正算中的角度均为弧度制；在上述高斯正算中，基本椭球参数包括：椭球长半轴a，扁率f，短半轴b，第一偏心率e和第二偏心率e'；b＝al”表示地面点i的经度值与中央子午线的经度值之差；当采用6度带时，L0的计算方法是地面点i的经度除以3，求得的结果四舍五入，然后再乘以3就是当地的中央子午线。N表示地面点i对应的子午圈曲率半径，地面点i对应的子午圈曲率半径N可以通过如下公式计算得到：t、η2、ρ”可以通过如下公式计算得到：t＝tanBiη2＝e′2cos2BiX表示地面点i对应的子午线弧长，可以通过如下公式计算得到：a0,a2,a4,a6,a8表示基本常量，可以通过如下公式计算得到：m0,m2,m4,m6,m8表示基本常量，可以通过如下公式计算得到：高斯投影坐标值向物方坐标的转换包括：高斯投影坐标运用的高斯-克吕格平面坐标系，该系是左手系，是二维平面坐标系，即原点位于赤道，正东方向是Y轴正方向，正北方向是X轴正方向。而物方坐标系是右手系，是三维立体坐标系，即原点位于赤道，正东方向是X轴正方向，正北方向是Y轴正方向，沿铅锤方向向上是Z轴正方向。高斯正算得到的地面点i的高斯投影坐标值向物方坐标的转换公式如下：基于拍摄装置的当前时刻位置信息、拍摄装置的镜头当前时刻姿态信息、拍摄装置的镜头参数信息和目标地理位置信息对应的物方坐标值，通过共线方程，获取目标地理位置信息对应的像方坐标值。需要说明的是，基于共线方程可以实现物方坐标系和像方坐标系之间的坐标系转换。因此，本申请实施例中可以基于拍摄装置的镜头当前时刻姿态信息以及拍摄装置的镜头参数信息，通过共线方法，对目标地理位置信息对应的物方坐标值进行像方坐标系转换，获取目标地理位置信息对应的像方坐标值。其中，共线方程是中心投影构想的数学基础，也是摄影测量处理方法的重要理论基础。具体地，为了实现物方坐标系和像方坐标系之间的坐标系转换，需要基于指定高空区域的当前时刻影像的内外方位元素构建共线方程，从而建立指定高空区域的当前时刻影像中的像素与地面点之间的坐标系转换关系。基于拍摄装置的当前时刻位置信息以及拍摄装置的镜头当前时刻姿态信息，可以计算得到指定高空区域的当前时刻影像的外方位元素值。基于拍摄装置的镜头参数信息，可以计算得到指定高空区域的当前时刻影像的内方位元素值。其中，x0,y0表示指定高空区域的当前时刻影像的像主点相对于影像中心点的偏差，F表示指定高空区域的当前时刻影像的主距。需要说明的是，摄像头的镜头在成像时，若影像面正好落在焦点处，则可以确定主距的大小就等于摄像头的焦距。获取指定高空区域的当前时刻影像的外方位元素值和内方位元素值之后，可以基于指定高空区域的当前时刻影像的外方位元素值和内方位元素值以及目标数字高程模式数据构建共线方程。基于上述共线方式，可以在上述地面点i位于拍摄装置当前时刻的拍摄范围的情况下，基于上述地面点i的物方坐标值，获取上述地面点i对应的像方坐标值上述共线方程可以通过如下公式表示：对上述共线方程进行反演，可以获得：其中，在三维空间中，坐标旋转通常用3×3的正交矩阵来表示，拍摄装置的镜头当前时刻的欧拉角的旋转矩阵可以通过如下公式计算得到。其中，Rh表示h角度对应的旋转矩阵；Rp表示p角度对应的旋转矩阵；Rr表示r角度对应的旋转矩阵。基于拍摄装置的镜头当前时刻的欧拉角计算旋转矩阵时，内旋为各个方向的旋转矩阵右乘，外旋为左乘。拍摄装置的镜头当前时刻的欧拉角对应的旋转矩阵R可以通过如下公式计算得到。λ是像方坐标系与物方坐标系之间的比例系数，λ可以通过如下公式表示：需要说明的是，基于上述共线方程，遍历目标地理位置信息中每一地面点对应的物方坐标值，可以获取目标地理位置信息对应的像方坐标值。基于拍摄装置的镜头参数信息，对目标地理位置信息对应的像方坐标值进行坐标系转换，获取目标地理位置信息对应的像素坐标值。需要说明的是，在影像平面内，像方坐标的原点是影像的中心点，x轴是水平向右的，y轴是垂直向上的，但是在影像的像素坐标系中，上述像素坐标系的原点在影像左上角，述像素坐标系的x轴沿影像上边界向右，述像素坐标系的y轴沿影像的左边界向下，并且像素坐标值只能是整数。基于上述地面点i对应的像方坐标值和拍摄装置的镜头参数信息，可以通过如下公式获取指定高空区域的当前时刻影像中上述地面点i对应的像素坐标值/＞其中，pixelsize表示拍摄装置的任一像元的真实大小。需要说明的是，在使用胶卷进行影像拍摄时，像主点与影像中心点之间可能会存在手动安装的误差，但对于配置有CMOS的摄像头而言，像主点与影像中心的偏差在摄像头出场前就会得到检校，故可以认为像主点和影像中心点之间的偏差近似为0，即x0和y0近似为0。基于拍摄装置的镜头参数信息，可以通过如下公式计算得到拍摄装置的任一像元的真实大小pixelsize：其中，W表示目标影像的宽；H表示目标影像的高；w和h表示拍摄装置的镜头的CMOS成像尺寸；目标影像的宽W和高H以及拍摄装置镜头的CMOS成像尺寸，可以基于拍摄装置的镜头参数信息确定。需要说明的是，CMOS通常为4:3的比例，在拍摄比例为16:9的视频或影像的情况下，CMOS并未完全启用，只启用了中间部分，因此，在比例为4:3的情况下，影像的像素数可以达到最大，在计算像元的真实大小pixelsize时需特别注意。基于目标地理位置信息对应的像素坐标值，在指定高空区域的当前时刻影像中标记监控目标所在区域。具体地，获取目标地理位置信息对应的像素坐标值之后，可以基于上述像素坐标值，直接在指定高空区域的当前时刻影像中标记监控目标所在区域，还可以基于上述像素坐标值，在空白影像中生成图斑，在通过影像叠加，在指定高空区域的当前时刻影像中标记监控目标所在区域，获得标记有监控目标所在区域的指定高空区域的当前时刻影像。基于目标地理位置信息对应的像素坐标值，在指定高空区域的当前时刻影像中标记监控目标所在区域，包括：基于所述目标地理位置信息对应的像素坐标值，在空白影像中生成图斑，获得当前时刻拍摄装置对应的图斑影像；在所述当前时刻拍摄装置对应的图斑影像中裁剪出所述指定高空区域的当前时刻影像对应的目标图斑影像；将所述目标图斑影像与所述指定高空区域的当前时刻影像进行逐帧叠加，获得标记有所述监控目标所在区域的所述指定高空区域的当前时刻影像。具体地，本申请实施例中对当前时刻的图斑影像与指定高空区域的当前时刻影像进行逐帧叠加时，可以基于机器视觉技术算法来实现。本申请实施例中对当前时刻的图斑影像与指定高空区域的当前时刻影像进行逐帧叠加时，可以基于OpenCV影像处理算法实现。可选的，高空作业人员行为识别单元对监控目标所在区域进行高空作业人员行为识别，在确定监控目标所在区域内存在高空作业人员，则采集高空作业人员的人体框、人脸框和安全帽框，并将人体框、人脸框和安全帽框显示在监控界面，对高空作业人员进行实时跟踪监控。可选的，终端浏览行为识别单元对视频流数据中的每一帧视频图像进行终端浏览行为识别布控，得到每一帧视频图像的头部位置区域和手部位置区域，并根据头部位置区域和手部位置区域，识别出用户是否存在浏览终端设备行为，具体为：终端浏览行为识别单元获取头部位置区域中的鼻子部位位置坐标和头部位置区域的第一中心位置坐标，并根据鼻子部位位置坐标和第一中心位置坐标计算位置坐标差值，即位置坐标差值＝。可选的，终端浏览行为识别单元根据位置坐标差值对头部位置区域进行放大或缩小，得到调整后的头部位置区域，并根据调整后的头部位置区域的各个顶点位置坐标，确定第一位置坐标。终端浏览行为识别单元获取手部位置区域中光源亮度最大的光源位置坐标和手部位置区域的第二中心位置坐标，并根据光源位置坐标和第二中心位置坐标，计算位置坐标差值，即位置坐标差值＝。可选的，终端浏览行为识别单元根据位置坐标差值对手部位置区域进行放大或缩小，得到调整后的手部位置区域，并根据调整后的手部位置区域的各个顶点位置坐标，确定第二位置坐标。终端浏览行为识别单元根据调整后的头部位置区域的各个顶点位置坐标，计算头部位置区域的第一区域面积，并根据调整后的手部位置区域的各个顶点位置坐标，计算手部位置区域的第二区域面积。终端浏览行为识别单元根据调整后的头部位置区域的各个顶点位置坐标及调整后的手部位置区域的各个顶点位置坐标进行计算差值，即差值＝调整后的头部位置区域的各个顶点位置坐标-调整后的手部位置区域的各个顶点位置坐标，在一实施例中，左顶点的横坐标对应作差，左顶点的纵坐标对应作差。可选的，终端浏览行为识别单元根据差值将最大的位置坐标确定为目标位置坐标，并基于目标位置坐标计算第一目标区域面积。在一实施例中，调整后的头部位置区域的左顶点的横坐标-调整后的手部位置区域的左顶点的横坐标＞0，调整后的头部位置区域的左顶点的横坐标-调整后的手部位置区域的左顶点的横坐标＜0，则目标位置坐标的左顶点为。终端浏览行为识别单元根据第一区域面积、第二区域面积和第一目标区域面积，计算第二目标区域面积，即第二目标区域面积＝第一区域面积+第二区域面积-第一目标区域面积。终端浏览行为识别单元根据第一目标区域面积和第二目标区域面积，计算头部位置区域和手部位置区域的区域面积比值，即区域面积比值＝第一目标区域面积/第二目标区域面积。若区域面积比值大于第一预设比值，终端浏览行为识别单元则确定用户存在浏览终端设备行为，其中，第一预设比值根据实际设定。若区域面积比值小于或者等于第一预设比值，终端浏览行为识别单元则确定用户不存在浏览终端设备行为。可选的，车辆异常停放识别单元对视频流数据中的每一帧视频图像进行车辆异常停放识别布控，得到每一帧视频图像的车辆停放检测框和停车区域检测框，并根据车辆停放检测框和停车区域检测框，识别出是否存在车辆异常停放行为，具体为：车辆异常停放识别单元根据车辆停放检测框的左上角点坐标和右下角点坐标，计算车辆停放检测框的第一检测框面积，一实施例中，左上角点坐标可以采用来表示，右下角点坐标可以采用来表示。rec是一个数组，可以包括目标框的左上角和右下角两个点的坐标，可以采用rec1来表示头部对应的头部位置区域，并计算头部位置区域的区域面积。因此，车辆异常停放识别单元计算头部位置区域的区域面积为rect1_area＝*。其中，rec1表示头部位置区域的右下角点横坐标，rec1表示头部位置区域的左上角点横坐标，rec1表示头部位置区域的右下角点纵坐标，rec1表示头部位置区域的左上角点的纵坐标。车辆异常停放识别单元根据停车区域检测框的左上角点坐标和右下角点坐标，计算停车区域检测框的第二检测框面积，可以采用rec2来表示手机对应的手部位置区域，并计算手部位置区域的区域面积。因此，车辆异常停放识别单元计算手部位置区域的区域面积为rect2_area＝*。其中，rec2表示手部位置区域的右下角点横坐标，rec2表示手部位置区域的左上角点横坐标，rec2表示手部位置区域的右下角点纵坐标，rec2表示手部位置区域的左上角点的纵坐标。车辆异常停放识别单元基于车辆停放检测框和停车区域检测框中的左上角点横坐标最大值、左上角点纵坐标最小值、右下角点横坐标最小值和右下角点纵坐标最大值，计算车辆停放检测框和停车区域检测框的交集检测框面积，在一实施例中，left_max＝max，表示两个目标框的左上角点横坐标取最大值；top_min＝min，表示两个目标框的左上角点纵坐标取最小值；right_min＝min，表示两个目标框的右下角点横坐标取最小值；bottom_max＝max，表示两个目标框的右下角点纵坐标取最大值。接着，可以计算头部位置区域和手部位置区域的交集区域面积area_cross＝*。车辆异常停放识别单元根据第一检测框面积、第二检测框面积和交集检测框面积，计算车辆停放检测框和停车区域检测框的并集检测框面积，因此，可以将头部位置区域的区域面积与手部位置区域的区域面积相加后减去两个目标框的交集区域面积，得到头部位置区域和手部位置区域的并集区域面积area_union＝rect1_area+rect2_area-area_cross。车辆异常停放识别单元将交集检测框面积除以并集检测框面积，得到车辆停放检测框和停车区域检测框的交并检测框面积比，得到头部位置区域和手部位置区域的交并检测框面积比iou＝area_cross/area_union。若交并检测框面积比大于预设阈值，则确定存在车辆异常停放行为。若交并检测框面积比小于或者等于预设阈值，则确定不存在车辆异常停放行为。可选的，垃圾混扔行为识别单元从视频流数据中实时抽取出至少两帧图像，识别出各帧图像中的目标主体，目标主体包括待扔垃圾、扔垃圾对象以及存放待扔垃圾的垃圾容器中的至少一种，具体为：本实施例中，可以使用训练好的机器学习算法识别出图像中的垃圾、人以及存放待扔垃圾的垃圾容器，比如采用yolov7机器学习算法。在一个示例中，收集多个涵盖各种不同的场景和角度的包含垃圾、人和垃圾容器的图像样本，使用收集到的图像样本，训练yolov7机器学习算法，使其可以识别出图像中的不同类别的物体，并给出它们的位置和边界框。在实际应用中，使用训练好的yolov7机器学习算法识别出图像中的每一类物体以及相应的二维坐标，根据预设目标主体识别规则对各类物体进行分析，识别出待扔垃圾、扔垃圾对象以及存放待扔垃圾的垃圾容器。垃圾混扔行为识别单元对至少两帧图像中的扔垃圾对象以及待扔垃圾进行分析，以筛选出各扔垃圾对象的扔垃圾事件所关联的目标图像，具体为：在一个示例中，可以通过比较至少相邻的两帧图像中同一扔垃圾对象或同一待扔垃圾的位置变化，可以判断该待扔垃圾是否正在被扔掉，以筛选出记录了此次扔垃圾过程的目标图像。在一个示例中，还可以将至少相邻的两帧图像进行比对，找出待扔垃圾在扔垃圾过程中位置变化显著的图像，根据待扔垃圾的运动轨迹等特征，推断出与扔垃圾事件相关的目标图像。在另一个示例中，考虑到扔垃圾事件可能涉及多个连续帧图像，因此可以设置一个时间窗口来筛选相关的目标图像。比如根据时间窗口长度和重叠程度，以确保涵盖扔垃圾过程，并排除其他无关的图像。垃圾混扔行为识别单元根据目标图像中所记录的扔垃圾对象所携带的待扔垃圾一次减少的数量或各垃圾容器的垃圾合并数量，识别出垃圾混扔的目标垃圾事件，具体为：本实施例中，通过对每帧目标图像中的扔垃圾对象所携带的待扔垃圾进行计数或者对往同一个垃圾容器中所扔垃圾的垃圾合并数量进行计数。在一个示例中，遍历各个扔垃圾对象所关联的目标图像，若识别到一个扔垃圾对象在扔垃圾过程中其所携带的待扔垃圾一次减少的数量大于或等于2，则判定此次扔垃圾事件为垃圾混仍的目标垃圾事件，并使用位置框将此目标图像中的扔垃圾对象、待扔垃圾以及垃圾容器框选出来，以便于后续进一步进行人工分析。在另一个示例中，遍历各个扔垃圾对象所关联的目标图像，合并往同一种垃圾容器中扔垃圾的目标图像，若通过合并后的目标图像中识别到往该垃圾容器中所扔的垃圾合并数量大于或者等于2，则判定此次扔垃圾事件为垃圾混仍的目标垃圾事件，并使用位置框将此目标图像中的扔垃圾对象、待扔垃圾以及垃圾容器框选出来，以便于后续进一步进行人工分析。垃圾混扔行为识别单元确定图像中的待扔垃圾，其中，图像之前的缓存图像中不存在待扔垃圾或待扔垃圾与缓存图像中出现的历史垃圾之间的重叠度小于预设重叠度；若图像中包括至少两个待识别对象，则确定与待扔垃圾之间的第一距离最小，且第一距离小于第一预设距离的待识别对象为扔垃圾对象；若图像中包括至少两个垃圾容器，则确定与扔垃圾对象之间的第二距离最小的垃圾容器为存放待扔垃圾的垃圾容器，具体为：当垃圾容器中的垃圾过多或垃圾没有完全扔到垃圾容器中时，图像中也会出现此类垃圾，因此本实施例中先对图像中的所有垃圾进行识别，识别出待扔垃圾。在一个示例中，先将当前图像中的垃圾与之前的缓存图像中的垃圾进行比较，比如将当前图像中的垃圾与之前的3张缓存图像中出现的垃圾进行比较，来判断此垃圾是否在过去的3张缓存图片中出现过，如果过去的3张缓存图片中出现过此垃圾，则计算此垃圾与缓存图片中出现的历史垃圾之间的IOU重叠度，如果IOU重叠度＞90，则表示此垃圾与缓存图片中存在的某个历史垃圾的位置相同，这种情况下判别此垃圾在地上或在垃圾箱里。垃圾混扔行为识别单元在识别出待扔垃圾后，如果图像中存在至少两个待识别对象，则计算每个待识别对象与待扔垃圾之间的第一距离，选择与待扔垃圾之间的第一距离最小且小于第一预设距离的待识别对象作为扔垃圾对象。在一个示例中，待识别对象的位置是通过两个不同区域处的二维坐标、确定出的，则可以遍历图像中所有的待识别对象的二维坐标中心点与待扔垃圾之间的第一距离，以提高所确定出的第一距离的准确性，其中，待识别对象的二维坐标中心点的坐标是通过公式PointX＝x1+/2、PointY＝y1+/2得到的。若图像之前的缓存图像中不存在扔垃圾对象，则确定图像中的扔垃圾对象所携带的待扔垃圾的第一数量；若第一数量大于预设数量，则确定图像为扔垃圾对象的扔垃圾事件所关联的目标图像，具体为：如果图像之前的缓存图像中不存在此扔垃圾对象，则表明在此图像对应的时间点之前，此扔垃圾对象为第一次出现，当此扔垃圾对象为第一次出现时，识别其第一次出现时所携带的待扔垃圾的第一数量。在一个示例中，可以设定预设数量为1，也即在此第一次出现时所携带的待扔垃圾的数量为1时，表明此扔垃圾对象不会存在垃圾混仍行为，则后续不再对此扔垃圾对象进行分析，在此第一次出现时所携带的待扔垃圾的数量为2时，表明此扔垃圾对象可能会存在垃圾混仍行为，则将该图像标识为扔垃圾对象的扔垃圾事件所关联的目标图像，以便后续进行垃圾混扔识别。本实施例中，如果图像之前的缓存图像中存在扔垃圾对象，则先判断之前是否存储了此扔垃圾对象的扔垃圾事件所关联的目标图像，若是，则从扔垃圾对象的扔垃圾事件所关联的第一目标图像中获取此扔垃圾对象上一次扔完垃圾后，还剩下的待扔垃圾的数量，计算出剩下的待扔垃圾的数量与当前图像中存在的待扔垃圾的数量之间的差值，若差值大于零，则表明此图像中记录了此扔垃圾对象此次扔垃圾的过程，则将该图像标识为扔垃圾对象的扔垃圾事件所关联的目标图像，以便后续进行垃圾混扔识别。在一个示例中，扔垃圾对象的二维坐标为、，当扔垃圾对象的二维坐标符合条件：x1＜20或y2＜20或x2＞2668或y2＞2500时，表明此扔垃圾对象处于非边缘区域。在一个示例中，如果在图像中的非边缘区域内识别出扔垃圾对象、则可以使用fast-reID模型，计算出扔垃圾对象的特征向量，接着计算的扔垃圾对象的特征向量与内存中最近3张历史图像中的历史对象的特征向量之间的相似度，如果相似度＞55，则表示此扔垃圾对象在最近3张历史图像中出现，也即之前标定过此扔垃圾对象的ID标识，则可以使用历史对象的ID标识作为此扔垃圾对象的第一ID标识，并将第一ID标识、此扔垃圾对象的相似度以及特征向量关联存储至字典中。如果未找到相似度＞55的历史对象，则表示此扔垃圾对象在最近3张历史图像中未出现，也即之前没有标定过此扔垃圾对象的ID标识，则为此扔垃圾对象生成一个新的第二ID标识，并将第二ID标识、此扔垃圾对象的相似度以及特征向量关联存储至字典中。需要说明的是，当一个图像中相似度大于预设阈值的扔垃圾对象的数量不止一个时，多个不同的扔垃圾对象可能会使用同一个ID标识进行标定，因此本实施例中为了提高后续垃圾混扔识别的准确性，先将此图像中同一个第一ID标识所关联的扔垃圾对象按照相似度进行排序，并将此第一ID标识赋予相似度最大的扔垃圾对象，并为同一个第一ID标识所关联的其他扔垃圾对象生成新的第三ID标识，以将多个不同的扔垃圾对象区分开。需要说明的是，本申请实施例集成有第一环境真伪识别单元和第二环境真伪识别单元，在进行环境真伪识别时，优先调用第一环境真伪识别单元，在第一环境真伪识别单元的识别存在一定时延时，如5秒，10秒，调用第二环境真伪识别单元进行环境真伪识别。可选的，第一环境真伪识别单元确定视频流数据对应的第一判别特征向量和第二判别特征向量；第一判别特征向量表示视频流数据中每帧人脸图像之间的时域特征信息；第二判别特征向量表示视频流数据中每帧人脸图像之间的频域特征信息，具体为：根据视频流数据，可以确定视频流数据对应的第一判别特征向量和第二判别特征向量。其中，第一判别特征向量表示视频流数据中每帧人脸图像之间的时域特征信息，即视频流数据中每帧人脸图像应该具有高度一致性；第二判别特征向量表示视频流数据中每帧人脸图像之间的频域特征信息。第一环境真伪识别单元基于第一判别特征向量和第二判别特征向量，确定视频流数据对应的目标特征向量；目标特征向量表示融合时域特征信息和频域特征信息的特征信息；基于目标特征向量，确定视频流数据的检测结果；检测结果用于指示视频流数据中的环境是否为伪造环境，具体为：根据第一判别特征向量和第二判别特征向量，可以确定视频流数据对应的目标特征向量；目标特征向量表示融合时域特征信息和频域特征信息的特征信息。检测结果用于指示视频流数据中的环境是否为伪造环境，检测结果为真实环境或者伪造环境。根据目标特征向量，可以确定视频流数据的检测结果。第一环境真伪识别单元基于视频流数据中的每帧人脸图像，确定人脸图像的人脸区域和非人脸区域；人脸区域包括人眼以下包括左右两侧脸颊的区域；非人脸区域包括人眼以上除了额头以外的左右两侧区域，具体为：根据视频流数据中的每帧人脸图像，采用目标检测算法检测每帧人脸图像中的人脸区域；例如，目标检测算法为人脸检测与定位算法或者基于关键点的人脸检测算法。人脸区域采用检测框表示，对检测框对每帧人脸图像进行裁剪，得到裁剪后的人脸图像。将人脸图像进行区域划分，得到人脸区域和非人脸区域，人脸区域包括人眼以下包括左右两侧脸颊的区域；非人脸区域考虑到发饰、饰物等的影响，非人脸区域包括人眼以上除了额头以外的左右两侧区域。第一环境真伪识别单元基于各人脸区域和各非人脸区域，分别提取各人脸区域对应的第一时域特征和各非人脸区域对应的第二时域特征，具体为：第一时域特征表示视频流数据中每帧人脸图像中的人脸区域之间的时域特征信息，即人脸区域rPPG特征，第二时域特征表示视频流数据中每帧人脸图像中的非人脸区域之间的时域特征信息，即非人脸区域rPPG特征。根据各人脸区域和各非人脸区域，可以分别提取各人脸区域对应的第一时域特征和各非人脸区域对应的第二时域特征。第一环境真伪识别单元基于第一时域特征和第二时域特征，确定视频流数据对应的第一判别特征向量，具体为：根据第一时域特征和第二时域特征，采用一致性分析算法进行关联性与一致性分析，确定视频流数据对应的第一判别特征向量。例如，一致性分析算法为典型关联分析、独立成分分析、斯皮尔曼等级相关系数或者互信息。第一环境真伪识别单元基于第一时域特征，确定视频流数据对应的第二判别特征向量，具体为：根据提取的第一时域特征，采用频域分析算法对第一时域特征进行频谱分析，可以得到更多的时域特征，如频谱分析得到的结果可以表示为频率和振幅之间的关系或者频率和能量之间的关系；频谱分析得到的结果包括心率频谱、频带能量等，得到视频流数据对应的第二判别特征向量。例如，频域分析算法为快速傅里叶变换、小波变换或者其他算法。第一环境真伪识别单元将第一判别特征向量和第二判别特征向量进行归一化，得到归一化之后的第一判别特征向量和归一化之后的第二判别特征向量，具体为：将第一判别特征向量除以第一判别特征向量和第二判别特征向量之和，得到归一化之后的第一判别特征向量；将第二判别特征向量除以第一判别特征向量和第二判别特征向量之和，得到归一化之后的第二判别特征向量。第一环境真伪识别单元将归一化之后的第一判别特征向量和归一化之后的第二判别特征向量进行拼接，得到视频流数据对应的目标特征向量，具体为：将归一化之后的第一判别特征向量和所述归一化之后的第二判别特征向量进行拼接，可以得到视频流数据对应的目标特征向量。第一环境真伪识别单元将目标特征向量输入分类判别网络模型，得到分类判别网络模型输出的检测结果；分类判别网络模型是基于样本检测视频对应的样本特征向量和标签数据进行训练得到的，分类判别网络模型用于对视频流数据中的环境是否为伪造环境进行分类判别，具体为：分类判别网络模型可以为视觉几何小组模型，也可以为其他判别网络。分类判别网络模型是基于样本检测视频对应的样本特征向量和标签数据进行训练得到的，分类判别网络模型用于对视频流数据中的环境是否为伪造环境进行分类判别，其中，标签数据为真实或者伪造，例如，标签数据1表示真实，标签数据0表示伪造。将目标特征向量输入分类判别网络模型，可以直接得到分类判别网络模型输出的检测结果。在对分类判别网络模型的训练阶段，选择初始分类判别网络模型作为基础模型，仅更改并重置最后的全连接层，以标签数据为目标。在每个训练周期中，将样本特征向量输入至初始分类判别网络模型，得到初始分类判别网络模型输出的判别结果；根据判别结果和标签数据，选择交叉熵损失函数计算损失值，并根据损失值对模型进行微调，并进行反向传播更新初始分类判别网络模型的全连接层的参数，保持分类判别网络的其它层的参数不变，并采用dropout等技术防止模型过拟合，直至分类判别网络模型满足预设条件时，停止分类判别网络模型的训练，得到训练好的分类判别网络模型；其中，预设条件为损失值的累计值趋于稳定或者训练次数达到最大预设次数。通过对分类判别网络模型的训练，能够提高分类判别网络模型的性能，能够节省大量的计算时间和资源，提升对深度伪造内容的检测效率。在分类判别网络模型的测试阶段，将视频流数据对应的目标特征向量输入训练好的分类判别网络模型中，得到分类判别网络模型输出的检测结果。第二环境真伪识别单元将视频流数据进行预处理，得到多个视频片段；视频流数据包括音频，每个视频片段包括音频，具体为：获取视频流数据，该视频流数据包括音频，视频流数据为包括人脸的视频，则视频流数据中的音频为人脸对应的任务的声音。将视频流数据裁剪为预设长度的视频片段，得到多个视频片段，每个视频片段包括音频。例如，每个视频片段的时长为7至10秒，视频片段的数量为6段。实际中，由于采集环境的不同，输入视频序列的分辨率和音频信息可能均有差异，在预处理阶段，将视频流数据中的图像序列均进行解码，每帧均以图像的方式存储，且每帧图像的分辨率均缩放至同样的大小，视频流数据中的音频均解码为波形声音文件，例如，每帧图像的分辨率为1280*720，编码格式为位图，每秒保留10至15帧图像；音频编码格式为A率8比特。再使用滤波器对视频流数据中的每帧图像和音频序列进行平滑处理，以降低噪声对后续处理的干扰；其中，视频流数据和音频的滤波器的参数不同。例如，滤波器为均值滤波器，或者其他类型的滤波器。第二环境真伪识别单元针对每个视频片段，分别提取视频片段的视频特征向量和视频片段中的音频的音频特征向量，具体为：针对每个视频片段，可以分别提取该视频片段的视频特征向量和该视频片段中的音频的音频特征向量；其中，视频特征向量为采用远程光电容积脉搏波描记法提取的时域特征向量，视频特征向量包括峰值幅度、波形宽度、上升时刻和下降时刻等组成的特征向量。音频特征向量为频谱能量特征和时域特征进行归一化并拼接融合后组成的特征向量；其中，频谱能量特征可以为梅尔频率倒谱系数、常数Q倒谱系数、频谱特征包络特征、语调特征中的至少一项，时域特征可以为峰值幅度、过零率、短时能量和短时平均幅度中的至少一项。第二环境真伪识别单元基于各视频特征向量和各音频特征向量，确定视频流数据对应的总视频特征向量和总音频特征向量；基于各视频特征向量、各音频特征向量、总视频特征向量和总音频特征向量，确定视频流数据的目标检测结果；目标检测结果表示视频流数据中的环境是否为伪造环境，具体为：根据每个视频片段的视频特征向量和音频特征向量，可以确定视频流数据对应的总视频特征向量和总音频特征向量。根据每个视频片段的视频特征向量和音频特征向量、视频流数据的总视频特征向量和总音频特征向量，可以确定视频流数据的目标检测结果；其中，目标检测结果表示视频流数据中的环境是否为伪造环境。第二环境真伪识别单元基于所述总视频特征向量和所述总音频特征向量，确定所述视频流数据对应的融合特征向量，具体为：根据视频流数据对应的总视频特征向量和总音频特征向量，可以确定视频流数据对应的融合特征向量。第二环境真伪识别单元基于各所述视频特征向量、各所述音频特征向量和所述融合特征向量，分别确定各所述视频特征向量对应的第一检测结果、各所述音频特征向量对应的第二检测结果和所述融合特征向量对应的第三检测结果，具体为：根据各视频特征向量、各音频特征向量和融合特征向量，可以分别确定各视频特征向量对应的第一检测结果、各音频特征向量对应的第二检测结果和融合特征向量对应的第三检测结果；其中，第一检测结果表示视频流数据中的环境是否为伪造环境，第二检测结果表示视频流数据中的环境是否为伪造环境，第三检测结果表示视频流数据中的环境是否为伪造环境。第二环境真伪识别单元基于所述第一检测结果、所述第二检测结果和所述第三检测结果，确定所述视频流数据的目标检测结果，具体为：根据第一检测结果、第二检测结果和第三检测结果，可以确定检测视频的目标检测结果。第二环境真伪识别单元针对每个所述视频片段，将所述视频片段对应的所述视频特征向量和所述音频特征向量进行归一化，分别得到归一化之后的视频特征向量和归一化之后的音频特征向量，具体为：针对每个视频片段，将视频片段对应的视频特征向量除以所有视频片段分别对应的各视频特征向量之和，得到归一化之后的视频特征向量；将视频片段对应的音频特征向量除以所有视频片段分别对应的各音频特征向量，得到归一化之后的音频特征向量。第二环境真伪识别单元分别将各所述归一化之后的视频特征向量和各所述归一化之后的音频特征向量进行拼接，得到所述视频流数据对应的总视频特征向量和总音频特征向量，具体为：将各归一化之后的视频特征向量进行拼接，得到视频流数据对应的总视频特征向量；将各归一化之后的音频特征向量进行拼接，得到视频流数据对应的总音频特征向量。目标跟踪单元获取视频流数据的目标图像和热成像装置采集的目标图像对应的第一点云数据，具体为：拍摄装置实时的采集待跟踪目标的目标图像，热成像装置通过激光束或者结构光辐射在环境中并记录辐射在环境中的反射数据，这些反射数据被用于生成点云数据。通过拍摄装置和热成像装置的标定参数，对目标图像和反射数据进行对齐，实现目标图像对应的第一点云数据的获取。目标跟踪单元基于目标图像和第一点云数据，确定待跟踪目标的第二点云数据，具体为：第一点云数据表示热成像装置采集的包括待跟踪目标的目标图像对应的点云数据，第二点云数据表示只包括待跟踪目标图像对应的点云数据，即将待跟踪目标从目标图像从分割出来，得到待跟踪目标的点云数据。根据目标图像和第一点云数据，可以确定待跟踪目标的第二点云数据。目标跟踪单元基于第二点云数据，确定待跟踪目标在下一时刻的位姿信息，具体为：位姿信息包括位置信息、方向信息和角度信息，根据待跟踪目标在当前时刻的第二点云数据，可以对待跟踪目标在下一时刻的位姿信息进行预测，确定待跟踪目标在下一时刻的位姿信息。目标跟踪单元基于待跟踪目标在下一时刻的位姿信息，对待跟踪目标进行跟踪，具体为：根据待跟踪目标在下一时刻的位姿信息，将拍着装置对准待跟踪目标表面，并逐步改变拍摄位姿的策略，不断尝试检测识别待跟踪目标，直到准确得到待跟踪目标的检测结果为止，待跟踪目标的检测结果的判断可以通过重叠度实现，IOU量化了检测框与真实标注框之间的重叠程度。目标跟踪单元将目标图像输入至目标检测网络模型，得到目标检测网络模型输出的待跟踪目标在当前时刻位置信息；目标检测网络模型是基于样本目标图像和标签数数据进行训练得到，用于对目标图像中的待跟踪目标进行检测，具体为：将目标图像输入至目标检测网络模型，目标检测网络模型利用待跟踪目标的特征和初始时刻的待跟踪目标的特征进行匹配，得到当前时刻的目标图像中与初始时刻的目标图像的最相似的区域，及根据匹配结果更新待跟踪目标的检测框，确保检测框能够准确地反应待跟踪目标的位置信息，进而更新待跟踪目标的位置信息，实现对待跟踪目标的定位和分类，得到目标检测网络模型输出的待跟踪目标在当前时刻位置信息。目标跟踪单元将第一点云数据和位置信息对应的待跟踪目标图像进行对齐，确定待跟踪目标在第一点云数据对应的位置和范围，具体为：通过将位置信息对应的待跟踪目标图像中每个位置的像素点与对应位置的第一点云数据进行对齐，可以确定待跟踪目标在对齐的第一点云数据对应的位置和范围。实际中，在待跟踪目标图像中检测每个像素对应的特征点，并将该特征点与第一点云数据中的对应点进行匹配，通过匹配待跟踪目标图像和第一点云数据中的对应点，可以建立像素点和点云数据之间的对应关系，实现第一点云数据和待跟踪目标图像的对齐。在对齐待跟踪目标图像和第一点云数据之后，通常需要对第一点云数据进行坐标系转换，即将第一点云数据转换为三维坐标，以使待跟踪目标图像和第一点云数据在相同的坐标系中表示，并将第一点云数据与待跟踪目标图像中的像素对应。目标跟踪单元基于位置和范围，确定待跟踪目标的第二点云数据，具体为：根据待跟踪目标在第一点云数据对应的位置和范围，将待跟踪目标从第一点云数据中分割出来，得到待跟踪目标的第二点云数据。本申请实施例提供的智能布控球包括热成像装置、拍摄装置、KA200类脑芯片和布控监测装置；拍摄装置和布控监测装置分别与KA200类脑芯片连接，KA200类脑芯片用于控制拍摄装置和布控监测装置；布控监测装置包括高空作业人员行为识别单元、终端浏览行为识别单元、车辆异常停放识别单元、垃圾混扔行为识别单元、第一环境真伪识别单元、第二环境真伪识别单元和目标跟踪单元。在智能布控球进行布控的过程中，智能布控球实现当通过内置的异常识别模块识别到异常情况时，可通过水平旋转或俯仰旋转调整拍摄装置，再对拍摄装置进行变焦镜头调节焦距，实现对异常情况的精准拍摄。可选的，一种智能布控球的布控方法，应用于如上述的智能布控球，包括：采集视频流数据和点云数据。基于视频流数据进行高空作业人员行为识别，具体为：获取拍摄装置的当前时刻位置信息、当前时刻镜头姿态信息和镜头参数信息，以及视频流数据中指定高空区域的当前时刻影像；基于当前时刻位置信息、当前时刻镜头姿态信息、镜头参数信息以及指定高空区域中监控目标所在区域的地理位置信息和数字高程模型数据，在当前时刻影像中标记监控目标所在区域；对监控目标所在区域进行高空作业人员行为识别，在确定监控目标所在区域内存在高空作业人员，则采集高空作业人员的人体框、人脸框和安全帽框，并将人体框、人脸框和安全帽框显示在监控界面。基于视频流数据进行进行终端浏览行为识别布控，具体为：对视频流数据中的每一帧视频图像进行终端浏览行为识别布控，得到每一帧视频图像的头部位置区域和手部位置区域，并根据头部位置区域和手部位置区域，识别出用户是否存在浏览终端设备行为；或，基于视频流数据车辆异常停放识别，具体为：对视频流数据中的每一帧视频图像进行车辆异常停放识别布控，得到每一帧视频图像的车辆停放检测框和停车区域检测框，并根据车辆停放检测框和停车区域检测框，识别出是否存在车辆异常停放行为。基于视频流数据进行垃圾混扔行为识别，具体为：从视频流数据中实时抽取出至少两帧图像，识别出各帧图像中的目标主体，目标主体包括待扔垃圾、扔垃圾对象以及存放待扔垃圾的垃圾容器中的至少一种；对至少两帧图像中的扔垃圾对象以及待扔垃圾进行分析，以筛选出各扔垃圾对象的扔垃圾事件所关联的目标图像；根据目标图像中所记录的扔垃圾对象所携带的待扔垃圾一次减少的数量或各垃圾容器的垃圾合并数量，识别出垃圾混扔的目标垃圾事件。基于视频流数据进行环境真伪识别，具体为：确定视频流数据对应的第一判别特征向量和第二判别特征向量；第一判别特征向量表示视频流数据中每帧人脸图像之间的时域特征信息；第二判别特征向量表示视频流数据中每帧人脸图像之间的频域特征信息；基于第一判别特征向量和第二判别特征向量，确定视频流数据对应的目标特征向量；目标特征向量表示融合时域特征信息和频域特征信息的特征信息；基于目标特征向量，确定视频流数据的检测结果；检测结果用于指示视频流数据中的环境是否为伪造环境。基于视频流数据进行环境真伪识别，具体为：将视频流数据进行预处理，得到多个视频片段；视频流数据包括音频，每个视频片段包括音频；针对每个视频片段，分别提取视频片段的视频特征向量和视频片段中的音频的音频特征向量；基于各视频特征向量和各音频特征向量，确定视频流数据对应的总视频特征向量和总音频特征向量；基于各视频特征向量、各音频特征向量、总视频特征向量和总音频特征向量，确定视频流数据的目标检测结果；目标检测结果表示视频流数据中的环境是否为伪造环境。基于视频流数据和点云数据进行目标跟踪，具体为：获取视频流数据的目标图像和热成像装置采集的目标图像对应的第一点云数据；基于目标图像和第一点云数据，确定待跟踪目标的第二点云数据；基于第二点云数据，确定待跟踪目标在下一时刻的位姿信息；基于待跟踪目标在下一时刻的位姿信息，对待跟踪目标进行跟踪。智能布控球的布控方法对应上述实施例，不再赘述。可选的，参考图2，图2是本申请实施例提供的智能布控球的结构示意图之二。智能布控球包括底座1、外罩2、内置装置3、拍摄装置4和热成像装置5。内置装置3集成有KA200类脑芯片和布控监测装置，布控监测装置集成有高空作业人员行为识别单元、终端浏览行为识别单元、车辆异常停放识别单元、垃圾混扔行为识别单元、第一环境真伪识别单元、第二环境真伪识别单元和目标跟踪单元。最后应说明的是：以上实施例仅用以说明本申请的技术方案，而非对其限制；尽管参照前述实施例对本申请进行了详细的说明，本领域的普通技术人员应当理解：其依然可以对前述各实施例所记载的技术方案进行修改，或者对其中部分技术特征进行等同替换；而这些修改或者替换，并不使相应技术方案的本质脱离本申请各实施例技术方案的精神和范围。
