标题title
基于标签共享的纵向联邦学习差分隐私保护方法及系统
摘要abst
一种基于标签共享的纵向联邦学习差分隐私保护方法及系统，方法包括对主方的标签数据进行差分隐私加噪扰动，并将扰动后的标签数据共享给各个来宾方；各个来宾方利用接收到的标签数据进行本地模型参数训练；本地模型训练好之后，各个来宾方将本地模型参数进行差分隐私加噪扰动后发送给主方；主方结合各个来宾方的本地模型参数和自身的模型数据进行聚合训练，获得学习模型。本发明还公开了一种基于标签共享的纵向联邦学习差分隐私保护系统、电子设备及计算机可读存储介质。本发明通过在数据标签和汇聚梯度上添加满足差分隐私的噪声，减小了计算和内存开销。在模型参数汇聚过程中对梯度信息添加噪声以防止信息的泄露，同时减少了通信次数与通信成本。
权利要求书clms
1.一种基于标签共享的纵向联邦学习差分隐私保护方法，其特征在于，包括：对主方的标签数据进行差分隐私加噪扰动，得到扰动后的标签数据，并将扰动后的标签数据共享给各个来宾方；各个来宾方利用接收到的标签数据进行本地模型参数训练；本地模型参数训练好之后，各个来宾方将本地模型参数进行差分隐私加噪扰动后发送给主方；主方结合各个来宾方差分隐私加噪扰动后的本地模型参数和自身的模型数据进行聚合训练，获得差分隐私加噪扰动后的学习模型。2.根据权利要求1所述基于标签共享的纵向联邦学习差分隐私保护方法，其特征在于，由主方与各个来宾方所有数据组成的全局数据集为，式中n为样本数量，假设样本的特征分布在m个来宾方中，即/＞，仅有一个主方有标签/＞，当主方结合各个来宾方差分隐私加噪扰动后的本地模型参数和自身的模型数据进行聚合训练，获得差分隐私加噪扰动后的学习模型时，由主方与各个来宾方组成参与方，其中，每个参与方/＞均拥有本地数据集/＞，通过所有来宾方/＞与主方协同合作训练一个模型/＞，式中/＞指所训练模型的参数；训练过程表达式为：式中，是损失函数，/＞是正则项。3.根据权利要求2所述基于标签共享的纵向联邦学习差分隐私保护方法，其特征在于，对主方的标签数据进行差分隐私加噪扰动，得到扰动后的标签数据，并将扰动后的标签数据共享给各个来宾方包括：标签数据分桶，统计主方原始的数据标签分布；使用k-RR本地差分隐私加噪扰动数据标签，假设标签有k种结果，对于任意输入R，以/＞的概率响应真实的结果/＞，以/＞的概率响应到其余k-1个结果/＞；设共享给来宾方j的最终的扰动结果为/＞；其中：如果，第个来宾方样本/＞的唯一标识符为/＞，则主方将所拥有样本数据的/＞发送给其余各来宾方，来宾方/＞根据标识符配对，得到/＞；/＞为所消耗的隐私代价，通过设置隐私代价/＞的大小控制隐私保护程度/＞。4.根据权利要求2所述基于标签共享的纵向联邦学习差分隐私保护方法，其特征在于，各个来宾方利用接收到的标签数据进行本地模型参数训练包括：计算损失函数和梯度/＞：式中，为来宾方/＞的参数，/＞为来宾方/＞在第t轮的模型函数，/＞为来宾方/＞接收到的加噪后的标签数据，/＞为损失函数的F范式平方，/＞则表示梯度求导函数；进行参数更新，为学习率：式中，为来宾方j在第t+1轮的参数，/＞为来宾方j在第t轮的参数，/＞为第t轮的学习率；直到收敛或达到设置的最大阶段数，得到模型，式中，/＞为来宾方j的模型代表，/＞为参数为/＞的模型函数。5.根据权利要求2所述基于标签共享的纵向联邦学习差分隐私保护方法，其特征在于，本地模型参数训练好之后，各个来宾方将本地模型参数进行差分隐私加噪扰动后发送给主方包括：对来宾方训练出的模型参数进行正则裁剪，引入裁剪阈值/＞，使得/＞，即：式中，为来宾方j经过正则裁剪后的参数，/＞为模型参数/＞的第一范式；添加满足拉普拉斯机制的噪声，即：式中，为参与方j加噪后的参数，/＞为拉普拉斯机制函数，/＞为隐私代价；得到模型参数，并将其发送给主方，式中，/＞为来宾方j的模型代表，/＞为加噪参数/＞的模型函数。6.根据权利要求2所述基于标签共享的纵向联邦学习差分隐私保护方法，其特征在于，主方结合各个来宾方差分隐私加噪扰动后的本地模型参数和自身的模型数据进行聚合训练，获得差分隐私加噪扰动后的学习模型包括：计算损失函数和梯度/＞：式中，为第t轮的损失函数，/＞为模型训练的参数，/＞为参与方1的特征数据，为了方便，将/＞表示为/＞，/＞为所有来宾方本地训练得到的模型代表结果，/＞为在第t轮中训练参数w的模型函数，/＞为主方的真实标签数据；利用高斯截断机制保护梯度信息，其中噪声大小为，/＞为学习率：式中，为在第t轮经过正则裁剪后的梯度，/＞为第t轮梯度的二范式，/＞为第t轮加噪后的梯度，/＞表示均值为0且方差为/＞的高斯函数，/＞为单位向量，为第t+1轮的参数；输出各个来宾方的加噪学习模型参数以及主方的加噪学习模型参数/＞。7.一种基于标签共享的纵向联邦学习差分隐私保护系统，其特征在于，包括：标签共享模块，用于对主方的标签数据进行差分隐私加噪扰动，得到扰动后的标签数据，并将扰动后的标签数据共享给各个来宾方；来宾方本地模型训练模块，用于各个来宾方利用接收到的标签数据进行本地模型参数训练；来宾方模型参数传输模块，用于本地模型参数训练好之后，各个来宾方将本地模型参数进行差分隐私加噪扰动后发送给主方；主方模型聚合训练模块，用于主方结合各个来宾方差分隐私加噪扰动后的本地模型参数和自身的模型数据进行聚合训练，获得差分隐私加噪扰动后的学习模型。8. 一种电子设备，其特征在于，包括：存储器，存储至少一个指令；及处理器，执行所述存储器中存储的指令以实现如权利要求1至6中任意一项所述基于标签共享的纵向联邦学习差分隐私保护方法。9.一种计算机可读存储介质，其特征在于：所述计算机可读存储介质中存储有至少一个指令，所述至少一个指令被电子设备中的处理器执行以实现如权利要求1至6中任意一项所述基于标签共享的纵向联邦学习差分隐私保护方法。
说明书desc
技术领域本发明属于数据隐私与安全技术领域，具体涉及一种基于标签共享的纵向联邦学习差分隐私保护方法及系统。背景技术如今，人工智能技术的发展蒸蒸日上，并广泛应用于生活的方方面面，遍布日常生活、工业生产、医疗卫生等各个领域。然而，人工智能技术的发展需要庞大数据量的推动，越高精度、越优秀的模型往往越需要大量的数据来训练。因此，可以说，庞大的数据是机器学习模型训练的基础。而在实际中，数据可能分布在各个移动设备或者不同拥有者手上。一个独立的机构所拥有的数据量是有限的，也很难训练出理想的模型。数据共享的需求应运而生。但是随着对数据的隐私与安全问题日益注重，同时数据的价值也日益增加，数据拥有者尤其是个人对于分享敏感、隐私数据的意愿日益降低。而对于公司而言，不可能轻易与其他公司共享隐私数据。在法律方面，隐私数据保护问题也被落实到法律法规中。那么如何在保证隐私数据安全，且满足各参与方意愿的情况下，合法共同训练一个模型就成为了问题。针对这个问题，2016年，谷歌提出了联邦学习，在联邦学习的框架下，通过建立一个全局模型解决不同数据拥有方在不交换数据的情况下进行协作的问题。在联邦学习隐私保护中，纵向联邦学习与横向联邦学习的不同在于，横向联邦学习拥有模型完整的数据特征，包括数据标签，但数据样本不足。在具有完整数据标签的情况下，可以采用正常的机器学习算法训练出一个完整的模型。而纵向联邦学习的数据特征是零散的，分布在各个参与方手上，仅有限个参与方有数据标签，不具备数据标签的参与方无法独立训练一个完整的模型或者只能采用无监督学习的方法。因此，一般会采用加密交换来达成数据共享，但需要多次通信，通信成本高且计算和内存开销大。纵向联邦学习也可以说是按照特征划分的联邦学习，各方的用户群体相似，但获得的用户特征不同。纵向联邦学习使得参与者在对齐样本后，使用分散特征共同训练机器学习模型，且不暴露自身的原始数据。尽管纵向联邦学习在某种程度上保证了安全性，由于参与方之间互不信任，为了保证各自的数据安全性，在进行参数共享的时候选择加密共享，但基于加密交换的纵向联邦学习往往需要多次通信，会产生昂贵的通信成本且加密会带来高昂的计算成本。发明内容本发明的目的在于针对上述现有技术中的问题，提供一种基于标签共享的纵向联邦学习差分隐私保护方法及系统，通过在数据标签和汇聚梯度上添加满足差分隐私的噪声，在保护参与方数据隐私的同时，减少通信代价和计算成本。为了实现上述目的，本发明有如下的技术方案：第一方面，提供一种基于标签共享的纵向联邦学习差分隐私保护方法，包括：对主方的标签数据进行差分隐私加噪扰动，得到扰动后的标签数据，并将扰动后的标签数据共享给各个来宾方；各个来宾方利用接收到的标签数据进行本地模型参数训练；本地模型参数训练好之后，各个来宾方将本地模型参数进行差分隐私加噪扰动后发送给主方；主方结合各个来宾方差分隐私加噪扰动后的本地模型参数和自身的模型数据进行聚合训练，获得差分隐私加噪扰动后的学习模型。作为一种优选的方案，由主方与各个来宾方所有数据组成的全局数据集为，式中n为样本数量，假设样本/＞的特征分布在m个来宾方中，即，仅有一个主方有标签/＞，当主方结合各个来宾方差分隐私加噪扰动后的本地模型参数和自身的模型数据进行聚合训练，获得差分隐私加噪扰动后的学习模型时，由主方与各个来宾方组成参与方，其中，每个参与方/＞均拥有本地数据集/＞，通过所有来宾方/＞与主方/＞协同合作训练一个模型，式中/＞指所训练模型的参数；训练过程表达式为：式中，是损失函数，/＞是正则项。作为一种优选的方案，对主方的标签数据进行差分隐私加噪扰动，得到扰动后的标签数据，并将扰动后的标签数据共享给各个来宾方包括：标签数据分桶，统计主方原始的数据标签分布；使用k-RR本地差分隐私加噪扰动数据标签，假设标签有k种结果，对于任意输入R，以/＞的概率响应真实的结果/＞，以的概率响应到其余k-1个结果/＞；设共享给来宾方j的最终的扰动结果为/＞；其中：如果，第个来宾方样本/＞的唯一标识符为/＞，则主方将所拥有样本数据的发送给其余各来宾方，来宾方/＞根据标识符配对，得到/＞；/＞为所消耗的隐私代价，通过设置隐私代价/＞的大小控制隐私保护程度/＞。作为一种优选的方案，各个来宾方利用接收到的标签数据进行本地模型参数训练包括：计算损失函数和梯度/＞：式中，为来宾方/＞的参数，/＞为来宾方/＞在第t轮的模型函数，/＞为来宾方/＞接收到的加噪后的标签数据，/＞为损失函数的F范式平方，/＞则表示梯度求导函数；进行参数更新，为学习率：式中，为来宾方j在第t+1轮的参数，/＞为来宾方j在第t轮的参数，/＞为第t轮的学习率；直到收敛或达到设置的最大阶段数，得到模型，式中，/＞为来宾方j的模型代表，/＞为参数为/＞的模型函数。作为一种优选的方案，本地模型参数训练好之后，各个来宾方将本地模型参数进行差分隐私加噪扰动后发送给主方包括：对来宾方训练出的模型参数进行正则裁剪，引入裁剪阈值/＞，使得/＞，即：式中，为来宾方j经过正则裁剪后的参数，/＞为模型参数/＞的第一范式；添加满足拉普拉斯机制的噪声，即：式中，为参与方j加噪后的参数，/＞为拉普拉斯机制函数，/＞为隐私代价；得到模型参数，并将其发送给主方，式中，/＞为来宾方j的模型代表，为加噪参数/＞的模型函数。作为一种优选的方案，主方结合各个来宾方差分隐私加噪扰动后的本地模型参数和自身的模型数据进行聚合训练，获得差分隐私加噪扰动后的学习模型包括：计算损失函数和梯度/＞：式中，为第t轮的损失函数，/＞为模型训练的参数，/＞为参与方1的特征数据，为了方便，将/＞表示为/＞，/＞为所有来宾方本地训练得到的模型代表结果，/＞为在第t轮中训练参数w的模型函数，/＞为主方的真实标签数据；利用高斯截断机制保护梯度信息，其中噪声大小为，/＞为学习率：式中，为在第t轮经过正则裁剪后的梯度，/＞为第t轮梯度的二范式，为第t轮加噪后的梯度，/＞表示均值为0且方差为/＞的高斯函数，/＞为单位向量，/＞为第t+1轮的参数；输出各个来宾方的加噪学习模型参数以及主方的加噪学习模型参数/＞。第二方面，提供一种基于标签共享的纵向联邦学习差分隐私保护系统，包括：标签共享模块，用于对主方的标签数据进行差分隐私加噪扰动，得到扰动后的标签数据，并将扰动后的标签数据共享给各个来宾方；来宾方本地模型训练模块，用于各个来宾方利用接收到的标签数据进行本地模型参数训练；来宾方模型参数传输模块，用于本地模型参数训练好之后，各个来宾方将本地模型参数进行差分隐私加噪扰动后发送给主方；主方模型聚合训练模块，用于主方结合各个来宾方差分隐私加噪扰动后的本地模型参数和自身的模型数据进行聚合训练，获得差分隐私加噪扰动后的学习模型。第三方面，提供一种电子设备，包括：存储器，存储至少一个指令；及处理器，执行所述存储器中存储的指令以实现所述基于标签共享的纵向联邦学习差分隐私保护方法。第四方面，提供一种计算机可读存储介质，所述计算机可读存储介质中存储有至少一个指令，所述至少一个指令被电子设备中的处理器执行以实现所述基于标签共享的纵向联邦学习差分隐私保护方法。相较于现有技术，本发明至少具有如下的有益效果：由于参与方之间互不信任，为了保证各自的数据安全性，在进行参数共享的时候选择加密共享，但基于加密交换的纵向联邦学习往往需要多次通信，会产生昂贵的通信成本且加密会带来高昂的计算成本。本发明适用于数据模型纵向联邦学习的差分隐私保护方法，通过在数据标签和汇聚梯度上添加满足差分隐私的噪声，减小了计算和内存开销。在模型参数汇聚过程中为了预防攻击者的重构攻击，对梯度信息添加噪声以防止信息的泄露。采用训练完整本地模型再加噪参数共享本地模型的方法，减少了通信次数进而降低了通信成本。附图说明为了更清楚地说明本发明实施例中的技术方案，下面将对实施例描述中所需要使用的附图作简单地介绍，显而易见地，下面描述中的附图是本发明的一些实施例，对于本领域普通技术人员来讲，在不付出创造性劳动的前提下，还可以根据这些附图获得其他的附图。图1 本发明实施例基于标签共享的纵向联邦学习差分隐私保护方法应用场景示意图；图2 本发明实施例基于标签共享的纵向联邦学习差分隐私保护方法流程图。具体实施方式下面结合附图对本发明做进一步的详细说明。请参阅图1，本发明实施例提出一种基于标签共享的纵向联邦学习差分隐私保护方法，在具体的应用场景中，多个参与方拥有不同特征的数据，但仅有一个参与方拥有数据标签，需要结合各方数据共同训练一个模型。数据标签共享、参数共享以及聚合参数过程均受差分隐私方案保护。其中，数据标签共享的差分隐私方案的主要过程为，根据数据标签分布进行分桶，对分桶后的数据标签进行随机响应，使得结果满足差分隐私。参数共享的差分隐私主要过程为，对参数添加噪声，并传输给主方。聚合训练的差分隐私方案过程为，对梯度进行正则裁剪，对裁剪后的梯度添加满足松弛差分隐私的噪声，再进行参数更新。对于纵向联邦学习算法而言，由于参与方之间互不信任，为了保证各自的数据安全性，在进行参数共享的时候可以选择加密共享，但基于加密交换的纵向联邦学习往往需要多次通信，会产生昂贵的通信成本，并且加密会带来高昂的计算成本。为了减少通信代价和计算成本，需要通过差分隐私设计出减少通信次数的学习框架。并且相比于加密和安全多方计算，差分隐私的计算代价更低。差分隐私应用于纵向联邦学习方案的主要问题在于，如何在保护用户隐私的情况下共享标签数据完成本地训练，以及如何在保护参数安全的情况下共享参数进行更新。本地缺乏数据标签，无法在本地进行模型训练，目前一般会采用基于加密的数据共享方案，例如，基于同态加密的纵向联邦学习方案。存在一个被信任的第三方，生成同态加密公钥和私钥，将公钥发送给主方和来宾方，来宾方在本地参与方计算前向传播结果，使用公钥执行加密发送给主方，主方接收到所有来宾方前向传播结果，与本地数据前向传播的结果进行累加，计算得到同态加密后的预测标签值。当反向传播时，主方计算损失函数关于标签值的梯度，将计算的梯度同态加密后下发给各个来宾方，来宾方和主方利用收到的梯度进行参数更新。但是以上的方案需要进行多次通信和同态加密计算，通信成本和计算成本高，大量消耗内存，且需要一个可信任的第三方，差分隐私可以很好的解决这些问题。在联邦学习隐私保护中，纵向联邦学习与横向联邦学习的不同在于，横向联邦学习拥有模型完整的数据特征，包括数据标签，但数据样本不足。在具有完整数据标签的情况下，可以采用正常的机器学习算法训练出一个完整的模型。纵向联邦学习的数据特征是零散的，分布在各个参与方手上，仅仅有限个参与方有数据标签，不具备数据标签的参与方无法独立训练一个完整的模型或只能采用无监督学习的方法。一般会采用加密交换来达成数据共享，但需要多次通信，且通信成本高以及计算和内存开销大。而差分隐私技术可以解决这个问题，常用的松弛差分隐私方案是高斯机制，即对梯度添加服从高斯分布Gauss的噪声，常用的多分类本地差分隐私方案是随机响应机制，对有多个候选值的变量进行随机响应。为了解决上述技术问题，本发明实施例基于标签共享的纵向联邦学习差分隐私保护方法采用以下方案：首先对主方的标签数据进行本地差分隐私加噪，并结合唯一id共享给其他参与方。接着各个来宾方根据接收到的标签数据和自身数据，利用神经网络进行训练，得到训练好的模型，将模型参数进行加噪发送给主方。主方收到各来宾方的模型参数，结合自身的模型数据进行聚合训练，训练过程中对梯度添加满足差分隐私的噪声，最后得到学习模型。如图2所示，本发明实施例基于标签共享的纵向联邦学习差分隐私保护方法包括：对主方的标签数据进行差分隐私加噪扰动，得到扰动后的标签数据，并将扰动后的标签数据共享给各个来宾方；各个来宾方利用接收到的标签数据进行本地模型参数训练；本地模型参数训练好之后，各个来宾方将本地模型参数进行差分隐私加噪扰动后发送给主方；主方结合各个来宾方差分隐私加噪扰动后的本地模型参数和自身的模型数据进行聚合训练，获得差分隐私加噪扰动后的学习模型。由主方与各个来宾方所有数据组成的全局数据集为，式中n为样本数量，假设样本/＞的特征分布在m个来宾方中，即/＞，仅有一个主方有标签，当主方结合各个来宾方差分隐私加噪扰动后的本地模型参数和自身的模型数据进行聚合训练，获得差分隐私加噪扰动后的学习模型时，由主方与各个来宾方组成参与方，其中，每个参与方/＞均拥有本地数据集/＞，通过所有来宾方与主方/＞协同合作训练一个模型/＞，式中/＞指所训练模型的参数；训练过程表达式为：式中，是损失函数，/＞是正则项。在一种可能的实施方式中，所述对主方的标签数据进行差分隐私加噪扰动，得到扰动后的标签数据，并将扰动后的标签数据共享给各个来宾方的步骤具体包括：标签数据分桶，统计主方原始的数据标签分布；使用k-RR本地差分隐私加噪扰动数据标签，假设标签有k种结果，对于任意输入R，以/＞的概率响应真实的结果/＞，以的概率响应到其余k-1个结果/＞；设共享给来宾方j的最终的扰动结果为/＞；其中：如果，第个来宾方样本/＞的唯一标识符为/＞，则主方将所拥有样本数据的发送给其余各来宾方，来宾方/＞根据标识符配对，得到/＞；/＞为所消耗的隐私代价，通过设置隐私代价/＞的大小控制隐私保护程度/＞。在一种可能的实施方式中，所述各个来宾方利用接收到的标签数据进行本地模型参数训练的步骤具体包括：计算损失函数和梯度/＞：式中，为来宾方/＞的参数，/＞为来宾方/＞在第t轮的模型函数，/＞为来宾方/＞接收到的加噪后的标签数据，/＞为损失函数的F范式平方，/＞则表示梯度求导函数；进行参数更新，为学习率：式中，为来宾方j在第t+1轮的参数，/＞为来宾方j在第t轮的参数，/＞为第t轮的学习率；直到收敛或达到设置的最大阶段数，得到模型，式中，/＞为来宾方j的模型代表，/＞为参数为/＞的模型函数。在一种可能的实施方式中，所述本地模型参数训练好之后，各个来宾方将本地模型参数进行差分隐私加噪扰动后发送给主方的步骤包括：对来宾方训练出的模型参数进行正则裁剪，引入裁剪阈值/＞，使得/＞，即：式中，为来宾方j经过正则裁剪后的参数，/＞为模型参数/＞的第一范式；添加满足拉普拉斯机制的噪声，即：式中，为参与方j加噪后的参数，/＞为拉普拉斯机制函数，/＞为隐私代价；得到模型参数，并将其发送给主方，式中，/＞为来宾方j的模型代表，为加噪参数/＞的模型函数。在一种可能的实施方式中，所述主方结合各个来宾方差分隐私加噪扰动后的本地模型参数和自身的模型数据进行聚合训练，获得差分隐私加噪扰动后的学习模型的步骤具体包括：计算损失函数和梯度/＞：式中，为第t轮的损失函数，/＞为模型训练的参数，/＞为参与方1的特征数据，为了方便，将/＞表示为/＞，/＞为所有来宾方本地训练得到的模型代表结果，/＞为在第t轮中训练参数w的模型函数，/＞为主方的真实标签数据；利用高斯截断机制保护梯度信息，其中噪声大小为，/＞为学习率：式中，为在第t轮经过正则裁剪后的梯度，/＞为第t轮梯度的二范式，为第t轮加噪后的梯度，/＞表示均值为0且方差为/＞的高斯函数，/＞为单位向量，/＞为第t+1轮的参数；输出各个来宾方的加噪学习模型参数以及主方的加噪学习模型参数/＞。在最终得到的学习模型中：模型函数是由参数决定的，所以最终获得的学习模型是指训练最终收敛所得到的参数。因此，不同参与方会得到不同的训练参数，包括一个是各个来宾方j均得到自己的学习模型参数，另一个是主方的学习模型参数/＞。本发明的另一实施还提出一种基于标签共享的纵向联邦学习差分隐私保护系统，包括：标签共享模块，用于对主方的标签数据进行差分隐私加噪扰动，得到扰动后的标签数据，并将扰动后的标签数据共享给各个来宾方；来宾方本地模型训练模块，用于各个来宾方利用接收到的标签数据进行本地模型参数训练；来宾方模型参数传输模块，用于本地模型参数训练好之后，各个来宾方将本地模型参数进行差分隐私加噪扰动后发送给主方；主方模型聚合训练模块，用于主方结合各个来宾方差分隐私加噪扰动后的本地模型参数和自身的模型数据进行聚合训练，获得差分隐私加噪扰动后的学习模型。本发明的另一实施还提出一种电子设备，包括：存储器，存储至少一个指令；及处理器，执行所述存储器中存储的指令以实现所述基于标签共享的纵向联邦学习差分隐私保护方法。本发明的另一实施还提出一种计算机可读存储介质，所述计算机可读存储介质中存储有至少一个指令，所述至少一个指令被电子设备中的处理器执行以实现所述基于标签共享的纵向联邦学习差分隐私保护方法。示例性的，所述存储器中存储的指令可以被分割成一个或多个模块/单元，所述一个或者多个模块/单元被存储在计算机可读存储介质中，并由所述处理器执行，以完成本发明基于标签共享的纵向联邦学习差分隐私保护方法。所述一个或多个模块/单元可以是能够完成特定功能的一系列计算机可读指令段，该指令段用于描述所述计算机程序在服务器中的执行过程。所述电子设备可以是智能手机、笔记本、掌上电脑及云端服务器等计算设备。所述电子设备可包括，但不仅限于，处理器、存储器。本领域技术人员可以理解，所述电子设备还可以包括更多或更少的部件，或者组合某些部件，或者不同的部件，例如所述电子设备还可以包括输入输出设备、网络接入设备、总线等。所述处理器可以是中央处理单元，还可以是其他通用处理器、数字信号处理器、专用集成电路、现成可编程门阵列或者其他可编程逻辑器件、分立门或者晶体管逻辑器件、分立硬件组件等。通用处理器可以是微处理器或者该处理器也可以是任何常规的处理器等。所述存储器可以是所述服务器的内部存储单元，例如服务器的硬盘或内存。所述存储器也可以是所述服务器的外部存储设备，例如所述服务器上配备的插接式硬盘，智能存储卡 ，安全数字卡，闪存卡等。进一步地，所述存储器还可以既包括所述服务器的内部存储单元也包括外部存储设备。所述存储器用于存储所述计算机可读指令以及所述服务器所需的其他程序和数据。所述存储器还可以用于暂时地存储已经输出或者将要输出的数据。需要说明的是，上述模块单元之间的信息交互、执行过程等内容，由于与方法实施例基于同一构思，其具体功能及带来的技术效果，具体可参见方法实施例部分，此处不再赘述。所属领域的技术人员可以清楚地了解到，为了描述的方便和简洁，仅以上述各功能单元、模块的划分进行举例说明，实际应用中，可以根据需要而将上述功能分配由不同的功能单元、模块完成，即将所述系统的内部结构划分成不同的功能单元或模块，以完成以上描述的全部或者部分功能。实施例中的各功能单元、模块可以集成在一个处理单元中，也可以是各个单元单独物理存在，也可以两个或两个以上单元集成在一个单元中，上述集成的单元既可以采用硬件的形式实现，也可以采用软件功能单元的形式实现。另外，各功能单元、模块的具体名称也只是为了便于相互区分，并不用于限制本申请的保护范围。上述系统中单元、模块的具体工作过程，可以参考前述方法实施例中的对应过程，在此不再赘述。所述集成的单元如果以软件功能单元的形式实现并作为独立的产品销售或使用时，可以存储在一个计算机可读取存储介质中。基于这样的理解，本申请实现上述实施例方法中的全部或部分流程，可以通过计算机程序来指令相关的硬件来完成，所述的计算机程序可存储于一计算机可读存储介质中，该计算机程序在被处理器执行时，可实现上述各个方法实施例的步骤。其中，所述计算机程序包括计算机程序代码，所述计算机程序代码可以为源代码形式、对象代码形式、可执行文件或某些中间形式等。所述计算机可读介质至少可以包括：能够将计算机程序代码携带到拍照装置/终端设备的任何实体或装置、记录介质、计算机存储器、只读存储器、随机存取存储器、电载波信号、电信信号以及软件分发介质。例如U盘、移动硬盘、磁碟或者光盘等。在上述实施例中，对各个实施例的描述都各有侧重，某个实施例中没有详述或记载的部分，可以参见其它实施例的相关描述。以上所述实施例仅用以说明本申请的技术方案，而非对其限制；尽管参照前述实施例对本申请进行了详细的说明，本领域的普通技术人员应当理解：其依然可以对前述各实施例所记载的技术方案进行修改，或者对其中部分技术特征进行等同替换；而这些修改或者替换，并不使相应技术方案的本质脱离本申请各实施例技术方案的精神和范围，均应包含在本申请的保护范围之内。
