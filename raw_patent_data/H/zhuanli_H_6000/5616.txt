标题title
一种基于大语言模型的钓鱼邮件检测方法
摘要abst
本发明提供一种基于大语言模型的钓鱼邮件检测方法，属于人工智能技术领域，大语言模型不需要进行复杂的特征工程，将写有待测邮件的提示模板输入大语言模型，大语言模型就可以直接处理邮件内容，最后由大语言模型判断待测邮件是否为钓鱼邮件；而且，大语言模型具有出色的语义理解能力，可以深入识别和理解邮件的上下文内容，从而更准确地识别钓鱼邮件中应用的社会工程学技术和心理操纵技巧；此外，大语言模型具有强大的多语言处理能力，可以解决语言障碍问题，为其他语言的钓鱼邮件检测提供新的研究思路；最后，本发明同时使用没有开源的和开源的大语言模型进行钓鱼邮件检测，能够更好地研究开源大语言模型检测钓鱼邮件的性能和探索社会工程学领域的垂直大模型构建。
权利要求书clms
1.一种基于大语言模型的钓鱼邮件检测方法，其特征在于，包括以下步骤：将待测邮件进行预处理，使得待测邮件的长度控制在设定范围内；将预处理后的待测邮件写入设定的提示模板中，其中，所述提示模板包括问题部分和邮件部分，且邮件部分用于写入预处理后的待测邮件，问题部分设置为：分析邮件的可疑因素以及是否包含社会工程学技术、分析邮件的URL、识别邮件意图、给出邮件是否为钓鱼邮件的结论及理由、以JSON格式输出判断结果；将写有预处理后的待测邮件的提示模板输入大语言模型，由大语言模型判断待测邮件是否为钓鱼邮件，其中，大语言模型为GPT-4、GPT-3.5或者开源大语言模型Llama2、BaiChuan2、ChatGLM2。2.如权利要求1所述的一种基于大语言模型的钓鱼邮件检测方法，其特征在于，所述提示模板具体为：您是一名网络安全专家和社会工程学专家，负责检查电子邮件以确定它是钓鱼邮件还是合法邮件，要完成此任务，请执行以下子任务：1).分析邮件的可疑因素以及是否包含社会工程学技术：分析邮件发件人地址、主题和正文中是否存在用于网络钓鱼攻击的社会工程学技术，指出发件人地址、主题或正文中发现的任何可疑因素；2).分析邮件的URL：如果邮件正文包含URL链接，提取出URL的特征并判断是否可疑，如果邮件正文不包含URL链接，则回答无；3).识别邮件意图：结合邮件的上下文内容和关键词来分析发件人的意图是否可疑；4).陈述您对该电子邮件是钓鱼邮件还是合法邮件的结论，并解释理由，如果没有足够的证据做出判断，请回答“未知”；5).以JSON格式的输出您的判断结果，其中，判断结果包含以下关键字：- phishing_score: int，其中，phishing_score用于表示钓鱼风险，int表示风险等级，等级从低至高分别为0到10；- suspicious_url: boolean，其中，suspicious_url用于表示邮件中的URL链接是否可疑，如果可疑则boolean为True，如果不可疑则boolean为False；- phishing: boolean，其中，phishing用于表示该邮件是钓鱼邮件还是合法邮件，如果为钓鱼邮件则boolean为True，如果为合法邮件则boolean为False；限制：- 邮件内容可能被缩短和简化；社会工程学技术举例：- 紧迫感：用时间期限催促收信人立即采取行动；- 威胁恐吓：采用安全警告恐吓收信人；- 欲望诱惑：提供奖励引诱收信人点击链接；- 冒充亲友或同事：获取信任来骗取钱财；Email：{预处理后的待测邮件}。3.如权利要求1所述的一种基于大语言模型的钓鱼邮件检测方法，其特征在于，将待测邮件进行预处理，使得待测邮件的长度控制在设定范围内具体为：计算待测邮件的token长度，如果token长度超出了设定范围，则按照设定范围中的最大长度对待测邮件进行截取，只保留设定范围内的邮件文本。4.如权利要求1所述的一种基于大语言模型的钓鱼邮件检测方法，其特征在于，采用LoRA微调技术调整开源大语言模型Llama2、BaiChuan2、ChatGLM2的网络参数，以此提升开源大语言模型对钓鱼邮件的检测效果，调整方法为：基于ACM IWSPA 2018的反网络钓鱼试点中提供的IWSPA数据集构造初始数据集，其中，IWSPA数据集中包括仅包含正文内容的电子邮件IWSPA_NH、包含完整邮件头信息和正文内容的电子邮件IWSPA_H；剔除初始数据集中长度大于设定范围的邮件，仅保留长度在设定范围内的邮件作为筛选后数据集；将筛选后数据集按照1:1的比例切分成验证数据集和准监督微调数据集，其中，验证数据集用于GPT-3.5、GPT-4、Llama2、BaiChuan2以及ChatGLM2检测钓鱼邮件性能的比较；将准监督微调数据集输入GPT-4，得到GPT-4对准监督微调数据集中各邮件样本的判断结果和分析回答，去除判断结果错误以及低质量分析回答对应的邮件样本，将剩余邮件样本组成最终的监督微调数据集；将监督微调数据集分别输入开源大语言模型Llama2、BaiChuan2、ChatGLM2，判断设定的损失函数是否满足要求，若为是，则完成开源大语言模型网络参数的调整，若为否，则通过低秩分解矩阵来更新开源大语言模型中的权重矩阵，再将监督微调数据集分别输入权重矩阵调整后的开源大语言模型，重新判断损失函数是否满足要求；以此类推，直到完成开源大语言模型网络参数的调整。5.如权利要求1~4任一权利要求所述的一种基于大语言模型的钓鱼邮件检测方法，其特征在于，采用准确率、精确度、召回率、F1分数、误报率、漏报率作为评估大语言模型检测钓鱼邮件性能的指标，其中，在所述指标的评估下，GPT-4检测钓鱼邮件的性能最优。6.如权利要求1~4任一权利要求所述的一种基于大语言模型的钓鱼邮件检测方法，其特征在于，所述待测邮件为带有邮件头的邮件或者不带有邮件头的邮件，采用准确率、精确度、召回率、F1分数、误报率、漏报率作为评估大语言模型检测钓鱼邮件性能的指标，其中，在所述指标的评估下，大语言模型GPT-3.5、Llama2检测不带有邮件头的钓鱼邮件的性能更优，大语言模型GPT-4、BaiChuan2、ChatGLM2检测带有邮件头的钓鱼邮件的性能更优。7.如权利要求1~4任一权利要求所述的一种基于大语言模型的钓鱼邮件检测方法，其特征在于，当发件人的邮件地址来自所属组织机构品牌的其他域名或者合法域名的多个子域名时，或者当邮件正文中提及的组织机构域名与发件人地址不匹配时，或者当邮件主题或正文中出现有关心理引导或操纵的关键词时，或者当合法的组织机构通过邮件进行广告宣传吸引用户时，或者邮件中包含的URL链接大于设定值时，或者邮件中包含的URL链接包含脱敏占位符时，大语言模型GPT-4检测钓鱼邮件的误报率将会提升。8.如权利要求1~4任一权利要求所述的一种基于大语言模型的钓鱼邮件检测方法，其特征在于，当邮件不带有邮件头时，或者当邮件使用正式的通知语气且没有任何明显使用社会工程学技术的迹象时，或者GPT-4未能识别邮件中的社会工程学技术时，大语言模型GPT-4检测钓鱼邮件的漏报率将会提升。
说明书desc
技术领域本发明属于人工智能技术领域，尤其涉及一种基于大语言模型的钓鱼邮件检测方法。背景技术钓鱼邮件攻击一般是指攻击者伪装成银行等权威部门的技术管理员，或者是收件人信任的朋友、家人等，通过发送电子邮件的方式诱导用户点击钓鱼链接或者下载附件，进而窃取用户的敏感信息或者在设备上植入恶意程序。近年来，随着互联网技术的快速发展，钓鱼邮件的数量也在日益增长。2022年APWG的第三季度报告显示，观察到的网络钓鱼攻击数量超过120万次，针对商业电子邮件攻击的数量增加了59%。Coremail发布的2023上半年研究报告显示，全国企业邮箱用户共收到1.4亿封钓鱼邮件，同比2022上半年增长40.89%。因此，对于个人和企业来说，如何防范钓鱼邮件攻击是网络安全的重要组成部分。随着生成式大语言模型在各种任务上展现的优异性能，人们也开始探索大语言模型在各个领域中的应用，但也带来了一系列安全风险，例如生成有害内容、数据泄露等。最近，在暗网上出现的基于大语言模型的网络犯罪工具WormGPT，对生成结果没有采取限制和安全过滤，专门用于恶意攻击活动。攻击者不需要掌握特定技能或语言，也能利用该工具生成针对目标的钓鱼邮件，大大提高了网络钓鱼攻击造成的威胁。大语言模型生成的钓鱼邮件通常更加自然、语法正确且有深层次的语义关联，传统的机器学习或深度学习算法在检测时存在局限性，尤其是基于文本特征的检测方法。LLMs可以生成内容和风格具有多样性的钓鱼邮件，现有的检测方法不足以应对这种新兴的网络钓鱼攻击技术。发明内容为解决上述问题，本发明提供一种基于大语言模型的钓鱼邮件检测方法，结合提示模板和输入邮件生成提示，可以使LLMs识别邮件中可疑的钓鱼特征，量化邮件的钓鱼风险程度并判断是否为钓鱼邮件。一种基于大语言模型的钓鱼邮件检测方法，包括以下步骤：将待测邮件进行预处理，使得待测邮件的长度控制在设定范围内；将预处理后的待测邮件写入设定的提示模板中，其中，所述提示模板包括问题部分和邮件部分，且邮件部分用于写入预处理后的待测邮件，问题部分设置为：分析邮件的可疑因素以及是否包含社会工程学技术、分析邮件的URL、识别邮件意图、给出邮件是否为钓鱼邮件的结论及理由、以JSON格式输出判断结果；将写有预处理后的待测邮件的提示模板输入大语言模型，由大语言模型判断待测邮件是否为钓鱼邮件，其中，大语言模型为GPT-4、GPT-3.5或者开源大语言模型Llama2、BaiChuan2、ChatGLM2。进一步地，所述提示模板具体为：您是一名网络安全专家和社会工程学专家，负责检查电子邮件以确定它是钓鱼邮件还是合法邮件，要完成此任务，请执行以下子任务：1).分析邮件的可疑因素以及是否包含社会工程学技术：分析邮件发件人地址、主题和正文中是否存在用于网络钓鱼攻击的社会工程学技术，指出发件人地址、主题或正文中发现的任何可疑因素；2).分析邮件的URL：如果邮件正文包含URL链接，提取出URL的特征并判断是否可疑，如果邮件正文不包含URL链接，则回答无；3).识别邮件意图：结合邮件的上下文内容和关键词来分析发件人的意图是否可疑；4).陈述您对该电子邮件是钓鱼邮件还是合法邮件的结论，并解释理由，如果没有足够的证据做出判断，请回答“未知”；5).以JSON格式的输出您的判断结果，其中，判断结果包含以下关键字：- phishing_score: int，其中，phishing_score用于表示钓鱼风险，int表示风险等级，等级从低至高分别为0到10；- suspicious_url: boolean，其中，suspicious_url用于表示邮件中的URL链接是否可疑，如果可疑则boolean为True，如果不可疑则boolean为False；- phishing: boolean，其中，phishing用于表示该邮件是钓鱼邮件还是合法邮件，如果为钓鱼邮件则boolean为True，如果为合法邮件则boolean为False；限制：- 邮件内容可能被缩短和简化；社会工程学技术举例：- 紧迫感：用时间期限催促收信人立即采取行动；- 威胁恐吓：采用安全警告恐吓收信人；- 欲望诱惑：提供奖励引诱收信人点击链接；- 冒充亲友或同事：获取信任来骗取钱财；Email：{预处理后的待测邮件}。进一步地，将待测邮件进行预处理，使得待测邮件的长度控制在设定范围内具体为：计算待测邮件的token长度，如果token长度超出了设定范围，则按照设定范围中的最大长度对待测邮件进行截取，只保留设定范围内的邮件文本。进一步地，采用LoRA微调技术调整开源大语言模型Llama2、BaiChuan2、ChatGLM2的网络参数，以此提升开源大语言模型对钓鱼邮件的检测效果，调整方法为：基于ACM IWSPA 2018的反网络钓鱼试点中提供的IWSPA数据集构造初始数据集，其中，IWSPA数据集中包括仅包含正文内容的电子邮件IWSPA_NH、包含完整邮件头信息和正文内容的电子邮件IWSPA_H；剔除初始数据集中长度大于设定范围的邮件，仅保留长度在设定范围内的邮件作为筛选后数据集；将筛选后数据集按照1:1的比例切分成验证数据集和准监督微调数据集，其中，验证数据集用于GPT-3.5、GPT-4、Llama2、BaiChuan2以及ChatGLM2检测钓鱼邮件性能的比较；将准监督微调数据集输入GPT-4，得到GPT-4对准监督微调数据集中各邮件样本的判断结果和分析回答，去除判断结果错误以及低质量分析回答对应的邮件样本，将剩余邮件样本组成最终的监督微调数据集；将监督微调数据集分别输入开源大语言模型Llama2、BaiChuan2、ChatGLM2，判断设定的损失函数是否满足要求，若为是，则完成开源大语言模型网络参数的调整，若为否，则通过低秩分解矩阵来更新开源大语言模型中的权重矩阵，再将监督微调数据集分别输入权重矩阵调整后的开源大语言模型，重新判断损失函数是否满足要求；以此类推，直到完成开源大语言模型网络参数的调整。进一步地，采用准确率、精确度、召回率、F1分数、误报率、漏报率作为评估大语言模型检测钓鱼邮件性能的指标，其中，在所述指标的评估下，GPT-4检测钓鱼邮件的性能最优。进一步地，所述待测邮件为带有邮件头的邮件或者不带有邮件头的邮件，采用准确率、精确度、召回率、F1分数、误报率、漏报率作为评估大语言模型检测钓鱼邮件性能的指标，其中，在所述指标的评估下，大语言模型GPT-3.5、Llama2检测不带有邮件头的钓鱼邮件的性能更优，大语言模型GPT-4、BaiChuan2、ChatGLM2检测带有邮件头的钓鱼邮件的性能更优。进一步地，当发件人的邮件地址来自所属组织机构品牌的其他域名或者合法域名的多个子域名时，或者当邮件正文中提及的组织机构域名与发件人地址不匹配时，或者当邮件主题或正文中出现有关心理引导或操纵的关键词时，或者当合法的组织机构通过邮件进行广告宣传吸引用户时，或者邮件中包含的URL链接大于设定值时，或者邮件中包含的URL链接包含脱敏占位符时，大语言模型GPT-4检测钓鱼邮件的误报率将会提升。进一步地，当邮件不带有邮件头时，或者当邮件使用正式的通知语气且没有任何明显使用社会工程学技术的迹象时，或者GPT-4未能识别邮件中的社会工程学技术时，大语言模型GPT-4检测钓鱼邮件的漏报率将会提升。有益效果：1、本发明提供一种基于大语言模型的钓鱼邮件检测方法，大语言模型不需要进行复杂的特征工程，将写有待测邮件的提示模板输入大语言模型，大语言模型就可以直接处理邮件内容，最后由大语言模型判断待测邮件是否为钓鱼邮件；而且，大语言模型具有出色的语义理解能力，可以深入识别和理解邮件的上下文内容，从而更准确地识别钓鱼邮件中应用的社会工程学技术和心理操纵技巧；此外，大语言模型具有强大的多语言处理能力，可以解决语言障碍问题，为其他语言的钓鱼邮件检测提供新的研究思路；最后，本发明除了使用没有开源的GPT-4、GPT-3.5，本发明还使用开源大语言模型 Llama2、BaiChuan2和ChatGLM2进行钓鱼邮件检测，能够更好地研究开源大语言模型检测钓鱼邮件的性能和探索社会工程学领域的垂直大模型构建。2、本发明提供一种基于大语言模型的钓鱼邮件检测方法，基于思维链的提示工程技巧，并结合钓鱼邮件包含的特征来创建提示模板；思维链技术模拟了人类在推理时的思维过程，将直接输入的任务目标分解为一系列中间任务，通过引导LLMs解决中间的推理任务才得到最终的输出答案；在数学、常识和符号推理等任务中应用思维链技术可以显著提高LLMs的性能；因此，本发明将钓鱼邮件检测任务分为五个子任务，能够引导LLMs在检测钓鱼邮件时进行更准确的推理分析。3、本发明提供一种基于大语言模型的钓鱼邮件检测方法，构造了用于钓鱼邮件检测的数据集IWSPA，并在GPT-3.5和GPT-4上对提出的方法进行了实验评估，GPT-4的准确率可达96.70%，F1分数可达96.68%，证明大语言模型LLMs在钓鱼邮件检测方面的有效性。4、本发明提供一种基于大语言模型的钓鱼邮件检测方法，采用LoRA微调技术调整开源大语言模型Llama2、BaiChuan2、ChatGLM2的网络参数，有效提升开源大语言模型对钓鱼邮件的检测效果。5、本发明提供一种基于大语言模型的钓鱼邮件检测方法，基于准确率、精确度、召回率、F1分数、误报率、漏报率等指标详细分析了大语言模型检测钓鱼邮件的能力，包括识别邮件意图和社会工程学技术等；通过对比GPT-4、GPT-3.5和开源大语言模型的实验结果，本发明分析了开源大语言模型存在的不足，为构建检测网络钓鱼攻击等安全垂直领域的大语言模型进行了探索工作。附图说明图1为本发明提供的一种基于大语言模型的钓鱼邮件检测方法的流程图；图2为GPT-4输出结果中“phishing_score”和“suspicious_url”字段在IWSPA_LLMs_H_dev数据集的分布；图2为GPT-4输出结果中“phishing_score”和“suspicious_url”字段在IWSPA_LLMs_NH_dev数据集的分布；图2为GPT-3.5输出结果中“phishing_score”和“suspicious_url”字段在IWSPA_LLMs_H_dev数据集的分布；图2为GPT-3.5输出结果中“phishing_score”和“suspicious_url”字段在IWSPA_LLMs_NH_dev数据集的分布；图3为phishing_score和suspicious_url的误报分布统计示意图；图4为phishing_score和suspicious_url的漏报分布统计示意图；图5为IWSPA_LLMs_NH_dev数据集上LoRA微调前后误报率和漏报率的对比示意图；图5为IWSPA_LLMs_H_dev数据集LoRA微调前后误报率和漏报率的对比示意图。具体实施方式为了使本技术领域的人员更好地理解本申请方案，下面将结合本申请实施例中的附图，对本申请实施例中的技术方案进行清楚、完整地描述。本发明提供一种基于大语言模型的钓鱼邮件检测方法，根据钓鱼邮件包含的钓鱼特征和分析钓鱼邮件的步骤设计了提示模板，目的是指导LLMs对邮件进行全面的分析和推理。本发明提出的方法除了可以识别邮件的可疑因素，在输出结果中可以直观地对邮件的钓鱼风险程度进行量化，并标记邮件中的URL链接是否可疑。在本发明构造的IWSPA_LLMs数据集上，对GPT-4、GPT-3.5、开源大语言模型Llama2、BaiChuan2和ChatGLM2上进行了实验评估，其中GPT-4的检测性能最好，召回率可达99.21%，漏报率只有0.794%；现有的开源大语言模型不具备太多关于钓鱼邮件检测等社会工程学方面的知识，所以本发明采用LoRA技术去微调模型，以提高Llama2等开源大语言模型分析钓鱼邮件和识别网络钓鱼攻击的性能；本发明的研究发现了LLMs防御新兴的网络安全攻击形式的潜力，这对构建网络安全垂直领域的大语言模型具有重要意义。如图1所示，一种基于大语言模型的钓鱼邮件检测方法，包括以下步骤：S1：将待测邮件进行预处理，使得待测邮件的长度控制在设定范围内。需要说明的是，传统的钓鱼邮件检测方法在分类任务前都会对电子邮件数据集进行预处理，例如将文本进行小写处理、删除特殊字符、停用词等，目的是去除邮件正文中的无关信息和冗余信息，筛选重要的文本特征并转换为统一格式。而LLMs是由大量的原始文本数据训练得到，这些数据包含了各种格式，也涵盖了特殊字符、停用词等，所以LLMs已经学会了识别和处理多样化的文本结构和表示。本发明在对邮件进行预处理时，仅需要对邮件长度进行控制，有些邮件包含较长的特殊编码或字符，可能会超出LLMs的上下文长度限制，所以本发明采用了简单的处理方式：计算待测邮件的token长度，如果token长度超出了设定范围，则按照设定范围最大长度对邮件进行截取，只保留限定范围内的邮件文本。S2：将预处理后的待测邮件写入设定的提示模板中，其中，所述提示模板包括问题部分和邮件部分，且邮件部分用于写入预处理后的待测邮件，问题部分设置为：分析邮件的可疑因素以及是否包含社会工程学技术、分析邮件的URL、识别邮件意图、给出邮件是否为钓鱼邮件的结论及理由、以JSON格式输出判断结果。S3：将写有预处理后的待测邮件的提示模板输入大语言模型，由大语言模型判断待测邮件是否为钓鱼邮件，其中，大语言模型为GPT-4、GPT-3.5或者开源大语言模型Llama2、BaiChuan2、ChatGLM2。需要说明的是，本发明通过访问OpenAI的API接口来调用GPT-4和GPT-3.5模型；同时，为了更好地研究开源大语言模型检测钓鱼邮件的性能和探索社会工程学领域的垂直大模型构建，本发明在实验中还对比了开源大语言模型：Llama2、BaiChuan2和ChatGLM2。进一步地，在本发明设计的提示模板中，首先分析了邮件头和正文内容中可能存在的可疑因素，并识别钓鱼攻击者利用的社会工程学和心理操纵技术；LLMs，如GPT-4能够处理复杂的上下文和文本结构，捕捉文本蕴含的关系和内在含义。因此，本发明提出的方法利用LLMs去理解邮件内容，并准确识别邮件的真实意图，除了邮件文本内容的分析，本发明还对邮件中存在的URLs进行检测，作为判断钓鱼邮件的依据之一；基于LLMs的方法可以直接对邮件进行检测，不需要收集大量的钓鱼邮件数据进行特征工程。具体的，根据输入的邮件，本发明创建了检测钓鱼邮件的提示，提示模板如表1所示；为了提高LLMs检测钓鱼邮件的性能，本发明基于思维链的提示工程技巧，并结合钓鱼邮件包含的特征来创建提示模板；思维链技术模拟了人类在推理时的思维过程，将直接输入的任务目标分解为一系列中间任务，通过引导LLMs解决中间的推理任务才得到最终的输出答案；在数学、常识和符号推理等任务中应用思维链技术可以显著提高LLMs的性能；因此，本发明将钓鱼邮件检测任务分为五个子任务，以便引导LLMs在检测时进行更准确的推理分析：表1检测钓鱼邮件的提示模板分析邮件的可疑因素以及是否包含社会工程学技术。本发明设计的提示要求LLMs从邮件包含的头信息和正文分析，而目前基于自然语言处理的钓鱼邮件检测方法是忽略了邮件头信息的；钓鱼邮件中常用的社会工程学技术包括利用紧迫感、威胁恐吓、欲望诱惑、冒充亲友或同事等，当LLMs分析出邮件包含这些语义信息或者发件人的邮箱地址很可疑时，则很大程度上表明是钓鱼邮件。分析URL。如果邮件的上下文没有表达明显的钓鱼话术，那么可以从邮件中包含的URL链接进行分析。LLMs会提取URL的特征进行检测，例如域名、子域名级别、路径深度、重定向等。本发明设计的提示要求LLMs识别URL是否可疑。识别邮件意图。钓鱼邮件中主题往往与正文内容存在不一致性，因此本发明设计的提示要求LLMs结合邮件的上下文去识别发件人的真实意图，并判断是否可疑。给出该邮件是否为钓鱼邮件的结论，并解释理由。本发明设计的提示要求LLMs依据上面的任务分析给出结论，并提供判断的理由，也方便人们对钓鱼邮件更进一步的分析。以JSON格式输出结果。本发明期望LLMs能够量化邮件可能是钓鱼攻击的风险，使用“phishing_score”字段表示，范围从0到10，0代表钓鱼风险最低，10代表钓鱼风险最高。如果邮件中的URL可疑，则期望“suspicious_url”字段返回为True。根据分析，如果邮件为钓鱼邮件，则期望“phishing”字段返回为True。因为有的电子邮件内容过长可能会超出LLMs上下文长度的token限制，token是指文本分词后的单个文本单元。GPT-3.5模型的上下文长度限制为4096个token，GPT-4模型的上下文长度限制为8192个token。在实验中使用的开源大语言模型Llama2的长度限制为4096个token，BaiChuan2的长度限制为4096个token，ChatGLM2的长度限制为32768个token，也有一些研究关于扩充LLMs的上下文长度，但为了更好地比较目前大语言模型检测钓鱼邮件的性能，本发明在研究中对输入包含邮件的提示模板进行优化，使得输入提示和输出结果的上下文长度满足4096个token限制。表2列出了每种文本数据类型的最大token数量，其中提示模板固定使用355个token。此外，本发明从构造数据集的每个类别中随机挑选10封电子邮件，根据GPT-4输出的token数量来估计输出结果的最大token数量。在GPT-4的输出结果中，最短的token数量为310，最长的token数量为372，平均token数量为348。因此本发明设置输出的最大token数量为375，从而推算得到输入邮件的最大token数量为3366，有关输入邮件的长度限制操作在预处理模块中已经介绍。表2提示模板、输入邮件、输出结果的token数量限制进一步地，由于开源的大语言模型因为参数量和训练数据量要远少于GPT-4和GPT-3.5，而且训练中并没有使用太多有关钓鱼邮件检测等领域的数据，所以Llama2、BaiChuan2、ChatGLM2等开源模型在直接检测钓鱼邮件上的性能要差很多；因此，本发明通过LoRA方法微调了开源大语言模型Llama2、BaiChuan2、ChatGLM2的网络参数，以此提升开源大语言模型对钓鱼邮件的检测性能，调整方法如下：步骤一、基于ACM IWSPA 2018的反网络钓鱼试点中提供的IWSPA数据集构造初始数据集，其中，IWSPA数据集中包括仅包含正文内容的电子邮件IWSPA_NH、包含完整邮件头信息和正文内容的电子邮件IWSPA_H；其中，IWSPA_NH和IWSPA_H数据详细信息如表3所示：表3 IWSPA数据集详细信息步骤二、剔除初始数据集中长度大于设定范围的邮件，仅保留长度在设定范围内的邮件作为筛选后数据集；也就是说，本发明首先需要对IWSPA_NH和IWSPA_H数据集进行去重清洗等操作，因为数据集中钓鱼邮件的占比较少，所以本发明尽可能保留所有的钓鱼邮件。如果钓鱼邮件的长度超出了3366个token数量的限制，则与预处理中的操作相同，对超出部分进行截取，只保留在长度范围内的邮件文本。而对于合法邮件，本发明计算其token长度，只保留完整长度满足限制范围内的邮件。对于筛选后的合法邮件，本发明按照钓鱼邮件在IWSPA_NH和IWSPA_H中的数量，采用相同比例来随机抽取合法邮件进行构造。表4给出了数据筛选后的详细信息，筛选后一共保留2216条数据，钓鱼邮件和合法邮件分别有1108条。表4筛选后的数据详细信息步骤三、将筛选后数据集按照1:1的比例切分成验证数据集和准监督微调数据集，其中，验证数据集用于GPT-3.5、GPT-4、Llama2、BaiChuan2以及ChatGLM2检测钓鱼邮件性能的比较；步骤四、将准监督微调数据集输入GPT-4，得到GPT-4对准监督微调数据集中各邮件样本的判断结果和分析回答，去除判断结果错误以及低质量分析回答对应的邮件样本，将剩余邮件样本组成最终的监督微调数据集；需要说明的是，本发明构造IWSPA_LLMs数据集的目的是为了比较不同的LLMs检测钓鱼邮件的性能以及在垂直领域中微调开源大语言模型的性能提升效果；验证数据集被直接用于GPT-3.5、GPT-4、Llama2、BaiChuan2以及ChatGLM2的检测性能比较，记作IWSPA_LLMs_dev，其中不包含邮件头信息的验证数据记作IWSPA_LLMs_NH_dev，包含头信息的验证数据记作IWSPA_LLMs_H_dev；最终的监督微调数据集记作IWSPA_LLMs_sft，其中不包含邮件头信息的微调数据集记作IWSPA_LLMs_NH_sft，包含头信息的微调数据集记作IWSPA_LLMs_H_sft；本发明构造的IWSPA_LLMs数据集有助于研究者在网络安全领域、社会工程学检测或攻击子领域中构建垂直领域大模型的研究，表5给出了IWSPA_LLMs数据集的详细信息。表5 IWSPA_LLMs数据集详细信息步骤五、将监督微调数据集分别输入开源大语言模型Llama2、BaiChuan2、ChatGLM2，判断设定的损失函数是否满足要求，若为是，则完成开源大语言模型网络参数的调整，若为否，则通过低秩分解矩阵来更新开源大语言模型中的权重矩阵，再将监督微调数据集分别输入权重矩阵调整后的开源大语言模型，重新判断损失函数是否满足要求；以此类推，直到完成开源大语言模型网络参数的调整。需要说明的是，LoRA是一种用于LLMs的参数高效微调方式，其基本思想是冻结预训练模型的权重矩阵，通过添加低秩分解矩阵来近似参数更新权重矩阵/＞，其中/＞，/＞，以及秩/＞。矩阵/＞使用随机高斯分布进行初始化，矩阵/＞使用全零矩阵初始化，保证矩阵/＞在训练开始时为零矩阵，前向更新过程可以表示为/＞。使用LoRA进行微调时，只训练矩阵/＞和/＞可以减少适配下游任务的训练参数，大大降低了对算力的要求，而且实验结果表明在自然语言推理和生成等任务上与全参数微调的性能相当甚至更好。因此，在本发明提出的方法中使用LoRA微调去提高开源大语言模型在钓鱼邮件检测方面的性能。进一步地，为了评估LLMs检测钓鱼邮件的性能，本发明使用准确率、精确度、召回率、F1分数、误报率、漏报率作为评估指标。在评估过程中，使用TP表示正确预测为钓鱼邮件的数量；TN表示正确预测为合法邮件的数量；FP表示合法邮件被错误分类为钓鱼邮件的数量；FN表示钓鱼邮件被错误分类为合法邮件的数量。准确率：邮件正确分类的数量占总数的比例：精确度：预测为钓鱼的所有邮件中正确分类的比例：召回率：标签为钓鱼的所有邮件中正确分类的比例：F1分数：定义为精确度和召回率的调和平均值：误报率：合法邮件被错误分类的数量占所有合法邮件的比例：漏报率：钓鱼邮件被错误分类的数量占所有钓鱼邮件的比例：本发明对GPT-4的性能评估实验具体如下：参数设置为了对比不同模型的效果，本发明将模型的上下文长度都统一设置为4096，参数temperature统一设置为0.8，其余参数保持不变。参数temperature表示采样温度，介于0和2之间，较高的值会使输出更加随机，而较低的值会使输出更加集中和确定性。在LoRA微调的实验中，参数秩r设置为8，学习率learning_rate大小为5e-5，批次大小batch_size设置为4，训练轮数epochs设置为10。Llama 2的微调模块设置为q_proj和v_proj，BaiChuan 2的微调模块设置为W_pack，ChatGLM2的微调模块设置为query_key_value。实验结果分析因为本发明设计的提示中要求LLMs除了执行子任务的分析外，还需要以JSON格式输出最后的检测结果，所以本发明通过正则表达式将结果提取出来。如果JSON文本中的“phishing”字段的值为True，则将检测结果定义为钓鱼邮件；如果“phishing”字段的值为False，则为合法邮件。在验证集IWSPA_LLMs_dev上，GPT-4的输出结果中“phishing”字段总共有78个是“未知”，其中有35个为钓鱼邮件，43个为合法邮件；GPT-3.5的输出结果中“phishing”字段总共有65个是“未知”，其中31个为钓鱼邮件，34个为合法邮件。如果“phishing”字段的值为“未知”，本发明的处理方式是判断“suspicious_url”字段的值，如果为True，则检测结果为钓鱼邮件；如果为False，那么进一步判断“phishing_score”的值，如果值大于等于5，则最终判断为钓鱼邮件；否则判断为合法邮件。表6给出了GPT-3.5和GPT-4检测钓鱼邮件的结果，性能指标包括准确率、精确度、召回率、F1分数、TP、FP、TN、FN、FPR、FNR。从结果可以看出，GPT-4在检测钓鱼邮件方面的性能远超GPT-3.5。在没有邮件头信息的验证集IWSPA_LLMs_NH_dev上，GPT-4的性能要优于GPT-3.5约15%到20%，GPT-4的召回率为96.04%，F1分数为96.68%，而GPT-3.5的召回率为72.28%，F1分数为76.84%。GPT-3.5有48个误报的，GPT-4有8个误报；在漏报方面，GPT-3.5有84个，GPT-4有12个，GPT-3.5漏报的数量远超GPT-4。在验证集IWSPA_LLMs_H_dev上，GPT-4的准确性平均超出GPT-3.5约13%，GPT-4的F1分数为94.70%，GPT-3.5的F1分数为82.21%；而GPT-4的召回率甚至达到99.21%，只有2个漏报，这表明GPT-4对带有头信息的钓鱼邮件的检测效果更好。此外，实验结果中带邮件头信息的误报要多于不带邮件头信息的误报，GPT-4的误报有26个，GPT-3.5的误报有65个，说明邮件头信息会对模型判断合法邮件产生一定影响。GPT-4的误报率和漏报率都远低于GPT-3.5，表明GPT-4在检测真实的钓鱼邮件场景方面有着更高的准确性，面对邮件的多样性时性能要更加稳定。表6 GPT-3.5和GPT-4检测结果对于输出结果的“phishing_score”字段，GPT-4在IWSPA_LLMs_NH_dev数据集上的打分相对均匀，有93个5分，有99个7分以及80个8分。而GPT-3.5则更多地给出2分和7分，其中有134个2分，111个7分。在IWSPA_LLMs_H_dev数据上，GPT-4在钓鱼风险较高时给出的8分最多，有144个8分；GPT-3.5则更倾向于给7分和8分，有104个7分和102个8分。这表明GPT-4在带有邮件头信息的数据集上更能检测到中高危的钓鱼邮件。此外，GPT-4和GPT-3.5对于给出最高钓鱼风险的邮件数量都很少，尤其是GPT-3.5在IWSPA_LLMs_NH_dev上没有邮件的分数为10分。对于“suspicious_url”字段，GPT-4在两个验证集上检测到的可疑链接数量都要少于GPT-3.5，这表明GPT-4对于可疑链接尤其是在不带头信息的邮件中的判断标准更为严格。图2~图2分别展示了GPT-4和GPT-3.5输出结果中“phishing_score”和“suspicious_url”字段在IWSPA_LLMs_dev数据集的分布，其中，图2~图2分别中左边的11个柱状表示phishing_score从0分到10分的数量分布，右侧的两个柱状表示suspicious_url为true和uspicious_url为false的情况；从图2~图2分别中可以分析出GPT-4和GPT-3.5在评估钓鱼邮件风险上存在差异，这可能是由于训练数据、模型架构大小等因素导致的。GPT-4在不带邮件头信息的数据集上检测出的合法邮件数量多于GPT-3.5，这表明GPT-4在处理不完整数据时要更加保守。基于GPT-4的表现，本发明将在后续部分对所提方法的检测能力进行详细的分析。GPT-4的输出样例分析如表7所示为钓鱼邮件示例，通过我们提出的方法使用GPT-4进行检测，表8给出了GPT-4的输出结果。这封钓鱼邮件冒充中科大官方的邮箱管理中心，利用真实的中秋节日让收件人放松警惕，并试图用“免费月饼领取”活动来诱惑收件人点击链接填写个人信息。GPT-4可以正确识别发件人和URL链接中的域名与中科大真实域名不符，确定是仿冒构造的域名地址。此外，GPT-4还能识别出邮件中可能利用的社会工程学技术，如利益诱惑、紧迫感等。在JSON格式的提交结果中，GPT-4给“phishing_score”的分数为9，并将“suspicious_url”和“phishing”字段都设置为True。表7钓鱼邮件示例表8 GPT-4检测结果GPT-4的检测能力分析本发明根据GPT-4的输出结果，对其检测钓鱼邮件的能力进行分析。本发明按照方法中构造提示的思路，对识别钓鱼邮件中发件人地址、邮件主题、正文内容、URL链接和邮件意图这五个方面的依据进行详细说明，包括GPT-4的上下文理解和识别的社会工程学技术等。发件人地址。识别发件人地址的域名是否可疑，是否冒充官方的电子邮箱地址，例如检测到合法域名的多级子域，修改或增加合法域名的字符进行构造等。GPT-4可以检测到邮件头信息中发件人地址和回复地址的不一致；以及发件人地址看似合法，而回复地址存在可疑性。此外，GPT-4通过邮件正文中出现的关键词和短语检测发件人地址是否可疑，例如发件人在正文说明自己所属机构后，发现与发件人邮箱地址并不匹配，识别出这是一种利用网络钓鱼的心理技巧，目的是建立和收件人之间的信任。邮件主题。识别主题中利用的网络钓鱼社会工程学技术和心理操纵技巧。例如“安全漏洞修复”、“账户停用通知”、“账户安全验证”等，GPT-4分析邮件主题营造了一种紧迫感和焦虑感，目的是让收件人立即采取行动。还有“中奖通知”、“税务退款”等，GPT-4结合邮件上下文识别出这是一种钓鱼攻击的典型技术，通过吸引收件人的兴趣来诱使其点击钓鱼链接。邮件正文。首先，GPT-4可以对邮件正文中提及到的机构名进行检测，分析其很大可能是随机生成的，并不符合合法机构的命名规则。其次，可以检测到正文中的语言和文本风格，是否模仿组织机构经常使用的官方语言。此外，GPT-4会检测到邮件内容缺乏专业性，例如正文中存在的语法错误、拼写错误和奇怪的措辞，因为这些错误对于一些来自银行等专业机构的邮件来说并不常见。本发明还观察到GPT-4可以识别出来自官方域名的正式邮件中使用到了个人姓名，官方邮件通常会使用“管理员”或“技术团队”等，而不是以个人名义。同样，GPT-4也会检测到邮件正文中使用到的社会工程学技术，例如正文中声明用户账户将被立即暂停，识别出攻击者利用恐吓威胁来引导用户点击链接。URL链接。GPT-4会提取URL链接的特征进行检测，包括使用近似的域名或多个子域名、URL的长度和路径深度、URL中的拼写错误或替代品牌名称、使用URL短链接隐藏真实目标地址、直接使用IP地址代替常规域名、文件路径或查询参数的异常等。例如邮件中的URL链接“www.bankofamerica.com/SingOn/Verify-Your-Identity_Profile-Form-do.htm”，GPT-4检测出链接存在拼写错误，登录的正确拼写是“SignIn”而不是“SingOn”，识别为可疑链接。邮件意图。钓鱼邮件的主要意图是诱使收件人点击链接，通常会催促收件人点击链接更新其个人信息，或者“重新激活”账户。GPT-4可以识别出这种可疑行为，因为合法组织通常不会要求其用户通过电子邮件，尤其是通过可点击的链接进行此类操作。当钓鱼邮件催促收件人更新其个人资料时，GPT-4会识别出邮件意图，目的是窃取收件人的登录凭据等信息。GPT-4误报分析在本发明的实验结果中，GPT-4在IWSPA_LLMs_dev数据集上一共有34个误报，图3展示了“phishing_score”和“suspicious_url”字段的分布统计。我们发现在误报中，存在不少“phishing_score”较高的情况，其中7分有18个，8分有5个，这说明GPT-4认为误报的合法邮件具有较高的钓鱼风险。对于“suspicious_url”字段，除了钓鱼分数为7的分布相同外，其余分数对应的False数量都要多于True。下面本发明将进一步对误报的邮件内容和检测结果进行分析。发件人地址的域名识别错误。当发件人的邮件地址来自所属组织机构品牌的其他域名或者合法域名的多个子域名时，GPT-4有的时候会错误识别，认为该邮件地址是通过网络钓鱼攻击技巧构造的。当GPT-4对某个特定域名不了解或者无法识别合法域名的子域名时，就会发生这种情况。此外，当邮件正文中提及的组织机构域名与发件人地址不匹配时，也会容易提高钓鱼风险分数，即使发件人地址是合法域名。邮件意图的错误识别。LLMs可以理解邮件的上下文内容，并分析邮件意图。当邮件主题或正文中出现有关心理引导或操纵的关键词时，GPT-4会错误识别邮件意图和社会工程学技术。在本发明的实验中，有一封关于股票网站吸引用户注册的邮件，主题中提及“立即注册”，以及正文中出现“股票赚钱”等关键词。GPT-4识别邮件使用了欲望诱惑的社会工程学技术，诱使收件人点击链接进行注册服务。当合法的组织机构通过邮件进行广告宣传吸引用户，尤其是出现金钱财务相关的关键词时，会提高GPT-4的钓鱼风险分数从而产生误报。可疑URL链接的错误识别。GPT-4可以提取邮件中包含的URL链接特征，例如域名、URL长度等。在本发明的实验中，有一封关于视频分享的邮件，GPT-4正确识别该视频链接的域名是合法的，并且没有在邮件内容中检测到可疑因素，但由于视频链接中URL路径的长度过长，导致GPT-4认为该URL链接可疑，从而错误地将该邮件标记为钓鱼。脱敏处理会放大可疑性。当邮件缺乏明确的上下文时，发件人的电子邮件地址和URL链接的脱敏处理会误导LLMs的判断。例如邮件中会出现以“domain.com”或者“＜＜link＞＞”作为敏感信息的占位符，当GPT-4没有检测出邮件利用社会工程学技术或者意图等其他可疑因素时，会对脱敏占位符过于敏感，放大脱敏占位符的可疑性，从而导致钓鱼风险分数较高以及可疑URL链接的误判，这种现象是产生误报的主要原因。GPT-4漏报分析与GPT-3.5相比，GPT-4在IWSPA_LLMs_NH_dev数据集上的漏报减少了20%以上，在IWSPA_LLMs_H_dev数据集上的漏报减少了10%以上。在本发明的实验结果中，GPT-4在IWSPA_LLMs_dev数据集上一共有14个误报，图4展示了“phishing_score”和“suspicious_url”字段的分布统计，其中“phishing_score”字段最多有8个0分，所有分数对应的“suspicious_url”字段都为False。这表明GPT-4认为漏报的钓鱼邮件都具有较低的钓鱼风险且没有可疑的URL链接，下面本发明将进一步对漏报的邮件内容和检测结果进行分析。邮件没有包含明显的可疑因素。实验结果表明不带邮件头的漏报要远多于带邮件头的漏报，这可能导致GPT-4利用的有用信息减少，无法全面分析给出结论。本发明观察到GPT-4漏报的钓鱼邮件中都只有较少的上下文内容，使用正式的通知语气且没有任何明显使用社会工程学技术的迹象，如紧迫感、威胁恐吓、欲望诱惑等，也没有提供任何URL链接，即使人工也很难根据正文内容作出钓鱼邮件的判断。此外，有的误报邮件的文本内容是说明附件接收的，GPT-4也给出了附件可能是恶意软件的说明，但邮件本身没有提供附件数据和更多的背景信息，且接收文件的一般行为也是正常的，GPT-4认为没有足够的证据进行判断。因此GPT-4给出的结论是在没有关于发件人、主题和确切URL信息的情况下，很难得出明确的结论判断是否为钓鱼邮件。未能识别社会工程学技术。GPT-4未能成功识别利用从众心理进行产品构造推荐的钓鱼技巧，例如邮件中说明收件人收到消息是因为其好友订阅了产品，且好友是注册会员。由于没有发件人地址和邮件主题等更多信息，且没有紧迫感等可疑因素，所以被误分类为合法邮件。还有当邮件意图没有直接说明是中奖或转账等利益诱惑，而是电影票等金额较小且是具体的消费产品时，GPT-4会判断为合法的产品促销邮件，并没有识别为钓鱼特征作为可疑因素，从而将其分类为合法邮件。进一步地，本发明对开源大语言模型的性能实验分析如下：LoRA微调前性能对比本发明在实验中对比了开源大语言模型Llama2-7B、BaiChuan2-7B、ChatGLM2-6B检测钓鱼邮件的性能，同样按照本发明提出的方法，直接将提示和邮件输入到模型中得到检测结果。在IWSPA_LLMs_dev数据集上的1110个输出中提取JSON结果时存在无法解析的情况：Llama2-7B有51个、BaiChuan2-7B有113个、ChatGLM2-6B有236个，错误原因是没有给出JSON格式的结论或者是给出JSON样式的文本格式有误。对于无法提取的输出结果，最终是由本发明人工启发式地解析得到。表9给出了三个模型在LoRA微调前的性能对比，在不带邮件头信息的IWSPA_LLMs_NH_dev数据集上，ChatGLM2-6B的表现是最好的，准确率为63.04%，F1分数为62.03%。Llama2-7B的表现其次，准确率为55.12%，召回率是三个模型中最高。而BaiChuan2-7B的表现相对较差，准确率为47.52%，F1分数为40.89%。在带有邮件头信息的IWSPA_LLMs_H_dev数据集上，ChatGLM2-6B的F1分数为63.64%，Llama2-7B的F1分数为67.41%，BaiChuan2-7B的性能仍然是最低的。表9 LoRA微调前的性能对比LoRA微调后性能对比本发明基于IWSPA_LLMs_sft数据集，按照{“instruction”: 提示, “input”: 邮件, “output”: 输出结果}的JSON格式来构造监督微调数据集，最后在IWSPA_LLMs_dev数据集上验证LoRA微调后的效果。LoRA微调后仍存在无法解析JSON结果的情况：Llama2-7B有21个、BaiChuan2-7B有85个、ChatGLM2-6B有151个。结果表明LoRA微调后输出结果的格式虽然更加规范，但生成的结果仍存在较多无法解析的问题。表10给出了实验中三个模型在LoRA微调后的性能对比，在IWSPA_LLMs_NH_dev数据集上，Llama2-7B的性能最好，准确率为79.54%，F1分数为76.78%。BaiChuan2-7B的性能大幅提升，准确率为75.91%，召回率在三个模型中达到最高。而ChatGLM2-6B的性能最差，准确率为71.95%，F1分数为70.79%。在IWSPA_LLMs_H_dev数据集上，BaiChuan2-7B经过LoRA微调后的性能最高，准确率高达82.54%，F1分数为82.04%。Llama2-7B的准确率为76.19%，而ChatGLM2-6B的准确率只有69.44%。实验结果表明，Llama2-7B在不带有邮件头信息的数据集上性能最好，BaiChuan2-7B在带邮件头信息的数据集上性能最好，结果表明BaiChuan2-7B能更好地利用邮件头信息进行钓鱼邮件检测。ChatGLM2-6B在两种数据集上的整体性能相对较低，但在IWSPA_LLMs_H_dev数据集上的召回率最好，说明ChatGLM2-6B更偏向于将邮件分类为钓鱼邮件，但这会导致更多的误报。表10 LoRA微调后的性能对比LoRA微调前后的性能提升这一部分本发明从表9和表10的实验结果中分析了LoRA微调对模型检测钓鱼邮件的性能提升。可以看出，对于Llama2-7B，LoRA微调对模型有着明显的正面效果，特别是在不带邮件头信息的数据集上，准确率提高了近25%，F1分数也提升了近10%。对于BaiChuan2-7B，在LoRA微调后的性能提升是最明显的，尤其是在带邮件头信息的数据集上，准确率提高了30%以上，这表明LoRA微调对BaiChuan2-7B模型非常有效。对于ChatGLM2-6B，LoRA微调后的性能也有所提升，但提升效果不如其他两个模型。可能是因为ChatGLM2-6B在微调前的性能相对较好，而且6B的参数量要少于其他两个模型，所以通过LoRA微调注入知识带来的性能提升没有其他两个模型明显。此外，图5和图5分别展示了三个模型在IWSPA_LLMs_NH_dev数据集和IWSPA_LLMs_H_dev数据集上LoRA微调前后误报率和漏报率的对比。对于Llama2-7B模型，微调后的FPR在两个数据集上都明显减少，说明LoRA微调提高了模型的准确性，减少了将合法邮件错误分类为钓鱼邮件的情况。而微调后的FNR在两个数据集上都有所增加，表明模型会漏报一些实际的钓鱼邮件，虽然LoRA微调增加了漏报率，但它大大减少了误报率。对于BaiChuan2-7B模型，LoRA微调后的FPR和FNR在两个数据集上都明显减少。与Llama2-7B相比，BaiChuan2-7B在两个指标上都有所提升，这可能说明BaiChuan2-7B更适合于LoRA微调，或者是因为其在微调前的表现不如Llama2-7B，因此有更大的改进空间。对于ChatGLM2-6B模型，LoRA微调后的FPR和FNR在两个数据集上都有所减少，FNR在IWSPA_LLMs_H_dev数据集上的减少更为明显，表明微调后ChatGLM2-6B减少了对实际钓鱼邮件的漏报。最后，本发明对GPT-3.5、GPT-4和开源大语言模型的对比如下：本发明通过实验对GPT-3.5、GPT-4、Llama2-7B、BaiChuan2-7B和ChatGLM2-6B模型检测钓鱼邮件的能力进行了对比分析，GPT-4直接检测钓鱼邮件的性能最强。开源大语言模型因为参数量和训练数据量要远少于GPT-4和GPT-3.5，而且训练中并没有使用太多有关钓鱼邮件检测等领域的数据，所以Llama2-7B等模型在直接检测钓鱼邮件上的性能要差很多。但通过本发明构造的IWSPA_LLMs_sft数据集对模型进行监督微调后，Llama2-7B和BaiChuan2-7B虽然与GPT-4仍有一定差距，但在准确率等指标上能够接近或者超过GPT-3.5，这表明在参数量较小的模型上注入特定领域知识的方法是可行的。为了能够更好地构建网络安全领域的大语言模型，本发明通过观察微调后的BaiChuan2-7B等模型的检测结果，分析其目前存在的不足和缺陷。指令任务的完成度。本发明在提取模型的检测结果时发现，GPT-3.5和GPT-4的指令完成度较高，没有出现JSON结果无法解析的情况。而Llama2-7B等模型存在只进行了钓鱼邮件分析，而没有执行JSON格式的输出，即使输入邮件的长度较短也会出现这种情况。还有输出的JSON文本存在格式问题，例如没有以逗号结尾、字段的键名拼写错误、缺少字段键名等。此外，对于“phishing_score”字段的分数，有的输出结果没有严格按照提示的要求在0到10范围内打分，而是按照100分的范围给出了30分。钓鱼分析和检测结果的不一致性。GPT-3.5和GPT-4对钓鱼邮件的分析和最终JSON格式的输出保持一致，而Llama2-7B等模型存在不一致性。例如在检测错误的结果中，“phishing_score”给出的是1分，而“phishing”标记的却是True；或者是“phishing_score”给出7分，而“phishing”标记为False。此外，分析过程和JSON结果也存在不一致性，例如分析中明确说明是合法邮件，“phishing”标记为False，但“phishing_score”却给出了8分。检测结果的幻觉问题。在本发明构造的数据集中存在Base64编码后的邮件文本，在所有模型中只有GPT-4检测出文本经过Base64编码，并解码出邮件原文。本发明分析了Llama2-7B等模型的输出结果发现，它们并没有识别出这是Base64编码后的内容，而且在分析过程中出现了不存在的发件人地址、主题和正文，与解码后的邮件内容也并不相符。这种幻觉问题在构建垂直领域大模型时值得人们关注。综上所述，本发明提出了一种使用LLMs检测钓鱼邮件的方法，通过本发明设计的提示模板指导模型分析和识别邮件中的钓鱼技术。为了评估方法的有效性，本发明构造了数据集IWSPA_LLMs并进行了两个实验：一个实验是使用GPT-4、GPT-3.5、Llama2-7B、BaiChuan2-7B和ChatGLM2-6B直接检测钓鱼邮件，另一个实验是通过LoRA微调Llama2-7B、BaiChuan2-7B和ChatGLM2-6B后去检测钓鱼邮件。实验结果表明，GPT-4的性能最好，误报率和漏报率都是最低的，可以准确分析和识别发件人地址、邮件主题和正文中的可疑因素，以及钓鱼链接和邮件意图。此外，开源大语言模型在LoRA微调后性能都有所提升，其中BaiChuan2-7B的提升效果最明显，但和GPT-4相比仍有一定的差距。本发明优化了LLMs检测钓鱼邮件的提示和方法，并对构建网络安全领域的大语言模型工作进行了探索。本发明的研究表明，LLMs可以适应不断发展的网络钓鱼威胁和策略，辅助研究人员发现新的钓鱼技术，为检测网络钓鱼攻击提供了新的研究方向。当然，本发明还可有其他多种实施例，在不背离本发明精神及其实质的情况下，熟悉本领域的技术人员当然可根据本发明作出各种相应的改变和变形，但这些相应的改变和变形都应属于本发明所附的权利要求的保护范围。
