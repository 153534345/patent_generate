标题title
一种基于边缘计算的智能路侧单元装置
摘要abst
本发明公开了一种基于边缘计算的智能路侧单元装置，通过融合摄像头感知模块、毫米波雷达、激光雷达和OBU单元的信息，基于边缘计算技术进行分析，提高了路侧单元的智能化感知能力，减少了网络传递信息量，具有实时性高、成本低的优点；同时还能对传输的信息进行简化传输，减少存储和传输压力，同步能够快速锁定需要分析的目标对象，还能保证视频的完整性传输；本发明简单有效且易于实用。
权利要求书clms
1.一种基于边缘计算的智能路侧单元装置，其特征在于，包括:AI边缘计算平台及与AI边缘计算平台通信连接的摄像头感知模块、毫米波雷达、固态激光雷达、OBU车载单元；摄像头感知模块、毫米波雷达、固态激光雷达安装于智能路侧单元装置上，采集智能路侧单元装置所在位置的固定场景；摄像头感知模块在采集视频信息之后，将视频信息传输到AI边缘计算平台进行视频压缩分析。2.根据权利要求1所述的一种基于边缘计算的智能路侧单元装置，其特征在于，摄像头感知模块用于采集视频信息，通过AI深度学习技术实现图像处理、图像分析和图像理解功能；固态激光雷达用于产生高精度的点云信息；毫米波雷达用于产生点云信息；OBU车载单元安装于汽车上，采集汽车行驶过程中的动态场景信息，摄像头感知模块、毫米波雷达、固态激光雷达、OBU车载单元采集的信息都传递给AI边缘计算平台，在网络边缘进行数据的提取、分析，产生交通场景的数据，通过V2X通信系统实现V2V、V2I、V2N的通信。3.根据权利要求1所述的一种基于边缘计算的智能路侧单元装置，其特征在于：视频压缩分析具体方式为：步骤一：获取到摄像头感知模块在临近阶段拍摄的全天候的视频信息，将其标记为过往视频，若干个过往视频构成过往视频组；步骤二：得到所有的过往视频组，进行静态挑选，得到核定视频及其对应的属性均值、属性截上均值和属性截下均值；步骤三：得到若干个核定视频，及其对应的属性均值、属性截上均值和属性截下均值；给予每个核定视频分配一个唯一标识符，之后将唯一标识符与对应的核定视频传输到AI边缘计算平台进行存储；步骤四：之后对实时录制的视频，将其标记为实况视频，按照相同方式将实况视频分为72个时段，得到72个实况分段视频；步骤五：获取到实况分段视频中保持连续没有车辆经过超过T2时间的视频，将该段视频截取下来，将其标记为，T2为预设时间，通常取值为两分钟；之后将该段视频标记为转化视频；步骤六：获取到转化视频的截取灰值的均值P、截取上值和截取下值，之后计算该转化视频与所有的核定视频的相似值；步骤七：将相似值最高的核定视频标记为对应转化视频的关联视频，获取到关联视频的唯一标识符，将该唯一标识符标记为对应转化视频的转化代码；步骤八：得到所有转化视频的转化代码；将转化代码融入到视频信息中取代原有转化视频，并将其标记为传输视频。4.根据权利要求3所述的一种基于边缘计算的智能路侧单元装置，其特征在于，步骤一中的临近阶段指代为从分析的当天起，往前推X1天不包括当天的时间阶段；X1为预设数值。5.根据权利要求3所述的一种基于边缘计算的智能路侧单元装置，其特征在于，步骤二中的静态挑选具体方式为：S1：首先进行时段划分，将一天划分为72个时段，将其标记为静态时段；静态时段具体划分方式为从零点开始，每十分钟标记为一个时段，得到72个时段；S2：之后任选一个静态时段，获取到该静态时段时，过往视频组中没有任何车辆的所有视频，将其标记为对应静态时段的静态视频，所有的静态视频构成静态视频组；S3：对静态视频组内的所有静态视频进行视度分析，根据视度分析的结果确定核定视频及其对应的属性均值、属性截上均值和属性截下均值。6.根据权利要求5所述的一种基于边缘计算的智能路侧单元装置，其特征在于，步骤S2中的没有任何车辆的具体判定方式为：将当前帧的照片与T1时间前所在帧的照片进行比较，若二者相似度超过X2时，标记为无任何车辆，持续监控判定；X2为预设数值。7.根据权利要求5所述的一种基于边缘计算的智能路侧单元装置，其特征在于，步骤S3中的视度分析具体方式为：S301：任选一静态视频，将其标记为初静态视频；S302：从初始开始，每间隔一分钟获取静态视频中的一帧图片，将其标记为截取图；S303：连续获取，得到10张截取图；将每个截取图进行灰度化处理，得到灰度图片，之后求取每个灰度图片的平均灰度值，将其标记为截取灰值Qi，i＝1、...、n；S304：之后自动计算截取灰值Qi的均值P，获取到截取灰值Qi中的最大值和最小值，分别标记为截取上值和截取下值；S305：之后选择下一静态视频，同样按照步骤S302-S304的方式获取到对应静态视频的截取灰值的均值P、截取上值和截取下值；S306：根据公式计算相似值，具体为：相似值＝0.35*均差值+0.33*截上差值+0.32*截下差值；S307：当相似值不超过X2时，将对应的两组静态视频划分为同组视频；否则自动将该静态视频标记为初静态视频；S308：任选下一静态视频，重复步骤S305-S308，对所有的静态视频处理完毕，得到包含选中的初静态视频和其余若干个静态视频构成的同组视频；S309：任选下一初静态视频，按照步骤S302-S309的原理，对剩余的所有的初静态视频处理完毕，得到若干组的同组视频；S310：对同组视频中所有的均值、截取上值和截取下值求取均值，将其标记为对应同组视频的认定均值、认定截上均值和认定截下均值；S311：得到所有的同组视频的认定均值、认定截上均值和认定截下均值；并从同组视频中任一选定一静态视频将其标记为核定视频，并将对应同组视频的认定均值、认定截上均值和认定截下均值，标记为对应核定视频的属性均值、属性截上均值和属性截下均值。8.根据权利要求7所述的一种基于边缘计算的智能路侧单元装置，其特征在于，求取静态视频和初静态视频的均值的差值，将其标记为均差值，求取两个截取上值的差值并将其标记为截上差值，求取两个截取下值的差值并将其标记为截下差值。
说明书desc
技术领域本发明涉及路侧单元技术领域，具体涉及一种基于边缘计算的智能路侧单元装置。背景技术随着我国国力强盛和汽车保有量激增引起的交通拥堵、交通事故、节能减排压力，政府连续颁布纲领性文件，发展智能汽车、建设交通强国已经是国家战略。车路协同采用先进的无线通信和新一代信息技术，全方位实现车与车、车与路、车与人之间动态实时信息交互，在全时空动态交通信息采集与融合的基础上开展车辆主动安全控制和道路协同管理，充分实现人车路的有效协同，保证交通安全，提高通行效率，从而形成安全、高效和环保的智慧交通系统。路侧单元RSU是车路协同路侧端的重要组成部分，是突破车路协同技术的关键所在，其主要功能是采集当前的道路状况、交通状况等信息，通过通信网络与路侧感知设备、交通信号灯、电子标牌等终端通信，实现车路互联互通、交通信号实时交互等功能，辅助驾驶员进行驾驶，保障整个交通领域的人员及车DSRC辆安全。目前车路协同的成熟应用是ETC系统，通过专用短程通信技术DSRC，实现路侧单元RSU与车载设备OBU的通信，实现车辆通过ETC车道时不停车完成计次与收费功能。但是，当前技术存在如下问题：首先路侧单元环境感知能力不足。以海康威视、浙江大华等厂家的路侧单元主要以视频技术为核心构建智慧物联解决方案，但是视频技术受环境影响大，照明不足、雨雾天气或镜头脏污都会影响视频采集效果。其次，路侧单元通过云计算方式将采集的视频信息上传，造成了网络传输量巨大、云计算中心算力负载巨大的问题。基于此，提供一种解决方案。发明内容本发明的目的在于提供一种基于边缘计算的智能路侧单元装置；主要侧重于实现全天候的道路侧交通场景感知，基于边缘计算计算在路侧端进行数据分析，有效增强环境感知能力与减少网络数据传输量。本发明的目的可以通过以下技术方案实现：一种基于边缘计算的智能路侧单元装置，包括AI边缘计算平台，和均与AI边缘计算平台通信连接的摄像头感知模块、毫米波雷达、固态激光雷达、OBU车载单元；摄像头感知模块、毫米波雷达、固态激光雷达安装于智能路侧单元装置上，采集智能路侧单元装置所在位置的固定场景；摄像头感知模块在采集视频信息之后，将视频信息传输到AI边缘计算平台时，会进行视频压缩分析，视频压缩分析具体方式为：步骤一：获取到摄像头感知模块在临近阶段拍摄的全天候的视频信息，将其标记为过往视频，若干个过往视频构成过往视频组；步骤二：得到所有的过往视频组，进行静态挑选，得到核定视频及其对应的属性均值、属性截上均值和属性截下均值；步骤三：得到若干个核定视频，及其对应的属性均值、属性截上均值和属性截下均值；给予每个核定视频分配一个唯一标识符，之后将唯一标识符与对应的核定视频传输到AI边缘计算平台进行存储；步骤四：之后对实时录制的视频，将其标记为实况视频，按照相同方式将实况视频分为72个时段，得到72个实况分段视频；步骤五：获取到实况分段视频中保持连续没有车辆经过超过T2时间的视频，将该段视频截取下来，将其标记为，T2为预设时间，通常取值为两分钟；之后将该段视频标记为转化视频；步骤六：获取到转化视频的截取灰值的均值P、截取上值和截取下值，之后按照步骤S306中的公式计算该转化视频与所有的核定视频的相似值；步骤七：将相似值最高的核定视频标记为对应转化视频的关联视频，获取到关联视频的唯一标识符，将该唯一标识符标记为对应转化视频的转化代码；步骤八：得到所有转化视频的转化代码；将转化代码融入到视频信息中取代原有转化视频，并将其标记为传输视频。进一步地，摄像头感知模块用于采集视频信息，通过AI深度学习技术可以实现图像处理、图像分析和图像理解功能；固态激光雷达用于产生高精度的点云信息；毫米波雷达用于产生点云信息；OBU车载单元安装于汽车上，采集汽车行驶过程中的动态场景信息，摄像头感知模块、毫米波雷达、固态激光雷达、OBU车载单元采集的信息都传递给AI边缘计算平台，在网络边缘进行数据的提取、分析，产生交通场景的数据，通过V2X通信系统实现V2V、V2I、V2N的通信。进一步地，步骤一中的临近阶段指代为从分析的当天起，往前推X1天不包括当天，这一阶段标记为临近阶段；X1为预设数值。进一步地，步骤二中的静态挑选具体方式为：S1：首先进行时段划分，将一天划分为72个时段，将其标记为静态时段；静态时段具体划分方式为从零点开始，每十分钟标记为一个时段，得到72个时段；S2：之后任选一个静态时段，获取到该静态时段时，过往视频组中没有任何车辆的所有视频，将其标记为对应静态时段的静态视频，所有的静态视频构成静态视频组；S3：对静态视频组内的所有静态视频进行视度分析，根据视度分析的结果确定核定视频及其对应的属性均值、属性截上均值和属性截下均值。进一步地，步骤S2中的没有任何车辆的具体判定方式为：将当前帧的照片与T1时间前所在帧的照片进行比较，若二者相似度超过X2时，标记为无任何车辆，持续监控判定；X2为预设数值，具体取值为0.85。进一步地，步骤S3中的视度分析具体方式为：S301：任选一静态视频，将其标记为初静态视频；S302：从初始开始，每间隔一分钟获取静态视频中的一帧图片，将其标记为截取图；S303：连续获取，得到10张截取图；将每个截取图进行灰度化处理，得到灰度图片，之后求取每个灰度图片的平均灰度值，将其标记为截取灰值Qi，i＝1、...、n；S304：之后自动计算截取灰值Qi的均值P，获取到截取灰值Qi中的最大值和最小值，分别标记为截取上值和截取下值；S305：之后选择下一静态视频，同样按照步骤S302-S304的方式获取到对应静态视频的截取灰值的均值P、截取上值和截取下值；求取静态视频和初静态视频的均值的差值，将其标记为均差值，求取两个截取上值的差值并将其标记为截上差值，求取两个截取下值的差值并将其标记为截下差值；S306：根据公式计算相似值，具体为：相似值＝0.35*均差值+0.33*截上差值+0.32*截下差值；S307：当相似值不超过X2时，将对应的两组静态视频划分为同组视频；否则自动将该静态视频标记为初静态视频；S308：任选下一静态视频，重复步骤S305-S308，对所有的静态视频处理完毕，得到包含选中的初静态视频和其余若干个静态视频构成的同组视频；S309：任选下一初静态视频，按照步骤S302-S309的原理，对剩余的所有的初静态视频处理完毕，得到若干组的同组视频；S310：对同组视频中所有的均值、截取上值和截取下值求取均值，将其标记为对应同组视频的认定均值、认定截上均值和认定截下均值；S311：得到所有的同组视频的认定均值、认定截上均值和认定截下均值；并从同组视频中任一选定一静态视频将其标记为核定视频，并将对应同组视频的认定均值、认定截上均值和认定截下均值，标记为对应核定视频的属性均值、属性截上均值和属性截下均值。本发明的有益效果：本发明提供了一种智能路侧单元装置的方案，融合摄像头感知模块、毫米波雷达、激光雷达和OBU单元的信息，基于边缘计算技术进行分析，提高了路侧单元的智能化感知能力，减少了网络传递信息量，具有实时性高、成本低的优点；同时还能对传输的信息进行简化传输，减少存储和传输压力，同步能够快速锁定需要分析的目标对象，还能保证视频的完整性传输；本发明简单有效且易于实用。附图说明下面结合附图对本发明作进一步的说明。图1为本发明的整体结构示意图；图2为本发明中视频压缩分析的示意图。具体实施方式下面将结合本发明实施例中的附图，对本发明实施例中的技术方案进行清楚、完整地描述，显然，所描述的实施例仅仅是本发明一部分实施例，而不是全部的实施例。基于本发明中的实施例，本领域普通技术人员在没有作出创造性劳动前提下所获得的所有其它实施例，都属于本发明保护的范围。请参阅图1-2所示，本发明为一种基于边缘计算的智能路侧单元装置，该智能路侧单元装置包括：摄像头感知模块、毫米波雷达、固态激光雷达、OBU车载单元、AI边缘计算平台；摄像头感知模块、毫米波雷达、固态激光雷达、OBU车载单元均与AI边缘计算平台通信连接；摄像头感知模块、毫米波雷达、固态激光雷达安装于智能路侧单元装置上，采集智能路侧单元装置附近的固定场景；摄像头感知模块用于采集视频信息，通过AI深度学习技术可以实现图像处理、图像分析和图像理解功能。固态激光雷达用于产生高精度的点云信息；毫米波雷达的点云数据不如激光雷达，但可以全天候工作。OBU车载单元安装于汽车上，采集汽车行驶过程中的动态场景信息，摄像头感知模块、毫米波雷达、固态激光雷达、OBU车载单元采集的信息都传递给AI边缘计算平台，在网络边缘进行数据的提取、分析，产生交通场景的数据，通过V2X通信系统实现V2V、V2I、V2N的通信。当然，摄像头感知模块在采集视频信息之后，将视频信息传输到AI边缘计算平台时，会进行视频压缩分析，视频压缩分析具体方式为：步骤一：获取到摄像头感知模块在临近阶段拍摄的全天候的视频信息，将其标记为过往视频，若干个过往视频构成过往视频组；临近阶段指代为从分析的当天起，往前推X1天不包括当天，这一阶段标记为临近阶段；X1为预设数值；步骤二：得到所有的过往视频组，进行静态挑选，静态挑选具体方式为：S1：首先进行时段划分，将一天划分为72个时段，将其标记为静态时段；静态时段具体划分方式为从零点开始，每十分钟标记为一个时段，得到72个时段；S2：之后任选一个静态时段，获取到该静态时段时，过往视频组中没有任何车辆的所有视频，将其标记为对应静态时段的静态视频，所有的静态视频构成静态视频组；没有任何车辆的具体判定方式为：将当前帧的照片与T1时间前所在帧的照片进行比较，若二者相似度超过X2时，标记为无任何车辆，持续监控判定；当然，此处也可以通过现有技术中其他方式来实现；X2为预设数值，具体取值为0.85；S3：对静态视频组内的所有静态视频进行视度分析，视度分析具体方式为：S301：任选一静态视频，将其标记为初静态视频；S302：从初始开始，每间隔一分钟获取静态视频中的一帧图片，将其标记为截取图；S303：连续获取，得到10张截取图；将每个截取图进行灰度化处理，得到灰度图片，之后求取每个灰度图片的平均灰度值，将其标记为截取灰值Qi，i＝1、...、n；S304：之后自动计算截取灰值Qi的均值P，获取到截取灰值Qi中的最大值和最小值，分别标记为截取上值和截取下值；S305：之后选择下一静态视频，同样按照步骤S302-S304的方式获取到对应静态视频的截取灰值的均值P、截取上值和截取下值；求取静态视频和初静态视频的均值的差值，将其标记为均差值，求取两个截取上值的差值并将其标记为截上差值，求取两个截取下值的差值并将其标记为截下差值；S306：根据公式计算相似值，具体为：相似值＝0.35*均差值+0.33*截上差值+0.32*截下差值；S307：当相似值不超过X2时，将对应的两组静态视频划分为同组视频；否则自动将该静态视频标记为初静态视频；S308：任选下一静态视频，重复步骤S305-S308，对所有的静态视频处理完毕，得到包含选中的初静态视频和其余若干个静态视频构成的同组视频；S309：任选下一初静态视频，按照步骤S302-S309的原理，对剩余的所有的初静态视频处理完毕，得到若干组的同组视频；S310：对同组视频中所有的均值、截取上值和截取下值求取均值，将其标记为对应同组视频的认定均值、认定截上均值和认定截下均值；S311：得到所有的同组视频的认定均值、认定截上均值和认定截下均值；并从同组视频中任一选定一静态视频将其标记为核定视频，并将对应同组视频的认定均值、认定截上均值和认定截下均值，标记为对应核定视频的属性均值、属性截上均值和属性截下均值；步骤三：得到若干个核定视频，及其对应的属性均值、属性截上均值和属性截下均值；给予每个核定视频分配一个唯一标识符，之后将唯一标识符与对应的核定视频传输到AI边缘计算平台进行存储；步骤四：之后对实时录制的视频，将其标记为实况视频，按照相同方式将实况视频分为72个时段，得到72个实况分段视频；步骤五：获取到实况分段视频中保持连续没有车辆经过超过T2时间的视频，将该段视频截取下来，T2为预设时间，通常取值为两分钟；之后将该段视频标记为转化视频；步骤六：获取到转化视频的截取灰值的均值P、截取上值和截取下值，之后按照步骤S306中的公式计算该转化视频与所有的核定视频的相似值；步骤七：将相似值最高的核定视频标记为对应转化视频的关联视频，获取到关联视频的唯一标识符，将该唯一标识符标记为对应转化视频的转化代码；步骤八：得到所有转化视频的转化代码；将转化代码融入到视频信息中取代原有转化视频，并将其标记为传输视频；摄像头感知模块用于将传输视频传输到AI边缘计算平台，进行后续分析步骤。以上对本发明的一个实施例进行了详细说明，但所述内容仅为本发明的较佳实施例，不能被认为用于限定本发明的实施范围。凡依本发明申请范围所作的均等变化与改进等，均应仍归属于本发明的专利涵盖范围之内。
