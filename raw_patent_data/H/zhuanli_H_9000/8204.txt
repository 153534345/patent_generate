标题title
一种应用于异地同场景直播连线的镜头移动拍摄方法
摘要abst
本发明涉及图像处理技术领域，公开了一种应用于异地同场景直播连线的镜头移动拍摄方法，两地同背景融合直播过程中将两地镜头进行同步移动拍摄，使两地屏幕呈现的背景画面均随着拍摄角度变换而变换，以保证两地人与背景的匹配位姿关系，然后将两地拍摄到的画面进行拼接合成后再播出。本发明解决了现有技术存在的异地同场景实时连线中难以实现同步运镜等问题。
权利要求书clms
1.一种应用于异地同场景直播连线的镜头移动拍摄方法，其特征在于，两地同背景融合直播过程中将两地镜头进行同步移动拍摄，使两地屏幕呈现的背景画面均随着拍摄角度变换而变换，以保证两地人与背景的匹配位姿关系，然后将两地拍摄到的画面进行拼接合成后再播出。2.根据权利要求1所述的一种应用于异地同场景直播连线的镜头移动拍摄方法，其特征在于，包括以下步骤：S1，虚拟场景建模：P地进行虚拟场景建模，完成背景制作，对P地的折幕屏进行分区域处理，区域包括A区域、B区域；其中，A区域代表本地场景呈现画面部分，B区域为待融合部分，折幕屏至少包括三面，A区域位于其中一面，B区域覆盖除A区域所在面之外的两面；S2，相机部署：确定P地拍摄机位，确定摄像机的相机参数，根据相机拍摄方位将背景建模的可呈现部分按照A区域和B区域进行切割；在Q地部署与B区域大小一致的折屏，接收B区域背景数据和P地的相机参数，以同样的相机参数进行Q地的相机部署；S3，拍摄投射：P地摄像机开始进行拍摄，获得待处理视频流，将当前拍摄角度下的B区域背景数据b发送Q地，并将接收到的背景数据投射至Q地的折屏上；S4，拼接合成：Q地摄像机进行拍摄，获得补充画面N，将Q地摄像机拍摄到的画面N传送回P地拼接合成服务器进行合成输出。3.根据权利要求2所述的一种应用于异地同场景直播连线的镜头移动拍摄方法，其特征在于，步骤S2中，相机参数包括相机内外参数数据α、相机物理空间位置信息β、相机滑轨物理地址信息。4.根据权利要求3所述的一种应用于异地同场景直播连线的镜头移动拍摄方法，其特征在于，步骤S3中，视频流由多张待拼接基础画面M组成。5.根据权利要求4所述的一种应用于异地同场景直播连线的镜头移动拍摄方法，其特征在于，基础画面M包括拍摄到的全部或局部P地折幕屏中的A区域、折幕屏内的人员i、待替换区域B。6.根据权利要求5所述的一种应用于异地同场景直播连线的镜头移动拍摄方法，其特征在于，对比基础画面M的时码t,将B区域背景数据bt、P地的t时刻的物理空间位置信息βt发送至Q地，并将接收到的背景数据bt投射至Q地的折幕屏上。7.根据权利要求6所述的一种应用于异地同场景直播连线的镜头移动拍摄方法，其特征在于，步骤S4中，异地拍摄融合过程中，当要进行机位变换产生镜头移动拍摄时，每隔设定的固定时间将P地βt发往Q地，同时每隔设定的固定时间将P地bt发往Q地，Q地摄像机在经历T1时长的延时后，接收到信息βt并进行移动，保证对P地摄像机的位姿跟踪。8.根据权利要求7所述的一种应用于异地同场景直播连线的镜头移动拍摄方法，其特征在于，步骤S4中，P地摄像机拍摄出来的基础画面M首先传送给拼接合成服务器，每帧基础画面M都有时码标注t，形成Mt队列，Mt=，拼接服务器在经过传输延时T2后接收到基础画面M；Q地拍摄出来的补充画面N也传输给拼接合成服务器，每帧画面都有时码标注tp，形成Nt队列，Nt=；Q地拍摄的补充画面N开始传输，在经过传输延时T3后，拼接服务器收到设定帧数的补充画面N开始合成，开始进行拼接任务，按照画面时码开始进行M和N的拼接；拼接服务器经过T4的计算延时后，完成画面拼接，开始输出视频流。9.根据权利要求2至8任一项所述的一种应用于异地同场景直播连线的镜头移动拍摄方法，其特征在于，P地的折幕屏为L形折屏。10.根据权利要求2至8任一项所述的一种应用于异地同场景直播连线的镜头移动拍摄方法，其特征在于，其特征在于，P地的折幕屏为Cube屏。
说明书desc
技术领域本发明涉及图像处理技术领域，具体是一种应用于异地同场景直播连线的镜头移动拍摄方法。背景技术异地同场景连线指在直播过程中本地人员和异地人员通过技术手段实现在同一背景下的连线互动，常见于演播室、新闻直播间、演唱会等场景。目前的异地同场景连线有两种方式，一种主要通过绿幕的形式将异地人员从拍摄到的画面中抠出然后再与本地视频进行合成，该方法成熟度较高，但这种方法存在两个弊端：1、由于抠像抠出的是二维画面，拼接过程中只能以单一视角进行播出，无法进行镜头变换，否则融合效果大幅下降，用户沉浸感明显降低；2、通过抠像的方式进行异地同场景融合，由于无法对异地抠出的图像与本地背景场景进行坐标系映射变换，所以植入后有较为明显的违和感；另一种方式是通过Cube屏或多折屏来进行异地同场景连线，由于该方法的背景是通过建模得到的，可以通过拍摄方向计算拍摄到的人和场景之间的物理空间关系，并更改背景屏幕呈现的画面，因此不存在绿幕抠像中人物与背景之间明显的违和感，但由于该方式下数据量较大，如果进行镜头移动拍摄，异地数据传输回本地后再进行拼接，存在较大延时，难以进行同步，因此，目前该方式下只能进行定机位拍摄。发明内容为克服现有技术的不足，本发明提供了一种应用于异地同场景直播连线的镜头移动拍摄方法，解决现有技术存在的异地同场景实时连线中难以实现同步运镜等问题。本发明解决上述问题所采用的技术方案是：一种应用于异地同场景直播连线的镜头移动拍摄方法，两地同背景融合直播过程中将两地镜头进行同步移动拍摄，使两地屏幕呈现的背景画面均随着拍摄角度变换而变换，以保证两地人与背景的匹配位姿关系，然后将两地拍摄到的画面进行拼接合成后再播出。作为一种优选的技术方案，包括以下步骤：S1，虚拟场景建模：P地进行虚拟场景建模，完成背景制作，对P地的折幕屏进行分区域处理，区域包括A区域、B区域；其中，A区域代表本地场景呈现画面部分，B区域为待融合部分，折幕屏至少包括三面，A区域位于其中一面，B区域覆盖除A区域所在面之外的两面；S2，相机部署：确定P地拍摄机位，确定摄像机的相机参数，根据相机拍摄方位将背景建模的可呈现部分按照A区域和B区域进行切割；在Q地部署与B区域大小一致的折屏，接收B区域背景数据和P地的相机参数，以同样的相机参数进行Q地的相机部署；S3，拍摄投射：P地摄像机开始进行拍摄，获得待处理视频流，将当前拍摄角度下的B区域背景数据b发送Q地，并将接收到的背景数据投射至Q地的折屏上；S4，拼接合成：Q地摄像机进行拍摄，获得补充画面N，将Q地摄像机拍摄到的画面N传送回P地拼接合成服务器进行合成输出。作为一种优选的技术方案，步骤S2中，相机参数包括相机内外参数数据α、相机物理空间位置信息β、相机滑轨物理地址信息。作为一种优选的技术方案，步骤S3中，视频流由多张待拼接基础画面M组成。作为一种优选的技术方案，基础画面M包括拍摄到的全部或局部P地折幕屏中的A区域、折幕屏内的人员i、待替换区域B。作为一种优选的技术方案，对比基础画面M的时码t,将B区域背景数据bt、P地的t时刻的物理空间位置信息βt发送至Q地，并将接收到的背景数据bt投射至Q地的折幕屏上。作为一种优选的技术方案，步骤S4中，异地拍摄融合过程中，当要进行机位变换产生镜头移动拍摄时，每隔设定的固定时间将P地βt发往Q地，同时每隔设定的固定时间将P地bt发往Q地，Q地摄像机在经历T1时长的延时后，接收到信息βt并进行移动，保证对P地摄像机的位姿跟踪。作为一种优选的技术方案，P地摄像机拍摄出来的基础画面M首先传送给拼接合成服务器，每帧基础画面M都有时码标注t，形成Mt队列，Mt=，拼接服务器在经过传输延时T2后接收到基础画面M；Q地拍摄出来的补充画面N也传输给拼接合成服务器，每帧画面都有时码标注tp，形成Nt队列，Nt=；Q地拍摄的补充画面N开始传输，在经过传输延时T3后，拼接服务器收到设定帧数的补充画面N开始合成，开始进行拼接任务，按照画面时码开始进行M和N的拼接；拼接服务器经过T4的计算延时后，完成画面拼接，开始输出视频流。作为一种优选的技术方案，P地的折幕屏为L形折屏。作为一种优选的技术方案，P地的折幕屏为Cube屏。本发明相比于现有技术，具有以下有益效果：本发明可以在异地同场景实时连线中实现同步运镜，在保证了异地融合的人与背景的位姿关系的同时，解决了之前异地连线方案中不支持移动机位拍摄的问题，同时利用本发明提到的合成手段，保证了在直播过程可以使用。附图说明图1为本发明所述的一种应用于异地同场景直播连线的镜头移动拍摄方法的步骤示意图；图2为P地的Cube屏进行分区域示意图；图3为直播过程中异地连线中镜头移动拍摄示意图；图4为直播过程中异地连线移动拍摄中事件时间轴图；图5为直播过程中异地连线移动拍摄中数据时间轴图。具体实施方式下面结合实施例及附图，对本发明作进一步的详细说明，但本发明的实施方式不限于此。实施例1如图1至图5所示，本发明提出了一种应用于异地同场景直播连线的镜头移动拍摄方法，包括以下步骤：S1，P地进行虚拟场景建模，可通过UE等建模软件进行制作，完成背景制作，对P地的Cube屏进行分区域处理，其中A区域代表本地场景呈现画面部分，B区域为待融合部分；S2，确定P地拍摄机位，确定相机内外参数、相机物理空间位置信息、相机滑轨位置，根据相机拍摄方位，将背景建模的可呈现部分按照A区域和B区域进行切割。Q地部署与B区域大小一致的L形折屏，接收B区域场景数据和P地的相机内外参数数据α、相机物理空间位置信息β、相机滑轨物理地址信息，以同样的相机内外参数、相对物理位置、滑轨位置信息进行Q地的相机部署；S3，在t0时刻，P地摄像机开始进行拍摄，获得待处理视频流，视频流由每秒50张待拼接基础画面M组成，基础画面M包括拍摄到的部分P地Cube屏中的A区域以及Cube屏内的人员i以及待替换区域B，对比基础画面M的时码t,将B区域场景数据bt以及P地的t时刻的相机内外参数据及物理空间位置信息β发送Q地，并将接收到的场景数据bt投射至Q地的L形屏上；S4，Q地摄像机进行拍摄，获得补充画面N，补充画面N包括P地传送来的B区画面以及L屏上的人员j，将Q地摄像机拍摄到的画面传送回P地拼接合成服务器进行合成输出。S4.1异地拍摄融合过程中，当要进行机位变换产生镜头移动拍摄时，为了保证画面一致性，需要两边摄像机保证同一状态，由于初始布置相机时已经将内外参、物理空间信息保持同步，因此每隔设定的固定时间将P地βt发往Q地，同时每隔设定的固定时间将P地bt发往Q地，，Q地摄像机在经历T1时长的延时后，接收到信息βt并进行移动，保证对P地摄像机的位姿跟踪。如图3所示，考虑到摄像机和滑轨的定位，需在P地和Q地建设同样的空间坐标系，坐标系原点保持一致，因此在经历T1后，βt0=βt0+T1以及βtn=βtn+T1，其中tn为相机位置变化的某个时间点；S4.2由于P地背景会随相机拍摄方向变换而发生变化，输出同场景异地人员实时连线画面的视频流。本发明实现了异地同场景实时连线中实现同步运镜，实现了异地摄像机的位姿同步，实现了异地拍摄到的画面拼接合成。相比绿幕抠像和Cube的异地联动方式，本发明可以在异地同场景实时连线中实现同步运镜，在保证了异地融合的人与背景的位姿关系的同时，解决了之前异地连线方案中不支持移动机位拍摄的问题，同时利用本发明提到的合成手段，保证了在直播过程可以使用。如上所述，可较好地实现本发明。本说明书中所有实施例公开的所有特征，或隐含公开的所有方法或过程中的步骤，除了互相排斥的特征和/或步骤以外，均可以以任何方式组合和/或扩展、替换。以上所述，仅是本发明的较佳实施例而已，并非对本发明作任何形式上的限制，依据本发明的技术实质，在本发明的精神和原则之内，对以上实施例所作的任何简单的修改、等同替换与改进等，均仍属于本发明技术方案的保护范围之内。
