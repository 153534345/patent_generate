标题title
基于近端策略优化的多类型终端随机接入竞争解决方法
摘要abst
本发明属于无线通信技术领域，具体涉及一种基于近端策略优化的多类型终端随机接入竞争解决方法，具体包括：S1：初始化各类型终端状态与数据队列状态、小区基站状态、竞争资源数量与竞争队列状态；对各类型终端进行优先级划分，得到不同优先级的终端；获取当前环境状态；S2：在基站侧建立智能体模型，基于分布式队列机制，结合当前环境状态利用近端策略优化PPO算法的策略网络对智能体模型进行训练，获取最优选择动作、以及即时奖励，并构成经验数据存储至经验池中；S3：构建目标函数，基于经验池中所存储的经验数据对目标函数进行深度学习，利用预设阈值对参数进行训练更新，完成多类型终端随机接入的分配优化。
权利要求书clms
1.一种基于近端策略优化的多类型终端随机接入竞争解决方法，其特征在于，具体包括如下步骤：S1：初始化各类型终端状态与数据队列状态、小区基站状态、竞争资源数量与竞争队列状态；并对各类型终端进行优先级划分，得到不同优先级的终端；获取当前环境状态；S2：在基站侧建立智能体模型，基于分布式队列机制，结合当前环境状态利用近端策略优化PPO算法的策略网络对智能体模型进行训练，获取最优选择动作、以及即时奖励，并构成经验数据存储至经验池中；S3：构建目标函数，并基于经验池中所存储的经验数据对目标函数进行深度学习；利用预设阈值对参数进行训练更新，以对预留的独占资源数量进行调整，完成多类型终端随机接入的分配优化；所述S3中，构建目标函数，并基于经验池中所存储的经验数据对目标函数进行深度学习；利用预设阈值对参数进行训练更新，以对预留的独占资源数量进行调整，完成多类型终端随机接入的分配优化的过程具体包括如下步骤：S31：判定经验池中所存储的经验数据是否达到预设阈值；S311：当经验池中所存储的经验数据达到预设阈值时，构建目标函数，对近端策略优化PPO算法进行训练，更新网络参数，并清空经验池；S312：当经验池中所存储的经验数据未达到预设阈值时，进入下一步；S32：判定迭代次数是否达到预设最大迭代次数；S321：当迭代次数达到预设最大迭代次数时，进入下一步；S322：当迭代次数未达到预设最大迭代次数时，基于当前环境状态，重新对智能体模型进行训练；S33：判定当前迭代周期结束后系统整体指标，即平均时延、平均前导码传递次数、平均能耗是否能达到预设要求；S331：当系统整体指标中任一指标未达到预设要求时，基于当前环境状态，重新对智能体模型进行训练；S332：当系统整体指标均达到预设要求时，输出最优解方案，完成多类型终端随机接入的分配优化。2.根据权利要求1所述的一种基于近端策略优化的多类型终端随机接入竞争解决方法，其特征在于，所述S1中，对各类型终端进行优先级划分，得到不同优先级的终端，并获取当前环境状态的过程具体包括如下步骤：S11：基于数据终端对时延和可靠性的敏感程度，对接入终端划分优先级，将低时延高可靠需求的终端划分为高优先级终端，将常规机器类通信终端划分为低优先级终端；S12：对环境参数进行环境初始化；其中，需要进行环境初始化的参数包括：发起接入的终端数量terminal_nums、竞争队列的状态、前导码总数slot_nums、为高优先级预留的独占资源数量；S13：获取当前环境状态，即获取当前低时延高可靠需求的终端数量URLLC_nums、机器类通信终端数量mMTC_nums、竞争队列的长度CDQ_length。3.根据权利要求2所述的一种基于近端策略优化的多类型终端随机接入竞争解决方法，其特征在于，所述S11中，高优先级终端包括控制类设备数据采集终端、故障预警与检测设备；低优先级终端包括运行指标数据采集终端、环境监控数据采集终端。4.根据权利要求2所述的一种基于近端策略优化的多类型终端随机接入竞争解决方法，其特征在于，所述S2中，获取最优选择动作、以及即时奖励，并构成经验数据存储至经验池中的过程具体包括如下步骤：S21：设定初始化高优先级终端独占的前导码数量为;S22：基于分布式队列机制，结合当前环境状态利用近端策略优化PPO算法的策略网络对智能体模型进行训练，获取最优选择动作；S23：将所获取的最优选择动作输入至环境状态中，基于基站广播的随机接入信息执行分布式队列随机接入过程；S24：更新环境状态，并基于终端接入结果计算即时奖励；S25：将当前环境状态、最优选择动作、选择动作的概率、即时奖励作为一组经验数据存储至经验池中。5.根据权利要求4所述的一种基于近端策略优化的多类型终端随机接入竞争解决方法，其特征在于，所述S22中，获取最优选择动作的过程具体包括如下步骤：S221：基于分布式队列机制，将当前环境状态输入至近端策略优化PPO算法的策略网络中；S222：在输出层中输出动作空间中概率最大的动作作为最优选择动作；S2221：输出层中输出每个动作，并利用softmax函数得到每个动作的分数向量；S2222：从每个动作的形成的概率分布中采样任一动作值，以表征独占接入资源比例，并设定选择该动作的概率为/＞；其中，选择动作的概率的计算表达式为：；式中，为在状态/＞下动作/＞的选择概率；/＞为动作空间的大小；/＞为选择动作分量的值；/＞为动作空间中第/＞个动作分量的值；S2223：选择动作空间中概率最高的动作作为最优选择动作；其中，动作空间的范围为：/＞。6.根据权利要求5所述的一种基于近端策略优化的多类型终端随机接入竞争解决方法，其特征在于，所述S23中，将所选取的动作输入环境中，基于基站广播的随机接入信息执行分布式队列随机接入过程的过程具体包括如下步骤：S231：检测参与当前回合随机接入终端的数据包重传次数是否达到容忍的重传次数；S2311：当检测到数据包重传次数达到容忍的重传次数时，接入失败，进行丢包处理；S2312：当检测到数据包重传次数未达到容忍的重传次数时，依照接入终端的优先级规则发起接入过程，即高优先级终端任选一个前导码发起接入请求，低优先级终端向与高优先级终端共享部分前导码发起接入请求；分别计算高优先级终端、低优先级终端成功接入的概率；其中，高优先级终端接入成功率的计算表达式为：；式中，为规定的高优先级终端独占的前导码的数量；/＞为本回合中发起接入请求的终端数量，且/＞；其中，低优先级终端接入成功率的计算表达式为：；式中，为前导码的可用数量；S232：将所选择的前导码通过物理层随机接入信道传递至基站，基站对其解码、并告知发生接入冲突的终端的序号；发生接入冲突的终端构成冲突终端组，并依据前导码的序号依序排入至CRQ中，等待下一次可随机接入的机会。7.根据权利要求6所述的一种基于近端策略优化的多类型终端随机接入竞争解决方法，其特征在于，所述S24中，更新环境状态，并基于终端接入结果计算即时奖励的过程具体包括如下步骤：S241：结合冲突终端组，统计当前位于竞争队列队首的高优先级终端的数量、位于竞争队列队首的低优先级终端的数量、以及竞争队列的长度，进入新的环境状态；S242：分别基于高优先级终端接入成功率、低优先级终端接入成功率、竞争队列的长度变化、以及丢包情况计算即时奖励；即时奖励的计算表达式为：；其中，为高优先级终端接入成功率的奖励，其计算表达式为：；式中，为参与接入过程的低时延高可靠需求的终端的接入成功率，/＞为系统可容忍的低时延高可靠需求的终端的最低接入成功率；其中，为低优先级终端接入成功率的奖励，其计算表达式为：；式中，为参与接入过程的机器类通信终端的接入成功率，/＞为系统可容忍的机器类通信终端的最低接入成功率；其中，为竞争队列长度变化的奖励，其计算表达式为：；式中，为本回合随机接入过程后竞争队列的长度；/＞为历史竞争队列的长度；其中，为本回合随机接入过程中丢包处理的惩罚，其计算表达式为：；式中，为丢包的个数。8.根据权利要求7所述的一种基于近端策略优化的多类型终端随机接入竞争解决方法，其特征在于，所述S311中，对近端策略优化PPO算法进行训练，更新网络参数的过程具体包括如下步骤：S3111：根据折扣率及结算这批数据中每次随机接入过程对应的奖励期望与优势估计；其中，奖励期望的计算表达式为：；式中，为第/＞次随机接入过程的奖励期望；/＞为第/＞次随机接入过程的即时奖励；/＞为利用预设的Critic网络获得的/＞状态的价值；/＞为一个回合的总次数；其中，优势估计的计算表达式为：；式中，为第/＞次随机接入过程的优势估计；/＞为利用预设的Critic网络获得的/＞状态的价值；S3112：采用MSEloss作为损失函数更新Critic网络，以最小化当前状态价值与折扣奖励之间的差值：；式中，为价值函数误差项；/＞为状态/＞的状态价值；/＞为折扣奖励，/＞为经验池中的数据量；S3113：计算Actor网络的损失函数；其中，Actor网络的损失函数的计算表达式为：；式中，为新旧策略的概率比，即/＞，/＞为新策略的概率，/＞为旧策略的概率；/＞为优势估计函数，即；/＞为截断函数；/＞为截断超参数，以限制网络更新幅度；S3114：构建近端策略优化PPO算法网络的目标函数；其中，近端策略优化PPO算法网络的目标函数的表达式为：；其中，为Actor网络的损失函数；/＞为价值函数误差项；/＞为策略模型的熵奖励；/＞、/＞为常系数，以调整目标函数中各部分的权重；S3115：通过最大化的近端策略优化PPO算法网络的目标函数，更新网络参数，且当经验池中数据对网络参数进行T次连续更新后，将网络参数/＞更新为/＞。9.根据权利要求7所述的一种基于近端策略优化的多类型终端随机接入竞争解决方法，其特征在于，所述S33中，当前迭代周期结束后系统整体指标的计算包括：平均时延的计算表达式为：；式中，表示所有终端完成随机接入过程所需要的RAO总和，即系统的整体平均时延；“1”表示第一个RAO；/＞表示参与接入过程的终端总数量；/＞表示可用前导码的总数量；/＞为参与接入过程的终端；/＞为在第一个RAO中发生冲突的终端在接下来全部完成随机接入过程需要的RAO总和；前导码传递次数的计算表达式为：；平均能耗的计算表达式为：；式中，、/＞、/＞分别为终端在退避状态、接入状态、以及监测状态的能耗；/＞、/＞分别为第/＞层参与随机接入的高优先级终端和低优先级终端的数量；/＞为预留的独占前导码的数量。
说明书desc
技术领域本发明属于无线通信技术领域，具体涉及一种基于近端策略优化的多类型终端随机接入竞争解决方法。背景技术随着人类社会进入万物互联的时代，在第五代通信技术中，大规模机器类通信的引入使得大规模终端设备的接入成为可能。随机接入过程是设备实现上行通信的重要过程，用于实现蜂窝网络中用户的初始化接入、在用户进行上行数据传输时分配上行链路资源、进行上行式中同步等。然而，随着无线通信设备数量的爆发式增长，随机接入过程中的碰撞问题日益突出。为此，需要设计高效的竞争解决机制来应对海量多类型终端的接入。目前，关于随机接入协议的研究，主要分为ALOHA家族协议与树分裂协议两大类。ALOHA家族协议以接入等级限制与退避机制在时域上对冲突设备进行离散处理减少发生碰撞的概率。分布式队列竞争解决机制源于树分裂协议，它通过引入竞争解决队列将冲突设备组合成设备组进行时域离散，以充分利用前导码并减少冲突终端在重传中发生二次冲突的概率。对于随机接入求解最优策略时，现有阶段多利用深度强化学习算法如DQN和AC算法来解决随机接入过程中的资源冲突问题。然而，目前大部分研究仅关注单类型用户的随机接入过程，未考虑到实际生产活动中多类型通信设备共存的情况；同时针对随机接入协议的优化大部分关注焦点集中于ALOHA家族协议的优化，并没有意识到分布式队列方案的潜在优势，并且现有的竞争解决机制无法适应海量终端大规模初始化接入和周期性数据上传造成的网络负载，进而会对通信系统的整体性能造成影响。发明内容本发明在于提供一种基于近端策略优化的多类型终端随机接入竞争解决方法，能够基于分布式队列机制，引入优先级划分的思想，依据需求增大特定终端的接入机会，减少其发生二次冲突的概率，从而提升整体系统的接入成功率和稳定性，以应对海量终端发起随机接入请求造成的网络拥塞；同时利用近端策略优化PPO算法对独占资源进行动态调整，满足预设条件下的最优资源规划，提高终端接入成功率，同时减少资源浪费。一种基于近端策略优化的多类型终端随机接入竞争解决方法，具体包括如下步骤：S1：初始化各类型终端状态与数据队列状态、小区基站状态、竞争资源数量与竞争队列状态；并对各类型终端进行优先级划分，得到不同优先级的终端；获取当前环境状态；S2：在基站侧建立智能体模型，基于分布式队列机制，结合当前环境状态利用近端策略优化PPO算法的策略网络对智能体模型进行训练，获取最优选择动作、以及即时奖励，并构成经验数据存储至经验池中；S3：构建目标函数，并基于经验池中所存储的经验数据对目标函数进行深度学习；利用预设阈值对参数进行训练更新，以对预留的独占资源数量进行调整，完成多类型终端随机接入的分配优化；所述S3中，构建目标函数，并基于经验池中所存储的经验数据对目标函数进行深度学习；利用预设阈值对参数进行训练更新，以对预留的独占资源数量进行调整，完成多类型终端随机接入的分配优化的过程具体包括如下步骤：S31：判定经验池中所存储的经验数据是否达到预设阈值；S311：当经验池中所存储的经验数据达到预设阈值时，构建目标函数，对近端策略优化PPO算法进行训练，更新网络参数，并清空经验池；S312：当经验池中所存储的经验数据未达到预设阈值时，进入下一步；S32：判定迭代次数是否达到预设最大迭代次数；S321：当迭代次数达到预设最大迭代次数时，进入下一步；S322：当迭代次数未达到预设最大迭代次数时，基于当前环境状态，重新对智能体模型进行训练；S33：判定当前迭代周期结束后系统整体指标，即平均时延、平均前导码传递次数、平均能耗是否能达到预设要求；S331：当系统整体指标中任一指标未达到预设要求时，基于当前环境状态，重新对智能体模型进行训练；S332：当系统整体指标均达到预设要求时，输出最优解方案，完成多类型终端随机接入的分配优化。能够基于分布式队列机制，引入优先级划分的思想，依据需求增大特定终端的接入机会，减少其发生二次冲突的概率，从而提升整体系统的接入成功率和稳定性，以应对海量终端发起随机接入请求造成的网络拥塞；同时利用近端策略优化PPO算法对独占资源进行动态调整，满足预设条件下的最优资源规划，提高终端接入成功率，同时减少资源浪费。进一步的，所述S1中，对各类型终端进行优先级划分，得到不同优先级的终端，并获取当前环境状态的过程具体包括如下步骤：S11：基于数据终端对时延和可靠性的敏感程度，对接入终端划分优先级，将对低时延高可靠需求的终端划分为高优先级终端，将常规机器类通信终端划分为低优先级终端；S12：对环境参数进行环境初始化；其中，需要进行环境初始化的参数包括：发起接入的终端数量terminal_nums、竞争队列的状态、前导码总数slot_nums、为高优先级预留的独占资源数量；S13：获取当前环境状态，即获取当前低时延高可靠需求的终端数量URLLC_nums、机器类通信终端数量mMTC_nums、竞争队列的长度CDQ_length。进一步的，所述S11中，高优先级终端包括控制类设备数据采集终端、故障预警与检测设备；低优先级终端包括运行指标数据采集终端、环境监控数据采集终端。进一步的，所述S2中，获取最优选择动作、以及即时奖励，并构成经验数据存储至经验池中的过程具体包括如下步骤：S21：设定初始化高优先级终端独占的前导码数量为;S22：基于分布式队列机制，结合当前环境状态利用近端策略优化PPO算法的策略网络对智能体模型进行训练，获取最优选择动作；S23：将所获取的最优选择动作输入至环境状态中，基于基站广播的随机接入信息执行分布式队列随机接入过程；S24：更新环境状态，并基于终端接入结果计算即时奖励；S25：将当前环境状态、最优选择动作、选择动作的概率、即时奖励作为一组经验数据存储至经验池中。进一步的，所述S22中，获取最优选择动作的过程具体包括如下步骤：S221：基于分布式队列机制，将当前环境状态输入至近端策略优化PPO算法的策略网络中；S222：在输出层中输出动作空间中概率最大的动作作为最优选择动作；S2221：输出层中输出每个动作，并利用softmax函数得到每个动作的分数向量；S2222：从每个动作的形成的概率分布中采样任一动作值，以表征独占接入资源比例，并设定选择该动作的概率为/＞；其中，选择动作的概率的计算表达式为：；式中，为在状态/＞下动作/＞的选择概率；/＞为动作空间的大小；为选择动作分量的值；/＞为动作空间中第/＞个动作分量的值；S2223：选择动作空间中概率最高的动作作为最优选择动作；其中，动作空间的范围为：/＞。进一步的，所述S23中，将所选取的动作输入环境中，基于基站广播的随机接入信息执行分布式队列随机接入过程的过程具体包括如下步骤：S231：检测参与当前回合随机接入终端的数据包重传次数是否达到容忍的重传次数；S2311：当检测到数据包重传次数达到容忍的重传次数时，接入失败，进行丢包处理；S2312：当检测到数据包重传次数未达到容忍的重传次数时，依照接入终端的优先级规则发起接入过程，即高优先级终端任选一个前导码发起接入请求，低优先级终端向与高优先级终端共享部分前导码发起接入请求；分别计算高优先级终端、低优先级终端成功接入的概率；其中，高优先级终端接入成功率的计算表达式为：；式中，为规定的高优先级终端独占的前导码的数量；/＞为本回合中发起接入请求的终端数量，且/＞；其中，低优先级终端接入成功率的计算表达式为：；式中，为前导码的可用数量；S232：将所选择的前导码通过物理层随机接入信道传递至基站，基站对其解码、并告知发生接入冲突的终端的序号；发生接入冲突的终端构成冲突终端组，并依据前导码的序号依序排入至CRQ中，等待下一次可随机接入的机会。进一步的，所述S24中，更新环境状态，并基于终端接入结果计算即时奖励的过程具体包括如下步骤：S241：结合冲突终端组，统计当前位于竞争队列队首的高优先级终端的数量、位于竞争队列队首的低优先级终端的数量、以及竞争队列的长度，进入新的环境状态；S242：分别基于高优先级终端接入成功率、低优先级终端接入成功率、竞争队列的长度变化、以及丢包情况计算即时奖励；即时奖励的计算表达式为：；其中，为高优先级终端接入成功率的奖励，其计算表达式为：；式中，为参与接入过程的低时延高可靠需求的终端的接入成功率，/＞为系统可容忍的低时延高可靠需求的终端的最低接入成功率；其中，为低优先级终端接入成功率的奖励，其计算表达式为：；式中，为参与接入过程的机器类通信终端的接入成功率，/＞为系统可容忍的机器类通信终端的最低接入成功率；其中，为竞争队列长度变化的奖励，其计算表达式为：；式中，为本回合随机接入过程后竞争队列的长度；/＞为历史竞争队列的长度；其中，为本回合随机接入过程中丢包处理的惩罚，其计算表达式为：；式中，为丢包的个数。进一步的，所述S311中，对近端策略优化PPO算法进行训练，更新网络参数的过程具体包括如下步骤：S3111：根据折扣率及结算这批数据中每次随机接入过程对应的奖励期望与优势估计；其中，奖励期望的计算表达式为：；式中，为第/＞次随机接入过程的奖励期望；/＞为第/＞次随机接入过程的即时奖励；为利用预设的Critic网络获得的/＞状态的价值；/＞为一个回合的总次数；其中，优势估计的计算表达式为：；式中，为第/＞次随机接入过程的优势估计；/＞为利用预设的Critic网络获得的状态的价值；S3112：采用MSEloss作为损失函数更新Critic网络，以最小化当前状态价值与折扣奖励之间的差值：；式中，为价值函数误差项；/＞为状态/＞的状态价值；/＞为折扣奖励，为经验池中的数据量；S3113：计算Actor网络的损失函数；其中，Actor网络的损失函数的计算表达式为：；式中，为新旧策略的概率比，即/＞，/＞为新策略的概率，/＞为旧策略的概率；/＞为优势估计函数，即；/＞为截断函数；/＞为截断超参数，以限制网络更新幅度；S3114：构建近端策略优化PPO算法网络的目标函数；其中，近端策略优化PPO算法网络的目标函数的表达式为：；其中，为Actor网络的损失函数；/＞为价值函数误差项；/＞为策略模型的熵奖励；/＞、/＞为常系数，以调整目标函数中各部分的权重；S3115：通过最大化的近端策略优化PPO算法网络的目标函数，更新网络参数，且当经验池中数据对网络参数进行T次连续更新后，将网络参数/＞更新为/＞。进一步的，所述S33中，当前迭代周期结束后系统整体指标的计算包括：平均时延的计算表达式为：；式中，表示所有终端完成随机接入过程所需要的RAO总和，即系统的整体平均时延；“1”表示第一个RAO；/＞表示参与接入过程的终端总数量；/＞表示可用前导码的总数量；/＞为参与接入过程的终端；/＞为在第一个RAO中发生冲突的终端在接下来全部完成随机接入过程需要的RAO总和；前导码传递次数的计算表达式为：；平均能耗的计算表达式为：；式中，、/＞、/＞分别为终端在退避状态、接入状态、以及监测状态的能耗；/＞、/＞分别为第/＞层参与随机接入的高优先级终端和低优先级终端的数量；/＞为预留的独占前导码的数量。本发明的有益效果为：本发明能够基于分布式队列机制，引入优先级划分的思想，依据需求增大特定终端的接入机会，减少其发生二次冲突的概率，从而提升整体系统的接入成功率和稳定性，以应对海量终端发起随机接入请求造成的网络拥塞；同时利用近端策略优化PPO算法对独占资源进行动态调整，满足预设条件下的最优资源规划，提高终端接入成功率，同时减少资源浪费。附图说明图1为本发明的流程图；图2为分布式队列竞争解决机制的流程示意图；图3为终端接入状态转移示意图；图4为实施例2中获取最优解的流程图。具体实施方式下面将结合本发明实施例中的附图，对本发明实施例中的技术方案进行清楚、完整地描述，显然，所描述的实施例仅仅是本发明一部分实施例，而不是全部的实施例。基于本发明中的实施例，本领域普通技术人员在没有做出创造性劳动前提下所获得的所有其他实施例，都属于本发明保护的范围。要说明的是，下文描述在所附权利要求书的范围内的实施例的各种方面。应显而易见，本文中所描述的方面可体现于广泛多种形式中，且本文中所描述的任何特定结构及/或功能仅为说明性的。基于本公开，所属领域的技术人员应了解，本文中所描述的一个方面可与任何其它方面独立地实施，且可以各种方式组合这些方面中的两者或两者以上。举例来说，可使用本文中所阐述的任何数目个方面来实施设备及/或实践方法。另外，可使用除了本文中所阐述的方面中的一或多者之外的其它结构及/或功能性实施此设备及/或实践此方法。另外，在以下描述中，提供具体细节是为了便于透彻理解实例，对于本领域的普通技术人员而言，可以具体情况理解上述术语在本申请中的具体含义。实施例1图1所示的是一种基于近端策略优化的多类型终端随机接入竞争解决方法，能够基于分布式队列机制，引入优先级划分的思想，依据需求增大特定终端的接入机会，减少其发生二次冲突的概率，从而提升整体系统的接入成功率和稳定性，以应对海量终端发起随机接入请求造成的网络拥塞；同时利用近端策略优化PPO算法对独占资源进行动态调整，满足预设条件下的最优资源规划，提高终端接入成功率，同时减少资源浪费。具体包括如下步骤：S1：初始化各类型终端状态与数据队列状态、小区基站状态、竞争资源数量与竞争队列状态；并对各类型终端进行优先级划分，得到不同优先级的终端；获取当前环境状态；S11：基于数据终端对时延和可靠性的敏感程度，对接入终端划分优先级，将对低时延高可靠需求的终端划分为高优先级终端，将常规机器类通信终端划分为低优先级终端；其中，高优先级终端包括控制类设备数据采集终端、故障预警与检测设备；低优先级终端包括运行指标数据采集终端、环境监控数据采集终端。S12：对环境参数进行环境初始化；其中，需要进行环境初始化的参数包括：发起接入的终端数量terminal_nums、竞争队列的状态、前导码总数slot_nums、为高优先级预留的独占资源数量；S13：获取当前环境状态，即获取当前低时延高可靠需求的终端数量URLLC_nums、机器类通信终端数量mMTC_nums、竞争队列的长度CDQ_length。S2：在基站侧建立智能体模型，基于分布式队列机制，结合当前环境状态利用近端策略优化PPO算法的策略网络对智能体模型进行训练，获取最优选择动作、以及即时奖励，并构成经验数据存储至经验池中；具体包括：S21：设定初始化高优先级终端独占的前导码数量为;S22：基于分布式队列机制，结合当前环境状态利用近端策略优化PPO算法的策略网络对智能体模型进行训练，获取最优选择动作；需要说明的是，如图2所示，在利用近端策略优化PPO算法的策略网络对智能体模型进行训练前，需要先构建近端策略优化PPO算法网络。其中，获取最优选择动作的过程具体包括如下步骤：S221：基于分布式队列机制，将当前环境状态输入至近端策略优化PPO算法的策略网络中；S222：在输出层中输出动作空间中概率最大的动作作为最优选择动作；S2221：输出层中输出每个动作，并利用softmax函数得到每个动作的分数向量；S2222：从每个动作的形成的概率分布中采样任一动作值，以表征独占接入资源比例，并设定选择该动作的概率为/＞；其中，选择动作的概率的计算表达式为：；式中，为在状态/＞下动作/＞的选择概率；/＞为动作空间的大小；为选择动作分量的值；/＞为动作空间中第/＞个动作分量的值；S2223：选择动作空间中概率最高的动作作为最优选择动作；其中，动作空间的范围为：/＞。在本实施例中，当第批终端设备请求接入时，智能体模型依据上一回合接入过程的即时奖励进行最优动作选择，进而以调整独占资源数量。S23：将所获取的最优选择动作输入至环境状态中，基于基站广播的随机接入信息执行分布式队列随机接入过程；其中，将所选取的动作输入环境中，基于基站广播的随机接入信息执行分布式队列随机接入过程的过程具体包括如下步骤：S231：检测参与当前回合随机接入终端的数据包重传次数是否达到容忍的重传次数；S2311：当检测到数据包重传次数达到容忍的重传次数时，接入失败，进行丢包处理；S2312：当检测到数据包重传次数未达到容忍的重传次数时，依照接入终端的优先级规则发起接入过程，即高优先级终端任选一个前导码发起接入请求，低优先级终端向与高优先级终端共享部分前导码发起接入请求；分别计算高优先级终端、低优先级终端成功接入的概率；其中，高优先级终端接入成功率的计算表达式为：；式中，为规定的高优先级终端独占的前导码的数量；/＞为本回合中发起接入请求的终端数量，且/＞；其中，低优先级终端接入成功率的计算表达式为：；式中，为前导码的可用数量；S232：将所选择的前导码通过物理层随机接入信道传递至基站，基站对其解码、并告知发生接入冲突的终端的序号；发生接入冲突的终端构成冲突终端组，并依据前导码的序号依序排入至CRQ中，等待下一次可随机接入的机会。S24：更新环境状态，并基于终端接入结果计算即时奖励；其中，更新环境状态，并基于终端接入结果计算即时奖励的过程具体包括如下步骤：S241：结合冲突终端组，统计当前位于竞争队列队首的高优先级终端的数量、位于竞争队列队首的低优先级终端的数量、以及竞争队列的长度，进入新的环境状态；S242：分别基于高优先级终端接入成功率、低优先级终端接入成功率、竞争队列的长度变化、以及丢包情况计算即时奖励；即时奖励的计算表达式为：；其中，为高优先级终端接入成功率的奖励，其计算表达式为：；式中，为参与接入过程的低时延高可靠需求的终端的接入成功率，/＞为系统可容忍的低时延高可靠需求的终端的最低接入成功率；其中，为低优先级终端接入成功率的奖励，其计算表达式为：；式中，为参与接入过程的机器类通信终端的接入成功率，/＞为系统可容忍的机器类通信终端的最低接入成功率；其中，为竞争队列长度变化的奖励，其计算表达式为：；式中，为本回合随机接入过程后竞争队列的长度；/＞为历史竞争队列的长度；其中，为本回合随机接入过程中丢包处理的惩罚，其计算表达式为：；式中，为丢包的个数。S25：将当前环境状态、最优选择动作、选择动作的概率、即时奖励作为一组经验数据存储至经验池中。S3：构建目标函数，并基于经验池中所存储的经验数据对目标函数进行深度学习；利用预设阈值对参数进行训练更新，以对预留的独占资源数量进行调整，完成多类型终端随机接入的分配优化。S31：判定经验池中所存储的经验数据是否达到预设阈值；S311：当经验池中所存储的经验数据达到预设阈值时，构建目标函数，对近端策略优化PPO算法进行训练，更新网络参数，并清空经验池；具体包括如下步骤：S3111：根据折扣率及结算这批数据中每次随机接入过程对应的奖励期望与优势估计；其中，奖励期望的计算表达式为：；式中，为第/＞次随机接入过程的奖励期望；/＞为第/＞次随机接入过程的即时奖励；为利用预设的Critic网络获得的/＞状态的价值；/＞为一个回合的总次数；其中，优势估计的计算表达式为：；式中，为第/＞次随机接入过程的优势估计；/＞为利用预设的Critic网络获得的状态的价值；S3112：采用MSEloss作为损失函数更新Critic网络，以最小化当前状态价值与折扣奖励之间的差值：；式中，为价值函数误差项；/＞为状态/＞的状态价值；/＞为折扣奖励，为经验池中的数据量；S3113：计算Actor网络的损失函数；其中，Actor网络的损失函数的计算表达式为：；式中，为新旧策略的概率比，即/＞，/＞为新策略的概率，/＞为旧策略的概率；/＞为优势估计函数，即；/＞为截断函数；/＞为截断超参数，以限制网络更新幅度；S3114：构建近端策略优化PPO算法网络的目标函数；其中，近端策略优化PPO算法网络的目标函数的表达式为：；其中，为Actor网络的损失函数；/＞为价值函数误差项；/＞为策略模型的熵奖励；/＞、/＞为常系数，以调整目标函数中各部分的权重；S3115：通过最大化的近端策略优化PPO算法网络的目标函数，更新网络参数，且当经验池中数据对网络参数进行T次连续更新后，将网络参数/＞更新为/＞。S312：当经验池中所存储的经验数据未达到预设阈值时，进入下一步；S32：判定迭代次数是否达到预设最大迭代次数；S321：当迭代次数达到预设最大迭代次数时，进入下一步；S322：当迭代次数未达到预设最大迭代次数时，基于当前环境状态，重新对智能体模型进行训练；S33：判定当前迭代周期结束后系统整体指标，即平均时延、平均前导码传递次数、平均能耗是否能达到预设要求；S331：当系统整体指标中任一指标未达到预设要求时，基于当前环境状态，重新对智能体模型进行训练；S332：当系统整体指标均达到预设要求时，输出最优解方案，完成多类型终端随机接入的分配优化。其中，当前迭代周期结束后系统整体指标的计算包括：平均时延的计算表达式为：；式中，表示所有终端完成随机接入过程所需要的RAO总和，即系统的整体平均时延；“1”表示第一个RAO；/＞表示参与接入过程的终端总数量；/＞表示可用前导码的总数量；/＞为参与接入过程的终端；/＞为在第一个RAO中发生冲突的终端在接下来全部完成随机接入过程需要的RAO总和；前导码传递次数的计算表达式为：；平均能耗的计算表达式为：；式中，、/＞、/＞分别为终端在退避状态、接入状态、以及监测状态的能耗；/＞、/＞分别为第/＞层参与随机接入的高优先级终端和低优先级终端的数量；/＞为预留的独占前导码的数量。图3所示的是终端接入状态转移示意图，即可知，终端常处于睡眠状态，当终端被激活后处于监测状态；当检测到竞争队列CRQ长度为空时，进行终端接入，即处于终端接入状态；当接入成功时，进行数据传递，数据传递成功后回归睡眠状态；当接入失败时，进入退避状态，依据选择的前导码序号依次进入CRQ，下一回合位于队首的终端组进入监测状态重新进行接入过程；若初始化的终端检测到竞争队列CRQ长度不为空时，进入退避状态，退避结束后重新处于监测状态。实施例2如图4所示，本实施例中，提供一种基于近端策略优化的多类型终端随机接入竞争解决方法，具体包括如下步骤：T1：获取初始化的各类型终端状态与数据队列状态、小区基站状态、竞争资源数量与竞争队列状态；并对各类型终端进行优先级划分，得到不同优先级的终端；获取各类型终端状态；获取当前环境状态；T2：判定本回合中竞争队列CRQ长度；T21：当本回合中竞争队列CRQ长度不为空，即CRQ_length≠0时，继续执行CRQ中数据终端的接入过程，等待下一个RAO，返回T1；T22：当本回合中竞争队列CRQ长度为空，即CRQ_length=0时，终端进行丢包判定，激活竞争队列CRQ中位于第一组的终端，判定本回合中数据包重传次数是否达到容忍的重传次数；T221：当本回合中数据包重传次数达到容忍的重传次数时，接入失败，进行丢包处理；T22：当本回合中数据包重传次数未达到容忍的重传次数时，发出终端接入请求，并向基站进行前导码传递；基站进行接入响应，并判定是否发生接入冲突；T221：当未发生接入冲突时，进行终端接入，解决接入竞争，完成多类型终端的接入；T222：当发生接入冲突时，进入下一回合；T2221：数据包重传次数加一；T2222：从T22中获取竞争队列CRQ信息，更新终端在队列中的位置，转至T22，等待第一组终端的激活。在本说明书的描述中，参考术语“一个实施例”、“一些实施例”、“示例”、“具体示例”、或“一些示例”等的描述意指结合该实施例或示例描述的具体特征、结构、材料或者特点包含于本发明的至少一个实施例或示例中。在本说明书中，对上述术语的示意性表述不一定指的是相同的实施例或示例。而且，描述的具体特征、结构、材料或者特点可以在任何的一个或多个实施例或示例中以合适的方式结合。尽管上面已经示出和描述了本发明的实施例，可以理解的是，上述实施例是示例性的，不能理解为对本发明的限制，本领域的普通技术人员在本发明的范围内可以对上述实施例进行变化、修改、替换和变型。
