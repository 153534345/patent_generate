标题title
一种基于立体摄像机和毫米波雷达信息融合的机器人自主导航系统
摘要abst
本发明提供一种基于立体摄像机和毫米波雷达信息融合的机器人自主导航系统及计算机设备。本发明提供的一种基于立体摄像机和毫米波雷达信息融合的机器人自主导航系统，包括：视觉感知模块：用于获取预设物体的图像算出预设物体与机器人的距离数据；毫米波雷达感知模块：用于发射毫米波信号，并且接收到来自障碍物反射回来的信号，获得障碍物数据；视觉和毫米波雷达融合模块：根据获取的数据进行数据处理和融合，生成一个环境感知信息；机器人模块：根据环境感知信息进行自主导航。本发明提供的一种基于立体摄像机和毫米波雷达信息融合的机器人自主导航系统及计算机设备可提高下水道检查的准确性和效率减少人为错误的发生。
权利要求书clms
1.一种基于立体摄像机和毫米波雷达信息融合的机器人自主导航系统，其特征在于，包括：视觉感知模块：用于获取预设物体的图像，根据获取的图像大小来计算出预设物体与机器人的距离数据；毫米波雷达感知模块：用于发射毫米波信号，并且接收到来自障碍物反射回来的信号，根据接受回来的信号获得障碍物数据；视觉和毫米波雷达融合模块：根据视觉感知模块获取的距离数据和毫米波雷达感知模块获取的障碍物数据进行数据处理和融合，生成一个环境感知信息；机器人模块：根据环境感知信息进行自主导航。2.根据权利要求1所述的基于立体摄像机和毫米波雷达信息融合的机器人自主导航系统，其特征在于，所述障碍物数据包括障碍物与机器人的距离、障碍物本身速度和机器人看障碍物位于的角度。3.根据权利要求1所述的基于立体摄像机和毫米波雷达信息融合的机器人自主导航系统，其特征在于，所述视觉和毫米波雷达融合模块中，数据处理和融合包括数据去噪，校准和坐标系转换，然后根据处理好的数据进行数据对齐和数据关联，根据对齐好和关联好的数据进行融合，最后生成一个环境感知信息。4.根据权利要求1所述的基于立体摄像机和毫米波雷达信息融合的机器人自主导航系统，其特征在于，在所述视觉感知模块中，获取预设的图像具体为：根据深度学习网络方法处理预设物体的特征像素，然后实现预设物体的自动成像，最后获取预设物体的图像。5.根据权利要求所述4的基于立体摄像机和毫米波雷达信息融合的机器人自主导航系统，其特征在于，获取预设的图像后，利用canny边缘检测算法对预设图像进行边缘检测，并且对图像中的边点数进行判定，若图像中的边点数Nedge＞T，则判定机器人非常靠近预设物体，最后使用LC匹配度量计算预设物体和机器人之间的距离数据；若图像中的边点数Nedge＜T，则停止，并处理下一幅图像。6.根据权利要求5所述的基于立体摄像机和毫米波雷达信息融合的机器人自主导航系统，其特征在于，所述LC匹配度量计算具体包括如下步骤：f1，按照如下公式计算机器人左眼图像中两个相邻像素之间的差值：DL＝IL-IL,其中，DL为左眼图像相邻像素差值，IL为左眼图像，x为像素在图像x轴上位置，y为像素在图像y轴上位置；f2，按照如下公式计算机器人右眼图像中两个相邻像素之间的差值：DR＝IR-IR其中，DR为右眼图像相邻像素差值，IR为右眼图像；f3，按照如下公式计算机器人左眼和右眼中两个相邻像素之间的差值之和来表示区别性，公示如下：Gd＝|DL|-|DR|其中，d为水平位移差值，Cd为计算机器人左眼和右眼中两个相邻像素之间的差值之和；f4，按照如下公式计算机器人左眼和右眼中两个相邻像素之间差值的差值绝对值，来表示位移d处的相似处,公式如下：Gd＝|DL-DR|其中，Gd为计算机器人左眼和右眼中两个相邻像素之间差值的差值绝对值；f5，按照如下公式计算给定位移d，匹配度量Ed为：Ed＝|DL|+|DR|-DL-DR 其中，Ed为计算在水平位移差值为d的两处像素的相关性；若匹配像素是非特征像素，则水平相邻像素之间的亮度差很小，DL和DR都具有较小的值，因此，Ed的价值也很小；相反，若匹配像素是特征像素，则其在水平方向上具有较大的亮度差异，这将导致较大的Ed。7.根据权利要求1所述的基于立体摄像机和毫米波雷达信息融合的机器人自主导航系统，其特征在于，在所述毫米波雷达感知模块中，接收到来自障碍物反射回来的信号进行快速傅立叶变换得到RF图像，根据峰值检测算法从RF图像中提取雷达点。8.根据权利要求7所述的基于立体摄像机和毫米波雷达信息融合的机器人自主导航系统，其特征在于，接收到来自障碍物反射回来的信号进行快速傅立叶变换得到RF图像的具体步骤包括：对反射回来的信号进行处理，根据样本实施快速傅立叶变换来估计反射回来的信号的反射范围，然后使用低通滤波器对反射回来的信号再次进行处理，最后根据不同接收器天线的样本进行第二次FFT来估计反射的方位角并获得最终的RF图像。9.根据权利要求8所述的基于立体摄像机和毫米波雷达信息融合的机器人自主导航系统，其特征在于，根据获得最终的RF图像得到角度、距离、chirp这三个维度的数据，然后再根据这三个维度的数据进行一个三维卷积操作后，通过最大池化将chirp压缩到一维得到角度-距离特征图，然后将每一帧RF图像都进行同样的操作，最后将RF片段中的所有帧中提取的特征雷达点，根据提取的特征雷达点按时间顺序连接。10.据权利要求9所述的基于立体摄像机和毫米波雷达信息融合的机器人自主导航系统，其特征在于，根据提取的特征雷达点按时间顺序连接获得特征雷达点的峰值，并将峰值标记出来，用于数据融合。
说明书desc
技术领域本发明涉及自主导航领域，尤其涉及一种基于立体摄像机和毫米波雷达信息融合的机器人自主导航系统及计算机设备。背景技术城市下水道系统是一个包含雨水、生产生活污水等多种污水的复杂管网系统，然而据区域城市政府的报告显示，这些污水的流量占总流量的约30％。由于管道壁的老化、车辆碾压、化学反应等多种的原因，下水道系统中的管道容易出现破损，导致污水泄漏到周围环境中，严重威胁到城市的环境和公共卫生安全。因此，应该加强对下水道系统的维护和管理，及时修复受损管道，以减少污水对周围环境的影响。目前，许多团队利用装有车载视频摄像系统的缆索栓系机器人进行下水道检查。缆索栓系机器人无法自主导航和检查下水道的情况，所以要通过操作员远程控制机器人移动，和对视频系统进行目视检查，然后通过视频记录任何明显的损坏或异常情况。这样的系统的可靠性取决于操作员的经验，并且容易出现人为错误，效率低。发明内容本发明提供一种基于立体摄像机和毫米波雷达信息融合的机器人自主导航系统及计算机设备。一种基于立体摄像机和毫米波雷达信息融合的机器人自主导航系统，包括：视觉感知模块：用于获取预设物体的图像，根据获取的图像大小来计算出预设物体与机器人的距离数据；毫米波雷达感知模块：用于发射毫米波信号，并且接收到来自障碍物反射回来的信号，根据接受回来的信号获得障碍物数据；视觉和毫米波雷达融合模块：根据视觉感知模块获取的距离数据和毫米波雷达感知模块获取的障碍物数据进行数据处理和融合，生成一个环境感知信息；机器人模块：根据环境感知信息进行自主导航。优选地，所述障碍物数据包括障碍物与机器人的距离、障碍物本身速度和机器人看障碍物位于的角度。优选地，所述视觉和毫米波雷达融合模块中，数据处理和融合包括数据去噪，校准和坐标系转换，然后根据处理好的数据进行数据对齐和数据关联，根据对齐好和关联好的数据进行融合，最后生成一个环境感知信息。优选地，在所述视觉感知模块中，获取预设的图像具体为：根据深度学习网络方法处理预设物体的特征像素，然后实现预设物体的自动成像，最后获取预设物体的图像。优选地，获取预设的图像后，利用canny边缘检测算法对预设图像进行边缘检测，并且对图像中的边点数进行判定，若图像中的边点数Nedge＞T，则判定机器人非常靠近预设物体，最后使用LC匹配度量计算预设物体和机器人之间的距离数据；若图像中的边点数Nedge＜T，则停止，并处理下一幅图像。优选地，所述LC匹配度量计算具体包括如下步骤：f1，按照如下公式计算机器人左眼图像中两个相邻像素之间的差值：DL＝IL-IL,其中，DL为左眼图像相邻像素差值，IL为左眼图像，x为像素在图像x轴上位置，y为像素在图像y轴上位置；f2，按照如下公式计算机器人右眼图像中两个相邻像素之间的差值为：DR＝IR-IR其中，DR为右眼图像相邻像素差值，IR为右眼图像；f3，按照如下公式计算机器人左眼和右眼中两个相邻像素之间的差值之和来表示区别性，公示如下：Cd＝|DL|+|DR|其中，d为水平位移差值，Cd为计算机器人左眼和右眼中两个相邻像素之间的差值之和；f4，按照如下公式计算机器人左眼和右眼中两个相邻像素之间差值的差值绝对值，来表示位移d处的相似处,公式如下：Gd＝|DL-DR|其中，Gd为计算机器人左眼和右眼中两个相邻像素之间差值的差值绝对值；f5，按照如下公式计算给定位移d，匹配度量Ed为：Ed＝|DL|+|DR|-DL-DR 其中，Ed为计算在水平位移差值为d的两处像素的相关性；若匹配像素是非特征像素，则水平相邻像素之间的亮度差很小，DL和DR都具有较小的值，因此，Ed的价值也很小；相反，若匹配像素是特征像素，则其在水平方向上具有较大的亮度差异，这将导致较大的Ed。优选地，在所述毫米波雷达感知模块中，接收到来自障碍物反射回来的信号进行快速傅立叶变换得到RF图像，根据峰值检测算法从RF图像中提取雷达点。优选地，接收到来自障碍物反射回来的信号进行快速傅立叶变换得到RF图像的具体步骤包括：对反射回来的信号进行处理，根据样本实施快速傅立叶变换来估计反射回来的信号的反射范围，然后使用低通滤波器对反射回来的信号再次进行处理，最后根据不同接收器天线的样本进行第二次FFT来估计反射的方位角并获得最终的RF图像。优选地，根据获得最终的RF图像得到角度、距离、chirp这三个维度的数据，然后再根据这三个维度的数据进行一个三维卷积操作后，通过最大池化将chirp压缩到一维得到角度-距离特征图，然后将每一帧RF图像都进行同样的操作，最后将RF片段中的所有帧中提取的特征雷达点，根据提取的特征雷达点按时间顺序连接。优选地，根据提取的特征雷达点按时间顺序连接获得特征雷达点的峰值，并将峰值标记出来，用于数据融合。本发明提供的一种基于立体摄像机和毫米波雷达信息融合的机器人自主导航系统，不需要人为操控，根据预设物体的特征像素计算当前的位置，从而实现准确的导航，可以提高下水道检查的准确性和效率减少人为错误的发生，从而更好地保障城市环境和公共卫生的安全。附图说明通过附图中所示的本发明优选实施例更具体说明，本发明上述及其它目的、特征和优势将变得更加清晰。图1是本发明提供的机器人在下水道看到的图像接头示意图。图2是本发明提供的机器人在下水道看到的图像人孔示意图。图3是本发明提供的机器人示意图。图4是本发明提供的数据进行融合的流程图。图5是本发明提供的立体相机里的自动成像示意图。图6是本发明提供的生成机器人导航所需的距离数据流程图。图7是本发明提供的雷达信号生成RF图像流程示意图。具体实施方式下面结合附图和具体实施例对本发明技术方案作进一步的详细描述，以使本领域的技术人员可以更好的理解本发明并能予以实施，但所举实施例不作为对本发明的限定。本发明提供一种基于立体摄像机和毫米波雷达信息融合的机器人自主导航系统，包括：视觉感知模块：用于获取预设物体的图像，根据获取的图像大小来计算出预设物体与机器人的距离数据；预设物体是指机器人进入下水道看到里面人孔和接头，机器人自主导航中预设物体被用来做地标，有利于机器人的自主导航。其中，具有视觉感知模块的设备是指立体相机。毫米波雷达感知模块：用于发射毫米波信号，并且接收到来自障碍物反射回来的信号，根据接受回来的信号获得障碍物数据；具有毫米波雷达感知模块的设备是指毫米波雷达。视觉和毫米波雷达融合模块：根据视觉感知模块获取的距离数据和毫米波雷达感知模块获取的障碍物数据进行数据处理和融合，生成一个环境感知信息；机器人模块：根据环境感知信息进行自主导航，具有机器人的设备是指机器人。在优选实施例中，所述障碍物数据包括障碍物与机器人的距离、障碍物本身速度和机器人看障碍物位于的角度。在优选实施例中，所述视觉和毫米波雷达融合模块中，数据处理和融合包括数据去噪，校准和坐标系转换，然后根据处理好的数据进行数据对齐和数据关联，根据对齐好和关联好的数据进行融合，最后生成一个环境感知信息。参考图4，具体地，视觉和毫米波雷达融合模块获得的数据是指预设物体位置信息和障碍物距离、速度和角度等信息，其中，将这些数据进行融合的具体步骤如下：h1，数据对齐：将视觉感知模块和毫米波雷达感知模块获得的数据进行对齐，保证两者获取的信息是在相同的坐标系下。h2，数据关联：将视觉感知模块和毫米波雷达感知模块获得的数据进行关联，匹配双目立体相机检测到的物体和毫米波雷达检测到的障碍物。h3，数据融合：将视觉感知模块和毫米波雷达感知模块获得的数据获取的障碍物距离、速度和角度等信息进行融合，生成一个更准确和完整的环境感知信息。具体融合方法可以采用卡尔曼滤波、扩展卡尔曼滤波等方法。h4，环境感知输出：将融合后的环境感知信息输出，供下水道机器人进行决策和控制，其中输出信息包括预设物体位置信息和障碍物距离、速度和角度等信息。参考图6，在本发明中，计算预设物体和机器人之间的距离数据具体步骤：S1：开始；S2：获取预设物体的特征像素；S3：根据获取预设物体的特征像素实现预设物体的自动成图像；S4：利用canny边缘检测算法对预设物体的图像进行边缘检测；S5：判断图像中的边点数Nedge是否大于T；S6：若图像中的边点数Nedge没有大于T，视觉感知模块停止处理这一幅图像，并开始处理下一幅图像；S7：若图像中的边点数Nedge大于T，与预设物体的特征像素相匹配；S8：最后使用LC匹配度量计算预设物体和机器人之间的距离数据。其中，立体匹配是通过模拟人类双眼观察物体时的视觉差异，从而使我们能够感知到物体的深度和形状。在立体匹配中，通常涉及到两个或多个不同视点或时间拍摄的图像，称为立体图像。这些图像之间存在微小的视差，即相同物体在不同图像中的像素位置之间的差异。通过分析这些视差，可以推断出物体表面上不同点的深度信息。参考图6，在优选实施例中，在所述视觉感知模块中，获取预设的图像具体为：根据深度学习网络方法处理预设物体的特征像素，然后实现预设物体的自动成像，最后获取预设物体的图像。深度学习网络方法是指通过学习预设物体的图像特征，其中预设物体的自动成像图分为人孔自动成像图和接头自动成像图。参考图6，在优选实施例中，获取预设的图像后，利用canny边缘检测算法对预设图像进行边缘检测，并且对图像中的边点数进行判定，若图像中的边点数Nedge＞T，则判定机器人非常靠近预设物体，最后使用LC匹配度量计算预设物体和机器人之间的距离数据；若图像中的边点数Nedge＜T，则停止，并处理下一幅图像。参考图6，在优选实施例中，所述LC匹配度量计算具体包括如下步骤：f1，按照如下公式计算机器人左眼图像中两个相邻像素之间的差值：DL＝IL-IL，其中，DL为左眼图像相邻像素差值，IL为左眼图像，x为像素在图像x轴上位置，y为像素在图像y轴上位置；f2，按照如下公式计算机器人右眼图像中两个相邻像素之间的差值为：DR＝IR-IR其中，DR为右眼图像相邻像素差值，IR为右眼图像；f3，按照如下公式计算机器人左眼和右眼中两个相邻像素之间的差值之和来表示区别性，公示如下：Cd＝|DL|+|DR|其中，d为水平位移差值，Cd为计算机器人左眼和右眼中两个相邻像素之间的差值之和；f4，按照如下公式计算机器人左眼和右眼中两个相邻像素之间差值的差值绝对值，来表示位移d处的相似处,公式如下：Gd＝|DL-DR|其中，Gd为计算机器人左眼和右眼中两个相邻像素之间差值的差值绝对值；f5，按照如下公式计算给定位移d，匹配度量Ed为：Ed＝|DL|+|DR|-DL-DR 其中，Ed为计算在水平位移差值为d的两处像素的相关性；其中，要最大化相对于定位移d的考虑，具体为：如果匹配像素不是这个预设物体的特征像素，则水平相邻像素之间的亮度差很小，DL和DR都具有较小的值，因此，Ed的价值也很小。相反，如果匹配像素是预设物体的特征像素，则其在水平方向上具有较大的亮度差异，这将导致较大的Ed，找到一个孤立像素与预设物体的特征像素相匹配。参考图7，在优选实施例中，在所述毫米波雷达感知模块中，接收到来自障碍物反射回来的信号进行快速傅立叶变换得到RF图像，根据峰值检测算法从RF图像中提取雷达点。参考图7，在优选实施例中，接收到来自障碍物反射回来的信号进行快速傅立叶变换得到RF图像的具体步骤包括：对反射回来的信号进行处理，根据样本实施快速傅立叶变换来估计反射回来的信号的反射范围，然后使用低通滤波器对所有反射回来的信号再次进行处理，最后根据不同接收器天线的样本进行第二次FFT来估计反射的方位角并获得最终的RF图像。其中，对反射回来的信号进行处理包括去噪声和滤波。使用低通滤波器对所有反射回来的信号再次进行处理具体为：低通滤波器以30FPS的速率去除所有反射回来的信号中的高频噪声。参考图7，A、B、C表示毫米波雷达感受视野范围内的不同物体，t-f表示时间-频率图，Ts表示一个chirp持续时间，在时间-频率图中的B表示信号带宽，τ表示在发射信号发出后，到被物体反射回来，经过一段延迟时间τ到达接收天线。接收器天线的样本是指在毫米波传感器中排列着阵列天线，通过计算不同天线接收到的同一物体的回波信号从而可以计算出物体的方位角。在优选实施例中，根据获得最终的RF图像得到角度、距离、chirp这三个维度的数据，然后再根据这三个维度的数据进行一个三维卷积操作后，通过最大池化将chirp压缩到一维得到角度-距离特征图，然后将每一帧RF图像都进行同样的操作，最后将输入的RF片段中的所有帧中提取的特征，根据提取的特征按时间顺序连接。其中，在本发明中的三维卷积操作是采用一种可变形卷积网络，用于基于图像的对象检测来处理图像中的变形对象。在优选实例中根据提取的特征雷达点按时间顺序连接获得特征雷达点的峰值，并将峰值标记出来，用于数据融合。其中数据融合是用视觉和毫米波雷达融合模块方法可以将视觉感知模块检测到预设物体的类别和3D位置，首先通过转换将检测从视觉感知模块坐标投影到毫米波雷达感知模块范围方位角坐标变换可以表示为:达距离方位坐标中的投影位置；表示视觉感知模块坐标中的对象位置；以及表示毫米波雷达感知模块在视觉感知模块标中的位置，从传感器系统校准对准。来自CFAR算法的峰值检测也涉及相同的毫米波雷达感知模块距离方位坐标。最后，应用融合算法来估计输入RF图像以上仅为本发明的优选实施例，并非因此限制本发明的专利范围，凡是利用本发明说明书及附图内容所作的等效结构或等效流程变换，或直接或间接运用在其他相关的技术领域，均同理包括在本发明的专利保护范围内。
