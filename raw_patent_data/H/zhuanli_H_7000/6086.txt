标题title
针对集群联邦学习攻击的防御方法、终端及存储介质
摘要abst
本发明涉及机器学习技术领域，公开了针对集群联邦学习攻击的防御方法、终端及存储介质。该防御方法用于集群联邦学习受到模型中毒攻击而导致分簇失败的防御，首先计算任意两个客户端之间的余弦相似度，基于聚类HDBSCAN算法对客户端之间的余弦相似度进行聚类操作，将恶意客户端与良性客户端分离。然后计算出全局模型与客户端的本地模型之间的欧氏距离集合。再在欧氏距离集合中选取中值作为裁剪上界进行范数裁剪，得到裁剪之后的权重并进行聚合，得到初步矫正之后的全局模型，最后对聚合出的全局模型上添加高斯噪声。本发明能够高效地找出集群联邦学习遭受模型中毒攻击中的攻击者，有效地起到了防御作用，提高集群联邦学习的鲁棒性。
权利要求书clms
1.针对集群联邦学习攻击的防御方法，其特征在于，用于集群联邦学习受到模型中毒攻击而导致分簇失败的防御，包括以下步骤：S1.计算任意两个客户端之间的余弦相似度来测量所有客户端所上传模型参数的角度差；S2.基于聚类HDBSCAN算法对两两客户端之间的余弦相似度进行聚类操作，进而将恶意客户端与良性客户端分离；S3.计算出全局模型与客户端的本地模型之间的欧氏距离集合；M为客户端的总数，所述全局模型由多个良性客户端经过联邦平均后得到；欧氏距离集合的表达如下：←Ed）式中，w1，…，wM表示所有参与训练的客户端在当前轮训练过程中的神经网络模型权重；G*t-1表示第t-1轮训练结束的全局梯度；Ed表示求欧氏距离；S4.在欧氏距离集合中选取中值作为裁剪上界N进行范数裁剪，得到裁剪之后的权重；S5.对裁剪之后的权重进行聚合，得到初步矫正之后的全局模型G：式中，/＞为第t轮次下簇c内的各恶意客户端的模型权重；||·||2表示求二范数；wi∈；S6.对聚合出的全局模型上添加高斯噪声。2.根据权利要求1所述的针对集群联邦学习攻击的防御方法，其特征在于，在步骤S1之前，服务器将接收到的每个客户端的梯度参数分别进行降维操作，使得梯度参数从高维矩阵张量转变成多个一维向量。3.根据权利要求1所述的针对集群联邦学习攻击的防御方法，其特征在于，所述余弦相似度的计算公式为：式中，CS表示求余弦相似度；/＞和/＞分别表示M个客户端中两个不同的客户端的经验风险函数；＜·＞表示求两向量的点积。4.根据权利要求1所述的针对集群联邦学习攻击的防御方法，其特征在于，步骤S2具体包括以下步骤：S21.计算点之间的相互可达距离：根据两两客户端之间的余弦相似度建立距离矩阵，通过计算点与点之间的距离以及点与核心点之间的距离得到各个范围内点的稀疏程度；S22.构建最小生成树：将点之间的相互可达距离通过最小生成树prim算法构造加权图；S23.构建层次聚类：通过二叉树算法将子簇两两合并，并通过递归得到不同距离下的聚类结果；S24.压缩聚类树：去除噪声点，对最小生成树做限制，控制每个聚类内的点数大小，进而降低类的数量；S25.聚类抽取：设定一个阈值，根据每个点到核心点的距离提取最终稳定的聚类结果，从而分离出恶意客户端和良性客户端。5.根据权利要求4所述的针对集群联邦学习攻击的防御方法，其特征在于，步骤S2中，将客户端个数大于+1的聚类视为良性集群，即聚类HDBSCAN算法的簇最小尺寸设置为+1，最小样本数设置为1。6.根据权利要求1所述的针对集群联邦学习攻击的防御方法，其特征在于，所述模型中毒攻击通过以下的模拟攻击手段实现：在攻击者得到一个客户端的梯度后，采用添加扰动的形式修改该客户端的模型参数，以此完成对该客户端梯度的投毒攻击；添加扰动的公式为：式中，/＞表示攻击者篡改之后的梯度，/＞表示客户端正常训练时的良性梯度，µ为所添加扰动的扰动系数。7.根据权利要求6所述的针对集群联邦学习攻击的防御方法，其特征在于，扰动的扰动范围满足下式：式中，Di表示第i个客户端的训练数据集；D表示全体客户端的数据集；/＞表示第i个客户端在第t轮训练时的梯度值；/＞表示第i个客户端在训练梯度达到驻点时的风险函数；ε1为全体客户端的参数之间的最大离散值。8.根据权利要求7所述的针对集群联邦学习攻击的防御方法，其特征在于，扰动方式采用逆向量扰动、逆标准差扰动/＞或取反扰动/＞，表达公式分别如下：其中，std表示求标准差；sign表示对“·”使用符号函数，根据“·”的正负值输出－1或0或1；/＞表示求平均值。9.一种计算机终端，其包括存储器、处理器以及存储在存储器上并可在处理器上运行的计算机程序，其特征在于，处理器执行程序时实现如权利要求1至8中任一项所述的针对集群联邦学习攻击的防御方法的步骤。10.一种计算机可读存储介质，其上存储有计算机程序，其特征在于，所述程序被处理器执行时，实现如权利要求1至8中任意一项所述的针对集群联邦学习攻击的防御方法的步骤。
说明书desc
技术领域本发明涉及机器学习技术领域，具体是针对集群联邦学习攻击的防御方法，以及应用该防御方法的计算机终端及计算机可读存储介质。背景技术联邦学习是一种分布式机器学习模型，本质上是通过多个用户设备共同训练一个代表所有用户设备的全局模型，而训练的过程不需要用户数据的交换，较常见的分布式机器学习而言更强调隐私性。联邦学习作为分布式的机器学习范式，可以有效解决数据孤岛问题，让参与方在不共享数据的基础上联合建模，能从技术上打破数据孤岛，实现AI协作。联邦学习针对多方用户场景，一般采用C/S架构，服务器联合多方合作共同完成训练。然而多种客户端的不同数据分布会极大影响联邦学习的训练精度。因此随之演化的集群联邦学习更具有广泛的应用价值。集群联邦学习在已有的联邦学习基础上加入了分簇算法，使得不同类型的客户端在训练过程中就能够进行区分。其主要流程如下：客户端进行本地的神经网络训练，并将训练若干轮之后的模型参数上传给服务器进行云端的聚合计算。服务器接收到参数之后通过聚类算法将客户端根据不同的参数相似度进行区分，并尝试将所有参与训练的客户端分成若干个簇，且在训练到一定程度下执行分簇。分簇成功之后，针对不同的簇服务器下发与该簇相匹配的模型，至此完成一整轮的全局训练。联邦学习的鲁棒性算法已经得到了广泛的有应用。而集群联邦学习作为一个新兴的且具有极大应用价值的机器学习算法，其鲁棒性研究仍有可以完善的方向。集群联邦学习虽然很好的解决了数据异质性的问题，但与之而来的就是分簇算法极容易被恶意攻击者攻击，攻击者仅仅通过改变一部分客户的模型参数可以破环整个分簇进程，进而影响整个集群联邦学习算法的执行结果。这一缺点是由于分簇算法本身的逻辑缺陷所导致的，即分簇决定阈值的计算方式。因此，亟待提高现有集群联邦学习的鲁棒性。发明内容为了解决现有技术中集群联邦学习的鲁棒性较差，从而在被攻击时容易导致分簇失败的技术问题，本发明提供了针对集群联邦学习攻击的防御方法、终端及存储介质。为实现上述目的，本发明提供如下技术方案：本发明公开一种针对集群联邦学习攻击的防御方法用于集群联邦学习受到模型中毒攻击而导致分簇失败的防御，包括以下步骤，即步骤S1~S6。S1.计算任意两个客户端之间的余弦相似度来测量所有客户端所上传模型参数的角度差。S2.基于聚类HDBSCAN算法对两两客户端之间的余弦相似度进行聚类操作，进而将恶意客户端与良性客户端分离。S3.计算出全局模型与客户端的本地模型之间的欧氏距离集合。M为恶意客户端的总数，全局模型由多个良性客户端经过联邦平均后得到。欧氏距离集合的表达如下：←Ed）式中，w1，…，wM表示所有参与训练的客户端在当前轮训练过程中的神经网络模型权重；G*t-1表示第t-1轮训练结束的全局梯度；Ed表示求欧氏距离。S4.在欧氏距离集合中选取中值作为裁剪上界N进行范数裁剪，得到裁剪之后的权重。S5.对裁剪之后的权重进行聚合，得到初步矫正之后的全局模型G：式中，为第t轮次下簇c内的各恶意客户端的模型权重；||·||2表示求二范数；wi∈。S6.对聚合出的全局模型上添加高斯噪声。作为上述方案的进一步改进，在步骤S1之前，服务器将接收到的每个客户端的梯度参数分别进行降维操作，使得梯度参数从高维矩阵张量转变成多个一维向量。作为上述方案的进一步改进，余弦相似度的计算公式为：式中，CS表示求余弦相似度。和/＞分别表示M个客户端中两个不同的客户端的经验风险函数；＜·＞表示求两向量的点积。作为上述方案的进一步改进，步骤S2具体包括以下步骤：S21.计算点之间的相互可达距离：根据两两客户端之间的余弦相似度建立距离矩阵，通过计算点与点之间的距离以及点与核心点之间的距离得到各个范围内点的稀疏程度。S22.构建最小生成树：将点之间的相互可达距离通过最小生成树prim算法构造加权图。S23.构建层次聚类：通过二叉树算法将子簇两两合并，并通过递归得到不同距离下的聚类结果。S24.压缩聚类树：去除噪声点，对最小生成树做限制，控制每个聚类内的点数大小，进而降低类的数量。S25.聚类抽取：设定一个阈值，根据每个点到核心点的距离提取最终稳定的聚类结果，从而分离出恶意客户端和良性客户端。作为上述方案的进一步改进，步骤S2中，将客户端个数大于+1的聚类视为良性集群，即聚类HDBSCAN算法的簇最小尺寸设置为+1，最小样本数设置为1。作为上述方案的进一步改进，模型中毒攻击通过以下的模拟攻击手段实现：在攻击者得到一个客户端的梯度后，采用添加扰动的形式修改该客户端的模型参数，以此完成对该客户端梯度的投毒攻击。添加扰动的公式为：式中，表示攻击者篡改之后的梯度，/＞表示客户端正常训练时的良性梯度，µ为所添加扰动的扰动系数。作为上述方案的进一步改进，扰动的扰动范围满足下式：式中，Di表示第i个客户端的训练数据集。D表示全体客户端的数据集。表示第i个客户端在第t轮训练时的梯度值。/＞表示第i个客户端在训练梯度达到驻点时的风险函数。ε1为全体客户端的参数之间的最大离散值。作为上述方案的进一步改进，扰动方式采用逆向量扰动、逆标准差扰动/＞或取反扰动/＞，表达公式分别如下：其中，std表示求标准差；sign表示对“·”使用符号函数，根据“·”的正负值输出－1或0或1；表示求平均值。本发明还公开一种计算机终端，其包括存储器、处理器以及存储在存储器上并可在处理器上运行的计算机程序，处理器执行程序时实现上述针对集群联邦学习攻击的防御方法的步骤。本发明还公开一种计算机可读存储介质，其上存储有计算机程序，程序被处理器执行时，实现上述针对集群联邦学习攻击的防御方法的步骤。与现有技术相比，本发明的有益效果是：1、本发明公开的针对集群联邦学习攻击的防御方法，采用了基于HDBSCAN的恶意客户端的检测算法，能够高效地找出集群联邦学习遭受模型中毒攻击中的攻击者，并通过调整手段矫正被攻击的客户端的参数，有效地起到了防御作用，从而使得集群联邦学习算法能够鲁棒地实现。本发明首次揭示了针对集群联邦学习分簇过程的攻防手段，为之后集群联邦学习相关系统架构的搭建提供了参考和警示作用。2、本发明通过模型中毒手段可对集群联邦学习进行模拟攻击，攻击者可选用三种添加扰动的方式对客户端所上传的参数进行修改，成功地破坏了集群联邦学习系统的分簇过程，从而验证防御方法的有效性。3、本发明公开的应用上述方法的计算机终端和计算机可读存储介质，其能够产生与上述方法相同的有益效果，在此不再赘述。附图说明图1为本发明实施例1中集群联邦学习系统的模型示意图。图2为本发明实施例1中集群联邦学习系统在没有受到攻击时训练精度随通信轮次数的曲线图。图3为本发明实施例1中集群联邦学习系统在没有受到攻击时的工作效果图。图4为本发明实施例1中集群联邦学习系统在攻击者使用SIGN攻击并且扰动系数为0.5时训练精度随通信轮次数的曲线图。图5为本发明实施例1中集群联邦学习系统在攻击者使用SIGN攻击并且扰动系数为0.5时的工作效果图。图6为本发明实施例1中集群联邦学习系统在攻击者使用UV攻击并且扰动系数为2时训练精度随通信轮次数的曲线图。图7为本发明实施例1中集群联邦学习系统在攻击者使用UV攻击并且扰动系数为2时的工作效果图。图8为本发明实施例1中集群联邦学习系统在攻击者使用STD攻击并且扰动系数为6时训练精度随通信轮次数的曲线图。图9为本发明实施例1中集群联邦学习系统在攻击者使用STD攻击并且扰动系数为6时的工作效果图。图10为本发明实施例1中针对集群联邦学习攻击的防御方法的流程图。具体实施方式下面将结合本发明实施例中的附图，对本发明实施例中的技术方案进行清楚、完整地描述，显然，所描述的实施例仅仅是本发明一部分实施例，而不是全部的实施例。基于本发明中的实施例，本领域普通技术人员在没有做出创造性劳动前提下所获得的所有其他实施例，都属于本发明保护的范围。实施例1本实施例考虑一个集群联邦学习场景，假设有若干个客户端参与训练，同时存在一个中心服务器负责参数的聚合以及客户端的分簇。训练过程为同步联邦学习。我们在每个客户端上使用通用性更强的卷积神经网络。客户端的数据分布遵循非独立同分布，即各个客户端之间的数据集无相互关系且不服从相似的分布特征。该场景中存在一个或多个被对手控制的客户端，这些客户端在每轮本地训练的部分训练梯度可以被攻击者获取。攻击者可以修改其上传的部分模型参数，从而影响整个集群联邦学习的训练与分簇过程。这里攻击者不需要知道某一客户端的所有模型参数，更不需要知道其训练数据。本实施例中的集群联邦学习系统模型图如图1所示。首先需要搭建一个通用的集群联邦学习算法框架，其主要分为以下几个部分：数据集以及神经网络模型：本实施例使用的是mnist手写体作为集群联邦学习的训练集以及测试集。神经网络模型由2个卷积层、1个池化层、1个全连接层所组成，由pytorch框架搭建。主要参数的设置：客户端数设置为10，通信轮数设置为100，ε1设置为0.4，ε2设置为1.6，本地训练迭代次数为1。其中ε1为全体客户端的参数之间的最大离散值，ε2为全体客户端的参数之间的平均离散值，他们是参数服务器用以判断是否分簇的依据。工作流程：1.各客户端进行本地训练，迭代到指定次数后上传梯度等参数。2.服务器对上传的参数进行余弦相似度的计算，每轮结束会将不同的客户端进行二分筛选，根据不同客户端的参数的差异性去分簇，分簇结束后，针对不同的客户端会下发不同的模型，从而完成一整个集群联邦学习过程，其训练结果如图2和图3所示，其中的L1表示模型参数簇内距离，L2表示模型参数簇间距离，后续的图同理。接下来说明攻击手段的步骤，本发明采用模型中毒攻击，并通过以下的模拟攻击手段实现：首先攻击者可利用例如木马、窃听、社会工程学等方法得到客户端的模型参数的一部分数据并对其做出修改。在得到某一客户端的梯度之后，本发明攻击的形式为添加扰动，扰动的范围需满足：式中，Di表示第i个客户端的训练数据集。D表示全体客户端的数据集。表示第i个客户端在第t轮训练时的梯度值。/＞表示第i个客户端在训练梯度达到驻点时的风险函数。本实施例中，选取了第一层卷积神经网络作为添加扰动的位置，扰动的范围选取基于攻击者所投毒的梯度。添加扰动的公式为：式中，表示攻击者篡改之后的梯度，/＞表示客户端正常训练时的良性梯度，µ为所添加扰动的扰动系数。本发明可通过以下三种扰动方式之一进行投毒攻击，即逆向量扰动、逆标准差扰动/＞和取反扰动/＞，表达公式分别如下：其中，std表示求标准差；sign表示对“·”使用符号函数，根据“·”的正负值输出－1或0或1；表示求平均值。请参阅图4-图9，可以看出利用SIGN方法可以使得全局模型的训练精度收敛于0.6左右，且一直保持不会发生分簇步骤。同理，UV方法也会产生相同的结果，STD方法使得系统在分簇的情况下仍然无法达到满意的精度。至此可以认定集群联邦学习的分簇过程失效，攻击成功。针对联邦学习的中毒攻击手段一般分为模型中毒与数据中毒。模型中毒指在各客户端本地训练完成后模型参数上传时进行的投毒攻击，通过修改关键参数，例如模型权重、梯度等，从而影响全局训练结果；数据中毒指在数据端进行投毒，例如修改数据集图片的部分像素，或者增添后门标记，利用标签翻转的方式使得整体算法的精度下降。而由于集群联邦学习针对不同客户端的数据异质性分布具有鲁棒性，因此本发明选用模型中毒手段。这里假设攻击者可以获取受害客户端的一部分上传参数并做出修改，经过实验发现对客户端卷积神经网络的早期参数进行扰动攻击更具有隐蔽性，同时使用三种不同的扰动方法进行攻击：分别为逆向量扰动，逆标准差扰动，取反扰动。通过应用以上三种扰动添加方法到客户端本地训练的第一层神经网络之中，可以在仅改变一个客户端的参数的情况下导致服务器分簇失败。通过以上操作可以破坏集群联邦学习的分簇进程。请参阅图10，本实施例提供一种针对集群联邦学习攻击的防御方法用于集群联邦学习受到模型中毒攻击而导致分簇失败的防御，该防御方法至少包括如下所示的步骤S1~S6。本实施例采用的模拟攻击，设定了恶意客户端并对其进行标记。对于服务器而言，其没有关于恶意客户端的相关信息。接着在每次参数上传时，服务器将接收到的每个客户端的梯度参数分别进行降维操作，使其从高维矩阵张量转变成多个一维向量，然后开始执行步骤S1。S1.计算任意两个客户端之间的余弦相似度来测量所有客户端所上传模型参数的角度差。其中，余弦相似度的计算公式为：式中，CS表示求余弦相似度。和/＞分别表示M个客户端中两个不同的客户端的经验风险函数；＜·＞表示求两向量的点积。S2.基于聚类HDBSCAN算法对两两客户端之间的余弦相似度进行聚类操作，进而将恶意客户端与良性客户端分离。其中，相似程度较高的客户端会被归为同一个类当中，将客户端个数大于。M为恶意客户端的总数，全局模型由多个良性客户端经过联邦平均后得到。欧氏距离集合的表达如下：←Ed）式中，w1，…，wM表示所有参与训练的客户端在当前轮训练过程中的神经网络模型权重；G*t-1表示第t-1轮训练结束的全局梯度。Ed表示对“·”求欧氏距离。S4.在欧氏距离集合中选取中值作为裁剪上界N进行范数裁剪，并表示为N←MEDIAN。裁剪的标准为其距离的大小，距离越远被裁剪的范围越大，从而得到裁剪之后的权重。S5.对裁剪之后的权重进行聚合，得到初步矫正之后的全局模型G：式中，为第t轮次下簇c内的各恶意客户端的模型权重；||·||2表示求二范数；wi∈。S6.对聚合出的全局模型上添加高斯噪声。在找到恶意客户端之后，服务器对其所上传的恶意梯度进行调整，使其满足正常的集群联邦学习功能，首先是将这些梯度进行自适应的裁剪，为了减轻恶意客户端的影响，这里针对恶意客户端的梯度参数选定合适的裁剪范围并进行范数裁剪，因而恶意客户端被添加的梯度扰动所造成的影响被消除。最后在集群联邦学习聚合时添加高斯噪声，进一步增强集群联邦学习系统的鲁棒性。实施例2本实施例提供一种计算机终端，其包括存储器、处理器以及存储在存储器上并可在处理器上运行的计算机程序。该计算机终端可以是能够执行程序的智能手机、平板电脑、笔记本电脑、台式计算机、机架式服务器、刀片式服务器、塔式服务器或机柜式服务器等。处理器在一些实施例中可以是中央处理器、控制器、微控制器、微处理器、或其他数据处理芯片。该处理器通常用于控制计算机设备的总体操作。本实施例中，处理器用于运行存储器中存储的程序代码或者处理数据。处理器执行程序时能够实现实施例1中针对集群联邦学习攻击的防御方法的步骤。实施例3本实施例提供一种计算机可读存储介质，其上存储有计算机程序，程序被处理器执行时，实现实施例1中针对集群联邦学习攻击的防御方法的步骤。该计算机可读存储介质可以包括闪存、硬盘、多媒体卡、卡型存储器、随机访问存储器、静态随机访问存储器、只读存储器、电可擦除可编程只读存储器、可编程只读存储器、磁性存储器、磁盘、光盘等。在一些实施例中，存储介质可以是计算机设备的内部存储单元，例如该计算机设备的硬盘或内存。在另一些实施例中，存储介质也可以是计算机设备的外部存储设备，例如计算机设备上配备的插接式硬盘，智能存储卡，安全数字卡，闪存卡等。当然，存储介质还可以既包括计算机设备的内部存储单元也包括其外部存储设备。本实施例中，存储器通常用于存储安装于计算机设备的操作系统和各类应用软件等。此外，存储器还可以用于暂时地存储已经输出或者将要输出的各类数据。以上所述，仅为本发明较佳的具体实施方式，但本发明的保护范围并不局限于此，任何熟悉本技术领域的技术人员在本发明揭露的技术范围内，根据本发明的技术方案及其发明构思加以等同替换或改变，都应涵盖在本发明的保护范围之内。
