标题title
基于多优先级的cache查询系统
摘要abst
本发明涉及一种基于多优先级的cache查询系统，包括第一缓冲模块和N个cache接收端{C1，C2，…CN}，M个发送端对应P个优先级{W1，W2，…WP}；每一Ci对应一个地址请求范围Zi，Zi对应的cache包括Q个独立的cache区域{CXi1,CXi2,…CXiQ}，当第一缓冲存模块为待发送的缓存请求信息确定对应的Ci时，基于缓存请求信息对应的发送端优先级所属的WRq确定对应的CXiq，将待发送的缓存请求信息发送至对应的CXiq中进行处理。本发明提高了多个发送端向多个cache发送请求信息的cache命中率和处理效率。
权利要求书clms
1.一种基于多优先级的cache查询系统，其特征在于，包括第一缓冲模块和N个cache接收端，其中，所述第一缓冲模块一端与M个发送端相连接，另一端与N个cache接收端{C1，C2，…CN}相连接，Ci表示第i个cache接收端，i的取值范围为1到N，所述第一缓冲存模块用于缓存所述M个发送端发送的请求信息，并向所述N个cache接收端分发请求信息，所述M个发送端对应P个优先级{W1，W2，…WP}，W1，W2，…WP的优先级级别依次降低，P≤N，每一优先级对应至少一个发送端，{W1，W2，…WP}分为Q个优先级组{WR1，WR2，…WRQ},Q ≤P ，WRq-1中的最低优先级高于WRq中的最高优先级，q的取值范围为1到Q；每一Ci对应一个地址请求范围Zi，不同Ci对应的Zi不重叠，Zi对应的cache包括Q个独立的cache区域{CXi1,CXi2,…CXiQ}，CXi1,CXi2,…CXiQ在物理上相互隔离，且对应的cache区域大小依次降低，CXiq对应的地址请求范围均为Zi，当所述第一缓冲存模块为待发送的缓存请求信息确定对应的Ci时，基于缓存请求信息对应的发送端优先级所属的WRq确定对应的CXiq，将待发送的缓存请求信息发送至对应的CXiq中进行处理。2.根据权利要求1所述的系统，其特征在于，若p≤px，且Wp对应的发送端与其他优先级对应的发送端共享一个cache接收端时，cache命中率较独享一个cache接收端的cache命中率的差值大于预设的命中率差值阈值时，则将Wp单独划分为一个优先级组中，其中，px预设的优先级标识阈值，px＜ P。3.根据权利要求1所述的系统，其特征在于，若P小于预设的阈值，则Q=P，每个优先级组中对应一个优先级。4.根据权利要求1所述的系统，其特征在于，WR1中仅包括W1，W1对应的发送端在每一cache终端中独享一个cache区域。5.根据权利要求4所述的系统，其特征在于，Q=2，WR2中包括{ W2，W3，…WP}，W2，W3，…WP对应的发送端在每一cache终端中共享一个cache区域。6.根据权利要求1所述的系统，其特征在于，所述系统还包括第二缓冲模块，所述第二缓冲模块一端与N个cache接收端连接，另一端与memory连接，所述第二缓冲模块用于缓存N个cache接收端发送的请求信息，并向所述memory分发。7.根据权利要求6所述的系统，其特征在于，所述第二缓冲模块包括Q个缓冲FIFO{F1，F2，…FQ},Fq用于接收所有CXiq输出的请求信息。8.根据权利要求7所述的系统，其特征在于，F1，F2，…FQ向所述memory发送请求信息优先级从高到低，所述第二缓冲模块将{F1，F2，…FQ}中存储有请求信息且优先级最高的Fq中的请求信息发送给所述memory。
说明书desc
技术领域本发明涉及计算机技术领域，尤其涉及一种基于多优先级的cache查询系统。背景技术在处理请求信息的场景中，通常会遇到多个发送端向多个接收端发送请求信息的情况，通常情况下，接收端需要通常需要一定时间来处理接收到的请求，且在处理过程中不能接收新的请求，现有技术中，通常在多个发送端和多个接收端之间设置一个FIFO对请求信息进行缓存，从而平衡多个发送端和多个接收端的带宽和处理速率。但是，不同发送端的响应速率不同，有些响应慢，有些响应快，如果将所通道的请求信息均缓存到一个FIFO中，则极易造成不同发送端的请求信息相互堵塞，缓存分发效率低。如果为每一发送端设置一个FIFO进行缓存，会占用大量的面积，浪费资源，降低性能。由此可知，如何提供一种合理的缓存分发技术，提高缓存分发效率成为亟待解决的技术问题。此外，如果接收端为cache，应用场景为多个发送端向多个cache请求信息时，在缓存分发后，如果将响应速率不同的发送端对接同一个cache终端，则会降低cache命中率，从而影响了请求信息的处理效率，由此可知，如何提高多个发送端向多个cache发送请求信息的处理效率，也成为亟待解决的技术问题。发明内容本发明目的在于，提供一种基于多优先级的cache查询系统，提高了多个发送端向多个cache发送请求信息的cache命中率和处理效率。本发明提供了一种基于多优先级的cache查询系统，包括第一缓冲模块和N个cache接收端，其中，所述第一缓冲模块一端与M个发送端相连接，另一端与N个cache接收端{C1，C2，…CN}相连接，Ci表示第i个cache接收端，i的取值范围为1到N，所述第一缓冲存模块用于缓存所述M个发送端发送的请求信息，并向所述N个cache接收端分发请求信息，所述M个发送端对应P个优先级{W1，W2，…WP}，W1，W2，…WP的优先级级别依次降低，P≤N，每一优先级对应至少一个发送端，{W1，W2，…WP}分为Q个优先级组{WR1，WR2，…WRQ},Q ≤P ，WRq-1中的最低优先级高于WRq中的最高优先级，q的取值范围为1到Q；每一Ci对应一个地址请求范围Zi，不同Ci对应的Zi不重叠，Zi对应的cache包括Q个独立的cache区域{CXi1,CXi2,…CXiQ}，CXi1,CXi2,…CXiQ在物理上相互隔离，且对应的cache区域大小依次降低，CXiq对应的地址请求范围均为Zi，当所述第一缓冲存模块为待发送的缓存请求信息确定对应的Ci时，基于缓存请求信息对应的发送端优先级所属的WRq确定对应的CXiq，将待发送的缓存请求信息发送至对应的CXiq中进行处理。本发明与现有技术相比具有明显的优点和有益效果。借由上述技术方案，本发明提供的一种基于多优先级的cache查询系统可达到相当的技术进步性及实用性，并具有产业上的广泛利用价值，其至少具有下列优点：本发明所述系统通过对不同优先级进行优先级分组，将每一cache接收端划分不同的cache区域，使得不同优先级分组对应的发送端请求对应的cache区域物理分隔，彼此不会替换对应cache区域中的数据，增加了cache命中率，提高了多个发送端向多个cache发送请求信息的处理效率。上述说明仅是本发明技术方案的概述，为了能够更清楚了解本发明的技术手段，而可依照说明书的内容予以实施，并且为了让本发明的上述和其他目的、特征和优点能够更明显易懂，以下特举较佳实施例，并配合附图,详细说明如下。附图说明图1为本发明实施例提供的基于多优先级的缓存分发系统示意图；图2为本发明实施例提供的基于多优先级的cache查询系统示意图。具体实施方式为更进一步阐述本发明为达成预定发明目的所采取的技术手段及功效,以下结合附图及较佳实施例，对依据本发明提出的一种基于多优先级的缓存分发系统以及基于多优先级的cache查询系统的具体实施方式及其功效，详细说明如后。实施例一、实施例一提供了一种基于多优先级的缓存分发系统，如图1所示，包括：缓冲存储器和至少一个状态更新器，其中，需要说明的是，缓冲存储器只有一个输入端口和输出端口，在一个周期内只能存入一个请求信息，也只能输出一个请求信息，一个周期可以为一个时钟周期。所述缓冲存储器一端与M个发送端相连接，另一端与N个接收端相连接，所述缓冲存储器用于缓存所述M个发送端发送的请求信息，所述M个发送端对应P个优先级，P≤N，每一优先级对应至少一个发送端。需要说明的是，发送端可以是不同响应等级的发送端，响应速率越高，响应等级越高，实时性要求越高，对应的优先级也越高。可以理解的是，发送端和接收端视具体应用场景而定，发送端具体可以为GPU核、DMA，每一Ci对应一个地址请求范围Zi，C1，C2，…CN对应的地址请求的最大总范围即为memory的范围，不同Ci对应的Zi不重叠。作为一种实施例，若p≤px，且Wp对应的发送端与其他优先级对应的发送端共享一个cache接收端时，cache命中率较独享一个cache接收端的cache命中率的差值大于预设的命中率差值阈值时，则将Wp单独划分为一个优先级组中，其中，px预设的优先级标识阈值，px＜ P。需要说明的是，通常情况下，高优先级的发送端的响应级别高，响应速率快，实时性要求高，优先级低的更容易影响到优先级高的cache命中率，因此主要需要为高优先级的发送端设置独立的cache区域。而低优先级的响应速率较慢，实时性要求低，因此cache命中率不易受到其他优先级发送端的影响。作为一种实施例，Q=2，WR1中仅包括W1，W1对应的发送端在每一cache终端中独享一个cache区域。WR2中包括{ W2，W3，…WP}，W2，W3，…WP对应的发送端在每一cache终端中共享一个cache区域。这样可以仅为最高优先级单独划分cache区域，提高最高优先级的发送端的cache命中率。作为一种实施例，若P小于预设的阈值，则Q=P，每个优先级组中对应一个优先级，当优先级组别较少时，例如只有3个，则可以为每一个有优先级组设置独立的cache区域。作为一种实施例，当请求信息进入cache中未查到目标数据时，则会向memory发送请求，通过memory获取数据，同一时间段内是可能出现多个发向memory的请求的，基于此，所述系统还包括第二缓冲模块，所述第二缓冲模块一端与N个cache接收端连接，另一端与memory连接，所述第二缓冲模块用于缓存N个cache接收端发送的请求信息，并向所述memory分发。所述第二缓冲模块包括Q个缓冲FIFO{F1，F2，…FQ},Fq用于接收所有CXiq输出的请求信息。这样即可将同一优先级组对应的发宋端所对应的memory请求信息存入一个队列中。F1，F2，…FQ向所述memory发送请求信息优先级从高到低，所述第二缓冲模块将{F1，F2，…FQ}中存储有请求信息且优先级最高的Fq中的请求信息发送给所述memory。实施例二所述系统通过对不同优先级进行优先级分组，将每一cache接收端划分不同的cache区域，使得不同优先级分组对应的发送端请求对应的cache区域物理分隔，彼此不会替换对应cache区域中的数据，增加了cache命中率，满足了cache的空间局限性和时间局限性需求，提高了多个发送端向多个cache发送请求信息的处理效率。需要说明的是，实施例一和实施例二的相关技术细节是可以组合使用的，在此不再逐一列举。在更加详细地讨论示例性实施例之前应当提到的是，一些示例性实施例被描述成作为流程图描绘的处理或方法。虽然流程图将各步骤描述成顺序的处理，但是其中的许多步骤可以被并行地、并发地或者同时实施。此外，各步骤的顺序可以被重新安排。当其操作完成时处理可以被终止，但是还可以具有未包括在附图中的附加步骤。处理可以对应于方法、函数、规程、子例程、子程序等等。以上所述，仅是本发明的较佳实施例而已，并非对本发明作任何形式上的限制，虽然本发明已以较佳实施例揭露如上，然而并非用以限定本发明,任何熟悉本专业的技术人员，在不脱离本发明技术方案范围内,当可利用上述揭示的技术内容作出些许更动或修饰为等同变化的等效实施例,但凡是未脱离本发明技术方案的内容，依据本发明的技术实质对以上实施例所作的任何简单修改、等同变化与修饰，均仍属于本发明技术方案的范围内。
