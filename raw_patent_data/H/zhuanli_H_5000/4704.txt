标题title
分布式训练方法及系统、终端设备、计算机可读存储介质
摘要abst
本发明提供了一种分布式训练方法及系统、终端设备及计算机可读存储介质，分布式训练方法包括：所述工作节点利用本地训练数据并根据初始模型参数对本地模型进行训练，获得本地模型的模型参数；所述工作节点根据所述本地模型的模型参数以及分组情况获得更新后的模型参数；将本轮训练获得的更新后的模型参数作为下一轮训练中的初始模型参数，循环执行多轮训练，直至满足训练停止条件时结束训练。本发明的分布式训练方法应用于由至少3个移动终端组成的分布式训练系统，从而避免现有的大型服务器上实现分布式机器学习导致的价格昂贵、能耗高、体积大、可移动性差的问题。
权利要求书clms
1.一种分布式训练方法，其特征在于，应用于分布式训练系统，所述分布式训练系统包括至少3个移动终端，将任一移动终端作为分组节点，将剩余的移动终端作为工作节点，所述分布式训练方法包括：所述工作节点利用本地训练数据并根据初始模型参数对本地模型进行训练，获得本地模型的模型参数；所述工作节点根据所述本地模型的模型参数以及分组情况获得更新后的模型参数；将本轮训练获得的更新后的模型参数作为下一轮训练中的初始模型参数，循环执行多轮训练，直至满足训练停止条件时结束训练。2.根据权利要求1所述的分布式训练方法，其特征在于，所述工作节点根据所述本地模型的模型参数以及分组情况获得更新后的模型参数，包括：所述工作节点发送分组请求至所述分组节点；所述分组节点在接收到所述分组请求后生成分组信息并将所述分组信息发送至所述工作节点；所述工作节点判断所述分组信息是否为空；若所述分组信息不为空，则所述工作节点判断所述工作节点所在的分组中是否存在发生异常的工作节点，若不存在，则将所述工作节点所在的分组中全部工作节点的本地模型的模型参数的平均值作为更新后的模型参数；若存在，则将所述工作节点所在的分组中未发生异常的工作节点的本地模型的模型参数的平均值作为更新后的模型参数；若所述分组信息为空，则将本地模型的模型参数作为更新后的模型参数。3.根据权利要求2所述的分布式训练方法，其特征在于，所述分组节点在接收到所述分组请求后生成分组信息，包括：判断所述工作节点的分组信息是否为空；若所述工作节点的分组信息为空，则对所述工作节点进行重新分组并生成分组信息；若所述工作节点的分组信息不为空，则将工作节点状态表中所述工作节点对应的已有分组信息作为所述工作节点的分组信息。4.根据权利要求3所述的分布式训练方法，其特征在于，对所述工作节点进行重新分组并生成分组信息，包括：将所述工作节点状态表中分组信息为空的工作节点作为待分组节点集；分别获取所述待分组节点集中每一个工作节点的已发送的分组请求的次数；计算所述待分组节点集中每一个工作节点的已发送的分组请求的次数与所述工作节点已发送的分组请求的次数的差值并将差值小于预定阈值的工作节点加入所述工作节点的分组中，生成分组信息；更新所述工作节点状态表。5.根据权利要求3所述的分布式训练方法，其特征在于，对所述工作节点进行重新分组并生成分组信息，包括：将所述工作节点状态表中分组信息为空的工作节点作为待分组节点集；判断在预定时长内是否接收到待分组节点集中的工作节点发送的分组请求；若在预定时长内接收到待分组节点集中的工作节点发送的分组请求，则将待分组节点集中发送分组请求的工作节点加入所述工作节点的分组中，生成分组信息。6.根据权利要求1～5任一项所述的分布式训练方法，其特征在于，在所述工作节点根据所述本地模型的模型参数以及分组情况获得更新后的模型参数后，所述分布式训练方法还包括：所述工作节点发送释放请求至所述分组节点；所述分组节点删除所述工作节点的分组信息并更新工作节点状态表。7.根据权利要求6所述的分布式训练方法，其特征在于，所述训练停止条件为训练次数达到预设的训练次数。8.一种分布式训练系统，其特征在于，所述分布式系统包括至少3个移动终端，将任一移动终端作为分组节点，将剩余的移动终端作为工作节点，所述分布式系统通过如权利要求1～7任一项所述的分布式训练方法对本地模型进行训练。9.一种终端设备，包括存储器、处理器及存储在存储器上的计算机程序，其特征在于，所述处理器执行所述计算机程序以实现如权利要求1～7任一项所述的分布式训练方法。10.一种计算机可读存储介质，所述计算机可读存储介质上存储有计算机指令，其特征在于，所述计算机指令被处理器执行时实现如权利要求1～7任一项所述的分布式训练方法。
说明书desc
技术领域本发明涉及机器学习技术领域，尤其涉及一种分布式训练方法及系统、终端设备及计算机可读存储介质。背景技术当下机器学习已被证明是自动提取数据信息的有效方法，并在各个领域都取得了巨大成功，如图像识别、语音处理、机器翻译、游戏、医疗保健等。为了获得有用的机器学习模型，需要对大量数据集进行长时间的训练，随着数据大小的不断增加，单一机器已无法顺利完成学习任务，因此需要在多台机器之间分配机器学习的工作量，以实现分布式训练，提升学习速度，从而促进机器学习的更广泛应用。现有的分布式机器学习都是在大型服务器上实现，大型设备具有内存大、性能好、更稳定的优势，但是，大型服务器普遍具有价格昂贵、能耗高、体积大、可移动性差的缺点，因此，在大型服务器上实现机器学习的成本很高。发明内容为了解决现有技术的不足，本发明提供一种分布式训练方法及系统、终端设备及计算机可读存储介质，应用于包括至少3个移动终端的分布式训练系统，从而降低了机器学习的成本。本发明提出的具体技术方案为：一种分布式训练方法，应用于分布式训练系统，所述分布式训练系统包括至少3个移动终端，将任一移动终端作为分组节点，将剩余的移动终端作为工作节点，所述分布式训练方法包括：所述工作节点利用本地训练数据并根据初始模型参数对本地模型进行训练，获得本地模型的模型参数；所述工作节点根据所述本地模型的模型参数以及分组情况获得更新后的模型参数；将本轮训练获得的更新后的模型参数作为下一轮训练中的初始模型参数，循环执行多轮训练，直至满足训练停止条件时结束训练。进一步地，所述工作节点根据所述本地模型的模型参数以及分组情况获得更新后的模型参数，包括：所述工作节点发送分组请求至所述分组节点；所述分组节点在接收到所述分组请求后生成分组信息并将所述分组信息发送至所述工作节点；所述工作节点判断所述分组信息是否为空；若所述分组信息不为空，则所述工作节点判断所述工作节点所在的分组中是否存在发生异常的工作节点，若不存在，则将所述工作节点所在的分组中全部工作节点的本地模型的模型参数的平均值作为更新后的模型参数；若存在，则将所述工作节点所在的分组中未发生异常的工作节点的本地模型的模型参数的平均值作为更新后的模型参数；若所述分组信息为空，则将本地模型的模型参数作为更新后的模型参数。进一步地，所述分组节点在接收到所述分组请求后生成分组信息，包括：判断所述工作节点的分组信息是否为空；若所述工作节点的分组信息为空，则对所述工作节点进行重新分组并生成分组信息；若所述工作节点的分组信息不为空，则将工作节点状态表中所述工作节点对应的已有分组信息作为所述工作节点的分组信息。进一步地，对所述工作节点进行重新分组并生成分组信息，包括：将所述工作节点状态表中分组信息为空的工作节点作为待分组节点集；分别获取所述待分组节点集中每一个工作节点的已发送的分组请求的次数；计算所述待分组节点集中每一个工作节点的已发送的分组请求的次数与所述工作节点已发送的分组请求的次数的差值并将差值小于预定阈值的工作节点加入所述工作节点的分组中，生成分组信息；更新所述工作节点状态表。进一步地，对所述工作节点进行重新分组并生成分组信息，包括：将所述工作节点状态表中分组信息为空的工作节点作为待分组节点集；判断在预定时长内是否接收到待分组节点集中的工作节点发送的分组请求；若在预定时长内接收到待分组节点集中的工作节点发送的分组请求，则将待分组节点集中发送分组请求的工作节点加入所述工作节点的分组中，生成分组信息。进一步地，在所述工作节点根据所述本地模型的模型参数以及分组情况获得更新后的模型参数后，所述分布式训练方法还包括：所述工作节点发送释放请求至所述分组节点；所述分组节点删除所述工作节点的分组信息并更新工作节点状态表。进一步地，所述训练停止条件为训练次数达到预设的训练次数。为了解决现有技术的不足，本发明还提供了一种分布式训练系统，所述分布式系统包括至少3个移动终端，将任一移动终端作为分组节点，将剩余的移动终端作为工作节点，所述分布式系统通过如上所述的分布式训练方法对本地模型进行训练。本发明还提供了一种终端设备，包括存储器、处理器及存储在存储器上的计算机程序，所述处理器执行所述计算机程序以实现如上所述的分布式训练方法。本发明还提供了一种计算机可读存储介质，所述计算机可读存储介质上存储有计算机指令，其特征在于，所述计算机指令被处理器执行时实现如上所述的分布式训练方法。本发明的分布式训练方法应用于由至少3个移动终端组成的分布式训练系统，将任一移动终端作为分组节点，将剩余的移动终端作为工作节点，每一个工作节点利用本地训练数据并根据初始模型参数对本地模型进行训练，获得本地模型的模型参数；再根据本地模型的模型参数以及分组情况获得更新后的模型参数，将本轮训练获得的更新后的模型参数作为下一轮训练中的初始模型参数，循环执行多轮训练，直至满足训练停止条件时结束训练，从而避免现有的大型服务器上实现分布式机器学习导致的价格昂贵、能耗高、体积大、可移动性差的问题。附图说明下面结合附图，通过对本发明的具体实施方式详细描述，将使本发明的技术方案及其它有益效果显而易见。图1为本发明的分布式训练系统的结构示意图；图2为本发明实施例一中的分布式训练方法的流程示意图；图3为本发明实施例一中步骤S2的具体流程示意图；图4为本发明实施例三中终端设备的结构示意图。具体实施方式以下，将参照附图来详细描述本发明的实施例。然而，可以以许多不同的形式来实施本发明，并且本发明不应该被解释为限制于这里阐述的具体实施例。相反，提供这些实施例是为了解释本发明的原理及其实际应用，从而使本领域的其他技术人员能够理解本发明的各种实施例和适合于特定预期应用的各种修改。在附图中，相同的标号将始终被用于表示相同的元件。实施例一参照图1、图2，本实施例提供的分布式训练系统包括至少3个移动终端，其中，将至少3个移动终端中的任一移动终端作为分组节点、剩余的移动终端作为工作节点形成移动终端集群，每一个worker节点利用本地数据独立对本地模型进行训练，master节点用于对worker节点进行分组并将分组信息发送给worker节点，master节点和worker节点通过如下的分布式训练方法对本地模型进行训练：步骤S1、worker节点利用本地训练数据并根据初始模型参数对本地模型进行训练，获得本地模型的模型参数；步骤S2、worker节点根据本地模型的模型参数以及分组情况获得更新后的模型参数；步骤S3、将本轮训练获得的更新后的模型参数作为下一轮训练中的初始模型参数，循环执行多轮训练，直至满足训练停止条件时结束训练。在步骤S1中，每一个worker节点在对本地模型进行训练之前会先获取自身的本地训练数据作为后续多轮训练的训练数据，其中，该移动终端集群的训练数据被均分为多个数据块，多个数据块的数量与worker节点的数量一致，每一个worker按照序号的先后顺序获取与之对应的数据块，例如，训练数据为{a1、a2、a3、a4、a5、a6、a7、a8、a9、a10、a11、a12}，分布式训练系统包括序号为Rank0、Rank1、Rank2、Rank3、Rank4、Rank5这6个worker节点，则将训练数据分为{a1、a2}、、{a5、a6}、{a7、a8}、{a9、a10}、{a11、a12}这6个数据块，序号为Rank0获取的数据块为{a1、a2}，序号为Rank1获取的数据块为{a3、a4}，以此类推，最终每一个worker节点均获得自身的本地训练数据作为后续多轮训练的训练数据。Worker节点在获取本地训练数据后利用本地训练数据并根据初始模型参数对本地模型进行训练，这里需要说明的是，在第一轮训练中，初始模型参数指的是本地模型未进行训练之前自身的模型参数。参照图3，步骤S2具体包括：步骤S21、worker节点发送分组请求至master节点；步骤S22、master节点在接收到分组请求后生成分组信息并将分组信息发送至worker节点；步骤S23、worker节点判断分组信息是否为空，若分组信息不为空，则进入步骤S24，若分组信息为空，则进入步骤S25；步骤S24、worker节点判断其所在的分组中是否存在发生异常的worker节点，若不存在，则将其所在的分组中全部worker节点的本地模型的模型参数的平均值作为更新后的模型参数；若存在，则将其所在的分组中未发生异常的worker节点的本地模型的模型参数的平均值作为更新后的模型参数；步骤S25、将本地模型的模型参数作为更新后的模型参数。本实施例中的分组请求表示一种通信指令，该通信指令可以为worker节点的序号，即worker节点发送其所对应的序号至master节点，当然，这里仅仅作为示例示出，在其他实施方式中，分组请求也可以是预先设定的标志位，该标志位的取值为1时表示分组请求，并不用于对本实施例进行限定。在步骤S22中，Master节点在接收到分组请求之前一直处于监听状态，其通过监听端口监听worker节点发送的消息，当接收到worker节点发送的消息时，master节点先判断接收到的消息是否是分组请求，若是，则master节点生成分组信息将分组信息发送至worker节点，若不是，则master节点将该worker节点的状态更新为空闲状态并更新worker节点状态表。本实施例中的worker节点状态表由master节点进行维护，worker节点状态表可以包括每个worker节点的序号、状态及分组信息，下表给出了worker节点状态表的一个示例：表1.worker节点状态表其中，worker节点的数量为6个，6个worker节点的序号分别是Rank0、Rank1、Rank2、Rank3、Rank4、Rank5，状态标志位为1表示worker节点处于忙碌状态，状态标志位为0表示worker节点处于空闲状态，序号为Rank0、Rank1、Rank2、Rank4、Rank5的worker节点的状态为忙碌状态，序号为Rank3的worker节点的状态为空闲状态，序号为Rank0的worker节点的分组信息为{Rank0，Rank2，Rank5}，该分组信息表示序号为Rank0、Rank2、Rank5的worker节点属于同一个分组，序号为Rank3的worker节点的分组信息为{}，即序号为Rank3的worker节点的分组信息为空。在步骤S23中，当master节点将分组信息发送至worker节点后，worker节点先判断接收到的分组信息是否为空，若不为空，则该worker与属于同一个分组中的其他worker之间互相建立连接，例如，上表中序号为Rank0的worker节点的分组信息为{Rank0，Rank2，Rank5}，则序号为Rank0、Rank2、Rank5的worker节点之间互相建立连接。本实施例中的移动终端为基于ARM架构的手机，master节点通过SockerServer与worker节点之间进行通信，worker节点中分别安装了pytorch深度学习框架，将分布式训练应用到基于ARM架构的手机中时有可能会产生异常，例如，若某一个worker节点出现NAN，由于NAN的出现具有传染性，在进行分布式训练的时候，发生NAN的worker节点将会感染正常的worker节点，从而使得正常的worker节点也出现NAN，最终会导致整个分布式训练中所有的worker节点均被感染，使得训练失败。因此，本实施例提出了一种防疫机制，该防疫机制的基本原理如步骤S24所述，下面对该防疫机制进行详细的描述。第一步，自我检测，各个worker节点先进行自我检测，即先判断自身是否发生异常，本实施例中在每个worker中加入是否健康的标志位，该标志位为布尔值变量，即该标志位的取值为0或1，其中，该标志位为0时表示worker节点出现异常，该标志位为1时表示worker节点未出现异常，当worker节点出现异常的时候，该标志位就会被置为0，因此，在自我检测步骤中，只需要检测worker节点的该标志位是否为0就可以判断出该worker节点是否发生异常，由于属于同一个分组中的各个worker之间已建立连接，当各个worker节点检测完后会将各自的检测结果发送给该分组内的其他worker节点，其中，本实施例利用pytorch深度学习框架中的detect_anomaly函数来追踪是否存在发生异常的worker节点。第二步，自我隔离，当同一个分组中存在发生异常的worker节点时，则模型参数更新的时候只会考虑未发生异常的worker节点的本地模型的模型参数，即发生异常的worker节点进行自我隔离，该worker节点不会将其本地模型的模型参数发送给其他worker节点。第三步，自我修复，若同一个分组中存在发生异常的worker节点，则该分组中未发生异常的worker节点分别将其本地模型的模型参数发送给其他未发生异常的worker节点，每一个未发生异常的worker节点在接收到其他未发生异常的worker节点的本地模型的模型参数后对自身以及接收到的本地模型的模型参数求平均并将平均值作为更新后的模型参数，未发生异常的worker节点将更新后的模型参数发送给自我隔离的worker节点，该分组中所有的worker节点利用更新后的模型参数对本地模型进行更新，由于发生异常的worker节点采用的是未发生异常的worker节点计算得到的更新后的模型参数，从而完成自我修复。若同一个分组中不存在发生异常的worker节点，则该分组中的每一个worker节点分别将其本地模型的模型参数发送给其他worker节点，每一个worker节点在接收到其他worker节点的本地模型的模型参数后对自身以及接收到的本地模型的模型参数求平均并将平均值作为更新后的模型参数，该分组中所有的worker节点利用更新后的模型参数对本地模型进行更新。本实施例通过采用上述防疫机制可以避免移动终端集群中NAN传染，保证了整个分布式训练系统的稳定性，且通过该防疫机制能够对发生异常的worker节点进行快速修复，从而节省了训练时间。在步骤S25中，当worker节点的分组信息为空时表示该worker节点未被分组，此时，若下一轮训练中该worker节点被分组，则将步骤S1中获得的本地模型的模型参数作为更新后的模型参数。具体地，在步骤S22中，master节点在接收到分组请求后生成分组信息包括：步骤S221、判断worker节点的分组信息是否为空，若该worker节点的分组信息为空，则进入步骤S222，若该worker节点的分组信息不为空，则进入步骤S223；步骤S222、对worker节点进行重新分组并生成分组信息；步骤S223、将worker节点状态表中worker节点对应的已有分组信息作为worker节点的分组信息。由于每一个worker节点的训练速度有可能存在差异，每个worker节点有可能在不同的时刻发送分组请求至master节点，例如，序号为Rank0的worker节点先发送分组请求至master节点，master节点对其进行分组，生成的分组信息为{Rank0，Rank2，Rank5}，此时，master节点会更新worker节点状态表，将序号为Rank2、Rank5的worker节点的分组信息均更新为{Rank0，Rank2，Rank5}，这样，当master节点在接收到序号为Rank2或Rank5的worker节点发送的分组请求时，master节点需要先查询worker节点状态表中序号为Rank2或Rank5的worker节点的分组信息，从而避免再次对序号为Rank2或Rank5的worker节点进行分组而影响训练时间，因此，master节点在接收到worker节点发送的分组请求后需要先判断worker节点的分组信息是否为空，若该worker节点的分组信息为空，则表示该worker节点未被分组，则master节点对worker节点进行重新分组并生成分组信息；若该worker节点的分组信息不为空，则表示该worker节点已被分组，此时，worker节点已有对应的分组信息，因此，master节点只需要通过查询worker节点状态表来获得该worker节点已有的分组信息并将该分组信息作为该worker节点的分组信息即可。本实施例在步骤S222中，对worker节点进行重新分组并生成分组信息具体包括：步骤S2221、将worker节点状态表中分组信息为空的worker节点作为待分组节点集；步骤S2222、分别获取待分组节点集中每一个worker节点的已发送的分组请求的次数；步骤S2223、计算待分组节点集中每一个worker节点的已发送的分组请求的次数与该worker节点已发送的分组请求的次数的差值并将差值小于预定阈值的worker节点加入该worker节点的分组中，生成分组信息；步骤S2224、更新worker节点状态表。master节点首先查询worker节点状态表，将worker节点状态表中分组信息为空的worker节点加入待分组节点集中，本实施例中在每个worker节点中设置有计数标志位，通过计数标志位来表示该worker节点已发送的分组请求的次数，master节点获取待分组节点集中每一个worker节点的已发送的分组请求的次数后计算待分组节点集中每一个worker节点的已发送的分组请求的次数与该worker节点已发送的分组请求的次数的差值并将差值小于预定阈值的worker节点加入该worker节点的分组中，生成分组信息，更新worker节点状态表，完成对该worker节点的分组。其中，预定阈值可以根据实际需要设定，这里不再进行具体限定。在步骤S2之后，本实施例中的分布式训练方法还包括：步骤S4、worker节点发送释放请求至master节点；步骤S5、master节点删除该worker节点的分组信息并更新worker节点状态表。本实施例在每一个worker节点完成一轮训练后都需要重新进行分组，因此，在每一轮训练结束后，worker节点需要发送释放请求至master节点，master节点在接收到worker节点发送的释放请求的时候将worker节点状态表中该worker节点的分组信息删除，完成对worker节点状态表的更新。本实施例在步骤上S25中，当worker节点的分组信息为空时，该worker节点也会发送释放请求至master节点，master节点删除该worker节点的分组信息并更新worker节点状态表。在步骤S3中，训练停止条件为训练次数达到预设的训练次数，在其他实施方式中，也可以将训练停止条件设定为本地模型收敛，当然，也可以采用本领域其他熟知的训练停止条件，这里不做具体限定。本实施例中的分布式训练方法应用于移动终端组集群中，避免了现有的大型服务器上实现分布式机器学习导致的价格昂贵、能耗高、体积大、可移动性差的问题，且本实施例在应用到移动终端集群中时还加入防疫机制，可以避免移动终端集群中NAN传染，保证了整个分布式训练系统的稳定性，且通过该防疫机制能够对发生异常的worker节点进行快速修复，从而节省了训练时间。实施例二本实施例提供的分布式训练方法与实施例一中的区别在于：对worker节点进行重新分组并生成分组信息的具体实现方式不同，本实施例中的其他步骤与实施例一均相同，这里不再赘述，仅对本实施例中对worker节点进行重新分组并生成分组信息的具体实现方式进行详细描述。本实施例中对worker节点进行重新分组并生成分组信息包括：步骤S2221、将worker节点状态表中分组信息为空的worker节点作为待分组节点集；步骤S2222、判断在预定时长内是否接收到待分组节点集中的工作节点发送的分组请求，若在预定时长内接收到其他worker节点发送的分组请求，则进入步骤S2223；步骤S2223、将待分组节点集中发送分组请求的worker节点加入该worker节点的分组中，生成分组信息。具体地，master节点首先查询worker节点状态表，将worker节点状态表中分组信息为空的worker节点加入待分组节点集中，本实施例在master节点中设置有计时器，当master节点接收到该worker节点的分组请求时，计时器开始计时直到计时器的计时时间达到预定时长，master节点判断在该预定时长内是否接收到待分组节点集中的工作节点发送的分组请求，若master节点在该预定时长内接收到待分组节点集中的工作节点发送的分组请求，则将待分组节点集中发送分组请求的worker节点加入到该worker节点的分组中，生成分组信息。其中，预定时长可以根据实际需要设定，这里不具体限定。在本实施例的另一实施方式中，预订时长也可以是master节点的监听周期，master节点检测该worker节点发送的分组请求的时刻所在的监听周期，在该监听周期中，将待分组节点集中所有发送分组请求的worker节点加入到该worker节点的分组中，生成分组信息。实施例三参照图4，本实施例提供了一种终端设备，包括存储器100、处理器200及存储在存储器100上的计算机程序，处理器200执行计算机程序以实现如实施例一和实施例二所述的分布式训练方法。存储器100可以包括高速随机存取存储器，也可能还包括非不稳定的存储器，例如至少一个磁盘存储器。处理器200可以是一种集成电路芯片，具有信号的处理能力。在实现过程中，实施例一和实施例二所述的分布式训练方法的各步骤可以通过处理器200中的硬件的集成逻辑电路或者软件形式的指令完成。处理器200也可以是通用处理器，包括中央处理器、网络处理器等，还可以是数字信号处理器、专用集成电路、现成可编程门阵列或者其它可编程逻辑器件、分立门或者晶体管逻辑器件、分立硬件组件。存储器100用于存储计算机程序，处理器200在接收到执行指令后，执行该计算机程序以实现如实施例一和实施例二所述的分布式训练方法。本实施例还提供了一种计算机存储介质，计算机存储介质中存储有计算机程序，处理器200用于读取并执行计算机存储介质201中存储的计算机程序，以实现如实施例一和实施例二所述的分布式训练方法。在上述实施例中，可以全部或部分地通过软件、硬件、固件或者其任意组合来实现。当使用软件实现时，可以全部或部分地以计算机程序产品的形式实现。所述计算机程序产品包括一个或多个计算机指令。在计算机上加载和执行所述计算机程序指令时，全部或部分地产生按照本发明实施例所述的流程或功能。所述计算机可以是通用计算机、专用计算机、计算机网络、或者其他可编程装置。所述计算机指令可以存储在计算机存储介质中，或者从一个计算机存储介质向另一个计算机存储介质传输，例如，所述计算机指令可以从一个网站站点、计算机、服务器或数据中心通过有线)或无线方式向另一个网站站点、计算机、服务器或数据中心进行传输。所述计算机存储介质可以是计算机能够存取的任何可用介质或者是包含一个或多个可用介质集成的服务器、数据中心等数据存储设备。所述可用介质可以是磁性介质、光介质、或者半导体介质)等。本发明实施例是参照根据本发明实施例的方法、装置、和计算机程序产品的流程图和/或方框图来描述的。应理解可由计算机程序指令实现流程图和/或方框图中的每一流程和/或方框、以及流程图和/或方框图中的流程和/或方框的结合。可提供这些计算机程序指令到通用计算机、专用计算机、嵌入式处理机或其他可编程数据处理设备的处理器以产生一个机器，使得通过计算机或其他可编程数据处理设备的处理器执行的指令产生用于实现在流程图一个流程或多个流程和/或方框图一个方框或多个方框中指定的功能的装置。这些计算机程序指令也可存储在能引导计算机或其他可编程数据处理设备以特定方式工作的计算机可读存储器中，使得存储在该计算机可读存储器中的指令产生包括指令装置的制造品，该指令装置实现在流程图一个流程或多个流程和/或方框图一个方框或多个方框中指定的功能。这些计算机程序指令也可装载到计算机或其他可编程数据处理设备上，使得在计算机或其他可编程设备上执行一系列操作步骤以产生计算机实现的处理，从而在计算机或其他可编程设备上执行的指令提供用于实现在流程图一个流程或多个流程和/或方框图一个方框或多个方框中指定的功能的步骤。以上所述仅是本申请的具体实施方式，应当指出，对于本技术领域的普通技术人员来说，在不脱离本申请原理的前提下，还可以做出若干改进和润饰，这些改进和润饰也应视为本申请的保护范围。
