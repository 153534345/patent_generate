标题title
基于多点扩散函数生成对抗网络的大景深成像方法及系统
摘要abst
本发明公开了基于多点扩散函数生成对抗网络的大景深成像方法及系统，包括以下步骤：步骤1：构建基于自动聚焦的多聚焦成像模型；步骤2：获取小景深多聚焦图像和大景深真值图像，构建数据集；步骤3：构建基于生成对抗网络的图像重建网络模型；步骤4：根据步骤2得到的数据集，对步骤3得到的网络模型进行训练；训练过程中基于反向传播梯度下降算法最小化损失函数；步骤5：将多聚焦图像输入步骤4得到的网络模型，即可得到重建的大景深图像；本发明具有简单、灵活、低成本的优点，缓解了景深与信噪比的之间制衡，提高了成像质量，能够满足各类场景的大景深成像需求。
权利要求书clms
1.一种基于多点扩散函数生成对抗网络的大景深成像方法，其特征在于，包括以下步骤：步骤1：构建基于自动聚焦的多聚焦成像模型；步骤2：获取小景深多聚焦图像和大景深真值图像，构建数据集；步骤3：构建基于生成对抗网络的图像重建网络模型；步骤4：根据步骤1得到的数据集，对步骤2得到的网络模型进行训练；训练过程中基于反向传播梯度下降算法最小化损失函数；步骤5：将多聚焦图像输入步骤3得到的网络模型，即可得到重建的大景深图像；所述步骤1中的多聚焦成像模型包括约束焦点设置模块，自动聚焦模块；约束焦点设置模块通过设置约束成像焦点与最终自动聚焦成像焦点之间的距离选择约束成像焦点的位置；自动聚焦模块利用自动聚焦过程在约束成像焦点处拍摄多聚焦图像。所述步骤2中的网络模型包括生成器，生成器包括点扩散函数学习及反卷积模块、特征融合模块和特征重建模块；点扩散函数及反卷积模块用于从多聚焦图像中提取空间和光谱特征，学习不同约束成像焦点处沿不同物方深度下的点扩散函数，并以此反卷积小景深多聚焦图像；特征融合模块用于提取反卷积图像中的清晰特征并融合得到融合图像；特征重建模块用于处理融合图像中出现的缺陷。2.根据权利要求1所述的一种基于多点扩散函数生成对抗网络的大景深成像方法，其特征在于，所述网络模型还包括鉴别器，用于在训练阶段鉴别输入图像的真假，输入图像为生成器生成的重建图像及真值图像。3.根据权利要求1所述的一种基于多点扩散函数生成对抗网络的大景深成像方法，其特征在于，所述点扩散函数学习及反卷积模块包括依次设置的n个卷积层、v个激活层、m个下采样层和m个上采样层、注意力层和b个归一化层。4.根据权利要求1所述的一种基于多点扩散函数生成对抗网络的大景深成像方法，其特征在于，所述特征融合模块包括依次设置的卷积层、卷积SoftMax层。5.根据权利要求1所述的一种基于多点扩散函数生成对抗网络的大景深成像方法，其特征在于，所述特征重建模块包括依次设置的4个卷积层、归一化层、激活层。6.根据权利要求1所述的一种基于多点扩散函数生成对抗网络的大景深成像方法，其特征在于，所述鉴别器包括依次设置的4个卷积下采样层、归一化层和激活层。7.根据权利要求2所述的一种基于多点扩散函数生成对抗网络的大景深成像方法，其特征在于，所述生成器的损失函数ГG如下：ΓG＝PL+LG+CFL其中，LG为生成器的对抗性损失函数，PL为感知损失函数，CFL为颜色保真度损失函数；鉴别器的损失函数ГD如下：ΓD＝LD其中，LD为鉴别器的对抗性损失函数；其中CFL为：其中：k为原始图像个数，Ii为第i幅原始图像，R为重建图像，Sm为SoftMax算子；C为维度，H为高度，W为宽度。8.根据权利要求7所述的一种基于多点扩散函数生成对抗网络的大景深成像方法，其特征在于，所述感知损失函数PL为：其中，为预训练网络模型，x为重建图像，real为真值图像，为神经网络第j个卷积层生成的大小为Cj×Hj×Wj的特征图；F为F-范数，Cj、Hj、Wj分别为第j个卷积层输出的特征图的维度、高度和宽度；h、w、c为特征像素点在特征图中的坐标；其中，为变量在真值数据分布的期望值，为变量在生成数据分布的期望值，S为Sigmoid非线性激活函数，xr为真值图像，xf为重建图像，鉴别器输入为x时输出D，E为生成数据分布，P为真值数据分布。9.一种如权利要求1～8所述基于多点扩散函数生成对抗网络的大景深成像图像系统，其特征在于，包括：光学成像模块：通过构建基于自动聚焦的多聚焦成像模型获取小景深多聚焦图像；图像重建模块：通过构建基于生成对抗网络的图像重建网络模型生成大景深重建图像，包括生成器和鉴别器；生成器包括点扩散函数学习及反卷积模块、特征融合模块和特征重建模块；点扩散函数及反卷积模块用于从多聚焦图像中提取空间和光谱特征，采用深度学习算法学习出不同物方深度下的点扩散函数，并以此反卷积小景深图像，重建源图像中的模糊区域；特征融合模块用于提取反卷积图像中的清晰特征并融合得到融合图像；特征重建模块用于处理融合图像中出现的缺陷；鉴别器用于在网络模型训练阶段鉴别输入图像的真假。
说明书desc
技术领域本发明涉及大景深成像方法技术领域，具体涉及基于多点扩散函数生成对抗网络的大景深成像方法及系统。背景技术大景深成像对于机器视觉和医学成像等应用是至关重要的。在光学成像中，球差、色差、慧差、畸变等像差影响了成像质量，其中球差是限制景深的主要因素。众所周知，理想的物像关系只有在傍轴近似条件下才是成立的，而实际的光学元件是不符合傍轴条件的。一个点物经过透镜聚焦后不再是一个点像，而是一个弥散斑，这就是球差的由来。在传统光学设计中，为了消除球差及扩展景深，减小光圈尺寸是最常见的方法，这种方法虽然可以扩展景深，但是减少了进入传感器的光通量，导致更多的图像噪声及更差的图像质量。组合透镜设计及复杂非球面透镜设计也是常见的景深扩展方法，但由于极其复杂的透镜设计及配准，其需要非常专业的光学设计及经验。在光学成像中，点扩散函数对成像质量至关重要，它也决定了光学系统的景深大小。由退化图像重建大景深的理想像可表征为成像逆问题求解，关键在于点扩散函数的精确估计及鲁棒的反卷积计算。因此许多图像反卷积算法被提出重建图像，扩展景深，但因为点扩散函数高度依赖于光谱及物方深度，使得依靠单图像估计出的点扩散函数不精确，导致反卷积后的图像被引入伪影、噪点。在数字图像处理中，多聚焦图像融合也是被广泛用于景深扩展的一种有效、低成本的技术，通过融合若干张部分聚焦图像获得大景深图像。如现有的融合算法使用深度学习算法学习清晰及模糊的特征提取，随后输出置信图用于后续图像融合。首先输入两张部分聚焦图像到设计的神经网络模型中，输出一对置信图，将其与相应的输入源图像点乘并将结果加权求和输出最终的大景深图像。但是，基于置信图的多聚焦图像融合本质上更像是一种分类任务，容易导致细节丢失，特别是在聚焦与非聚焦区域边界的附近。目前还有使用深度学习算法联合学习特征提取和融合规则，端到端地输出大景深的融合图像。虽然该方法能够很好的提取出输入源图像的聚焦区域，并将其融合为一张大景深图像。但是该方法没有考虑任何光学成像端的因素，高度依赖于图像信息，当所有输入源图像中的某一相同区域都是模糊的，算法对此区域失效，融合图像中的这一区域仍是模糊的，导致景深扩展受限。在实际成像中，由于算法与成像端之间的断层，使算法的表现不够鲁棒，成像质量的提升不够理想。并且多聚焦图像融合算法大多需要互补图像作为输入，互补图像包含场景中所有感兴趣的信息，这就需要精确对焦及多次拍摄，从而降低实际使用的效率。发明内容本发明提供一种可以解决多聚焦图像融合技术中存在的实际成像使用中效率低及景深扩展受限的问题以及缓解大景深与高信噪比之间的制衡的基于多点扩散函数生成对抗网络的大景深成像方法及系统。本发明采用的技术方案是：一种基于多点扩散函数生成对抗网络的大景深成像方法，包括以下步骤：步骤1：构建基于自动聚焦的多聚焦成像模型；步骤2：获取小景深多聚焦图像和大景深真值图像，构建数据集；步骤3：构建基于生成对抗网络的图像重建网络模型；步骤4：根据步骤1得到的数据集，对步骤2得到的网络模型进行训练；训练过程中基于反向传播梯度下降算法最小化损失函数；步骤5：将多聚焦图像输入步骤3得到的网络模型，即可得到重建的大景深图像；所述步骤1中的多聚焦成像模型包括约束焦点设置模块，自动聚焦模块；约束焦点设置模块通过设置约束成像焦点与最终自动聚焦成像焦点之间的距离选择约束成像焦点的位置；自动聚焦模块利用自动聚焦过程在约束成像焦点处拍摄多聚焦图像。所述步骤2中的网络模型包括生成器，生成器包括点扩散函数学习及反卷积模块、特征融合模块和特征重建模块；点扩散函数及反卷积模块用于从多聚焦图像中提取空间和光谱特征，学习不同约束成像焦点处沿不同物方深度下的点扩散函数，并以此反卷积小景深多聚焦图像；特征融合模块用于提取反卷积图像中的清晰特征并融合得到融合图像；特征重建模块用于处理融合图像中出现的缺陷，如伪影及颜色偏移。进一步的，所述网络模型还包括鉴别器，用于在训练阶段鉴别输入图像的真假，以此促进生成器生成更高质量图像。输入图像为真值图像及生成器的重建图像。进一步的，所述点扩散函数学习及反卷积模块包括依次设置的n个卷积层、v个激活层、m个下采样层和m个上采样层、注意力层和b个归一化层。进一步的，所述特征融合模块包括依次设置的卷积层、卷积SoftMax层。进一步的，所述特征重建模块包括依次设置的4个卷积层、归一化层和激活层。进一步的，所述鉴别器包括依次设置的4个卷积下采样层、归一化层和激活层。进一步的，所述生成器的损失函数ГG如下：ΓG＝PL+LG+CFL其中，LG为生成器的对抗性损失函数，PL为感知损失函数，CFL为颜色保真度损失函数；鉴别器的损失函数ГD如下：ΓD＝LD其中，LD为鉴别器的对抗性损失函数；其中CFL为：其中：k为原始图像个数，Ii为第i幅原始图像，R为重建图像，Sm为SoftMax算子；C为维度，H为高度，W为宽度。进一步的，所述感知损失函数PL为：其中，为预训练网络模型，x为重建图像，real为真值图像，为神经网络第j个卷积层生成的大小为Cj×Hj×Wj的特征图；F为F-范数，Cj、Hj、Wj分别为第j个卷积层输出的特征图的维度、高度和宽度；h、w、c为特征像素点在特征图中的坐标；其中，为变量在真值数据分布的期望值，为变量在生成数据分布的期望值，S为Sigmoid非线性激活函数，xr为真值图像，xf为重建图像，鉴别器输入为x时输出D，E为生成数据分布，P为真值数据分布。一种基于多点扩散函数生成对抗网络的大景深成像图像系统，包括：光学成像模块：通过构建基于自动聚焦的多聚焦成像模型拍摄小景深多聚焦图像；图像重建模块：通过构建基于生成对抗网络的图像重建网络模型生成大景深重建图像，包括生成器和鉴别器；生成器包括点扩散函数学习及反卷积模块、特征融合模块和特征重建模块；点扩散函数及反卷积模块用于从多聚焦图像中提取空间和光谱特征，采用深度学习算法学习出不同物方深度下的点扩散函数，并以此反卷积小景深图像，重建源图像中的模糊区域；特征融合模块用于提取反卷积图像中的清晰特征并融合得到融合图像；特征重建模块用于处理融合图像中出现的缺陷；鉴别器用于在训练阶段鉴别输入图像的真假，促进生成器生成更高质量的图像。本发明的有益效果是：本发明通过深度结合多聚焦成像模型及深度学习算法，提高了光学成像模型与后处理算法之间的耦合度。与现有的多聚焦图像融合算法相比可以保持更高的视觉信息保真度，保留更多的结构信息，生成更大景深的图像。本发明使用深度卷积网络扩展景深的同时，通过装配大光圈保持足够的光通量，缓解了景深和信噪比之间的制衡，可以实现高信噪比及大景深成像。本发明构建的基于多点扩散函数的生成对抗网络模型，用于重建大景深图像。源图像中的模糊区域被很好的重建并和真值的清晰度相当，景深被成功扩展，源图像中的细节也被很好的恢复及保存；本发明构建的基于多点扩散函数的生成对抗网络模型可微调以接受不同数量的输入图像，以适应不同的应用场景。附图说明图1为本发明流程方法及系统示意图。图2为不同深度h的成像焦点处的点扩散函数沿物方深度H的变化规律示意图。图3为本发明实施例中的输入源图像、重建图像和真值图像。图4本发明实施例中的输入源图像及不同方法得到的重建图像。图5本发明实施例中的输入源图像及不同方法得到的重建图像。具体实施方式下面结合附图和具体实施例对本发明做进一步说明。一种基于多点扩散函数生成对抗网络的大景深成像方法，包括以下步骤：步骤1：如图1所示，在成像端，建立并分析了基于共轭成像关系的多聚焦成像模型。通过分析可知在不同成像焦点处得到的点扩散函数沿物方深度的分布是极其相关的，并且非常相似，如图2所示。因此我们可以采用深度学习算法学习点扩散函数间的相关性，得到精确的点扩散函数。因此在所设计的多聚焦成像模型中，若干个约束焦点被预先设置，约束焦点的位置是通过设置其与最终自动聚焦成像焦点之间的距离确定的。通过设置约束焦点，使得每次拍摄得到的多聚焦图像具有相似的空间模糊特征及点扩散函数分布，有利于点扩散函数学习及高质量图像重建。约束焦点的位置及数量可以根据应用场景自由设置。所设计的成像模型利用自动聚焦过程在约束成像焦点处拍摄多聚焦图像。如图1所示，一旦按下快门触发自动聚焦功能，成像在约束焦点下的图像就被记录下来，这些图像也是场景中A1、A2、A3及A4处所对应的共轭像。约束焦点的位置是通过预设其与最终自动聚焦焦点A’之间的距离来设置的。步骤2：获取小景深多聚焦图像和大景深真值图像，构建数据集；步骤3：构建基于生成对抗网络的图像重建网络模型；网络模型包括生成器和鉴别器，生成器包括点扩散函数学习及反卷积模块、特征融合模块和特征重建模块；点扩散函数及反卷积模块用于从多聚焦图像中提取空间和光谱特征，采用深度学习算法学习出不同物方深度下的点扩散函数，并以此反卷积小景深图像，重建源图像中的模糊区域。点扩散函数及反卷积模块包括依次设置的n个卷积层、v个激活层、m个下采样层和m个上采样层、注意力层和b个归一化层。卷积下采样操作用于提取光谱及空间特征信息。卷积上采样操作用于反卷积输入源图像。注意力层用于提取具有全局上下文信息的空间特征，有利于精确的点扩散函数学习。激活层用于增强网络模型非线性，优化梯度下降过程。归一化层用于加速网络收敛。其中n＝13，v＝11，m＝4，b＝8。特征融合模块用于提取反卷积图像中的清晰特征并融合得到融合图像；特征融合模块包括依次设置的卷积层、卷积SoftMax层。卷积层用于提取反卷积图像中的清晰及显著特征。卷积SoftMax层用于对提取的特征进行融合。由于在点扩散函数及反卷积模块为了增大感受野，更深度的提取特征，重复多次使用了上采样及下采样，容易导致重建图像中出现伪影及噪点等，通过特征重建模块解决上述问题。特征重建模块用于处理重建图像中出现的缺陷。特征重建模块包括依次设置的4个卷积层、归一化层、激活层。卷积层用于提取光谱及空间特征，阻止伪影、噪点及颜色偏移。归一化层用于加速收敛。激活层用于增强过拟合能力。鉴别器的输入是真值图像与生成器生成的重建图像，通过连续的卷积层提取输入图像的深度感知特征，鉴别输入图像的真假，以此促进生成器生成更高质量的图像。鉴别器只在网络的训练阶段需要，在测试阶段对于训练好的网络模型不再需要鉴别器。鉴别器包括依次设置的4个卷积下采样层、归一化层和激活层。卷积下采样层用于提取深度光谱及空间特征。归一化层用于加速收敛。激活层用于增加网络模型非线性，增强过拟合能力。步骤4：根据步骤2得到的数据集，对步骤3得到的网络模型进行训练；训练过程中基于反向传播梯度下降算法最小化损失函数；生成器的损失函数ГG如下：ΓG＝PL+LG+CFL其中，LG为生成器的对抗性损失函数，PL为感知损失函数，CFL为颜色保真度损失函数；鉴别器的损失函数ГD如下：ΓD＝LD其中，LD为鉴别器的对抗性损失函数；其中CFL为：其中：k为原始图像个数，Ii为第i幅原始图像，R为重建图像，Sm为SoftMax算子；C为维度，H为高度，W为宽度。感知损失函数PL为：其中，为预训练网络模型VGG19，x为重建图像，real为真值图像，为神经网络第j个卷积层生成的大小为Cj×Hj×Wj的特征图；F为F-范数，Cj、Hj、Wj分别为第j个卷积层输出的特征图的维度、高度和宽度；h、w、c为特征像素点在特征图中的坐标；其中，为变量在真值数据分布的期望值，为变量在生成数据分布的期望值，S为Sigmoid非线性激活函数，xr为真值图像，xf为重建图像，鉴别器输入为x时输出D，E为生成数据分布，P为真值数据分布。步骤5：将多聚焦图像输入步骤3得到的网络模型，即可得到重建的大景深图像；一种基于多点扩散函数生成对抗网络的大景深成像图像系统，包括：光学成像模块：通过设计基于自动聚焦的多聚焦成像模型获取小景深多聚焦图像；图像重建模块：通过构建基于生成对抗网络的图像重建网络模型生成大景深重建图像，包括生成器和鉴别器；生成器包括点扩散函数学习及反卷积模块、特征融合模块和特征重建模块；点扩散函数及反卷积模块用于从多聚焦图像中提取空间和光谱特征，采用深度学习算法学习出不同物方深度下的点扩散函数，并以此反卷积小景深图像，去模糊源图像中的模糊区域；特征融合模块用于提取反卷积图像中的清晰特征并融合得到融合图像；特征重建模块用于处理重建图像中出现的缺陷，如伪影及颜色偏移；鉴别器用于在网络模型训练阶段鉴别输入图像的真假，以此促进生成器生成更高质量图像。采用本发明方法处理的图像如图3所示，在成像端，获取在约束焦点下的多聚焦图像。通过配备大光圈，可以获得高信噪比、小景深的图像，因此不同约束焦点下拍摄得到的图像都有模糊区域。将获取的多聚焦图像输入到图像重建模块中，具体为基于多点扩散函数的生成对抗网络模型，经过模型处理后即可得到大景深重建图像。从图中可以看到源图像中的模糊区域都被很好的重建并和真值的清晰度相当，景深被成功扩展，并且源图像中的细节也被很好的恢复和保存。为了说明本发明方法的有效性，将本发明方法与现有多聚焦图像融合的景深扩展方法进行比较。具体方法包括DTCWT、RP、DSIFT、CVT、DRPL、MFF-GAN、IFCNN、U2Fusion。上述方法的输入都是两幅图像，为了公平比较，所有的对比实验都是在两幅输入图像上进行的。除了主观评价，SAM、rSFe、MG、PSNR和SSIM质量评价指标被用于客观评价。具体结果如表1所示。其中PSNR用于评价重建图像与真值图像对应像素点间的误差；SSIM用于评价重建图像与真值图像在亮度、对比度及结构三方面上的相似性；SAM用于评价重建图像与真值图像的光谱相似性；rSFe用于衡量重建图像的梯度信息与源图像中清晰区域的梯度信息的差异；MG是衡量重建图像清晰度的一个指标。除SAM和rSFe外，PSNR、SSIM和MG三个指标的数值越高，重建效果越好。表1.不同景深扩展方法的客观评价指标本发明方法能够很好的提取出清晰特征并将它们融合在一张高清图中，但当所有输入图像的某一相同区域都是模糊的时，由于这一区域没有明确的信息可以学习，使得现有的方法在这种情况下失效。如图4和图5所示，图中a～h为现有方法处理结果，i为本发明得到的重建图像。如矩形框中的特写可以看出这些区域在重建图像中依然是模糊的，如图a～h所示。这也导致现有的方法在PSNR和SSIM指标上表现较差，如表1所示。本发明方法由于具有点扩散函数学习和反卷积模块，在上述情况下依然能够去模糊此区域，如图4i和图5i所示。DSIFT和DRPL方法中的不稳定的特征提取过程，使得重建图像丢失了一些源图像中的关键信息，如图4c和图5g中的矩形框中的图所示。本发明方法由于具有特征重建模块，重建图像很好的保存了来自源图像中的信息如图4i及图5i所示。从表1中可以看出U2Fusion和MFF-GAN方法在rSFe和MG指标表现较好，说明源图像中的梯度信息被很好的提取并融合进重建图。但由于不够鲁棒的特征提取及融合过程，重建图像出现了很多伪影及噪点，如图5e和图5f。这也导致它们的PSNR、SSIM和SAM指标表现不佳。本发明方法在rSFe和MG指标上排名第二及第三，但由于稳定的点扩散函数学习及反卷积模块和有效的特征重建模块，重建结果没有受到伪影及噪点的影响。与DTCWT、RP、IFCNN相比，本发明方法的重建图像的感知效果更好，如图4和图5中a、c、h及i所示。并且本发明方法在PSNR、SSIM和SAM指标上均取得了最佳值。本发明方法在保证成像质量的前提下，能够比现有方法更有效的实现大景深成像。并且可以保持更高的视觉信息保真度，保留更多的结构信息。
