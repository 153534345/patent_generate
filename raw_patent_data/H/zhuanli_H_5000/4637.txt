标题title
声源分离方法及装置
摘要abst
本发明提供一种声源分离方法及装置，所述方法包括：获取视频帧图像中的视觉引导特征；将第一混叠多声源声谱图和所述视觉引导特征输入训练好的预测编码循环卷积神经网络模型，获取第一掩膜图；根据所述第一混叠多声源声谱图和所述第一掩膜图，获取分离的声音信号。本发明通过将视觉引导特征和混叠多声源声谱图输入训练好的预测编码循环卷积神经网络模型预测各声音分量的掩膜图，然后利用掩膜图和混叠多声源声谱图获取分离的声音信号，实现声谱图和视觉引导特征在同一网络模型中进行处理，网络模型规模小，且视觉特征和声音特征能够渐进式的有效融合，提高了声源分离的精度。
权利要求书clms
1.一种声源分离方法，其特征在于，包括：获取视频帧图像中的视觉引导特征；将第一混叠多声源声谱图和所述视觉引导特征输入训练好的预测编码循环卷积神经网络模型，获取第一掩膜图；根据所述第一混叠多声源声谱图和所述第一掩膜图，获取分离的声音信号。2.根据权利要求1所述的声源分离方法，其特征在于，所述训练好的预测编码循环卷积神经网络模型通过以下步骤获取：将第二混叠多声源声谱图和单声源视频的帧图像对应的视觉引导特征输入预测编码循环卷积神经网络模型，输出第二掩膜图；所述第二掩膜图为预测的掩膜图；将第一单声源声谱图和所述第二混叠多声源声谱图中的对应元素进行比较，获取第三掩膜图；所述第三掩膜图为真实的掩膜图；将所述第二掩膜图与所述第三掩膜图之间的二值交叉熵作为损失函数；对所述损失函数的值进行优化，获取训练好的预测编码循环卷积神经网络模型。3.根据权利要求1所述的声源分离方法，其特征在于，所述预测编码循环卷积神经网络模型包括预测编码循环卷积神经网络、单层转置卷积层和上采样层；其中，所述预测编码循环卷积神经网络中的卷积层之间采用反馈连接，转置卷积层之间采用前馈连接，同层的卷积层和转置卷积层之间采用循环连接。4.根据权利要求3所述的声源分离方法，其特征在于，将第一混叠多声源声谱图和所述视觉引导特征输入训练好的预测编码循环卷积神经网络模型，获取第一掩膜图，包括：将所述第一混叠多声源声谱图和所述视觉引导特征输入所述预测编码循环卷积神经网络，获取视觉声音融合特征；将所述视觉声音融合特征输入所述单层转置卷积层和所述上采样层，获取第一掩膜图。5.根据权利要求4所述的声源分离方法，其特征在于，将所述第一混叠多声源声谱图和所述视觉引导特征输入所述预测编码循环卷积神经网络，获取视觉声音融合特征，包括：将所述第一混叠多声源声谱图输入所述卷积层的顶层，依次获取每一层卷积层的预测信号，并利用所述每一层卷积层的预测信号获取每一层卷积层的神经元响应；将所述视觉引导特征输入所述转置卷积层的底层，根据同层卷积层的神经元响应，依次获取每一层转置卷积层的神经元响应；在最后一次循环迭代中，将转置卷积层的顶层的神经元响应作为视觉声音融合特征。6.根据权利要求1所述的声源分离方法，其特征在于，根据所述第一混叠多声源声谱图和所述第一掩膜图，获取分离的声音信号，包括：将所述第一混叠多声源声谱图与所述第一掩膜图进行对应元素相乘，获取第二单声源声谱图；利用短时傅里叶逆变换将所述第二单声源声谱图变换至时域，获取分离的声音信号。7.根据权利要求2所述的声源分离方法，其特征在于，所述第二混叠多声源声谱图通过以下步骤获取：对不同的单声源视频数据进行声音采样，获取不同的单声源声音信号；将所述不同的单声源声音信号进行线性叠加，获取混叠多声源声音信号；利用短时傅里叶变换将所述混叠多声源声音信号变换为所述第二混叠多声源声谱图。8.一种声源分离装置，其特征在于，包括：第一获取模块，用于获取视频帧图像中的视觉引导特征；第二获取模块，用于将第一混叠多声源声谱图和所述视觉引导特征输入训练好的预测编码循环卷积神经网络模型，获取第一掩膜图；第三获取模块，用于根据所述第一混叠多声源声谱图和所述第一掩膜图，获取分离的声音信号。9.一种电子设备，包括存储器、处理器及存储在所述存储器上并可在所述处理器上运行的计算机程序，其特征在于，所述处理器执行所述计算机程序时实现如权利要求1至7中的任一项所述声源分离方法的步骤。10.一种非暂态计算机可读存储介质，其上存储有计算机程序，其特征在于，所述计算机程序被处理器执行时实现如权利要求1至7中的任一项所述声源分离方法的步骤。
说明书desc
技术领域本发明涉及计算机视觉和音频信号分离技术领域，尤其涉及一种声源分离方法及装置。背景技术视觉引导的声源分离是一个重要且具有挑战性的经典视觉-声音多模态任务，在视频中说话人的识别、语音增强、音频去噪、智能视频编辑等领域具有广泛的应用。由于图像和声音信号之间在数据格式和数据特征上的不一致，因此，现有方法设计不同的网络模型来分别处理图像和声音信号，另外再使用单独的模型实现不同模态特征的融合，这样导致整个模型的规模较大，部署困难，且特征融合仅作用在网络模型的高水平层，分离得到的声源精度也不高。因此，提供一种模型规模小且声源分离精度高的声源分离方法是急需解决的技术问题。发明内容本发明提供一种声源分离方法及装置，用以解决现有技术中网络模型规模大且声源分离精度不高的缺陷。本发明提供一种声源分离方法，包括：获取视频帧图像中的视觉引导特征；将第一混叠多声源声谱图和所述视觉引导特征输入训练好的预测编码循环卷积神经网络模型，获取第一掩膜图；根据所述第一混叠多声源声谱图和所述第一掩膜图，获取分离的声音信号。可选地，所述训练好的预测编码循环卷积神经网络模型通过以下步骤获取：将第二混叠多声源声谱图和单声源视频的帧图像对应的视觉引导特征输入预测编码循环卷积神经网络模型，输出第二掩膜图；所述第二掩膜图为预测的掩膜图；将第一单声源声谱图和所述第二混叠多声源声谱图中的对应元素进行比较，获取第三掩膜图；所述第三掩膜图为真实的掩膜图；将所述第二掩膜图与所述第三掩膜图之间的二值交叉熵作为损失函数；对所述损失函数的值进行优化，获取训练好的预测编码循环卷积神经网络模型。可选地，所述预测编码循环卷积神经网络模型包括预测编码循环卷积神经网络、单层转置卷积层和上采样层；其中，所述预测编码循环卷积神经网络中的卷积层之间采用反馈连接，转置卷积层之间采用前馈连接，同层的卷积层和转置卷积层之间采用循环连接。可选地，将第一混叠多声源声谱图和所述视觉引导特征输入训练好的预测编码循环卷积神经网络模型，获取第一掩膜图，包括：将所述第一混叠多声源声谱图和所述视觉引导特征输入所述预测编码循环卷积神经网络，获取视觉声音融合特征；将所述视觉声音融合特征输入所述单层转置卷积层和所述上采样层，获取第一掩膜图。可选地，将所述第一混叠多声源声谱图和所述视觉引导特征输入所述预测编码循环卷积神经网络，获取视觉声音融合特征，包括：将所述第一混叠多声源声谱图输入所述卷积层的顶层，依次获取每一层卷积层的预测信号，并利用所述每一层卷积层的预测信号获取每一层卷积层的神经元响应；将所述视觉引导特征输入所述转置卷积层的底层，根据同层卷积层的神经元响应，依次获取每一层转置卷积层的神经元响应；在最后一次循环迭代中，将转置卷积层的顶层的神经元响应作为视觉声音融合特征。可选地，根据所述第一混叠多声源声谱图和所述第一掩膜图，获取分离的声音信号，包括：将所述第一混叠多声源声谱图与所述第一掩膜图进行对应元素相乘，获取第二单声源声谱图；利用短时傅里叶逆变换将所述第二单声源声谱图变换至时域，获取分离的声音信号。可选地，所述第二混叠多声源声谱图通过以下步骤获取：对不同的单声源视频数据进行声音采样，获取不同的单声源声音信号；将所述不同的单声源声音信号进行线性叠加，获取混叠多声源声音信号；利用短时傅里叶变换将所述混叠多声源声音信号变换为所述第二混叠多声源声谱图。本发明还提供一种声源分离装置，包括：第一获取模块，用于获取视频帧图像中的视觉引导特征；第二获取模块，用于将第一混叠多声源声谱图和所述视觉引导特征输入训练好的预测编码循环卷积神经网络模型，获取第一掩膜图；第三获取模块，用于根据所述第一混叠多声源声谱图和所述第一掩膜图，获取分离的声音信号。本发明还提供一种电子设备，包括存储器、处理器及存储在存储器上并可在处理器上运行的计算机程序，所述处理器执行所述计算机程序时实现如上述任一种所述声源分离方法的步骤。本发明还提供一种非暂态计算机可读存储介质，其上存储有计算机程序，该计算机程序被处理器执行时实现如上述任一种所述声源分离方法的步骤。本发明提供的声源分离方法及装置，通过将视觉引导特征和混叠多声源声谱图输入训练好的预测编码循环卷积神经网络模型预测各声音分量的掩膜图，然后利用掩膜图和混叠多声源声谱图获取分离的声音信号，实现声谱图和视觉引导特征在同一网络模型中进行处理，网络模型规模小，且视觉特征和声音特征能够渐进式的有效融合，提高了声源分离的精度。附图说明为了更清楚地说明本发明或现有技术中的技术方案，下面将对实施例或现有技术描述中所需要使用的附图作以简单地介绍，显而易见地，下面描述中的附图是本发明的一些实施例，对于本领域普通技术人员来讲，在不付出创造性劳动的前提下，还可以根据这些附图获得其他的附图。图1是本发明实施例提供的声源分离方法的流程示意图；图2是本发明实施例提供的声源分离方法的整体框架示意图；图3是本发明实施例提供的预测编码循环卷积神经网络模型的训练和应用流程图；图4是本发明实施例提供的预测编码循环卷积神经网络模型的结构示意图；图5是本发明实施例提供的预测编码循环卷积神经网络模型的计算流程图；图6是本发明实施例提供的声源分离装置的结构示意图；图7是本发明实施例提供的电子设备的结构示意图。具体实施方式为使本发明的目的、技术方案和优点更加清楚，下面将结合本发明中的附图，对本发明中的技术方案进行清楚、完整地描述，显然，所描述的实施例是本发明一部分实施例，而不是全部的实施例。基于本发明中的实施例，本领域普通技术人员在没有做出创造性劳动前提下所获得的所有其他实施例，都属于本发明保护的范围。图1是本发明实施例提供的声源分离方法的流程示意图，如图1所示，本发明提供一种声源分离方法，该方法包括：步骤101，获取视频帧图像中的视觉引导特征。具体地，图2是本发明实施例提供的声源分离方法的整体框架示意图，如图2所示，将视频帧图像v1和视频帧图像v2分别输入视觉特征提取模型，获取视觉引导特征f1和视觉引导特征f2。视频帧图像的获取方法可以为：从给定的视频中提取M1帧视频图像，将每一帧图像再截取为两张图像，让每张图像为只含单个发声物体像素的图像，并对图像进行归一化处理，得到大小为M1×H1×W1×3的两组帧图像v1和v2。H1表示图像的高段，W1表示图像的宽段，3表示红绿蓝三色通道。例如，首先从给定的二重奏视频中提取3帧视频帧，再将每一帧图像再截取为两张图像，让每张图像为只含单个发声物体像素的图像，并对图像进行归一化，得到大小为3×224×224×3的两组帧图像。将预训练好的残差神经网络作为视觉特征提取模型来提取视频帧图像的表观语义特征，把ResNet-18的最后一个卷积层的输出作为视觉引导特征。步骤102，将第一混叠多声源声谱图和所述视觉引导特征输入训练好的预测编码循环卷积神经网络模型，获取第一掩膜图。具体地，将视觉引导特征f1和混叠多声源声谱图输入训练好的预测编码循环卷积神经网络模型，获取预测的掩膜图类似地，将视觉引导特征f2和混叠多声源声谱图输入训练好的预测编码循环卷积神经网络模型，获取预测的掩膜图混叠多声源声谱图的获取方法可以为：从给定的视频中以采样率K1提取定长G1秒的混叠多声源声音信号，再将混叠多声源声音信号经短时傅里叶变换转化为混叠多声源声谱图。例如，从给定的二重奏视频中以11kHz的采样率提取6秒的混叠多声源声音信号，再将采样得到的混叠多声源声音信号经STFT转化为混叠多声源声谱图。将第一混叠多声源声谱图和视觉引导特征输入训练好的预测编码循环卷积神经网络模型，获取第一掩膜图之前，需要获取训练好的预测编码循环卷积神经网络模型。可选地，训练好的预测编码循环卷积神经网络模型通过以下步骤获取：将第二混叠多声源声谱图和单声源视频的帧图像对应的视觉引导特征输入预测编码循环卷积神经网络模型，输出第二掩膜图；第二掩膜图为预测的掩膜图；将第一单声源声谱图和第二混叠多声源声谱图中的对应元素进行比较，获取第三掩膜图；第三掩膜图为真实的掩膜图；将第二掩膜图与第三掩膜图之间的二值交叉熵作为损失函数；对损失函数的值进行优化，获取训练好的预测编码循环卷积神经网络模型。具体地，图3是本发明实施例提供的预测编码循环卷积神经网络模型的训练和应用流程图，如图3所示，分为模型训练阶段和模型应用阶段。在模型训练阶段，从单声源视频数据中进行采样获取单声源视频帧图像，利用视觉特征提取模型从单声源视频帧图像中提取视觉引导特征。利用单声源视频数据构造混叠多声源声音信号，利用STFT将单声源声音信号和混叠多声源声音信号分别转化为单声源声谱图和混叠多声源声谱图。将混叠多声源声谱图和视觉引导特征输入预测编码循环卷积神经网络模型，输出预测的掩膜图。将单声源声谱图和混叠多声源声谱图中的对应元素进行比较，获取真实的掩膜图。将模型输出的预测的掩膜图和真实的掩膜图之间的二值交叉熵作为损失函数，利用算法对损失函数的值进行优化，获取训练好的预测编码循环卷积神经网络模型。对N段不同的单声源视频数据进行图像采样，以采样率K2分别从每段单声源视频中提取M2帧视频图像，并对图像进行归一化处理，得到大小为M2×H2×W2×3的N组帧图像，H2表示图像的高段，W2表示图像的宽段，3表示红绿蓝三色通道，将N组帧图像记为vn，n的取值范围为1到N的自然数。将N组单声源视频的帧图像分别输入预训练好的ResNet-18模型，获取N组单声源视频的帧图像对应的视觉引导特征，将得到的视觉引导特征记为fn，n的取值范围为1到N的自然数。可选地，第二混叠多声源声谱图通过以下步骤获取：对不同的单声源视频数据进行声音采样，获取不同的单声源声音信号；将不同的单声源声音信号进行线性叠加，获取混叠多声源声音信号；利用短时傅里叶变换将混叠多声源声音信号变换为第二混叠多声源声谱图。具体地，对N段不同的单声源视频数据进行声音采样，以采样率K3分别提取定长G2秒的单声源声音信号，单声源声音信号记为an，n的取值范围为1到N的自然数。利用声音信号的近似线性可加性，将获取的不同的单声源声音信号进行线性叠加，获取混叠多声源声音信号。混叠多声源声音信号的表达式如下所示：式中，amix表示混叠多声源声音信号，an表示第n段单声源声音信号，N表示单声源声音信号的总段数。利用STFT将单声源声音信号an和混叠多声源声音信号amix分别转化为单声源声谱图Sn和混叠多声源声谱图Smix。其中，STFT使用的汉宁窗窗宽为1022，相邻汉宁窗的间隔为256。通过先利用单声源视频数据合成混叠多声源声音信号，再转化为混叠多声源声谱图作为模型的训练数据，这种数据合成方式可充分利用互联网上海量的视频数据，并且不需要人为标注即可获得各个声音分量已知的混叠多声源声音信号，可方便地实现自监督学习。在获取视觉引导特征fn和混叠多声源声谱图Smix之后，将fn和Smix输入预测编码循环卷积神经网络模型。可选地，预测编码循环卷积神经网络模型包括预测编码循环卷积神经网络、单层转置卷积层和上采样层；其中，预测编码循环卷积神经网络中的卷积层之间采用反馈连接，转置卷积层之间采用前馈连接，同层的卷积层和转置卷积层之间采用循环连接。具体地，图4是本发明实施例提供的预测编码循环卷积神经网络模型的结构示意图，如图4所示，预测编码循环卷积神经网络模型包括预测编码循环卷积神经网络、单层转置卷积层和上采样层。在预测编码循环卷积神经网络中包括多层卷积层和多层转置卷积层，从顶层卷积层到底层卷积层之间采用反馈连接，利用反馈连接传递预测信号，从底层转置卷积层到顶层转置卷积层之间采用前馈连接，利用前馈连接传递预测信号与实际响应之间的误差信号，同层的卷积层和转置卷积层之间采用循环连接，利用循坏连接在同层的卷积层和转置卷积层之间传递神经元响应。通过让预测编码循环卷积神经网络具有前馈、反馈和循环连接，能够实现视觉特征和声音特征渐进式的有效融合，有利于提高声源分离的精度。将fn和Smix输入预测编码循环卷积神经网络模型中的预测编码循环卷积神经网络，经若干步迭代后，将预测编码循环卷积神经网络中转置卷积层的顶层神经元响应作为视觉声音融合特征，再将视觉声音融合特征输入预测编码循环卷积神经网络模型中的单层转置卷积层和上采样层，得到掩膜图该掩膜图是预测编码循环卷积神经网络模型输出的预测掩膜图。将单声源声谱图Sn和混叠多声源声谱图Smix中的对应元素进行比较，若Sn中对应元素的值大于Smix中对应元素的值，则将对应元素的位置赋值为1，其余对应元素的位置赋值为0，得到掩膜图Mn，该掩膜图为声音分量的真实的掩膜图。将掩膜图和掩膜图Mn之间的二值交叉熵作为损失函数。损失函数的表达式如下所示：式中，L表示损失函数的值，N表示单声源声音信号的总段数，BCE表示二值交叉熵函数，Mn表示声音分量的真实的掩膜图，表示预测编码循环卷积神经网络模型输出的预测掩膜图。采用误差反向传播算法和随机梯度下降算法来减小损失函数的值，以训练预测编码循环卷积神经网络模型，经过多次迭代训练之后，获取训练好的预测编码循环卷积神经网络模型。通过先获取预测的掩膜图和真实的掩膜图，再利用二者之间的二值交叉熵作为损失函数，并优化损失函数的值，从而获取训练好的预测编码循环卷积神经网络模型，实现了在同一网络模型中处理声谱图和视觉引导特征，网络模型规模小，为后续利用训练好的预测编码循环卷积神经网络模型获取掩膜图奠定基础。在模型应用阶段，利用训练好的预测编码循环卷积神经网络模型输出预测的掩膜图，再根据混叠多声源声谱图和预测的掩膜图，获取预测的单声源声谱图，最后将单声源声谱图进行短时傅里叶逆变换，获取分离的声音信号。可选地，将第一混叠多声源声谱图和视觉引导特征输入训练好的预测编码循环卷积神经网络模型，获取第一掩膜图，包括：将第一混叠多声源声谱图和视觉引导特征输入预测编码循环卷积神经网络，获取视觉声音融合特征；将视觉声音融合特征输入单层转置卷积层和上采样层，获取第一掩膜图。具体地，将视觉引导特征和混叠多声源声谱图输入训练好的预测编码循环卷积神经网络模型中的预测编码循环卷积神经网络，获取视觉声音融合特征。可选地，将第一混叠多声源声谱图和视觉引导特征输入预测编码循环卷积神经网络，获取视觉声音融合特征，包括：将第一混叠多声源声谱图输入卷积层的顶层，依次获取每一层卷积层的预测信号，并利用每一层卷积层的预测信号获取每一层卷积层的神经元响应；将视觉引导特征输入转置卷积层的底层，根据同层卷积层的神经元响应，依次获取每一层转置卷积层的神经元响应；在最后一次循环迭代中，将转置卷积层的顶层的神经元响应作为视觉声音融合特征。具体地，图5是本发明实施例提供的预测编码循环卷积神经网络模型的计算流程图，如图5所示，将混叠多声源声谱图和视觉引导特征输入预测编码循环卷积神经网络，开始进行迭代，判断迭代次数t是否达到最大迭代次数T，若迭代次数小于最大迭代次数，依次进行反馈过程和前馈过程，之后将迭代次数加1，再次判断迭代次数t是否达到最大迭代次数T，再次进行反馈过程和前馈过程，直到迭代次数t达到最大迭代次数T，停止迭代，将转置卷积层的顶层的神经元响应通过单层转置卷积层和上采样层，输出预测的掩膜图。具体过程如下所示：将混叠多声源声谱图输入卷积层的顶层rL，经反馈过程依次得到每一层卷积层的预测信号，并利用每一层卷积层的预测信号获取每一层卷积层的神经元响应。卷积层可以设置为7层。每一层卷积层的预测信号的表达式如下所示：pl＝Trl+1式中，pl表示t次迭代中第l层卷积层的预测信号，其中，l的取值范围为7至1的自然数，Wl+1,l表示从l+1层到l层的反馈连接，rl+1表示t次迭代中第l+1层卷积层的神经元响应。当l等于7时，rl+1即为r8，可以将混叠多声源声谱图Smix当作r8的神经元响应。在初次迭代中，根据每一层卷积层的预测信号可以从高层到低层依次获取每一层卷积层的神经元响应。在t等于0的情况下，每一层卷积层的神经元响应的表达式如下所示：rl＝LeakyReLU)式中，rl表示初次迭代中第l层卷积层的神经元响应，其中，l的取值范围为7至1的自然数，LeakyReLU表示非饱和激活函数，pl表示初次迭代中第l层卷积层的预测信号。在后续迭代中，根据每一层卷积层的预测信号和前一次迭代中转置卷积层的神经元响应，可以从高层到低层依次获取每一层卷积层的神经元响应。在t大于0的情况下，每一层卷积层的神经元响应的表达式如下所示：rl＝LeakyReLUql+blpl)式中，rl表示t次迭代中第l层卷积层的神经元响应，其中，l的取值范围为7至1的自然数，LeakyReLU表示非饱和激活函数，bl表示可学习的参数，用于平衡不同项的重要性，ql表示t-1次迭代中第l层转置卷积层的神经元响应，pl表示t次迭代中第l层卷积层的预测信号。经反馈过程之后，再经前馈过程，转置卷积层的层数与卷积层的层数相同，也将转置卷积层设置为7层。计算每一转置卷积层的神经元响应和每一卷积层的预测信号之间的预测误差。预测误差的表达式如下所示：el-1＝ql-1-pl-1式中，el-1表示t次迭代中第l-1层的预测误差，ql-1表示t次迭代中第l-1层转置卷积层的神经元响应，pl-1表示t次迭代中第l-1层卷积层的预测信号，其中，l的取值范围为1至7的自然数。当l等于1时，ql-1即为q0，可以将视觉引导特征fn当作q0对应的神经元响应，pl-1即为p0，p0可以根据t次迭代中第1层卷积层的神经元响应r1进行获取。p0的表达式如下所示：p0＝LeakyReLUTr1)式中，p0表示t次迭代中第0层卷积层的预测信号，LeakyReLU表示非饱和激活函数，W1,0表示从1层到0层的反馈连接，r1表示t次迭代中第1层卷积层的神经元响应。根据下一层的预测误差和同层的卷积层的神经元响应，可以从低层到高层依次获取上一层转置卷积层的神经元响应。每一层转置卷积层的神经元响应的表达式如下所示：ql＝LeakyReLU+alTel-1)式中，ql表示t次迭代中第l层转置卷积层的神经元响应，LeakyReLU表示非饱和激活函数，rl表示t次迭代中第l层卷积层的神经元响应，al表示可学习的平衡参数，Wl-1,l表示从l-1层到l层的前馈连接，el-1表示t次迭代中第l-1层的预测误差。循环交替执行反馈过程和前馈过程，直至迭代次数t为最大的迭代次数T，通常设置T等于5。在最后一次循环迭代中，将预测编码循环卷积神经网络中的转置卷积层的顶层的神经元响应qL作为视觉声音融合特征。通过循环交替执行反馈过程和前馈过程，实现视觉特征和声音特征渐进式的有效融合，有利于提高声源分离的精度。将视觉声音融合特征输入一个单层转置卷积层和上采样层，单层转置卷积层的维度为3×1×1，上采样层的尺度因子为2，进而输出预测的掩膜图通过将混叠多声源声谱图和视觉引导特征输入训练好的预测编码循环卷积神经网络模型，获取预测的掩膜图，实现声谱图和视觉引导特征在同一网络模型中进行处理，网络模型规模小，且视觉特征和声音特征能够渐进式的有效融合，提高了声源分离的精度，为后续获取分离的声音信号奠定基础。步骤103，根据第一混叠多声源声谱图和第一掩膜图，获取分离的声音信号。具体地，可以根据混叠多声源声谱图和训练好的预测编码循环卷积神经网络模型输出的预测掩膜图，获取分离的声音信号。可选地，根据第一混叠多声源声谱图和第一掩膜图，获取分离的声音信号，包括：将第一混叠多声源声谱图与第一掩膜图进行对应元素相乘，获取第二单声源声谱图；利用短时傅里叶逆变换将第二单声源声谱图变换至时域，获取分离的声音信号。具体地，将混叠多声源声谱图分别与预测的掩膜图和的对应元素相乘，得到预测的单声源声谱图和利用短时傅里叶逆变换将单声源声谱图和变换至时域，即可得到分离的声音信号1和分离的声音信号2。通过将混叠多声源声谱图和预测的掩膜图进行对应元素相乘，再进行短时傅里叶逆变换，获取分离的声音信号，实现了声源分离。本发明提供的声源分离方法，通过将视觉引导特征和混叠多声源声谱图输入训练好的预测编码循环卷积神经网络模型预测各声音分量的掩膜图，然后利用掩膜图和混叠多声源声谱图获取分离的声音信号，实现声谱图和视觉引导特征在同一网络模型中进行处理，网络模型规模小，且视觉特征和声音特征能够渐进式的有效融合，提高了声源分离的精度。图6是本发明实施例提供的声源分离装置的结构示意图，如图6所示，本发明还提供一种声源分离装置，包括：第一获取模块601、第二获取模块602和第三获取模块603，其中：第一获取模块601，用于获取视频帧图像中的视觉引导特征；第二获取模块602，用于将第一混叠多声源声谱图和所述视觉引导特征输入训练好的预测编码循环卷积神经网络模型，获取第一掩膜图；第三获取模块603，用于根据所述第一混叠多声源声谱图和所述第一掩膜图，获取分离的声音信号。具体来说，本申请实施例提供的声源分离装置，能够实现上述方法实施例所实现的所有方法步骤，且能够达到相同的技术效果，在此不再对本实施例中与方法实施例相同的部分及有益效果进行具体赘述。图7是本发明实施例提供的电子设备的结构示意图，如图7所示，该电子设备可以包括：处理器710、通信接口720、存储器730和通信总线740，其中，处理器710，通信接口720，存储器730通过通信总线740完成相互间的通信。处理器710可以调用存储器730中的逻辑指令，以执行声源分离方法，该方法包括：获取视频帧图像中的视觉引导特征；将第一混叠多声源声谱图和所述视觉引导特征输入训练好的预测编码循环卷积神经网络模型，获取第一掩膜图；根据所述第一混叠多声源声谱图和所述第一掩膜图，获取分离的声音信号。此外，上述的存储器730中的逻辑指令可以通过软件功能单元的形式实现并作为独立的产品销售或使用时，可以存储在一个计算机可读取存储介质中。基于这样的理解，本发明的技术方案本质上或者说对现有技术做出贡献的部分或者该技术方案的部分可以以软件产品的形式体现出来，该计算机软件产品存储在一个存储介质中，包括若干指令用以使得一台计算机设备执行本发明各个实施例所述方法的全部或部分步骤。而前述的存储介质包括：U盘、移动硬盘、只读存储器、随机存取存储器、磁碟或者光盘等各种可以存储程序代码的介质。另一方面，本发明还提供一种计算机程序产品，所述计算机程序产品包括存储在非暂态计算机可读存储介质上的计算机程序，所述计算机程序包括程序指令，当所述程序指令被计算机执行时，计算机能够执行上述各方法所提供的声源分离方法，该方法包括：获取视频帧图像中的视觉引导特征；将第一混叠多声源声谱图和所述视觉引导特征输入训练好的预测编码循环卷积神经网络模型，获取第一掩膜图；根据所述第一混叠多声源声谱图和所述第一掩膜图，获取分离的声音信号。又一方面，本发明还提供一种非暂态计算机可读存储介质，其上存储有计算机程序，该计算机程序被处理器执行时实现以执行上述各提供的声源分离方法，该方法包括：获取视频帧图像中的视觉引导特征；将第一混叠多声源声谱图和所述视觉引导特征输入训练好的预测编码循环卷积神经网络模型，获取第一掩膜图；根据所述第一混叠多声源声谱图和所述第一掩膜图，获取分离的声音信号。以上所描述的装置实施例仅仅是示意性的，其中所述作为分离部件说明的单元可以是或者也可以不是物理上分开的，作为单元显示的部件可以是或者也可以不是物理单元，即可以位于一个地方，或者也可以分布到多个网络单元上。可以根据实际的需要选择其中的部分或者全部模块来实现本实施例方案的目的。本领域普通技术人员在不付出创造性的劳动的情况下，即可以理解并实施。通过以上的实施方式的描述，本领域的技术人员可以清楚地了解到各实施方式可借助软件加必需的通用硬件平台的方式来实现，当然也可以通过硬件。基于这样的理解，上述技术方案本质上或者说对现有技术做出贡献的部分可以以软件产品的形式体现出来，该计算机软件产品可以存储在计算机可读存储介质中，如ROM/RAM、磁碟、光盘等，包括若干指令用以使得一台计算机设备执行各个实施例或者实施例的某些部分所述的方法。本申请实施例中术语“第一”、“第二”等是用于区别类似的对象，而不用于描述特定的顺序或先后次序。应该理解这样使用的术语在适当情况下可以互换，以便本申请的实施例能够以除了在这里图示或描述的那些以外的顺序实施，且“第一”、“第二”所区别的对象通常为一类，并不限定对象的个数，例如第一对象可以是一个，也可以是多个。最后应说明的是：以上实施例仅用以说明本发明的技术方案，而非对其限制；尽管参照前述实施例对本发明进行了详细的说明，本领域的普通技术人员应当理解：其依然可以对前述各实施例所记载的技术方案进行修改，或者对其中部分技术特征进行等同替换；而这些修改或者替换，并不使相应技术方案的本质脱离本发明各实施例技术方案的精神和范围。
