标题title
基于神经网络的LDPC归一化最小和译码方法及装置
摘要abst
本发明公开了一种基于神经网络的LDPC归一化最小和译码方法及装置，包括：获取LDPC码信号，并根据LDPC码信号，对第一软信息进行初始化；对第一软信息进行迭代计算，以使在每一次迭代计算中，根据预设的神经网络，来更新归一化因子，从而根据更新后的归一化因子和第一软信息，计算并更新第二软信息，继而根据更新后的第二软信息，计算并更新硬判决信息，根据更新后的第二软信息和更新后的硬判决信息，对第一软信息进行更新，直至达到迭代停止的预设条件或迭代次数达到预设值后，获得迭代后的硬判决信息；对迭代后的硬判决信息进行硬判决译出码矢量，从而输出译码结果。本发明能够提高译码结果的准确性，译码性能得到了增强，误码率进一步降低。
权利要求书clms
1.一种基于神经网络的LDPC归一化最小和译码方法，其特征在于，包括：获取LDPC码信号，并根据LDPC码信号，对第一软信息进行初始化；对所述第一软信息进行迭代计算，以使在每一次迭代计算中，根据预设的神经网络，来更新归一化因子，从而根据更新后的归一化因子和所述第一软信息，计算并更新第二软信息，继而根据更新后的第二软信息，计算并更新硬判决信息，根据更新后的第二软信息和更新后的硬判决信息，对第一软信息进行更新操作，直至达到迭代停止的预设条件或迭代次数达到预设值后，获得迭代后的硬判决信息；对所述迭代后的硬判决信息进行硬判决译出码矢量，从而输出译码结果。2.如权利要求1所述的一种基于神经网络的LDPC归一化最小和译码方法，其特征在于，所述获取LDPC码信号，并根据LDPC码信号，对第一软信息进行初始化，具体为：将所述LDPC码信号进行解调，转换成对数似然比，并根据所述对数似然比，对第一软信息进行初始化。3.如权利要求2所述的一种基于神经网络的LDPC归一化最小和译码方法，其特征在于，所述根据预设的神经网络，来更新归一化因子，具体为：将每个校验节点的输入数据，输入至预设的神经网络，从而得出对应于的每个校验节点的归一化因子；其中，在所述LDPC码信号的校验矩阵中，每一行对应一个校验节点，每一列对应的一个变量节点，所述校验矩阵由LDPC码信号的码长和信息长度求得。4.如权利要求3所述的一种基于神经网络的LDPC归一化最小和译码方法，其特征在于，所述根据更新后的归一化因子和所述第一软信息，计算并更新第二软信息，具体为：根据更新后的归一化因子和所述第一软信息，计算每个所述校验节点传递给相连变量节点的第二软信息：Lij＝αNN×minj′∈Nj|Zij′|×∏j′∈Njsign；其中，i为校验节点，j为变量节点，Nj表示为从集合N中除去j，N表示所有与校验节点相连的变量节点的集合，min表示取最小值，sign为符号函数，αNN为归一化因子，Zij为第一软信息，Lij为第二软信息。5.如权利要求4所述的一种基于神经网络的LDPC归一化最小和译码方法，其特征在于，所述根据更新后的第二软信息，计算并更新硬判决信息，根据更新后的第二软信息和更新后的硬判决信息，对第一软信息进行更新操作，具体为：根据更新后的第二软信息，以及所述对数似然比，计算出硬判决信息：Zj＝lj+∑i∈MLij；其中，lj为所述对数似然比，M表示所有与变量节点相连的校验节点；根据更新后的第二软信息和更新后的硬判决信息，对第一软信息进行更新操作：Zij＝Zj-Lij。6.如权利要求5所述的一种基于神经网络的LDPC归一化最小和译码方法，其特征在于，所述对所述迭代后的硬判决信息进行硬判决译出码矢量，从而输出译码结果，具体为：对所述迭代后的硬判决信息进行硬判决译出码矢量：从而输出译码结果b＝。7.一种基于神经网络的LDPC归一化最小和译码装置，其特征在于，包括：初始化模块、迭代计算模块和硬判决模块；所述初始化模块，用于获取LDPC码信号，并根据LDPC码信号，对第一软信息进行初始化；所述迭代计算模块用于对所述第一软信息进行迭代计算，以使在每一次迭代计算中，根据预设的神经网络，来更新归一化因子，从而根据更新后的归一化因子和所述第一软信息，计算并更新第二软信息，继而根据更新后的第二软信息，计算并更新硬判决信息，根据更新后的第二软信息和更新后的硬判决信息，对第一软信息进行更新操作，直至达到迭代停止的预设条件或迭代次数达到预设值后，获得迭代后的硬判决信息；所述硬判决模块，用于对所述迭代后的硬判决信息进行硬判决译出码矢量，从而输出译码结果。8.如权利要求7所述的一种基于神经网络的LDPC归一化最小和译码装置，其特征在于，所述初始化模块，用于获取LDPC码信号，并初始化第一软信息，具体为：将所述LDPC码信号进行解调，转换成对数似然比，并根据所述对数似然比，对第一软信息进行初始化。9.如权利要求8所述的一种基于神经网络的LDPC归一化最小和译码装置，其特征在于，所述迭代计算模块用于对所述第一软信息进行迭代计算，以使在每一次迭代计算中，根据预设的神经网络，来更新归一化因子，从而根据更新后的归一化因子和所述第一软信息，计算并更新第二软信息，继而根据更新后的第二软信息，计算并更新硬判决信息，从而对所述第一软信息进行更新操作，直至达到迭代停止的预设条件或迭代次数达到预设值后，获得迭代后的硬判决信息，具体为：将每个校验节点的输入数据，输入至预设的神经网络，从而得出对应于的每个校验节点的归一化因子；其中，在所述LDPC码信号的校验矩阵中，每一行对应一个校验节点，每一列对应的一个变量节点，所述校验矩阵由LDPC码信号的码长和信息长度求得；根据更新后的归一化因子和所述第一软信息，计算每个所述校验节点传递给相连变量节点的第二软信息：Lij＝αNN×minj′∈Nj|Zij′|×∏j′∈Njsign；其中，i为校验节点，j为变量节点，Nj表示为从集合N中除去j，N表示所有与校验节点相连的变量节点的集合，min表示取最小值，sign为符号函数，αNN为归一化因子，Zij为第一软信息，Lij为第二软信息；根据更新后的第二软信息，以及所述对数似然比，计算出硬判决信息：Zj＝lj+∑i∈MLij；其中，lj为所述对数似然比，M表示所有与变量节点相连的校验节点；根据更新后的第二软信息和更新后的硬判决信息，对第一软信息进行更新操作：Zij＝Zj-Lij。10.如权利要求9所述的一种基于神经网络的LDPC归一化最小和译码装置，其特征在于，所述硬判决模块，用于对所述硬判决信息进行硬判决译出码矢量，从而输出译码结果，具体为：对所述迭代后的硬判决信息进行硬判决译出码矢量：从而输出译码结果b＝。
说明书desc
技术领域本发明涉及深度学习和通信技术领域，尤其涉及一种基于神经网络的LDPC归一化最小和译码方法及装置。背景技术在通信、存储系统中，为纠正传输错误而广泛使用前向纠错编码。LDPC码是线性分组码，经过仔细构造校验矩阵的LDPC码具有接近香农极限的纠错能力，因此广泛用于数据存储和各种通信方式。例如，在卫星通信领域常用的CCSDS标准中定义了应用于不同场景、不同码长、码率的LDPC码。传统的置信传播译码方式由于采用大量的双曲正切tanh和反双曲正切arctanh函数，导致译码计算复杂度过高。最小和译码器使用取最小值代替上述两种非线性函数，只需要对数据进行比较，大大降低了译码器的复杂度。但由于采用了最小值近似，最小和译码器的软信息迭代中，算出的校验节点至变量节点的值比BP算出的值偏大，因此纠错性能比BP算法差。通常采用的方法是对该值乘上一个归一化因子，该归一化因子由于很难使用公式计算，故一般采用经验估计，大多取值于0.6至0.9之间。由于归一化因子通过经验估计，因此会导致译码存在一定的误差，使得该译码方式的性能与BP译码仍存在较大的偏差。因此，本领域技术人员有动机开发一种计算复杂度比BP译码方式低，同时性能接近BP译码方式。发明内容本发明提供了一种基于神经网络的LDPC归一化最小和译码方法及装置，以解决现有技术中经验估计的归一化因子导致译码误差大的技术问题。为了解决上述技术问题，本发明实施例提供了一种基于神经网络的LDPC归一化最小和译码方法，包括：获取LDPC码信号，并根据LDPC码信号，对第一软信息进行初始化；对所述第一软信息进行迭代计算，以使在每一次迭代计算中，根据预设的神经网络，来更新归一化因子，从而根据更新后的归一化因子和所述第一软信息，计算并更新第二软信息，继而根据更新后的第二软信息，计算并更新硬判决信息，根据更新后的第二软信息和更新后的硬判决信息，对第一软信息进行更新操作，直至达到迭代停止的预设条件或迭代次数达到预设值后，获得迭代后的硬判决信息；对所述迭代后的硬判决信息进行硬判决译出码矢量，从而输出译码结果。进一步地，所述获取LDPC码信号，并根据LDPC码信号，对第一软信息进行初始化，具体为：将所述LDPC码信号进行解调，转换成对数似然比，并根据所述对数似然比，对第一软信息进行初始化。进一步地，所述根据预设的神经网络，来更新归一化因子，具体为：将每个校验节点的输入数据，输入至预设的神经网络，从而得出对应于的每个校验节点的归一化因子；其中，在所述LDPC码信号的校验矩阵中，每一行对应一个校验节点，每一列对应的一个变量节点，所述校验矩阵由LDPC码信号的码长和信息长度求得。进一步地，所述根据更新后的归一化因子和所述第一软信息，计算并更新第二软信息，具体为：根据更新后的归一化因子和所述第一软信息，计算每个所述校验节点传递给相连变量节点的第二软信息：Lij＝αNN×minj′∈Nj|Zij′|×∏j′∈Njsign；其中，i为校验节点，j为变量节点，Nj表示为从集合N中除去j，N表示所有与校验节点相连的变量节点的集合，min表示取最小值，sign为符号函数，αNN为归一化因子，Zij为第一软信息，Lij为第二软信息。进一步地，所述根据更新后的第二软信息，计算并更新硬判决信息，根据更新后的第二软信息和更新后的硬判决信息，对第一软信息进行更新操作，具体为：根据更新后的第二软信息，以及所述对数似然比，计算出硬判决信息：Zj＝lj+∑i∈MLij；其中，lj为所述对数似然比，M表示所有与变量节点相连的校验节点；根据更新后的第二软信息和更新后的硬判决信息，对第一软信息进行更新操作：Zij＝Zj-Lij。进一步地，所述对所述迭代后的硬判决信息进行硬判决译出码矢量，从而输出译码结果，具体为：对所述迭代后的硬判决信息进行硬判决译出码矢量：从而输出译码结果b＝。相应地，本发明实施例还提供一种基于神经网络的LDPC归一化最小和译码装置，包括：初始化模块、迭代计算模块和硬判决模块；所述初始化模块，用于获取LDPC码信号，并根据LDPC码信号，对第一软信息进行初始化；所述迭代计算模块用于对所述第一软信息进行迭代计算，以使在每一次迭代计算中，根据预设的神经网络，来更新归一化因子，从而根据更新后的归一化因子和所述第一软信息，计算并更新第二软信息，继而根据更新后的第二软信息，计算并更新硬判决信息，根据更新后的第二软信息和更新后的硬判决信息，对第一软信息进行更新操作，直至达到迭代停止的预设条件或迭代次数达到预设值后，获得迭代后的硬判决信息；所述硬判决模块，用于对所述迭代后的硬判决信息进行硬判决译出码矢量，从而输出译码结果。进一步地，所述初始化模块，用于获取LDPC码信号，并初始化第一软信息，具体为：将所述LDPC码信号进行解调，转换成对数似然比，并根据所述对数似然比，对第一软信息进行初始化。进一步地，所述迭代计算模块用于对所述第一软信息进行迭代计算，以使在每一次迭代计算中，根据预设的神经网络，来更新归一化因子，从而根据更新后的归一化因子和所述第一软信息，计算并更新第二软信息，继而根据更新后的第二软信息，计算并更新硬判决信息，从而对所述第一软信息进行更新操作，直至达到迭代停止的预设条件或迭代次数达到预设值后，获得迭代后的硬判决信息，具体为：将每个校验节点的输入数据，输入至预设的神经网络，从而得出对应于的每个校验节点的归一化因子；其中，在所述LDPC码信号的校验矩阵中，每一行对应一个校验节点，每一列对应的一个变量节点，所述校验矩阵由LDPC码信号的码长和信息长度求得。根据更新后的归一化因子和所述第一软信息，计算每个所述校验节点传递给相连变量节点的第二软信息：Lij＝αNN×minj′∈Nj|zij′|×Πj′∈Njsign；其中，i为校验节点，j为变量节点，Nj表示为从集合N中除去j，N表示所有与校验节点相连的变量节点的集合，min表示取最小值，sign为符号函数，αNN为归一化因子，Zij为第一软信息，Lij为第二软信息；根据更新后的第二软信息，以及所述对数似然比，计算出硬判决信息：Zj＝lj+∑i∈MLij；其中，lj为所述对数似然比，M表示所有与变量节点相连的校验节点；根据更新后的第二软信息和更新后的硬判决信息，对第一软信息进行更新操作：Zij＝Zj-Lij。进一步地，所述硬判决模块，用于对所述硬判决信息进行硬判决译出码矢量，从而输出译码结果，具体为：对所述迭代后的硬判决信息进行硬判决译出码矢量：从而输出译码结果b＝。相比于现有技术，本发明实施例具有如下有益效果：本发明的技术方案通过对第一软信息进行一次初始化操作后，进行第一软信息和第二软信息迭代计算，并且在每一次迭代中增加了神经网络对归一化因子的估值，保证了每一次迭代过程中都采取不同的归一化因子来对第二软信息进行计算，提高了后续对信息硬判决的译码结果的准确性，以达到精确的估计效果，使得译码性能得到了增强，误码率进一步降低。附图说明图1：为本发明实施例所提供的基于神经网络的LDPC归一化最小和译码方法的步骤流程图；图2：为本发明实施例所提供的基于神经网络的LDPC归一化最小和译码方法的示意图；图3：为本发明实施例所提供的基于神经网络的LDPC归一化最小和译码方法中神经网络的结构示意图；图4：为本发明实施例所提供的基于神经网络的LDPC归一化最小和译码方法与现有技术的信噪比和误码率的关系示意图；图5：为本发明实施例所提供的基于神经网络的LDPC归一化最小和译码装置的结构示意图。具体实施方式下面将结合本发明实施例中的附图，对本发明实施例中的技术方案进行清楚、完整地描述，显然，所描述的实施例仅仅是本发明一部分实施例，而不是全部的实施例。基于本发明中的实施例，本领域普通技术人员在没有作出创造性劳动前提下所获得的所有其他实施例，都属于本发明保护的范围。实施例一请参照图1，为本发明实施例提供的一种基于神经网络的LDPC归一化最小和译码方法，包括以下步骤S101-S103：S101：获取LDPC码信号，并根据LDPC码信号，对第一软信息进行初始化。具体地，将所述LDPC码信号进行解调，转换成对数似然比，并根据所述对数似然比，对第一软信息进行初始化。需要说明的是，对数似然比记为lj，根据所述对数似然比，对第一软信息进行初始化，令第一软信息Zij＝lj。S102：对所述第一软信息进行迭代计算，以使在每一次迭代计算中，根据预设的神经网络，来更新归一化因子，从而根据更新后的归一化因子和所述第一软信息，计算并更新第二软信息，继而根据更新后的第二软信息，计算并更新硬判决信息，根据更新后的第二软信息和更新后的硬判决信息，对第一软信息进行更新操作，直至达到迭代停止的预设条件或迭代次数达到预设值后，获得迭代后的硬判决信息。具体地，请参阅图2，为本发明实施例所提供的基于神经网络的LDPC归一化最小和译码方法的示意图，将每个变量节点的输入数据，输入至预设的神经网络，从而得出对应于的每个校验节点的归一化因子；其中，在所述LDPC码信号的校验矩阵中，每一行对应一个校验节点，每一列对应的一个变量节点，所述校验矩阵由LDPC码信号的码长和信息长度求得。需要说明的是，LDPC码信息的码长为n，信息长度k，校验部分长度n-k；LDPC码的生成矩阵G为k行n列，校验矩阵H为n-k行，n列。校验矩阵的每一行对应一个校验节点i，每一列对应一个变量节点j，矩阵中为1的元素代表校验关系。例如，若第i行第j列为1，则表示校验节点i与变量节点j之间存在校验关系，在迭代译码中需要往复传递软信息。作为本实施例中的优选方案，对于卫星通信中广泛使用的CCSDS LDPC码，码长为8176，信息长度为7154，校验位有1022比特，其校验矩阵是规则的，即每一行都有32个1，每一列都有4个1，代表每一个校验节点都有32个变量节点与之相连；每一个变量节点都有4个校验节点与之相连。需要说明的是，每个校验节点i的输入数据为Z＝{Zij：hij＝1}，将其输入至预设的神经网络，由神经网络估计出对应校验节点i的归一化因子αNN。请参阅图3，预设的神经网络结构包括输入层、若干层隐藏层和输出层，输入层将变量节点提供给每个校验节点i的数据Z交给第一个隐藏层的每个神经元，输入层的神经元数量即校验节点i相连的变量节点j数量。隐藏层内部均为全连接网络：上一层的每一个神经元与下一层的每个神经元相连；每个神经元的输出都经过一个激活函数处理。最后一层隐藏层仅有一个神经元，其输出经过激活函数后给网络的输出层。输出层不做任何数据处理，仅用于输出数据αNN。作为本实施例中的优选方案，神经网络设置有一层输入层、10层隐藏层和一层输出层；输入层的神经元数量为32，无激活函数；10层隐藏层中，前8层隐藏层的神经元数量均为8，激活函数均为ReLU函数；第9层隐藏层的神经元数量为64，激活函数为ReLU函数，ReLU函数的表达式为y＝0，x＜0；y＝x，x＞0；第10层隐藏层的神经元数量为1，激活函数为Softplus函数，Softplus函数表达式为y＝log)；输出层的神经元数量为1，无激活函数。神经网络经过输入数据和参考数据的训练，并使用优化器进行反向传播和权值更新，最终完成收敛，便可得到性能较优的权值参数。需要说明的是，上述优选方案仅为一个优选实施例，根据实际的应用情形，对于每一个校验节点i，在每一次迭代计算中都会使用一次上述神经网络，且该神经网络适用于各种LDPC码型，包括规则码、非规则码，以及1/2，3/4，7/8，等各种码率，各隐藏层的神经元数量可以根据实际情况调整，以达到精确的估计效果。对于所有校验节点i相连的变量节点j数量相同的情形，例如规则码，则可以重复使用相同的网络参数；对于非规则码，即每个校验节点i相连的变量节点j数量有差异的情形，只需要将输入层的神经元数量相应更改，而后训练网络即可达到理想的译码效果。在本实施例中，根据更新后的归一化因子和所述第一软信息，计算每个所述校验节点传递给相连变量节点的第二软信息：Lij＝αNN×minj′∈Nj|Zij′|×Πj′∈Njsign；其中，i为校验节点，j为变量节点，Nj表示为从集合N中除去j，N表示所有与校验节点相连的变量节点的集合，min表示取最小值，sign为符号函数，αNN为归一化因子，Zij为第一软信息，Lij为第二软信息。需要说明的是，所有与校验节点i相连的变量节点j集合为N＝{j：hij＝1}，其中，hij表示校验矩阵第i行第j列的元素值；所有与变量节点j相连的校验节点i为M＝{i：hij＝1}。在迭代计算中，变量节点j传递给校验节点i的第一软信息记为Zij，校验节点i传递给变量节点j的第二软信息记为Lij。在本实施例中，根据更新后的第二软信息，以及所述对数似然比，计算出硬判决信息：Zj＝lj+∑i∈MLij；其中，lj为所述对数似然比，M表示所有与变量节点相连的校验节点；根据更新后的第二软信息和更新后的硬判决信息，对第一软信息进行更新操作：Zij＝Zj-Lij。需要说明的是，达到迭代停止的预设条件或迭代次数达到预设值后，则停止迭代计算，并获取迭代计算结束后当前的硬判决信息Zj。迭代停止的预设条件为bHT＝0，其中T为对校验矩阵H的转置，b＝，bi为对迭代后的硬判决信息进行硬判决译出的码矢量。作为本实施例的优选方案，迭代次数达到的预设值最大值为30，在运算中进行30次迭代。S103：对所述迭代后的硬判决信息进行硬判决译出码矢量，从而输出译码结果。具体地，对所述迭代后的硬判决信息进行硬判决译出码矢量：从而输出译码结果b＝，共n个比特，即图2中的判决比特。请参阅图4，其为现有技术与本发明实施例的译码方法的性能对比示意图，采用了CCSDS标准中的LDPC码。由图4可得，“○”标记的BP译码的性能最佳，在不同信噪比下其误码率最低，但由于BP译码中大量的非线性运算，导致运算十分复杂；而本发明实施例的优选方案，“╳”神经网络辅助的最小和译码的性能已非常接近BP译码，且规避了BP译码中大量的非线性运算，可作为BP译码的低复杂度替代方案；而“□”标记的归一化因子＝0.8的归一化最小和译码与“┼”标记的无归一化因子的最小和译码性能都没有本发明实施例的优选方案的性能优异。因此，本发明实施例的优选方案具有很大的应用前景，能够适配于实际的通信系统中。实施本发明实施例，具有如下效果：本发明的技术方案通过对第一软信息进行一次初始化操作后，进行第一软信息和第二软信息迭代计算，并且在每一次迭代中增加了神经网络对归一化因子的估值，保证了每一次迭代过程中都采取不同的归一化因子来对第二软信息进行计算，同时神经网络各层均采用了神经元全连接的方式，使得神经网络输出的归一化因子的准确性能够提高，并且也提高了后续对信息硬判决的译码结果的准确性，以达到精确的估计效果，使得译码性能得到了增强，误码率进一步降低，同时也规避了BP译码中大量的非线性运算，在保证性能的前提下尽可能降低了计算复杂度。实施例二相应地，请参阅图5，其为本发明实施例还提供一种基于神经网络的LDPC归一化最小和译码装置，包括：初始化模块201、迭代计算模块202和硬判决模块203。所述初始化模块201，用于获取LDPC码信号，并根据LDPC码信号，对第一软信息进行初始化。在本实施例中，初始化模块201用于将所述LDPC码信号进行解调，转换成对数似然比，并根据所述对数似然比，对第一软信息进行初始化。所述迭代计算模块202用于对所述第一软信息进行迭代计算，以使在每一次迭代计算中，根据预设的神经网络，来更新归一化因子，从而根据更新后的归一化因子和所述第一软信息，计算并更新第二软信息，继而根据更新后的第二软信息，计算并更新硬判决信息，根据更新后的第二软信息和更新后的硬判决信息，对第一软信息进行更新操作，直至达到迭代停止的预设条件或迭代次数达到预设值后，获得迭代后的硬判决信息。在本实施例中，迭代计算模块202用于将每个校验节点的输入数据，输入至预设的神经网络，从而得出对应于的每个校验节点的归一化因子；其中，在所述LDPC码信号的校验矩阵中，每一行对应一个校验节点，每一列对应的一个变量节点，所述校验矩阵由LDPC码信号的码长和信息长度求得。在本实施例中，迭代计算模块202还用于根据更新后的归一化因子和所述第一软信息，计算每个所述校验节点传递给相连变量节点的第二软信息：Lij＝αNN×minj′∈Nj|Zij′|×Πj′∈Njsign；其中，i为校验节点，j为变量节点，Nj表示为从集合N中除去j，N表示所有与校验节点相连的变量节点的集合，min表示取最小值，sign为符号函数，αNN为归一化因子，Zij为第一软信息，Lij为第二软信息。在本实施例中，迭代计算模块202还用于根据更新后的第二软信息，以及所述对数似然比，计算出硬判决信息：Zj＝lj+∑i∈MLij；其中，lj为所述对数似然比，M表示所有与变量节点相连的校验节点。在本实施例中，迭代计算模块202还用于根据更新后的第二软信息和更新后的硬判决信息，对第一软信息进行更新操作：Zij＝Zj-Lij。所述硬判决模块203，用于对所述迭代后的硬判决信息进行硬判决译出码矢量，从而输出译码结果。在本实施例中，硬判决模块203用于对所述迭代后的硬判决信息进行硬判决译出码矢量：从而输出译码结果b＝。实施本发明实施例，具有如下效果：本发明的技术方案通过对第一软信息进行一次初始化操作后，进行第一软信息和第二软信息迭代计算，并且在每一次迭代中增加了神经网络对归一化因子的估值，保证了每一次迭代过程中都采取不同的归一化因子来对第二软信息进行计算，同时神经网络各层均采用了神经元全连接的方式，使得神经网络输出的归一化因子的准确性能够提高，并且也提高了后续对信息硬判决的译码结果的准确性，以达到精确的估计效果，使得译码性能得到了增强，误码率进一步降低。以上所述的具体实施例，对本发明的目的、技术方案和有益效果进行了进一步的详细说明，应当理解，以上所述仅为本发明的具体实施例而已，并不用于限定本发明的保护范围。特别指出，对于本领域技术人员来说，凡在本发明的精神和原则之内，所做的任何修改、等同替换、改进等，均应包含在本发明的保护范围之内。
