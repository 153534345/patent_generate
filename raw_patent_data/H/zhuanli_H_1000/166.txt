标题title
一种基于AR的多人复杂交互会议方法和装置
摘要abst
本发明涉及数字化技术领域，提供了一种基于AR的多人复杂交互会议方法和装置。方法包括：当各参会人员单独发言时，建立正在发言的参会人员与声纹特征之间的关联关系；当多位参会人员同时发言时，使用各正在发言的第一参会人员的第一声纹特征对实时语音数据进行特征匹配，分离提取各第一参会人员的语义信息；对实时影像识别得到各操作物，将各第一参会人员的语义信息与各操作物进行匹配，使用与参会人员相同的颜色对匹配操作物进行标记。本发明通过对多人语音进行分离，对分离得到个人音频进行识别，根据识别结果对操作物进行标记，以便于远程操作人员在多人同时发言时，能够迅速识别各人的表述消息，提升多人会议的效率，确保多人会议的正常有序进行。
权利要求书clms
1.一种基于AR的多人复杂交互会议方法，其特征在于，在远程会议室中设置有第一摄像头、麦克风和显示屏，所述第一摄像头用于采集远程会议室中的实时会议室图像，所述麦克风用于采集各参会人员的实时语音数据，远程操作人员佩戴AR设备进行操作，所述AR设备上设置有第二摄像头，所述第二摄像头用于采集远程操作人员前方的实时影像，方法包括：接收来自远程会议室侧的实时会议室图像和实时语音数据，接收来自AR设备侧的实时影像，将所述实时影像传输到远程会议室侧，以在所述显示屏上进行显示，所述实时影像，将所述实时语音数据传输到AR设备侧，以在AR设备侧播放所述实时语音数据；并对各参会人员匹配相应的虚拟头像，将各参会人员与对应的虚拟头像传输给远程会议室侧和AR设备侧，以便于在所述显示屏上和所述AR设备上同步显示参会人员列表；对所述实时会议室图像进行人脸识别，得到各参会人员的人脸信息，根据人脸信息，识别各参会人员是否正在进行发言；当识别得到各参会人员单独进行发言时，对当前采集得到的实时语音数据进行特征提取，得到正在发言的参会人员的声纹特征，建立正在发言的参会人员与该声纹特征之间的关联关系；当识别得到存在多位参会人员同时进行发言时，根据所述人脸信息，识别得到正在发言的多位第一参会人员，从关联关系中找到各第一参会人员所对应的第一声纹特征，使用各第一声纹特征对当前采集得到的实时语音数据进行特征匹配，以从所述实时语音数据中分离得到各第一参会人员的个人音频，对各第一参会人员的个人音频进行语义识别，得到各第一参会人员的语义信息；对所述实时影像进行识别，得到所述实时影像中的各操作物，将各第一参会人员的语义信息与所述实时影像中的各操作物进行匹配，根据匹配结果生成指导信息，将所述指导信息传输给AR设备侧；其中，所述指导信息包括正在发言的各参会人员的信息、各参会人员所对应匹配上的操作物相关信息；AR设备根据所述指导信息，对参会人员列表中正在发言的参会人员使用不同的颜色进行标记，并使用与相应参会人员相同的颜色对该参会人员所匹配的操作物进行标记，以便于所述远程操作人员根据不同标记识别正在发言的参会人员和各参会人员所提及的操作物。2.根据权利要求1所述的基于AR的多人复杂交互会议方法，其特征在于，所述使用各第一声纹特征对当前采集得到的实时语音数据进行特征匹配，以从所述实时语音数据中分离得到各第一参会人员的个人音频，具体包括：对当前采集得到的实时语音数据进行短时傅里叶变换，得到混合频谱特征；将所述混合频谱特征与相应第一声纹特征进行拼接，得到参考频谱特征，将所述参考频谱特征输入至扩张卷积层，得到基础特征；将所述基础特征输入至语音分离模型，输出得到频谱掩码，将所述频谱掩码与所述混合频谱特征相乘，得到相应第一参会人员的个人频谱，使用当前采集得到的实时语音数据的相位谱对所述个人频谱进行恢复，得到相应第一参会人员的个人音频。3.根据权利要求1所述的基于AR的多人复杂交互会议方法，其特征在于，所述根据所述人脸信息，识别得到正在发言的多位第一参会人员，具体包括：在识别得到人脸信息后，选取各个人脸区域，使用特征点检测模型检测人脸区域的多个关键特征点，使用多个关键特征点之间的位置关系，计算得到人脸区域的特征值，根据所述特征值，识别该人脸区域是否处于张嘴状态；若在连续的多帧实时会议室图像中，相应人脸区域处于张嘴状态的帧数占比高于预设比例，且在处于张嘴状态的多帧实时会议室图像中，该人脸区域的特征值的方差大于第一预设值，则识别得到该人脸区域所对应的参会人员正在发言。4.根据权利要求3所述的基于AR的多人复杂交互会议方法，其特征在于，所述多个关键特征点包括嘴唇左边缘特征点P1、嘴唇右边缘特征点P2、上嘴唇左侧唇峰最高处特征点P3、上嘴唇右侧唇峰最高处特征点P4、与上嘴唇左侧唇峰最高处特征点相对的下嘴唇左侧特征点P5以及与上嘴唇右侧唇峰最高处特征点相对的下嘴唇右侧特征点P6；所述使用多个关键特征点之间的位置关系，计算得到人脸区域的特征值，具体包括：使用P2与P1之间的差值作为第一差值，使用P3与P5之间的差值作为第二差值，使用P4与P6之间的差值作为第三差值；使用第二差值与第三差值相加所得的结果除以所述第一差值，再乘以预设系数得到特征值；所述根据所述特征值，识别该人脸区域是否处于张嘴状态，具体包括：当所述特征值大于第一预设值时，识别得到该人脸区域为张嘴状态。5.根据权利要求1所述的基于AR的多人复杂交互会议方法，其特征在于，所述将各第一参会人员的语义信息与所述实时影像中的各操作物进行匹配，具体包括：在识别得到操作物后，从语义网络中选取与所述操作物所对应的操作物向量；计算在所述语义网络中，所述语义信息中的各个语义向量与各操作物向量之间的距离；从与相应语义向量之间的距离小于预设距离的操作物向量中，选取其中距离最小的一个操作物向量，该操作物向量所对应的操作物即为与第一参会人员的语义信息匹配的操作物。6.根据权利要求5所述的基于AR的多人复杂交互会议方法，其特征在于，所述方法还包括：当一个参会人员的语义信息匹配多个操作物时，按照各操作物所对应的语义向量在语义信息中的排列顺序，为各操作物进行排序，并将排序得到的顺序信息传输给AR设备；AR设备在将同一个参会人员所提及的多个操作物使用与参会人员相同的颜色进行标记的同时，还根据所述顺序信息，在操作物周边标记序号；其中，所述序号用于代表相应操作物被提及的顺序。7.根据权利要求1所述的基于AR的多人复杂交互会议方法，其特征在于，所述对所述实时影像进行识别，得到所述实时影像中的各操作物是基于对实施影像进行轮廓分析，将分析得到的各个轮廓在预设的物体库进行匹配实现的；当对于相应第一轮廓未在所述预设的物体库中未匹配到相应物体时，在实时影像中所述第一轮廓所在位置标记盲区标识，以提醒远程操作人员对所述第一轮廓进行人工识别。8.根据权利要求7所述的基于AR的多人复杂交互会议方法，其特征在于，所述远程操作人员对所述第一轮廓进行人工识别，具体包括：当识别到远程操作人员的手势指向所述第一轮廓所在位置，并采集到远程操作人员的语音数据时，对所述语音数据进行语义识别，得到所述第一轮廓所对应的操作物。9.根据权利要求1所述的基于AR的多人复杂交互会议方法，其特征在于，所述方法还包括：在参会人员所对应的虚拟头像旁，显示该参会人员的语义信息，当识别到远程操作人员的手势指向相应参会人员的语义信息时，播放该参会人员的个人音频。10.一种基于AR的多人复杂交互会议装置，其特征在于，包括：至少一个处理器；以及，与所述至少一个处理器通信连接的存储器；其中，所述存储器存储有可被所述至少一个处理器执行的指令，所述指令被所述处理器执行，用于执行权利要求1-9任一所述的基于AR的多人复杂交互会议方法。
说明书desc
技术领域本发明涉及数字化技术领域，特别是涉及一种基于AR的多人复杂交互会议方法和装置。背景技术基于互联网的视频通信技术被广泛应用于工作和生活的视频会议场景。随着增强现实硬件和软件技术的发展，基于增强现实技术的视频会议应用已经逐步成熟，并为更多人使用。其中，增强现实，是一种实时地计算摄影机影像的位置及角度并加上相应图像的数字化技术，一种将真实世界信息和虚拟世界信息“无缝”集成的新技术，这种技术的目标是在屏幕上把虚拟世界套在现实世界并进行互动，是把原本在现实世界的一定时间空间范围内很难体验到的实体信息通过电脑等科学技术，模拟仿真后再叠加，将虚拟的信息应用到真实世界，被人类感官所感知，从而达到超越现实的感官体验。真实的环境和虚拟的物体实时地叠加到了同一个画面或空间同时存在。增强现实技术，不仅展现了真实世界的信息，而且将虚拟的信息同时显示出来，两种信息相互补充、叠加。在视觉化的增强现实中，用户利用增强现实硬件，如头盔显示器或增强现实眼镜，把真实世界与电脑图形多重合成在一起，便可以看到真实的世界围绕着它。增强现实技术包含了多媒体、三维建模、实时视频显示及控制、多传感器融合、实时跟踪及注册、场景融合等新技术与新手段。增强现实提供了在一般情况下，不同于人类可以感知的信息。现有技术中，基于AR会议中交流的主要手段依旧是音频，但当存在多个人参加会议时，多个人之间往往会存在未有效把握发言时机，导致出现多人同时发言的情况，此时，在远端的操作人员可能无法准确辨别哪个参会人员具体说了什么，从而影响会议的进行效率。鉴于此，克服该现有技术所存在的缺陷是本技术领域亟待解决的问题。发明内容本发明要解决的技术问题是提供一种基于AR的多人复杂交互会议方法。本发明采用如下技术方案：第一方面，本发明提供了一种基于AR的多人复杂交互会议方法，在远程会议室中设置有第一摄像头、麦克风和显示屏，所述第一摄像头用于采集远程会议室中的实时会议室图像，所述麦克风用于采集各参会人员的实时语音数据，远程操作人员佩戴AR设备进行操作，所述AR设备上设置有第二摄像头，所述第二摄像头用于采集远程操作人员前方的实时影像，方法包括：接收来自远程会议室侧的实时会议室图像和实时语音数据，接收来自AR设备侧的实时影像，将所述实时影像传输到远程会议室侧，以在所述显示屏上进行显示，所述实时影像，将所述实时语音数据传输到AR设备侧，以在AR设备侧播放所述实时语音数据；并对各参会人员匹配相应的虚拟头像，将各参会人员与对应的虚拟头像传输给远程会议室侧和AR设备侧，以便于在所述显示屏上和所述AR设备上同步显示参会人员列表；对所述实时会议室图像进行人脸识别，得到各参会人员的人脸信息，根据人脸信息，识别各参会人员是否正在进行发言；当识别得到各参会人员单独进行发言时，对当前采集得到的实时语音数据进行特征提取，得到正在发言的参会人员的声纹特征，建立正在发言的参会人员与该声纹特征之间的关联关系；当识别得到存在多位参会人员同时进行发言时，根据所述人脸信息，识别得到正在发言的多位第一参会人员，从关联关系中找到各第一参会人员所对应的第一声纹特征，使用各第一声纹特征对当前采集得到的实时语音数据进行特征匹配，以从所述实时语音数据中分离得到各第一参会人员的个人音频，对各第一参会人员的个人音频进行语义识别，得到各第一参会人员的语义信息；对所述实时影像进行识别，得到所述实时影像中的各操作物，将各第一参会人员的语义信息与所述实时影像中的各操作物进行匹配，根据匹配结果生成指导信息，将所述指导信息传输给AR设备侧；其中，所述指导信息包括正在发言的各参会人员的信息、各参会人员所对应匹配上的操作物相关信息；AR设备根据所述指导信息，对参会人员列表中正在发言的参会人员使用不同的颜色进行标记，并使用与相应参会人员相同的颜色对该参会人员所匹配的操作物进行标记，以便于所述远程操作人员根据不同标记识别正在发言的参会人员和各参会人员所提及的操作物。优选的，所述使用各第一声纹特征对当前采集得到的实时语音数据进行特征匹配，以从所述实时语音数据中分离得到各第一参会人员的个人音频，具体包括：对当前采集得到的实时语音数据进行短时傅里叶变换，得到混合频谱特征；将所述混合频谱特征与相应第一声纹特征进行拼接，得到参考频谱特征，将所述参考频谱特征输入至扩张卷积层，得到基础特征；将所述基础特征输入至语音分离模型，输出得到频谱掩码，将所述频谱掩码与所述混合频谱特征相乘，得到相应第一参会人员的个人频谱，使用当前采集得到的实时语音数据的相位谱对所述个人频谱进行恢复，得到相应第一参会人员的个人音频。优选的，所述根据所述人脸信息，识别得到正在发言的多位第一参会人员，具体包括：在识别得到人脸信息后，选取各个人脸区域，使用特征点检测模型检测人脸区域的多个关键特征点，使用多个关键特征点之间的位置关系，计算得到人脸区域的特征值，根据所述特征值，识别该人脸区域是否处于张嘴状态；若在连续的多帧实时会议室图像中，相应人脸区域处于张嘴状态的帧数占比高于预设比例，且在处于张嘴状态的多帧实时会议室图像中，该人脸区域的特征值的方差大于第一预设值，则识别得到该人脸区域所对应的参会人员正在发言。优选的，所述多个关键特征点包括嘴唇左边缘特征点P1、嘴唇右边缘特征点P2、上嘴唇左侧唇峰最高处特征点P3、上嘴唇右侧唇峰最高处特征点P4、与上嘴唇左侧唇峰最高处特征点相对的下嘴唇左侧特征点P5以及与上嘴唇右侧唇峰最高处特征点相对的下嘴唇右侧特征点P6；所述使用多个关键特征点之间的位置关系，计算得到人脸区域的特征值，具体包括：使用P2与P1之间的差值作为第一差值，使用P3与P5之间的差值作为第二差值，使用P4与P6之间的差值作为第三差值；使用第二差值与第三差值相加所得的结果除以所述第一差值，再乘以预设系数得到特征值；所述根据所述特征值，识别该人脸区域是否处于张嘴状态，具体包括：当所述特征值大于第一预设值时，识别得到该人脸区域为张嘴状态。优选的，所述将各第一参会人员的语义信息与所述实时影像中的各操作物进行匹配，具体包括：在识别得到操作物后，从语义网络中选取与所述操作物所对应的操作物向量；计算在所述语义网络中，所述语义信息中的各个语义向量与各操作物向量之间的距离；从与相应语义向量之间的距离小于预设距离的操作物向量中，选取其中距离最小的一个操作物向量，该操作物向量所对应的操作物即为与第一参会人员的语义信息匹配的操作物。优选的，所述方法还包括：当一个参会人员的语义信息匹配多个操作物时，按照各操作物所对应的语义向量在语义信息中的排列顺序，为各操作物进行排序，并将排序得到的顺序信息传输给AR设备；AR设备在将同一个参会人员所提及的多个操作物使用与参会人员相同的颜色进行标记的同时，还根据所述顺序信息，在操作物周边标记序号；其中，所述序号用于代表相应操作物被提及的顺序。优选的，所述对所述实时影像进行识别，得到所述实时影像中的各操作物是基于对实施影像进行轮廓分析，将分析得到的各个轮廓在预设的物体库进行匹配实现的；当对于相应第一轮廓未在所述预设的物体库中未匹配到相应物体时，在实时影像中所述第一轮廓所在位置标记盲区标识，以提醒远程操作人员对所述第一轮廓进行人工识别。优选的，所述远程操作人员对所述第一轮廓进行人工识别，具体包括：当识别到远程操作人员的手势指向所述第一轮廓所在位置，并采集到远程操作人员的语音数据时，对所述语音数据进行语义识别，得到所述第一轮廓所对应的操作物。优选的，所述方法还包括：在参会人员所对应的虚拟头像旁，显示该参会人员的语义信息，当识别到远程操作人员的手势指向相应参会人员的语义信息时，播放该参会人员的个人音频。第二方面，本发明还提供了一种基于AR的多人复杂交互会议装置，用于实现第一方面所述的基于AR的多人复杂交互会议方法，所述装置包括：至少一个处理器；以及，与所述至少一个处理器通信连接的存储器；其中，所述存储器存储有可被所述至少一个处理器执行的指令，所述指令被所述处理器执行，用于执行第一方面所述的基于AR的多人复杂交互会议方法。第三方面，本发明还提供了一种非易失性计算机存储介质，所述计算机存储介质存储有计算机可执行指令，该计算机可执行指令被一个或多个处理器执行，用于完成第一方面所述的基于AR的多人复杂交互会议方法。本发明通过对多人语音进行分离，并对分离得到个人音频进行识别，根据识别结果对操作物进行标记，从而便于远程操作人员在多人同时发言时，能够迅速识别各人的表述消息，从而提升多人会议的效率，确保多人会议的正常有序进行。附图说明为了更清楚地说明本发明实施例的技术方案，下面将对本发明实施例中所需要使用的附图作简单地介绍。显而易见地，下面所描述的附图仅仅是本发明的一些实施例，对于本领域普通技术人员来讲，在不付出创造性劳动的前提下，还可以根据这些附图获得其他的附图。图1是本发明实施例提供的一种基于AR的多人复杂交互会议方法中远程会议室、服务器和AR设备之间的架构示意图；图2是本发明实施例提供的第一种基于AR的多人复杂交互会议方法的流程示意图；图3是本发明实施例提供的一种基于AR的多人复杂交互会议方法中远程会议室、服务器和AR设备之间的交互示意图；图4是本发明实施例提供的一种基于AR的多人复杂交互会议方法中指导信息的结构示意图；图5是本发明实施例提供的第一种基于AR的多人复杂交互会议方法中AR设备侧的示意图；图6是本发明实施例提供的第二种基于AR的多人复杂交互会议方法中AR设备侧的示意图；图7是本发明实施例提供的又一种基于AR的多人复杂交互会议方法中指导信息的结构示意图；图8是本发明实施例提供的第二种基于AR的多人复杂交互会议方法的流程示意图；图9是本发明实施例提供的第三种基于AR的多人复杂交互会议方法的流程示意图；图10是本发明实施例提供的又一种基于AR的多人复杂交互会议方法的示意图；图11是本发明实施例提供的再一种基于AR的多人复杂交互会议方法的示意图；图12是本发明实施例提供的第四种基于AR的多人复杂交互会议方法的流程示意图；图13是本发明实施例提供的第五种基于AR的多人复杂交互会议方法的流程示意图；图14是本发明实施例提供的第六种基于AR的多人复杂交互会议方法的流程示意图；图15是本发明实施例提供的第三种基于AR的多人复杂交互会议方法中AR设备侧的示意图；图16是本发明实施例提供的一种基于AR的多人复杂交互会议方法中初始厂房环境模型中水泥泵喷浆机的示意图；图17是本发明实施例提供的一种基于AR的多人复杂交互会议方法中前方实际厂房图像中水泥泵喷浆机的示意图；图18是本发明实施例提供的另一种基于AR的多人复杂交互会议方法的示意图；图19是本发明实施例提供的第四种基于AR的多人复杂交互会议方法中AR设备侧的示意图；图20是本发明实施例提供的第五种基于AR的多人复杂交互会议方法中AR设备侧的示意图；图21是本发明实施例提供的第六种基于AR的多人复杂交互会议方法中AR设备侧的示意图；图22是本发明实施例提供的一种基于AR的多人复杂交互会议装置的架构示意图。具体实施方式为了使本发明的目的、技术方案及优点更加清楚明白，以下结合附图及实施例，对本发明进行进一步详细说明。应当理解，此处所描述的具体实施例仅仅用以解释本发明，并不用于限定本发明。本发明中术语“第一”、“第二”等仅用于描述目的，而不能理解为指示或暗示相对重要性或者隐含指明所指示的技术特征的数量。由此，限定有“第一”、“第二”等的特征可以明示或者隐含地包括一个或者更多个该特征。在本申请的描述中，除非另有说明，“多个”的含义是两个或两个以上。此外，下面所描述的本发明各个实施方式中所涉及到的技术特征只要彼此之间未构成冲突就可以相互组合。实施例1:本发明实施例1提供了一种基于AR的多人复杂交互会议方法，在远程会议室中设置有第一摄像头、麦克风和显示屏，所述第一摄像头用于采集远程会议室中的实时会议室图像，所述麦克风用于采集各参会人员的实时语音数据，远程操作人员佩戴AR设备进行操作，所述AR设备上设置有第二摄像头，所述第二摄像头用于采集远程操作人员前方的实时影像，在实际使用中，所述AR设备可以是AR眼镜，在远程会议室中设置有主机，所述主机和所述AR设备连接到服务器，从而实现通信，其中，所述AR设备可以是直接连接到服务器上的，如图1所示，也可以是通过蓝牙等连接终端设备，再通过终端设备连接到服务器的，在此需要说明的是，在本实施例的后续内容中，远程会议室侧代指远程会议室侧主机，AR设备侧代指AR眼镜，或用于控制AR设备的终端设备。如图2所示，本实施例所述方法包括：在步骤201中，接收来自远程会议室侧的实时会议室图像和实时语音数据，接收来自AR设备侧的实时影像，将所述实时影像传输到远程会议室侧，以在所述显示屏上进行显示，所述实时影像，将所述实时语音数据传输到AR设备侧，以在AR设备侧播放所述实时语音数据；并对各参会人员匹配相应的虚拟头像，将各参会人员与对应的虚拟头像传输给远程会议室侧和AR设备侧，以便于在所述显示屏上和所述AR设备上同步显示参会人员列表。在步骤202中，对所述实时会议室图像进行人脸识别，得到各参会人员的人脸信息，根据人脸信息，识别各参会人员是否正在进行发言。在步骤203中，当识别得到各参会人员单独进行发言时，对当前采集得到的实时语音数据进行特征提取，得到正在发言的参会人员的声纹特征，建立正在发言的参会人员与该声纹特征之间的关联关系；本实施例是考虑到在实际使用中，参会人员往往会在会议起始阶段进行自我介绍，此时，各参会人员通常是单独进行发言的，本实施例则利用此时间段采集各参会人员的声纹特征，建立各参会人员与声纹特征之间的关联关系，从而为后续会议的正常进行做准备。其中，所述声纹特征可以是幅度谱、梅尔频谱、梅尔倒谱等特征中的一种或多种，其对应的特征提取为现有技术，在此不加以赘述。在步骤204中，当识别得到存在多位参会人员同时进行发言时，根据所述人脸信息，识别得到正在发言的多位第一参会人员，从关联关系中找到各第一参会人员所对应的第一声纹特征，使用各第一声纹特征对当前采集得到的实时语音数据进行特征匹配，以从所述实时语音数据中分离得到各第一参会人员的个人音频，对各第一参会人员的个人音频进行语义识别，得到各第一参会人员的语义信息。在步骤205中，对所述实时影像进行识别，得到所述实时影像中的各操作物，将各第一参会人员的语义信息与所述实时影像中的各操作物进行匹配，根据匹配结果生成指导信息，将所述指导信息传输给AR设备侧；其中，所述指导信息包括正在发言的各参会人员的信息、各参会人员所对应匹配上的操作物相关信息；在实际使用中，所述指导信息还传输给远程会议室侧，以便于在远程会议室侧的显示屏上显示，实现所述AR设备侧与所述远程会议室侧的显示屏的影像同步，如图3所示。在实际使用中，所述指导信息如图4所示，包括参会人员数量和各参会人员相关信息，每个参会人员相关信息至少包括参会人员id、操作物数量和终止符，当相应参会人员未发言时，操作物数量为0，当相应参会人员正在发言时，所述参会人员相关信息还包括各操作物相关信息,每个操作物信息包括操作物序号、轮廓信息长度和轮廓信息，其中，所述轮廓信息长度即轮廓信息所占用的比特位数，从而在接收侧接收到所述指导信息时，根据所述轮廓信息长度解析得到对应的轮廓信息，所述轮廓信息即在最新的实时影像中操作物所对应的轮廓，以便于在后续步骤206中，对操作物的轮廓进行标记。在所述指导信息中，参会人员数量、参会人员id、操作物数量、操作物序号和操作物数量所占用的比特位数量均是由本领域技术人员根据经验分析得到并预先设置的，轮廓信息所对应的长度由自身所占用的比特位数确定，不同轮廓信息所对应的长度可能不同。在步骤206中，AR设备根据所述指导信息，对参会人员列表中正在发言的参会人员使用不同的颜色进行标记，并使用与相应参会人员相同的颜色对该参会人员所匹配的操作物进行标记，以便于所述远程操作人员根据不同标记识别正在发言的参会人员和各参会人员所提及的操作物。以图5所示举例而言，若远程操作人员正在实验室中进行某项试验，对应AR设备所采集到的实验室环境图像以实时影像的形式传输到服务器，服务器对所述实时影像进行识别得到存在多个操作物分别为：铁架台、试剂瓶、酒精灯、烧杯和玻璃试管，而服务器经过对实时会议室图像分析得到当前存在两位参会人员同时进行了发言，分别为人员1和人员3，对人员1和人员3的个人音频进行分离，并进行语义识别得到人员1的语义信息为“从试剂瓶中取出试剂，倒入烧杯中”，而人员3的语义信息为“点燃酒精灯”，则服务器向AR设备侧发送指导信息如图7所示，其中，参会人员1相关信息中包含两条操作物相关信息，分别为试剂瓶的相关信息和烧杯的相关信息，参会人员3相关信息中包含一条操作物相关信息，即酒精灯相关信息。AR设备侧在接收到指导信息后，对指导信息进行解析，对对应操作物数量不为零的参会人员使用不同颜色进行标记，如在图5中，对人员1和人员3进行标记，并将人员1所对应的操作物使用与人员1相同的标记形式进行标记，将人员3所对应的操作物使用与人员3相同的标记形式进行标记，并将各人员的语义信息中与操作物匹配的单词突出显示。在此需要说明的是，图5仅仅是为了表现本发明技术方案而做的示意性呈现，并非代表实际使用中远程操作人员所看到的实际影像，在实际使用中，远程操作人员通过AR设备所看到的为三维的现实环境影像，而并非图5所示的二维平面呈现，且在实际使用中，各参会人员使用不同颜色标记，在图5中为了表现各标记的颜色不同，使用颜色一和颜色二进行标示说明。在实际使用中，所述操作物不仅仅代指独立的物品，还可以是相应设备上的装配零件，此时，所述对所述实时影像进行识别，得到所述实时影像中的各操作物具体包括：先对相对独立的设备进行识别，再根据设备所对应的预设零件轮廓库，识别设备中的各个零件。独立的物品或设备均是通过在预设的物品库中进行匹配进行识别的。以图6举例而言，当识别得到实时会议室图像中存在水泥泵喷浆机这一设备时，在水泥泵喷浆机所对应的零件轮廓库中进行零件匹配，从而识别各零件。当人员1的语义信息为“检查料斗中是否存在沉积，并检查振动器是否正常运行”，与此同时，人员3的语义信息为“检查喷浆管道是否正常”时，对应标识操作物“料斗”“振动器”和“喷浆管道”的轮廓。本实施例通过对多人语音进行分离，并对分离得到个人音频进行识别，根据识别结果对操作物进行标记，从而便于远程操作人员在多人同时发言时，能够迅速识别各人的表述消息，从而提升多人会议的效率，确保多人会议的正常有序进行。在可选的实施方式中，所述使用各第一声纹特征对当前采集得到的实时语音数据进行特征匹配，以从所述实时语音数据中分离得到各第一参会人员的个人音频，如图8所示，具体包括：在步骤301中，对当前采集得到的实时语音数据进行短时傅里叶变换，得到混合频谱特征。在步骤302中，将所述混合频谱特征与相应第一声纹特征进行拼接，得到参考频谱特征，将所述参考频谱特征输入至扩张卷积层，得到基础特征；所述扩张卷积层用于捕捉低级别音频特征。所述扩张卷积层包括一个或多个卷积神经网络。如包含8层卷积神经网络。在步骤303中，将所述基础特征输入至语音分离模型，输出得到频谱掩码，将所述频谱掩码与所述混合频谱特征相乘，得到相应第一参会人员的个人频谱，使用当前采集得到的实时语音数据的相位谱对所述个人频谱进行恢复，得到相应第一参会人员的个人音频。其中，所述语音分离模型是由本领域技术人员预先训练得到，所述语音分离模型可以是深度学习模型，如PIDNet模型等。在实际应用场景下，所述根据所述人脸信息，识别得到正在发言的多位第一参会人员，如图9所示，具体包括：在步骤401中，在识别得到人脸信息后，选取各个人脸区域，使用特征点检测模型检测人脸区域的多个关键特征点，使用多个关键特征点之间的位置关系，计算得到人脸区域的特征值，根据所述特征值，识别该人脸区域是否处于张嘴状态。在步骤402中，若在连续的多帧实时会议室图像中，相应人脸区域处于张嘴状态的帧数占比高于预设比例，且在处于张嘴状态的多帧实时会议室图像中，该人脸区域的特征值的方差大于第一预设值，则识别得到该人脸区域所对应的参会人员正在发言。所述预设比例和第一预设值由本领域技术人员根据经验分析得到。所述连续的多帧实时会议室图像是由采集到的实时语音数据确定得到的，具体的：根据实时语音数据的幅度，确定发言起始时间t1和发言终止时间t2，对t1~t2之间的实时会议室图像执行上述步骤401-步骤402，并在执行步骤402时，使用预设大小w的滑窗和预设步长s选取多个滑窗，对每个滑窗内的连续的多帧实时会议室图像执行上述步骤402。如图10所示，每间隔一个预设步长s，选取一个滑窗，滑窗大小为w，如图10中距离t1最近形成的两个滑窗为win1和win2，当在滑窗中检测到相应人脸区域所对应的特征值的方差大于第一预设值，且人脸区域处于张嘴状态的帧数占比高于预设比例时，认为该人脸区域所对应参会人员在该滑窗时间段中正在发言，当识别得到存在多个连续的滑窗中某一参会人员始终在发言时，将多个滑窗所对应的时间段整体作为一个分析主体，进行个人音频的提取和语义识别。其中，所述预设大小w和预设步长s由本领域技术人员根据经验分析得到。所述根据实时语音数据的幅度，确定发言起始时间t1和发言终止时间t2，具体包括：当检测到相应位置的幅度高于第一预设幅度时，以该位置为起点，选取大小为w的滑窗，计算在滑窗内的平均幅度，若平均幅度高于第二预设幅度，则该位置为发言起始时间t1，同样的，在检测到发言时间后，若检测到相应位置的幅度低于第三预设幅度，则以该位置为起点，选取大小为w的滑窗，计算在滑窗内的平均幅度，若平均幅度低于第四预设幅度，则该位置为发言终止时间t2。所述第一预设幅度、第二预设幅度、第三预设幅度和第四预设幅度均由本领域技术人员根据经验分析得到。在可选的实施方式中，所述特征点检测模型可以是dlib库的shape_predictor_68_face_landmarks模型，如图11所述，所述多个关键特征点包括嘴唇左边缘特征点P1、嘴唇右边缘特征点P2、上嘴唇左侧唇峰最高处特征点P3、上嘴唇右侧唇峰最高处特征点P4、与上嘴唇左侧唇峰最高处特征点相对的下嘴唇左侧特征点P5以及与上嘴唇右侧唇峰最高处特征点相对的下嘴唇右侧特征点P6；所述使用多个关键特征点之间的位置关系，计算得到人脸区域的特征值，如图12所示，具体包括：在步骤501中，使用P2与P1之间的差值作为第一差值，使用P3与P5之间的差值作为第二差值，使用P4与P6之间的差值作为第三差值。在步骤502中，使用第二差值与第三差值相加所得的结果除以所述第一差值，再乘以预设系数得到特征值；所述预设系数由本领域技术人员根据经验分析得到，在可选的实施方式中，所述预设系数的取值范围为1.5~2.5。以公式的形式表现为：其中，k为预设系数。所述根据所述特征值，识别该人脸区域是否处于张嘴状态，具体包括：当所述特征值大于第一预设值时，识别得到该人脸区域为张嘴状态。在实际应用场景下，所述将各第一参会人员的语义信息与所述实时影像中的各操作物进行匹配，如图13所示，具体包括：在步骤601中，在识别得到操作物后，从语义网络中选取与所述操作物所对应的操作物向量；所述操作物向量即语义网络中操作物的名称所对应的向量。在步骤602中，计算在所述语义网络中，所述语义信息中的各个语义向量与各操作物向量之间的距离；其中，所述语义信息包含多个语义向量，每个语义向量代表一个单词。在步骤603中，从与相应语义向量之间的距离小于预设距离的操作物向量中，选取其中距离最小的一个操作物向量，该操作物向量所对应的操作物即为与第一参会人员的语义信息匹配的操作物。所述预设距离由本领域技术人员根据经验分析得到。在优选的实施方式中，如图14所示，所述方法还包括：在步骤701中，当一个参会人员的语义信息匹配多个操作物时，按照各操作物所对应的语义向量在语义信息中的排列顺序，为各操作物进行排序，并将排序得到的顺序信息传输给AR设备。在步骤702中，AR设备在将同一个参会人员所提及的多个操作物使用与参会人员相同的颜色进行标记的同时，还根据所述顺序信息，在操作物周边标记序号；其中，所述序号用于代表相应操作物被提及的顺序，如图5所示。其中，所述对所述实时影像进行识别，得到所述实时影像中的各操作物是基于对实施影像进行轮廓分析，将分析得到的各个轮廓在预设的物体库进行匹配实现的；在一些方式中，还存在物体库中不存在相应操作物，或因观察角度的不同而导致操作物未被正确识别的情况，本实施例还提供了一种优选的实施方式，即当对于相应第一轮廓未在所述预设的物体库中未匹配到相应物体时，在实时影像中所述第一轮廓所在位置标记盲区标识，以提醒远程操作人员对所述第一轮廓进行人工识别。如图15所示，当从左到右的第二个操作物未能匹配到时，在第二操作物所在位置标识盲区标识。所述预设的物体库由本领域技术人员预先对会议的应用场景需求进行分析设置的。其中，所述远程操作人员对所述第一轮廓进行人工识别，具体包括：当识别到远程操作人员的手势指向所述第一轮廓所在位置，并采集到远程操作人员的语音数据时，对所述语音数据进行语义识别，得到所述第一轮廓所对应的操作物。即由远程操作人员指定相应操作物具体是什么，并在远程操作人员指定后，将远程操作人员的语义信息转换为语义向量，该语义向量即为所指定的操作物所对应的操作物向量。在一些实施例中，所述方法还包括：在参会人员所对应的虚拟头像旁，显示该参会人员的语义信息，当识别到远程操作人员的手势指向相应参会人员的语义信息时，播放该参会人员的个人音频，以为远程操作人员指导操作。实施例2:在实施例1的基础上，本实施例还提供了一种优选的实施方式，预先在厂家服务器中预设初始厂房环境模型，远程操作人员佩戴AR设备在厂房中进行操作，所述AR设备通过蓝牙连接至远程操作人员的终端，所述终端在经过安全验证后，连接至所述厂家服务器，其中，所述AR设备可以是AR眼镜，所述初始厂房环境模型是在新建厂房，或在厂房中装配新设备时建立得到的，所述初始厂房环境模型中包含各设备的初始形状、各设备的名称、各设备在厂房中的位置和厂房中的通行路径等，在此需要说明的是，本实施例中所述的厂房代指安装有相应设备的空间，而并非代指该空间必然位于室内，如在实际的工业生产中，一些设备可能位于室外，此时，室外也试做厂房的一部分。所述安全验证的方式由厂家提供，如使用证书签发，报文加解密、用户登录等方式实现，本实施例所述方法包括：所述厂家服务器接收来自终端的前方实际厂房图像，将所述前方实际厂房图像与所述初始厂房环境模型中的各个初始设备进行一次匹配，根据一次匹配结果，确定远程操作人员操作的实际设备。将所述实际设备与所述初始厂房环境模型中的对应初始设备进行二次匹配，根据二次匹配结果，判断所述实际设备的操作面是否存在沉积物，并在判断得到存在沉积物时，计算沉积物的厚度；其中，所述一次匹配用于匹配实际设备与相应初始设备之间的轮廓相似度是否大于预设相似度，在匹配得到实际设备与第一初始设备之间的轮廓相似度大于预设相似度后，将实际设备与所述第一初始设备进行二次匹配，所述二次匹配用于在将实际设备的各个边缘与所述第一初始设备匹配上之后，计算沉积物的沉积面到达相应边缘的距离，根据该距离计算得到沉积物的厚度；所述轮廓相似度可使用matchShapes函数获取得到。所述预设相似度由本领域技术人员根据经验分析得到。当实际设备与第一初始设备在一次匹配中匹配上时，认为该实际设备即为第一初始设备在经过使用后的状态。所述第二匹配则可以认为是将设备的初始状态与设备的当前状态。当所述沉积物的厚度大于预设厚度时，判断得到需要进行去除沉积物处理，在AR设备上显示提示信息和/或发出提示语音信息，以提醒远程操作人员在进行操作前去除所述沉积物。所述预设厚度由本领域技术人员根据经验分析得到，对于不同类型的实际设备，可设置不同的预设厚度。以某施工工地上的水泥泵喷浆机举例而言，在初始厂房环境模型中，建立有未使用时的水泥泵喷浆机的三维模型，如图16所示，其工作原理为：将混合好的浆料添加到料斗中，由安装在料斗侧壁的振动器和料斗底部的叶片，将浆料推送至出口，使用高压泵或空气压缩的形式将出口处的浆料喷射到需要覆盖的位置，浆料通常为水泥、砂子、水和其他添加剂的混合物，当上一次施工结束后，料斗中的浆料未及时清理疏通时，极可能导致在下一次使用时，料斗中还沉积有部分浆料，导致料斗可用容积减小，甚至堵塞叶片，导致叶片无法正常转动。当对前方实际厂房图像进行一次匹配得到前方实际厂房图像中存在水泥泵喷浆机后，将前方厂房图像中的水泥泵喷浆机与初始厂房环境模型中未经使用的水泥泵喷浆机进行边缘匹配，即对前方厂房图像中的水泥泵喷浆机进行相应放大或缩小操作，使其与初始厂房环境模型中的水泥泵喷浆机边缘对齐后，得到前方厂房图像中的水泥泵喷浆机相对初始厂房环境模型中的突出部分，该突出部分即为沉积物，根据前方厂房图像的缩放比例和初始厂房环境模型中水泥泵喷浆机的尺寸信息。如前方厂房图像中的水泥泵喷浆机如图17所示时，当前方厂房图像中的水泥泵喷浆机与初始厂房环境模型中的水泥泵喷浆机边缘对齐后，如图18所示，测量得到前方厂房图像中水泥泵喷浆机的料斗内壁还存在沉积物，导致测量得到的料斗内壁最大直径为L2，而初始厂房环境模型中水泥泵喷浆机的料斗内壁最大直径为L1，则沉积物的厚度T=/2，当计算得到的厚度大于本领域技术人员的预设厚度时，在AR设备上显示提示信息，如图19所示。本实施例通过厂家服务器侧获取AR设备侧的图像，从而根据图像和自身存储的初始厂家环境模型进行匹配，对匹配得到的设备进行沉积物的检测，从而能够为远程操作人员提供有效技术参考，以便于后续专家对远程操作人员正常进行技术指导，且由于初始厂家环境模型和沉积物的检测识别均交由厂家服务器侧进行处理，从而能够确保厂家的信息安全，避免模型在传输中的信息泄露。在优选的实施方式中，在判断得到需要进行去除沉积物处理后，所述方法还包括：从所述初始厂房环境模型中，找到相应的去沉积设备和/或去沉积试剂；识别所述沉积物的种类，根据沉积物的种类、沉积物的厚度、所述去沉积设备或去沉积试剂，为所述远程操作人员生成一种或多种去沉积方案，将所述一种或多种去沉积方案显示在所述AR设备上。当远程操作人员选定一种去沉积方案后，在AR设备中显示去向相应去沉积设备和/或去沉积试剂的导航信息；其中，先依次按照实际设备的种类推断沉积物的种类，若无法将沉积物的种类限定到单一种类下，则再根据历史采集得到的操作人员的操作记录进行推断。由于在实际使用中，一种设备可能能够处理多种物料，不同物料附着的牢固程度不同，所对应的去沉积方案也可能不同，故先通过实际设备的种类进行沉积物种类的限定，如对于水泥泵喷浆机而言，其处理的物料为水泥，当通过实际设备的种类无法将沉积物种类限定到单一种类下时，再根据历史采集到的操作人员的操作记录进行判断，在该实施方式下，所有历史操作人员佩戴AR设备在厂房中进行操作的历史厂房图像均被传输到厂家服务器中，厂家服务器对历史历史厂房图像进行分析得到历史操作人员获取了哪些物料，将哪些物料添加到了实际设备中，以历史上最近一次添加到实际设备中的物料作为实际设备的沉积物。所能够处理的沉积物的种类和对应的去沉积方案是由本领域技术人员预先设置存储的，所述将沉积物的种类限定到单一种类下并非代指将沉积物的种类限定到某一单一化合物，而是限定至本领域技术人员预先设置存储的沉积物种类中的一种。如当确定实际设备为水泥泵喷浆机后，可确定沉积物为水泥，从而获取本领域技术人员预先设置的在沉积不同厚度的水泥时所对应的去沉积方案，举例而言，当水泥的沉积厚度小于等于0.5cm时，认为沉积物对于实际设备的正常工作影响较小，无需处理，当水泥的沉积厚度大于0.5cm小于1.5cm时，认为水泥沉积厚度较薄，此时，可通过人工使用工具钎敲料斗的方式，或导入水泥浆，通过启动振动器，并反复正反启动叶片的方式，使附着的水泥从料斗内壁脱落；而水泥的沉积厚度大于等于1.5cm且小于等于5cm时，认为通过上述人工使用锤子钎敲或导入水泥浆，通过启动振动器，并反复正反启动叶片的方式，使附着的水泥从料斗内壁脱落的方式可行，并且还可使用风镐对料斗内壁附着的水泥进行开凿，当水泥的沉积厚度大于5cm时，认为通过简单的物理工具或水泥泵喷浆机自身已无法处理，需使用风镐对料斗内壁附着的水泥进行开凿，或通过使用水泥溶解剂对附着水泥进行溶解，本领域技术人员预先将去沉积方案存储在厂家服务器中，在计算得到沉积物的厚度后，厂家服务器选择相应的去沉积方案发送给AR设备，以在AR设备中显示去沉积方案，以水泥泵喷浆机的料斗中沉积水泥的厚度T为3cm举例而言，则如图19所示，显示三种可选的去沉积方案。所述远程操作人员选定一种去沉积方案可以通过手势识别实现，也可通过AR设备上所提供的硬件按钮实现。所述在AR设备中显示去向相应去沉积设备或去沉积试剂的导航信息，具体包括：厂家服务器根据一次匹配结果，确定远程操作人员的所在位置，并从所述初始厂房环境模型中找到相应沉积方案所对应的去沉积设备和/或去沉积试剂的所在位置；所述根据一次匹配结果，确定远程操作人员的所在位置即把第一初始设备在厂家环境模型中的所在位置作为远程操作人员的所在位置。根据去沉积设备和/或去沉积试剂的所在位置和远程操作人员的所在位置，生成去往去沉积设备和/或去沉积试剂的最短路径；将所述最短路径发送给所述终端，以便于所述终端根据所述最短路径和远程操作人员的实时位置，在AR设备上显示相应的行进方向。如在初始建立厂房时，在厂房的相应位置放置了风镐，则该风镐的所在位置也同样被建立到初始厂房环境模型中。各去沉积方案所需的去沉积设备和/或去沉积试剂可以是本领域技术人员预先设置存储的，也可在获取到相应去沉积方案后，从去沉积方案中提取语义信息，从语义信息中分析得到所需的去沉积设备和/或去沉积试剂，在初始厂房环境模型中查找是否存在该去沉积设备和/或去沉积试剂，若存在，则根据去沉积设备和/或去沉积试剂的所在位置、远程操作人员的实时位置，以及初始厂房环境模型中的环境和设备布局，生成最短路径。举例而言，当远程操作人员选中如图19中的方案3时，如图20所示，在AR设备的左上角显示完整导航路线，并显示起点位置、终点位置和远程操作人员的当前位置，同时，在AR设备的上方显示为远程操作人员指示行进方向的箭头。在可选的实施方式中，当厂家服务器根据远程操作人员的前方实际厂房图像识别得到远程操作人员到达去沉积设备和/或去沉积试剂所在位置时，从前方实际厂房图像中识别所述去沉积设备和/或去沉积试剂，对所述去沉积设备和/或去沉积试剂进行标记，以便于远程操作人员识别所述去沉积设备和/或去沉积试剂。在实际使用中，考虑到远程操作人员还需要对远程操作人员进行指导，本实施例还提供了一种优选的实施方式，即在专家会议室中设置有主机、第一摄像头、麦克风和显示屏，所述主机在经过安全验证后，连接至所述厂家服务器，所述方法还包括：所述主机对所述实时会议室图像进行人脸识别，得到各参会人员的人脸信息，根据人脸信息，识别各参会人员是否正在进行发言。当判断得到相应参会人员正在进行发言时，对当前的实时语音数据进行语义识别，得到参会人员的语义信息。将所述参会人员的语义信息传输给所述厂家服务器，所述厂家服务器将所述语义信息与所述初始厂房环境模型中的各初始设备进行匹配，得到参会人员所提及的第一初始设备，根据一次匹配结果，判断在所述前方实际厂房图像中，是否存在与所述第一初始设备对应的第一实际设备。若在所述前方实际厂房图像中，存在与所述第一初始设备对应的第一实际设备，则所述厂家服务器向所述终端发送指导信息，以便于所述终端根据所述指导信息，在所述AR设备上对所述第一实际设备进行标记显示，如图21所示,参会人员的语音信息同样显示在AR设备上，并对第一实际设备所对应匹配的单词突出显示；其中，所述指导信息包括正在发言的参会人员信息和第一实际设备相关信息。在实际使用中，所述指导信息还传输给远程会议室侧，以便于在远程会议室侧的显示屏上显示，实现所述AR设备侧与所述远程会议室侧的显示屏的影像同步。在实际使用中，所述指导信息包括参会人员id、第一实际设备的序号、第一实际设备的轮廓信息长度和第一实际设备的轮廓信息，其中，所述轮廓信息长度即轮廓信息所占用的比特位数，从而在接收侧接收到所述指导信息时，根据所述轮廓信息长度解析得到对应的轮廓信息，所述轮廓信息即在前方实际厂房图像中第一实际设备所对应的轮廓，以便于后续对第一实际设备的轮廓进行标记。在此需要说明的是，实施例1中的方法在本实施例中均适用。在优选的实施方式中，若在所述前方实际厂房图像中，不存在与所述第一初始设备对应的第一实际设备，所述方法还包括：厂家设备根据一次匹配结果，确定远程操作人员的所在位置，根据远程操作人员的所在位置，以及第一初始设备在所述初始厂房环境模型中的所在位置，生成第二指导信息，生成去往第一初始设备的最短路径；将所述最短路径发送给所述终端，以便于所述终端根据所述最短路径和远程操作人员的实时位置，在AR设备上显示相应的行进方向。在实际应用场景下，所述厂家服务器将所述语义信息与所述初始厂房环境模型中的各初始设备进行匹配，具体包括：从语义网络中选取与各初始设备所对应的初始设备向量；计算在所述语义网络中，所述语义信息中的各个语义向量与各初始设备向量之间的距离；其中，所述语义信息包含多个语义向量，每个语义向量代表一个单词。从与相应语义向量之间的距离小于预设距离的初始设备向量中，选取其中距离最小的一个初始设备向量，该初始设备向量所对应的初始设备即为与所述语义信息匹配的操作物。所述预设距离由本领域技术人员根据经验分析得到。在一种可选的实施方式中，当在所述前方实际厂房图像中，存在多个设备，且这多个设备均与初始厂房环境模型中多个初始设备之间的轮廓相似度大于预设相似度时，可能难以区分前方实际厂房图像中的多个设备具体应对应到哪一初始设备，为了解决此问题，本发明提供了一种优选的实施方式，具体包括：当一次匹配得到存在n个实际设备与m个初始设备之间的轮廓相似度大于预设相似度时，以在初始厂房环境模型中n个初始设备之间的距离小于预设阈值作为筛选条件，对所述m个初始设备进行筛选，得到n个初始设备；所述预设阈值由本领域技术人员根据经验分析得到。按照n个实际设备在当前实际厂房中的位置分布，以及所述n个初始设备在初始厂房环境模型中的位置分布进行一对一的匹配。本实施方式是在考虑到在实际使用中，远程操作人员的观察视角有限，AR设备往往仅能够采集远程操作人员周边的图像，故在前方实际厂房图像中的多个设备必然聚集在同一区域内，即多个设备之间的距离小于预设阈值，故而根据多个设备之间的这一位置关系进行筛选，即可排除掉初始厂房环境模型中不匹配的设备，再按照多个设备之间的相对位置关系，将各实际设备与各初始设备相匹配。当一次匹配得到存在单个实际设备与多个初始设备之间的轮廓相似度大于预设相似度时，以轮廓相似度最大的一个初始设备作为与所述实际设备匹配上的第一初始设备。实施例3:如图22所示，是本发明实施例的基于AR的多人复杂交互会议装置的架构示意图。本实施例的基于AR的多人复杂交互会议装置包括一个或多个处理器21以及存储器22。其中，图22中以一个处理器21为例。处理器21和存储器22可以通过总线或者其他方式连接，图22中以通过总线连接为例。存储器22作为一种非易失性计算机可读存储介质，可用于存储非易失性软件程序和非易失性计算机可执行程序，如实施例1中的基于AR的多人复杂交互会议方法。处理器21通过运行存储在存储器22中的非易失性软件程序和指令，从而执行基于AR的多人复杂交互会议方法。存储器22可以包括高速随机存取存储器，还可以包括非易失性存储器，例如至少一个磁盘存储器件、闪存器件、或其他非易失性固态存储器件。在一些实施例中，存储器22可选包括相对于处理器21远程设置的存储器，这些远程存储器可以通过网络连接至处理器21。上述网络的实例包括但不限于互联网、企业内部网、局域网、移动通信网及其组合。所述程序指令/模块存储在所述存储器22中，当被所述一个或者多个处理器21执行时，执行上述实施例1中的基于AR的多人复杂交互会议方法。值得说明的是，上述装置和系统内的模块、单元之间的信息交互、执行过程等内容，由于与本发明的处理方法实施例基于同一构思，具体内容可参见本发明方法实施例中的叙述，此处不再赘述。本领域普通技术人员可以理解实施例的各种方法中的全部或部分步骤是可以通过程序来指令相关的硬件来完成，该程序可以存储于一计算机可读存储介质中，存储介质可以包括：只读存储器、随机存取存储器、磁盘或光盘等。以上所述仅为本发明的较佳实施例而已，并不用以限制本发明，凡在本发明的精神和原则之内所作的任何修改、等同替换和改进等，均应包含在本发明的保护范围之内。
