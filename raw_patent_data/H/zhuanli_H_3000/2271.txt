标题title
面向全局时延优化的云边端协同CNN推理方法及系统
摘要abst
本发明公开了面向全局时延优化的云边端协同CNN推理方法，通过构建训练分块推理时延预测模型、计算理论数据传输时延、构建并训练时延损耗预测模型、构建全局时延预测模型；利用全局时延预测模型计算各个边缘服务器的理论全局时延，以全局时延最小化为优化目标，决定参与协同推理的边缘服务器的选择和推理任务量的分配。本发明同时提出面向全局时延优化的云边端协同CNN推理系统。相较于传统的协同推理研究工作在时延指标制定方面仅关注当前推理任务的时延优化，本方法将处理当前推理任务对其他并行处理的推理任务可能产生的时延影响也纳入了决策考量范围，同时，本发明还提供一种CNN分割优化方法，能够有效节省协同推理中的决策时延。
权利要求书clms
1.面向全局时延优化的云边端协同CNN推理方法，其特征在于，包括如下步骤：S1、基于已训练好的并且已划分为N层CNN模型，对该N层CNN模型划分为n块：，/＞，/＞；S2、离线学习阶段：以已知的边缘服务器自身浮点计算能力/＞、正在处理的CNN块的计算复杂度、待处理的CNN块的平均计算复杂度、待处理的CNN块包含的操作层层数为输入，以对应的边缘服务器/＞计算待处理的CNN块产生的实际分块推理时延为输出，构建并训练分块推理时延预测模型；所述操作层包括卷积层、全连接层和池化层；S3、以已知的缘服务器自身的浮点计算能力、待处理的CNN块的计算复杂度、正在处理的CNN块的平均计算复杂度、正在处理的CNN块包含的操作层层数为输入，以对应的边缘服务器计算待处理的CNN块对正在处理的CNN块产生的实际时延损耗为输出，构建并训练时延损耗预测模型；S4、基于物理终端将初始图像数据处理为分辨率相同、数据量大小相等的张量数据，并将张量数据发送给与其在同一局域网内的边缘服务器；边缘服务器采集其与局域网内其他边缘服务器之间网络带宽，计算理论数据传输时延；S5、将实际的边缘服务器自身浮点计算能力、正在处理的CNN块的计算复杂度、待处理的CNN块的平均计算复杂度、待处理的CNN块包含的层数输入至步骤S2得到的分块推理时延预测模型，计算得到边缘服务器计算待处理CNN块产生的理论分块推理时延；将实际的边缘服务器自身的浮点计算能力、待处理的CNN块的计算复杂度、正在处理的CNN块的平均计算复杂度、正在处理的CNN块包含的操作层层数输入至步骤S3得到的时延损耗预测模型中，计算得到边缘服务器计算待处理的CNN块对正在处理的CNN块产生的理论时延损耗；S6、以S4得到的理论数据传输时延、步骤S5得到的边缘服务器计算待处理CNN块产生的理论分块推理时延、边缘服务器计算CNN块对正在处理的CNN块产生的理论时延损耗为输入、以边缘服务器理论全局时延为输出，构建全局时延预测模型；S7、利用全局时延预测模型计算各个边缘服务器的理论全局时延；S8、判断当前边缘服务器的理论全局时延是否小于等于其他边缘服务器的理论全局时延，是则由当前边缘服务器计算待处理的CNN块，然后执行步骤S9；否则将待处理的CNN块传输至其他边缘服务器计算，由选定的其他边缘服务器完成待处理CNN块的计算，然后执行步骤S9，完成对下一个CNN块的决策；S9、判断CNN块是否全部计算完成，是则边缘服务器将CNN块的计算结果发送给发出任务请求的物理终端，否则返回执行步骤S7，完成对下一个CNN块的决策。2.根据权利要求1所述的面向全局时延优化的云边端协同CNN推理方法，其特征在于，步骤S2中，分块推理时延预测模型如下式：，式中，是缘服务器/＞自身的浮点计算能力，/＞是自身正在处理的CNN块/＞的计算复杂度，/＞是待处理的CNN块/＞的平均计算复杂度、/＞是/＞包含的操作层层数，/＞是边缘服务器/＞计算/＞产生的理论分块推理时延输出。3.根据权利要求2所述的面向全局时延优化的云边端协同CNN推理方法，其特征在于，步骤S3中，时延损耗预测模型如下式：，式中，是边缘服务器的浮点计算能力，/＞是待处理的CNN块/＞的计算复杂度，/＞是正在处理的CNN块/＞的平均计算复杂度，/＞是正在处理的CNN块包含的操作层层数，/＞是边缘服务器/＞计算/＞对正在处理的/＞产生的理论时延损耗。4.根据权利要求3所述的面向全局时延优化的云边端协同CNN推理方法，其特征在于，步骤S4中，按如下公式计算理论数据传输时延：，式中，是张量数据，/＞是边缘服务器之间的网络带宽。5.根据权利要求4所述的面向全局时延优化的云边端协同CNN推理方法，其特征在于，步骤S6中，所述全局时延预测模型如下式：，。6.根据权利要求1所述的面向全局时延优化的云边端协同CNN推理方法，其特征在于，步骤S1中，中含有至少两个连续的张量数据，对于任一含有/＞个张量数据的/＞而言，它含有的张量数据和操作层分别为：/＞，/＞，，其中/＞的计算复杂度大于/＞中其他任意一个张量数据的计算复杂度；对于任意两个相邻的CNN块，即/＞和/＞：/＞，，/＞，/＞中的最后一个张量数据和/＞中的第一个张量数据相同。7.根据权利要求1所述的面向全局时延优化的云边端协同CNN推理方法，其特征在于，所述步骤S4中，基于物理终端将初始图像数据处理为分辨率相同、数据量大小相等的张量数据，并将张量数据发送给与其在同一局域网内的边缘服务器，具体为：初始图像数据被处理为数据量大小相同、分辨率大小相等的图像特征数据，图像特征数据作为张量数据输入/＞，/＞经过/＞中的操作层计算后，生成张量数据/＞并传入/＞，即：在/＞中，张量数据/＞经过操作层/＞的计算后，生成张量数据并传入下一个CNN块，CNN块/＞中最后一个张量数据的生成标志着CNN推理的结束。8.根据权利要求1所述的面向全局时延优化的云边端协同CNN推理方法，其特征在于，CNN块中所有操作层的计算复杂度共计为：/＞，/＞记为的计算复杂度，/＞的平均计算复杂度记为：/＞；计算包含的所有操作层所产生的分块推理时延为/＞，/＞为任一操作层的计算复杂度。9.根据权利要求8所述的面向全局时延优化的云边端协同CNN推理方法，其特征在于，CNN各个操作层的计算复杂度为：，式中，操作层为卷积层，其计算复杂度为/＞；操作层/＞为全连接层，其计算复杂度为/＞； /＞、/＞、/＞依次代表输入操作层/＞的张量数据/＞的高度、宽度、通道数，/＞代表输入操作层/＞的卷积核的边长，/＞代表输出操作层/＞的张量数据/＞的通道数，/＞、/＞分别代表输入操作层/＞的张量数据/＞的维数、输出操作层/＞的张量数据/＞的维数。10.面向全局时延优化的云边端协同CNN推理系统，其特征在于，包括：云服务器，云服务器/＞的通信范围内至少设有两个边缘服务器，所述边缘服务器部署在WIFI接入点或基站上，各边缘服务器的通信范围内至少设有一个物理终端；针对云服务器/＞通信范围内的任意一个边缘服务器/＞，边缘服务器/＞通信范围内与其物理距离小于预设距离/＞的其他/＞个边缘服务器记为：/＞，/＞，/＞，且这/＞个边缘服务器也在云服务器/＞的通信范围内，此/＞个边缘服务器同边缘服务器/＞一起组成边缘集群；所述云服务器包括：卷积神经网络、模型训练中心、通信模块；所述边缘服务器包括：态势感知中心、卷积神经网络、策略生成中心、通信模块；所述物理终端包括：通信模块；所述模型训练中心用于训练卷积神经网络、推理时延预测模型和时延损耗预测模型；所述卷积神经网络用于已经训练完备的、服务于智能应用程序的、被分割为块CNN块的/＞层CNN；所述通信模块用于云服务器、边缘服务器和物理终端之间数据发送、接收；所述态势感知中心包括工作负载感知模块和网络遥测模块；所述工作负载感知模块用于采集边缘服务器自身的浮点计算能力、自身正在负责推理的CNN块/＞的计算复杂度/＞和平均计算复杂度/＞、其他/＞个边缘服务器的浮点计算能力/＞、其他/＞个边缘服务器/＞正在负责推理的CNN块/＞的计算复杂度/＞和平均计算复杂度/＞；所述网络遥测模块用于采集边缘服务器和边缘服务器/＞间的网络带宽/＞；所述策略生成中心包括分块推理时延预测模块、传输时延计算模块、全局时延预测模块、离线样本数据存储模块和决策信息生成模块；所述分块推理时延预测模块用于以已知的边缘服务器自身浮点计算能力/＞、正在处理的CNN块的计算复杂度、待处理的CNN块的平均计算复杂度、待处理的CNN块包含的层数为输入，以对应的边缘服务器/＞计算待处理的CNN块产生的实际分块推理时延为输出，构建并训练分块推理时延预测模型；所述传输时延计算模块用于基于物理终端将图像数据处理为分辨率相同、数据量大小相等的张量数据，并将张量数据发送给与其在同一局域网内的边缘服务器；边缘服务器采集其与局域网内其他边缘服务器之间网络带宽，计算理论数据传输时延；所述全局时延预测模块用于以理论数据传输时延、边缘服务器计算待处理CNN块产生的理论分块推理时延、边缘服务器计算CNN块对正在处理的CNN块产生的理论时延损耗为输入、以边缘服务器理论全局时延为输出，构建全局时延预测模型；所述离线样本存储模块用于采集、存储边缘服务器在自身浮点计算能力为/＞、自身正在处理的CNN块/＞的计算复杂度为/＞时，计算层数为/＞层且平均计算复杂度为/＞的CNN块/＞产生的实际分块推理时延/＞；采集、存储边缘服务器/＞在自身浮点计算能力为/＞、自身正在处理的操作层层数为且平均计算复杂度为/＞的CNN块/＞时，处理计算复杂度为/＞的CNN块/＞对正在计算的/＞产生的实际时延损耗/＞；所述决策信息生成模块用于判断当前边缘服务器的理论全局时延是否小于等于其他边缘服务器的理论全局时延，是则由当前边缘服务器计算待处理的CNN块，然后判断CNN块是否全部计算完成，是则边缘服务器将CNN块的计算结果发送给发出任务请求的物理终端；否则将待处理的CNN块传输至其他边缘服务器计算，直到CNN块全部计算完成。
说明书desc
技术领域本发明属于云边端协同计算领域，具体涉及面向全局时延优化的云边端协同CNN推理方法及系统。背景技术CNN的最新进展推动了越来越多的网络边缘侧智能应用，例如智能家居、智能工厂和智能城市。要在资源受限的物理设备上部署计算密集型CNN，传统方法依赖于将推理工作卸载到远程云或在本地端设备上优化计算。然而，云辅助方法受到不可靠和延迟显著的广域网的影响，本地计算方法受限于端设备有限的计算能力。为了满足低时延和高准确率的CNN推理需求，新兴的云边端协同推理计算范式成为研究重点。然而，目前的协同推理研究工作在时延指标制定方面仅关注当前推理任务的时延优化，未考虑对其他并行处理的推理任务可能产生的时延影响。发明内容本发明所要解决的技术问题在于：针对现有的云边端协同推理计算中未考虑对其他并行处理的推理任务可能产生的时延影响问题，提供了面向全局时延优化的云边端协同CNN推理方法及系统，更好地将云服务器和边缘计算范式结合起来，充分挖掘边缘服务器的计算潜力，同时本发明提出的CNN分割优化方法，在CNN块与块之间做协同推理决策，能够有效节省协同推理中的决策时延。为解决以上技术问题，本发明提供如下技术方案：面向全局时延优化的云边端协同CNN推理方法，包括如下步骤：S1、基于已训练好的并且已划分为N层CNN模型，对该N层CNN模型划分为n块：，/＞，/＞；S2、离线学习阶段：以已知的边缘服务器自身浮点计算能力/＞、正在处理的CNN块的计算复杂度、待处理的CNN块的平均计算复杂度、待处理的CNN块包含的操作层层数为输入，以对应的边缘服务器/＞计算待处理的CNN块产生的实际分块推理时延为输出，构建并训练分块推理时延预测模型；所述操作层包括卷积层、全连接层和池化层；S3、以已知的缘服务器自身的浮点计算能力、待处理的CNN块的计算复杂度、正在处理的CNN块的平均计算复杂度、正在处理的CNN块包含的操作层层数为输入，以对应的边缘服务器计算待处理的CNN块对正在处理的CNN块产生的实际时延损耗为输出，构建并训练时延损耗预测模型；S4、基于物理终端将初始图像数据处理为分辨率相同、数据量大小相等的张量数据，并将张量数据发送给与其在同一局域网内的边缘服务器；边缘服务器采集其与局域网内其他边缘服务器之间网络带宽，计算理论数据传输时延；S5、将实际的边缘服务器自身浮点计算能力、正在处理的CNN块的计算复杂度、待处理的CNN块的平均计算复杂度、待处理的CNN块包含的层数输入至步骤S2得到的分块推理时延预测模型，计算得到边缘服务器计算待处理CNN块产生的理论分块推理时延；将实际的边缘服务器自身的浮点计算能力、待处理的CNN块的计算复杂度、正在处理的CNN块的平均计算复杂度、正在处理的CNN块包含的操作层层数输入至步骤S3得到的时延损耗预测模型中，计算得到边缘服务器计算待处理的CNN块对正在处理的CNN块产生的理论时延损耗；S6、以S4得到的理论数据传输时延、步骤S5得到的边缘服务器计算待处理CNN块产生的理论分块推理时延、边缘服务器计算CNN块对正在处理的CNN块产生的理论时延损耗为输入、以边缘服务器理论全局时延为输出，构建全局时延预测模型；S7、利用全局时延预测模型计算各个边缘服务器的理论全局时延；S8、判断当前边缘服务器的理论全局时延是否小于等于其他边缘服务器的理论全局时延，是则由当前边缘服务器计算待处理的CNN块，然后执行步骤S9；否则将待处理的CNN块传输至其他边缘服务器计算，由选定的其他边缘服务器完成待处理CNN块的计算，然后执行步骤S9，完成对下一个CNN块的决策；S9、判断CNN块是否全部计算完成，是则边缘服务器将CNN块的计算结果发送给发出任务请求的物理终端，否则返回执行步骤S7，完成对下一个CNN块的决策。进一步地，前述的步骤S2中，分块推理时延预测模型如下式：，式中，是缘服务器/＞自身的浮点计算能力，/＞是自身正在处理的CNN块/＞的计算复杂度，/＞是待处理的CNN块/＞的平均计算复杂度、/＞是/＞包含的操作层层数，/＞是边缘服务器/＞计算/＞产生的理论分块推理时延输出。进一步地，前述的步骤S3中，时延损耗预测模型如下式：，式中，是边缘服务器的浮点计算能力，/＞是待处理的CNN块/＞的计算复杂度，/＞是正在处理的CNN块/＞的平均计算复杂度，/＞是正在处理的CNN块包含的操作层层数，/＞是边缘服务器/＞计算对正在处理的/＞产生的理论时延损耗。进一步地，前述的步骤S4中，按如下公式计算理论数据传输时延：，式中，是张量数据，/＞是边缘服务器之间的网络带宽。进一步地，前述的步骤S6中，所述全局时延预测模型如下式：，。进一步地，前述的步骤S1中，中含有至少两个连续的张量数据，对于任一含有个张量数据的/＞而言，它含有的张量数据和操作层分别为：/＞，，/＞，其中/＞的计算复杂度大于/＞中其他任意一个张量数据的计算复杂度；对于任意两个相邻的CNN块，即/＞和/＞：，/＞，/＞，/＞中的最后一个张量数据和/＞中的第一个张量数据相同。进一步地，前述的步骤S4中，基于物理终端将初始图像数据处理为分辨率相同、数据量大小相等的张量数据，并将张量数据发送给与其在同一局域网内的边缘服务器，具体为：初始图像数据被处理为数据量大小相同、分辨率大小相等的图像特征数据，图像特征数据作为张量数据输入/＞，/＞经过/＞中的操作层计算后，生成张量数据并传入/＞，即：在/＞中，张量数据/＞经过操作层/＞的计算后，生成张量数据/＞并传入下一个CNN块，CNN块/＞中最后一个张量数据的生成标志着CNN推理的结束。进一步地，前述的面向全局时延优化的云边端协同CNN推理方法，CNN块中所有操作层的计算复杂度共计为：/＞，/＞记为/＞的计算复杂度，/＞的平均计算复杂度记为：/＞；计算包含的所有操作层所产生的分块推理时延为/＞，/＞为任一操作层/＞的计算复杂度。进一步地，前述的面向全局时延优化的云边端协同CNN推理方法，CNN各个操作层的计算复杂度为：，式中，操作层为卷积层，其计算复杂度为/＞；操作层/＞为全连接层，其计算复杂度为/＞； /＞、/＞、/＞依次代表输入操作层/＞的张量数据的高度、宽度、通道数，/＞代表输入操作层/＞的卷积核的边长，/＞代表输出操作层的张量数据/＞的通道数，/＞、/＞分别代表输入操作层/＞的张量数据/＞的维数、输出操作层/＞的张量数据/＞的维数。本发明另一方面提出面向全局时延优化的云边端协同CNN推理系统，包括：云服务器，云服务器/＞的通信范围内至少设有两个边缘服务器，所述边缘服务器部署在WIFI接入点或基站上，各边缘服务器的通信范围内至少设有一个物理终端；针对云服务器/＞通信范围内的任意一个边缘服务器/＞，边缘服务器/＞通信范围内与其物理距离小于预设距离的其他/＞个边缘服务器记为：/＞，/＞，/＞，且这/＞个边缘服务器也在云服务器/＞的通信范围内，此/＞个边缘服务器同边缘服务器/＞一起组成边缘集群；所述云服务器包括：卷积神经网络、模型训练中心、通信模块；所述边缘服务器包括：态势感知中心、卷积神经网络、策略生成中心、通信模块；所述物理终端包括：通信模块；所述模型训练中心用于训练卷积神经网络、推理时延预测模型和时延损耗预测模型；所述卷积神经网络用于已经训练完备的、服务于智能应用程序的、被分割为块CNN块/＞的/＞层CNN；所述通信模块用于云服务器、边缘服务器和物理终端之间数据发送、接收；所述态势感知中心包括工作负载感知模块和网络遥测模块；所述工作负载感知模块用于采集边缘服务器自身的浮点计算能力、自身正在负责推理的CNN块/＞的计算复杂度/＞和平均计算复杂度/＞、其他/＞个边缘服务器/＞的浮点计算能力/＞、其他/＞个边缘服务器/＞正在负责推理的CNN块/＞的计算复杂度/＞和平均计算复杂度/＞；所述网络遥测模块用于采集边缘服务器和边缘服务器/＞间的网络带宽/＞；所述策略生成中心包括分块推理时延预测模块、传输时延计算模块、全局时延预测模块、离线样本数据存储模块和决策信息生成模块；所述分块推理时延预测模块用于以已知的边缘服务器自身浮点计算能力/＞、正在处理的CNN块的计算复杂度、待处理的CNN块的平均计算复杂度、待处理的CNN块包含的层数为输入，以对应的边缘服务器/＞计算待处理的CNN块产生的实际分块推理时延为输出，构建并训练分块推理时延预测模型；所述传输时延计算模块用于基于物理终端将图像数据处理为分辨率相同、数据量大小相等的张量数据，并将张量数据发送给与其在同一局域网内的边缘服务器；边缘服务器采集其与局域网内其他边缘服务器之间网络带宽，计算理论数据传输时延；所述全局时延预测模块用于以理论数据传输时延、边缘服务器计算待处理CNN块产生的理论分块推理时延、边缘服务器计算CNN块对正在处理的CNN块产生的理论时延损耗为输入、以边缘服务器理论全局时延为输出，构建全局时延预测模型；所述离线样本存储模块用于采集、存储边缘服务器在自身浮点计算能力为/＞、自身正在处理的CNN块/＞的计算复杂度为/＞时，计算层数为/＞层且平均计算复杂度为/＞的CNN块/＞产生的实际分块推理时延/＞；采集、存储边缘服务器/＞在自身浮点计算能力为/＞、自身正在处理的操作层层数为且平均计算复杂度为/＞的CNN块/＞时，处理计算复杂度为/＞的CNN块/＞对正在计算的/＞产生的实际时延损耗/＞；所述决策信息生成模块用于判断当前边缘服务器的理论全局时延是否小于等于其他边缘服务器的理论全局时延，是则由当前边缘服务器计算待处理的CNN块，然后判断CNN块是否全部计算完成，是则边缘服务器将CNN块的计算结果发送给发出任务请求的物理终端；否则将待处理的CNN块传输至其他边缘服务器计算，直到CNN块全部计算完成。相较于现有技术，本发明的有益效果如下：区别于以端设备和云计算中心为主导的CNN协同推理系统，本发明通过将云服务器和边缘计算范式结合起来，其中云服务器负责模型的训练，在边缘集群内部完成CNN的协同推理工作，充分挖掘边缘服务器的计算潜力。本发明通过对CNN协同推理过程中的分块推理时延、数据传输时延和时延损耗进行理论建模，并以全局时延最小化为优化目标，决定参与协同推理的边缘服务器的选择和推理任务量的分配。相较于传统的协同推理研究工作在时延指标制定方面仅关注当前推理任务的时延优化，本发明将处理当前推理任务对其他并行处理的推理任务可能产生的时延影响也纳入了决策考量范围。同时，本发明还提供一种CNN分割优化方法，在CNN块与块之间做协同推理决策，能够有效节省协同推理中的决策时延。以边缘集群为主导的CNN协同推理工作，将计算工作放在离物理终端更近的边缘侧，可有效保证计算数据的安全性和降低网络带宽的占用率。附图说明图1为本发明的CNN分割优化原理图。图2为本发明的技术原理图。图3为本发明策略生成中心的模块组成示意图。图4为本发明的工作流程图。具体实施方式为了更了解本发明的技术内容，特举具体实施例并配合所附图式说明如下。在本发明中参照附图来描述本发明的各方面，附图中示出了许多说明性实施例。本发明的实施例不局限于附图所述。应当理解，本发明通过上面介绍的多种构思和实施例，以及下面详细描述的构思和实施方式中的任意一种来实现，这是因为本发明所公开的构思和实施例并不限于任何实施方式。另外，本发明公开的一些方面可以单独使用，或者与本发明公开的其他方面的任何适当组合来使用。结合图1，CNN为多层节构，对于一个层CNN而言，它的操作层有/＞个：，/＞，/＞，它的张量数据有/＞个：，其中张量数据/＞经过操作层/＞计算后产生张量数据/＞。CNN推理产生的时延消耗主要由计算各个操作层/＞产生的分层计算时延/＞组成。操作层/＞可分为三类：卷积层、全连接层和池化层，其中卷积层的计算复杂度最高，全连接层次之，池化层运算最简单，可以忽略。CNN各个操作层/＞的计算复杂度用下式来表示：；式中，操作层为卷积层，其计算复杂度为/＞；操作层/＞为全连接层，其计算复杂度为/＞；/＞、/＞、/＞依次代表输入操作层/＞的张量数据/＞的高度、宽度、通道数，/＞代表输入操作层/＞的卷积核的边长，/＞代表输出操作层/＞的张量数据/＞的通道数，/＞、/＞分别代表输入操作层/＞的张量数据/＞的维数、输出操作层的张量数据/＞的维数。对于一个层CNN，本发明对其进行分割优化操作并分为/＞块：，/＞，/＞。任一CNN块/＞的组成特征如下：每个中含有至少两个连续的张量数据；对于任一含有个张量数据的/＞而言，它含有的张量数据和操作层分别为：，/＞，/＞，其中/＞的计算复杂度大于中其他任意一个张量数据的计算复杂度；对于任意两个相邻的CNN块：和/＞，则/＞中的最后一个张量数据和/＞中的第一个张量数据是相同的；在具体的CNN推理过程中，初始图像数据被处理为数据量大小相同、分辨率大小相等的图像特征数据，图像特征数据作为张量数据输入/＞，/＞经过/＞中的一系列操作层计算后，生成张量数据/＞并传入/＞，即：在/＞中，张量数据经过操作层/＞的计算后，生成张量数据/＞并传入下一个CNN块，CNN块/＞中最后一个张量数据的生成标志着CNN推理的结束。CNN块中所有操作层的计算复杂度共计为/＞，/＞记为/＞的计算复杂度，/＞的平均计算复杂度记为：/＞；计算包含的所有操作层所产生的分块推理时延记为：/＞，/＞为任一操作层/＞的计算复杂度。参考图4，本发明提出的1.面向全局时延优化的云边端协同CNN推理方法，包括如下步骤：S1、基于已训练好的并且已划分为N层CNN模型，对该N层CNN模型划分为n块：，/＞，/＞；S2、离线学习阶段：以已知的边缘服务器自身浮点计算能力/＞、正在处理的CNN块的计算复杂度、待处理的CNN块的平均计算复杂度、待处理的CNN块包含的操作层层数为输入，以对应的边缘服务器/＞计算待处理的CNN块产生的实际分块推理时延为输出，构建并训练分块推理时延预测模型；所述操作层包括卷积层、全连接层和池化层；所述分块推理时延预测模型如下式：，式中，是缘服务器/＞自身的浮点计算能力，/＞是自身正在处理的CNN块/＞的计算复杂度，/＞是待处理的CNN块/＞的平均计算复杂度、/＞是/＞包含的操作层层数，/＞是边缘服务器/＞计算/＞产生的理论分块推理时延输出。S3、以已知的缘服务器自身的浮点计算能力、待处理的CNN块的计算复杂度、正在处理的CNN块的平均计算复杂度、正在处理的CNN块包含的操作层层数为输入，以对应的边缘服务器计算待处理的CNN块对正在处理的CNN块产生的实际时延损耗为输出，构建并训练时延损耗预测模型；所述时延损耗预测模型如下式：，式中，是边缘服务器的浮点计算能力，/＞是待处理的CNN块/＞的计算复杂度，/＞是正在处理的CNN块/＞的平均计算复杂度，/＞是正在处理的CNN块包含的操作层层数，/＞是边缘服务器/＞计算对正在处理的/＞产生的理论时延损耗。S4、基于物理终端将初始图像数据处理为分辨率相同、数据量大小相等的张量数据，并将张量数据发送给与其在同一局域网内的边缘服务器；边缘服务器采集其与局域网内其他边缘服务器之间网络带宽，按如下公式计算理论数据传输时延：，式中，是张量数据，/＞是边缘服务器之间的网络带宽。S5、将实际的边缘服务器自身浮点计算能力、正在处理的CNN块的计算复杂度、待处理的CNN块的平均计算复杂度、待处理的CNN块包含的层数输入至步骤S2得到的分块推理时延预测模型，计算得到边缘服务器计算待处理CNN块产生的理论分块推理时延；将实际的边缘服务器自身的浮点计算能力、待处理的CNN块的计算复杂度、正在处理的CNN块的平均计算复杂度、正在处理的CNN块包含的操作层层数输入至步骤S3得到的时延损耗预测模型中，计算得到边缘服务器计算待处理的CNN块对正在处理的CNN块产生的理论时延损耗；S6、以S4得到的理论数据传输时延、步骤S5得到的边缘服务器计算待处理CNN块产生的理论分块推理时延、边缘服务器计算CNN块对正在处理的CNN块产生的理论时延损耗为输入、以边缘服务器理论全局时延为输出，构建全局时延预测模型；所述全局时延预测模型如下式：，。S7、利用全局时延预测模型计算各个边缘服务器的理论全局时延；S8、判断当前边缘服务器的理论全局时延是否小于等于其他边缘服务器的理论全局时延，是则由当前边缘服务器计算待处理的CNN块，然后执行步骤S9；否则将待处理的CNN块传输至其他边缘服务器计算，由选定的其他边缘服务器完成待处理CNN块的计算，然后执行步骤S9，完成对下一个CNN块的决策；S9、判断CNN块是否全部计算完成，是则边缘服务器将CNN块的计算结果发送给发出任务请求的物理终端，否则返回执行步骤S7，完成对下一个CNN块的决策。本发明另一方面提出面向全局时延优化的云边端协同CNN推理系统，包括：云服务器，云服务器/＞的通信范围内至少设有两个边缘服务器，所述边缘服务器部署在WIFI接入点或基站上，各边缘服务器的通信范围内至少设有一个物理终端；针对云服务器/＞通信范围内的任意一个边缘服务器/＞，边缘服务器/＞通信范围内与其物理距离小于预设距离的其他/＞个边缘服务器记为：/＞，/＞，/＞，且这/＞个边缘服务器也在云服务器/＞的通信范围内，此/＞个边缘服务器同边缘服务器/＞一起组成边缘集群；所述云服务器包括：卷积神经网络、模型训练中心、通信模块；所述边缘服务器包括：态势感知中心、卷积神经网络、策略生成中心、通信模块；所述物理终端包括：通信模块；所述模型训练中心用于训练卷积神经网络、推理时延预测模型和时延损耗预测模型；所述卷积神经网络用于已经训练完备的、服务于智能应用程序的、被分割为块CNN块/＞的/＞层CNN；所述通信模块用于云服务器、边缘服务器和物理终端之间数据发送、接收；所述态势感知中心包括工作负载感知模块和网络遥测模块；所述工作负载感知模块用于采集边缘服务器自身的浮点计算能力、自身正在负责推理的CNN块/＞的计算复杂度/＞和平均计算复杂度/＞、其他/＞个边缘服务器/＞的浮点计算能力/＞、其他/＞个边缘服务器/＞正在负责推理的CNN块/＞的计算复杂度/＞和平均计算复杂度/＞所述网络遥测模块用于采集边缘服务器和边缘服务器/＞间的网络带宽/＞；参考图3，所述策略生成中心包括分块推理时延预测模块、传输时延计算模块、全局时延预测模块、离线样本数据存储模块和决策信息生成模块；所述分块推理时延预测模块用于以已知的边缘服务器自身浮点计算能力/＞、正在处理的CNN块的计算复杂度、待处理的CNN块的平均计算复杂度、待处理的CNN块包含的层数为输入，以对应的边缘服务器/＞计算待处理的CNN块产生的实际分块推理时延为输出，构建并训练分块推理时延预测模型；所述传输时延计算模块用于基于物理终端将图像数据处理为分辨率相同、数据量大小相等的张量数据，并将张量数据发送给与其在同一局域网内的边缘服务器；边缘服务器采集其与局域网内其他边缘服务器之间网络带宽，计算理论数据传输时延；所述全局时延预测模块用于以理论数据传输时延、边缘服务器计算待处理CNN块产生的理论分块推理时延、边缘服务器计算CNN块对正在处理的CNN块产生的理论时延损耗为输入、以边缘服务器理论全局时延为输出，构建全局时延预测模型；所述离线样本存储模块用于采集、存储边缘服务器在自身浮点计算能力为/＞、自身正在处理的CNN块/＞的计算复杂度为/＞时，计算层数为/＞层且平均计算复杂度为/＞的CNN块/＞产生的实际分块推理时延/＞；采集、存储边缘服务器/＞在自身浮点计算能力为/＞、自身正在处理的操作层层数为/＞且平均计算复杂度为/＞的CNN块/＞时，处理计算复杂度为/＞的CNN块/＞对正在计算的/＞产生的实际时延损耗/＞；所述决策信息生成模块用于判断当前边缘服务器的理论全局时延是否小于等于其他边缘服务器的理论全局时延，是则由当前边缘服务器计算待处理的CNN块，然后判断CNN块是否全部计算完成，是则边缘服务器将CNN块的计算结果发送给发出任务请求的物理终端；否则将待处理的CNN块传输至其他边缘服务器计算，直到CNN块全部计算完成。虽然本发明已以较佳实施例阐述如上，然其并非用以限定本发明。本发明所属技术领域中具有通常知识者，在不脱离本发明的精神和范围内，当可作各种的更动与润饰。因此，本发明的保护范围当视权利要求书所界定者为准。
